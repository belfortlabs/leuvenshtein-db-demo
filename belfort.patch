diff --git a/.gitignore b/.gitignore
index 9babe2bc8..7a403ab49 100644
--- a/.gitignore
+++ b/.gitignore
@@ -1,6 +1,7 @@
 target/
 .idea/
 .vscode/
+testvectors/
 
 # Path we use for internal-keycache during tests
 /keys/
@@ -34,3 +35,6 @@ package-lock.json
 
 # Dir used for backward compatibility test data
 tfhe/tfhe-backward-compat-data/
+
+# Python caches
+**/__pycache__
\ No newline at end of file
diff --git a/.gitlab-ci.yml b/.gitlab-ci.yml
new file mode 100644
index 000000000..8e845e36b
--- /dev/null
+++ b/.gitlab-ci.yml
@@ -0,0 +1,77 @@
+before_script:
+  - export RUSTUP_HOME=/tools/gitlab-runner/rust/rustup
+  - export CARGO_HOME=/tools/gitlab-runner/rust/cargo
+  - export PATH="/tools/cmake/cmake-3.30.4/bin:$PATH"
+  - source /tools/source_tools
+  - source /tools/gitlab-runner/rust/cargo/env
+
+# Define default settings
+default:
+  tags:
+    - flipflop
+
+cache:
+  key: ${CI_COMMIT_REF_SLUG}
+  paths:
+    - target/
+    - $CARGO_HOME/registry/
+
+stages:
+  - test
+  - benchmark
+
+# Reusable templates
+.reset_fpga: &reset_fpga
+  - xball xbutil reset --force
+
+# Jobs
+clippy_and_fmt:
+  stage: test
+  timeout: 1h
+  rules:
+    - if: $CI_PIPELINE_SOURCE == 'merge_request_event'
+  script:
+    - make install_rs_check_toolchain
+    - cargo clippy
+    - make check_fmt
+
+test_integer_fpga:
+  stage: test
+  rules:
+    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_TYPE == "test"
+  timeout: 1h
+  script:
+    - *reset_fpga
+    - make install_rs_build_toolchain
+    - make test_integer_fpga
+    - make test_arrays_fpga
+
+bench_integer_ops:
+  stage: benchmark
+  timeout: 8h
+  rules:
+    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_TYPE == "benchmark"
+  script:
+    - bash scripts/copy_benchmarks.sh
+    - *reset_fpga
+    - make install_rs_check_toolchain
+    - make bench_integer_fpga
+    - cp -r target/criterion/integer__fpga/* /home/benches/tfhe-rs/latest
+  artifacts:
+    paths:
+      - target/criterion/integer__fpga/*.md
+    expire_in: 1 month
+
+bench_throughput:
+  stage: benchmark
+  timeout: 1h
+  rules:
+    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_TYPE == "benchmark"
+  script:
+    - *reset_fpga
+    - make install_rs_check_toolchain
+    - make bench_fpga_throughput
+  artifacts:
+    paths:
+      - target/criterion/fpga__throughput/*.png
+    expire_in: 1 month
diff --git a/Cargo.toml b/Cargo.toml
index dd2856286..4f80cabc5 100644
--- a/Cargo.toml
+++ b/Cargo.toml
@@ -4,19 +4,19 @@ members = [
     "tfhe",
     "tfhe-fft",
     "tfhe-ntt",
-    "tfhe-zk-pok",
-    "tasks",
     "apps/trivium",
-    "tfhe-csprng",
-    "backends/tfhe-cuda-backend",
+    # "backends/tfhe-cuda-backend",
     "utils/tfhe-versionable",
     "utils/tfhe-versionable-derive",
 ]
 
 exclude = [
+    "tasks",
+    "apps/trivium",
+    "tfhe-zk-pok",
     "tfhe/backward_compatibility_tests",
     "utils/cargo-tfhe-lints-inner",
-    "utils/cargo-tfhe-lints"
+    "utils/cargo-tfhe-lints",
 ]
 [workspace.dependencies]
 aligned-vec = { version = "0.6", default-features = false }
@@ -43,6 +43,7 @@ lto = "off"
 # Compiles much faster for tests and allows reasonable performance for iterating
 [profile.devo]
 inherits = "dev"
-opt-level = 3
+opt-level = 0
 lto = "off"
 debug-assertions = false
+overflow-checks = false
diff --git a/Makefile b/Makefile
index 4c85ac43c..e1b0922f7 100644
--- a/Makefile
+++ b/Makefile
@@ -558,6 +558,38 @@ test_core_crypto_cov: install_rs_build_toolchain install_rs_check_toolchain inst
 			-p $(TFHE_SPEC) -- -Z unstable-options --report-time core_crypto::; \
 	fi
 
+# Run the internal tests of the FPGA
+# --lib            : Avoid doctests for now
+# --test-threads=1 : Sequential tests, as multiple threads cannot share FPGA
+# --show-output    : For seeing println's while executing tests
+.PHONY: test_integer_fpga
+test_integer_fpga:
+	RUSTFLAGS="$(RUSTFLAGS)" cargo $(CARGO_RS_BUILD_TOOLCHAIN) test --profile $(CARGO_PROFILE) \
+		--lib \
+		--features=fpga -p $(TFHE_SPEC) -- integer::fpga:: \
+		--test-threads=1 \
+		--show-output
+		
+.PHONY: test_integer_fpga_emulate
+test_integer_fpga_emulate:
+	RUSTFLAGS="$(RUSTFLAGS)" cargo $(CARGO_RS_BUILD_TOOLCHAIN) test --profile $(CARGO_PROFILE) \
+		--lib \
+		--features=fpga,emulate_fpga -p $(TFHE_SPEC) -- integer::fpga:: \
+		--show-output
+
+.PHONY: test_arrays_fpga # Run all the tests for high_level_api
+test_arrays_fpga: install_rs_build_toolchain
+	RUSTFLAGS="$(RUSTFLAGS)" cargo $(CARGO_RS_BUILD_TOOLCHAIN) test --profile devo \
+		--features=fpga -p $(TFHE_SPEC) \
+		-- high_level_api::array::fpga::tests \
+		--test-threads=1 \
+
+.PHONY: test_arrays_fpga_emulate # Emulate all the tests for the high_level_api
+test_arrays_fpga_emulate: install_rs_build_toolchain
+	RUSTFLAGS="$(RUSTFLAGS)" cargo $(CARGO_RS_BUILD_TOOLCHAIN) test --profile devo \
+		--features=fpga,emulate_fpga -p $(TFHE_SPEC) \
+		-- high_level_api::array::tests::unsigned_fpga  --nocapture
+
 .PHONY: test_cuda_backend # Run the internal tests of the CUDA backend
 test_cuda_backend:
 	mkdir -p "$(TFHECUDA_BUILD)" && \
@@ -598,6 +630,13 @@ test_integer_compression: install_rs_build_toolchain
 	RUSTFLAGS="$(RUSTFLAGS)" cargo $(CARGO_RS_BUILD_TOOLCHAIN) test --doc --profile $(CARGO_PROFILE) \
 		--features=integer -p $(TFHE_SPEC) -- integer::ciphertext::compress
 
+.PHONY: test_integer_compression
+test_integer_compression: install_rs_build_toolchain
+	RUSTFLAGS="$(RUSTFLAGS)" cargo $(CARGO_RS_BUILD_TOOLCHAIN) test --profile $(CARGO_PROFILE) \
+		--features=integer -p $(TFHE_SPEC) -- integer::ciphertext::compressed_ciphertext_list::tests::
+	RUSTFLAGS="$(RUSTFLAGS)" cargo $(CARGO_RS_BUILD_TOOLCHAIN) test --doc --profile $(CARGO_PROFILE) \
+		--features=integer -p $(TFHE_SPEC) -- integer::ciphertext::compress
+
 .PHONY: test_integer_compression_gpu
 test_integer_compression_gpu: install_rs_build_toolchain
 	RUSTFLAGS="$(RUSTFLAGS)" cargo $(CARGO_RS_BUILD_TOOLCHAIN) test --profile $(CARGO_PROFILE) \
@@ -805,9 +844,9 @@ test_integer_cov: install_rs_check_toolchain install_tarpaulin
 
 .PHONY: test_high_level_api # Run all the tests for high_level_api
 test_high_level_api: install_rs_build_toolchain
-	RUSTFLAGS="$(RUSTFLAGS)" cargo $(CARGO_RS_BUILD_TOOLCHAIN) test --profile $(CARGO_PROFILE) \
-		--features=boolean,shortint,integer,internal-keycache,zk-pok,strings -p $(TFHE_SPEC) \
-		-- high_level_api::
+	RUSTFLAGS="$(RUSTFLAGS)" cargo $(CARGO_RS_BUILD_TOOLCHAIN) test --profile devo \
+		--features=fpga,shortint,integer,internal-keycache -p $(TFHE_SPEC) \
+		-- high_level_api::array::tests::fpga  --nocapture
 
 test_high_level_api_gpu: install_rs_build_toolchain install_cargo_nextest
 	RUSTFLAGS="$(RUSTFLAGS)" cargo $(CARGO_RS_BUILD_TOOLCHAIN) nextest run --cargo-profile $(CARGO_PROFILE) \
@@ -1034,6 +1073,40 @@ dieharder_csprng: install_dieharder build_tfhe_csprng
 #
 # Benchmarks
 #
+.PHONY: print_doc_bench_parameters # Print parameters used in doc benchmarks
+print_doc_bench_parameters:
+	RUSTFLAGS="" cargo run --example print_doc_bench_parameters \
+	--features=shortint,internal-keycache -p tfhe
+
+.PHONY: bench_integer_fpga # Run benchmarks for integer ops on fpga
+bench_integer_fpga:
+	RUSTFLAGS="$(RUSTFLAGS)" __TFHE_RS_BENCH_OP_FLAVOR=$(BENCH_OP_FLAVOR) __TFHE_RS_FAST_BENCH=$(FAST_BENCH) \
+	cargo $(CARGO_RS_CHECK_TOOLCHAIN) bench \
+	--bench fpga-integer \
+	--features=integer,internal-keycache,boolean,shortint,fpga -p $(TFHE_SPEC) --
+	# -- --baseline base
+	python3 tfhe/benches/fpga/report_integers.py
+	python3 tfhe/benches/fpga/compare_benchmarks.py
+
+.PHONY: bench_erc20_fpga # Run benchmarks for erc20 ops on fpga
+bench_erc20_fpga:
+	RUSTFLAGS="$(RUSTFLAGS)" __TFHE_RS_BENCH_OP_FLAVOR=$(BENCH_OP_FLAVOR) __TFHE_RS_FAST_BENCH=$(FAST_BENCH) \
+	cargo $(CARGO_RS_CHECK_TOOLCHAIN) bench \
+	--bench fpga-erc20 \
+	--features=integer,internal-keycache,boolean,shortint,fpga -p $(TFHE_SPEC) --
+	
+.PHONY: bench_fpga_throughput # Run benchmarks for fpga pbs throughput
+bench_fpga_throughput:
+	RUSTFLAGS="$(RUSTFLAGS)" __TFHE_RS_BENCH_OP_FLAVOR=$(BENCH_OP_FLAVOR) __TFHE_RS_FAST_BENCH=$(FAST_BENCH) \
+	cargo $(CARGO_RS_CHECK_TOOLCHAIN) bench \
+	--bench fpga-throughput \
+	--features=internal-keycache,boolean,shortint,fpga -p $(TFHE_SPEC) --
+	python3 tfhe/benches/fpga/plot_throughput.py
+
+.PHONY: print_doc_bench_parameters # Print parameters used in doc benchmarks
+print_doc_bench_parameters:
+	RUSTFLAGS="" cargo run --example print_doc_bench_parameters \
+	--features=shortint,internal-keycache -p tfhe
 
 .PHONY: print_doc_bench_parameters # Print parameters used in doc benchmarks
 print_doc_bench_parameters:
diff --git a/README.md b/README.md
index 88d4c1076..d4f491e88 100644
--- a/README.md
+++ b/README.md
@@ -1,26 +1,15 @@
-<p align="center">
-<!-- product name logo -->
-<picture>
-  <source media="(prefers-color-scheme: dark)" srcset="https://github.com/zama-ai/tfhe-rs/assets/157474013/5283e0ba-da1e-43af-9f2a-c5221367a12b">
-  <source media="(prefers-color-scheme: light)" srcset="https://github.com/zama-ai/tfhe-rs/assets/157474013/b94a8c96-7595-400b-9311-70765c706955">
-  <img width=600 alt="Zama TFHE-rs">
-</picture>
-</p>
+# TFHE-rs
 
-<hr/>
+This repository is a fork of [tfhe-rs]() with integration of FPT. Refer to `tfhe-rs`' [README.md](./ZAMA_README.md) for more information.
 
-<p align="center">
-  <a href="https://docs.zama.ai/tfhe-rs"> ðŸ“’ Documentation</a> | <a href="https://zama.ai/community"> ðŸ’› Community support</a> | <a href="https://github.com/zama-ai/awesome-zama"> ðŸ“š FHE resources by Zama</a>
-</p>
+## Apps
 
+A number of apps have been added to profile, test, and demo FPT. Refer to [apps/README.md](./apps/README.md) for more information.
 
-<p align="center">
-  <a href="https://github.com/zama-ai/tfhe-rs/releases"><img src="https://img.shields.io/github/v/release/zama-ai/tfhe-rs?style=flat-square"></a>
-  <a href="LICENSE"><img src="https://img.shields.io/badge/License-BSD--3--Clause--Clear-%23ffb243?style=flat-square"></a>
-  <a href="https://github.com/zama-ai/bounty-program"><img src="https://img.shields.io/badge/Contribute-Zama%20Bounty%20Program-%23ffd208?style=flat-square"></a>
-</p>
 
-## About
+## Syncing with upstream
+
+To sync with an upstream version of `tfhe-rs`, run the following:
 
 ### What is TFHE-rs
 
diff --git a/ZAMA_README.md b/ZAMA_README.md
new file mode 100644
index 000000000..4614ca3fe
--- /dev/null
+++ b/ZAMA_README.md
@@ -0,0 +1,256 @@
+### What is TFHE-rs
+
+**TFHE-rs** is a pure Rust implementation of TFHE for boolean and integer arithmetics over encrypted data.
+
+It includes:
+- a **Rust** API
+- a **C** API
+- and a **client-side WASM** API
+
+TFHE-rs is designed for developers and researchers who want full control over
+what they can do with TFHE, while not having to worry about the low-level
+implementation. The goal is to have a stable, simple, high-performance, and
+production-ready library for all the advanced features of TFHE.
+<br></br>
+
+### Main features
+
+- **Low-level cryptographic library** that implements Zamaâ€™s variant of TFHE, including programmable bootstrapping
+- **Implementation of the original TFHE boolean API** that can be used as a drop-in replacement for other TFHE libraries
+- **Short integer API** that enables exact, unbounded FHE integer arithmetics with up to 8 bits of message space
+- **Size-efficient public key encryption**
+- **Ciphertext and server key compression** for efficient data transfer
+- **Full Rust API, C bindings to the Rust High-Level API, and client-side Javascript API using WASM**.
+
+*Learn more about TFHE-rs features in the [documentation](https://docs.zama.ai/tfhe-rs/readme).*
+<br></br>
+
+## Table of Contents
+- **[Getting started](#getting-started)**
+   - [Cargo.toml configuration](#cargotoml-configuration)
+   - [A simple example](#a-simple-example)
+- **[Resources](#resources)**
+   - [TFHE deep dive](#tfhe-deep-dive)
+   - [Tutorials](#tutorials)
+   - [Documentation](#documentation)
+- **[Working with TFHE-rs](#working-with-tfhe-rs)**
+   - [Disclaimers](#disclaimers)
+   - [Citations](#citations)
+   - [Contributing](#contributing)
+   - [License](#license)
+- **[Support](#support)**
+<br></br>
+
+## Getting started
+
+### Cargo.toml configuration
+To use the latest version of `TFHE-rs` in your project, you first need to add it as a dependency in your `Cargo.toml`:
+
++ For x86_64-based machines running Unix-like OSes:
+
+```toml
+tfhe = { version = "*", features = ["boolean", "shortint", "integer", "x86_64-unix"] }
+```
+
++ For Apple Silicon or aarch64-based machines running Unix-like OSes:
+
+```toml
+tfhe = { version = "*", features = ["boolean", "shortint", "integer", "aarch64-unix"] }
+```
+
++ For x86_64-based machines with the [`rdseed instruction`](https://en.wikipedia.org/wiki/RDRAND) running Windows:
+
+```toml
+tfhe = { version = "*", features = ["boolean", "shortint", "integer", "x86_64"] }
+```
+
+> [!Note]
+> Note: You need to use a Rust version >= 1.73 to compile TFHE-rs.
+
+> [!Note]
+> Note: aarch64-based machines are not yet supported for Windows as it's currently missing an entropy source to be able to seed the [CSPRNGs](https://en.wikipedia.org/wiki/Cryptographically_secure_pseudorandom_number_generator) used in TFHE-rs.
+
+<p align="right">
+  <a href="#about" > â†‘ Back to top </a> 
+</p>
+
+### A simple example
+
+Here is a full example:
+
+``` rust
+use tfhe::prelude::*;
+use tfhe::{generate_keys, set_server_key, ConfigBuilder, FheUint32, FheUint8};
+
+fn main() -> Result<(), Box<dyn std::error::Error>> {
+    // Basic configuration to use homomorphic integers
+    let config = ConfigBuilder::default().build();
+
+    // Key generation
+    let (client_key, server_keys) = generate_keys(config);
+
+    let clear_a = 1344u32;
+    let clear_b = 5u32;
+    let clear_c = 7u8;
+
+    // Encrypting the input data using the (private) client_key
+    // FheUint32: Encrypted equivalent to u32
+    let mut encrypted_a = FheUint32::try_encrypt(clear_a, &client_key)?;
+    let encrypted_b = FheUint32::try_encrypt(clear_b, &client_key)?;
+
+    // FheUint8: Encrypted equivalent to u8
+    let encrypted_c = FheUint8::try_encrypt(clear_c, &client_key)?;
+
+    // On the server side:
+    set_server_key(server_keys);
+
+    // Clear equivalent computations: 1344 * 5 = 6720
+    let encrypted_res_mul = &encrypted_a * &encrypted_b;
+
+    // Clear equivalent computations: 6720 >> 5 = 210
+    encrypted_a = &encrypted_res_mul >> &encrypted_b;
+
+    // Clear equivalent computations: let casted_a = a as u8;
+    let casted_a: FheUint8 = encrypted_a.cast_into();
+
+    // Clear equivalent computations: min(210, 7) = 7
+    let encrypted_res_min = &casted_a.min(&encrypted_c);
+
+    // Operation between clear and encrypted data:
+    // Clear equivalent computations: 7 & 1 = 1
+    let encrypted_res = encrypted_res_min & 1_u8;
+
+    // Decrypting on the client side:
+    let clear_res: u8 = encrypted_res.decrypt(&client_key);
+    assert_eq!(clear_res, 1_u8);
+
+    Ok(())
+}
+```
+
+To run this code, use the following command: 
+<p align="center"> <code> cargo run --release </code> </p>
+
+> [!Note]
+> Note that when running code that uses `TFHE-rs`, it is highly recommended
+to run in release mode with cargo's `--release` flag to have the best performances possible.
+
+*Find an example with more explanations in [this part of the documentation](https://docs.zama.ai/tfhe-rs/get-started/quick_start)*
+
+<p align="right">
+  <a href="#about" > â†‘ Back to top </a> 
+</p>
+
+
+
+## Resources 
+
+### TFHE deep dive
+- [TFHE Deep Dive - Part I - Ciphertext types](https://www.zama.ai/post/tfhe-deep-dive-part-1)
+- [TFHE Deep Dive - Part II - Encodings and linear leveled operations](https://www.zama.ai/post/tfhe-deep-dive-part-2)
+- [TFHE Deep Dive - Part III - Key switching and leveled multiplications](https://www.zama.ai/post/tfhe-deep-dive-part-3)
+- [TFHE Deep Dive - Part IV - Programmable Bootstrapping](https://www.zama.ai/post/tfhe-deep-dive-part-4)
+<br></br>
+
+### Tutorials
+- [[Video tutorial] Implement signed integers using TFHE-rs ](https://www.zama.ai/post/video-tutorial-implement-signed-integers-ssing-tfhe-rs)
+- [Homomorphic parity bit](https://docs.zama.ai/tfhe-rs/tutorials/parity_bit)
+- [Homomorphic case changing on Ascii string](https://docs.zama.ai/tfhe-rs/tutorials/ascii_fhe_string)
+- [Boolean SHA256 with TFHE-rs](https://www.zama.ai/post/boolean-sha256-tfhe-rs)
+- [Dark market with TFHE-rs](https://www.zama.ai/post/dark-market-tfhe-rs)
+- [Regular expression engine with TFHE-rs](https://www.zama.ai/post/regex-engine-tfhe-rs)
+
+*Explore more useful resources in [TFHE-rs tutorials](https://docs.zama.ai/tfhe-rs/tutorials) and [Awesome Zama repo](https://github.com/zama-ai/awesome-zama)*
+<br></br>
+### Documentation
+
+Full, comprehensive documentation is available here: [https://docs.zama.ai/tfhe-rs](https://docs.zama.ai/tfhe-rs).
+<p align="right">
+  <a href="#about" > â†‘ Back to top </a> 
+</p>
+
+
+## Working with TFHE-rs
+
+### Disclaimers
+
+#### Security estimation
+
+Security estimations are done using the
+[Lattice Estimator](https://github.com/malb/lattice-estimator)
+with `red_cost_model = reduction.RC.BDGL16`.
+
+When a new update is published in the Lattice Estimator, we update parameters accordingly.
+
+### Security model
+
+The default parameters for the TFHE-rs library are chosen considering the IND-CPA security model, and are selected with a bootstrapping failure probability fixed at p_error = $2^{-64}$. In particular, it is assumed that the results of decrypted computations are not shared by the secret key owner with any third parties, as such an action can lead to leakage of the secret encryption key. If you are designing an application where decryptions must be shared, you will need to craft custom encryption parameters which are chosen in consideration of the IND-CPA^D security model [1]. 
+
+[1] Li, Baiyu, et al. "Securing approximate homomorphic encryption using differential privacy." Annual International Cryptology Conference. Cham: Springer Nature Switzerland, 2022. https://eprint.iacr.org/2022/816.pdf
+
+#### Side-channel attacks
+
+Mitigation for side-channel attacks has not yet been implemented in TFHE-rs,
+and will be released in upcoming versions.
+<br></br>
+
+### Citations
+To cite TFHE-rs in academic papers, please use the following entry:
+
+```text
+@Misc{TFHE-rs,
+  title={{TFHE-rs: A Pure Rust Implementation of the TFHE Scheme for Boolean and Integer Arithmetics Over Encrypted Data}},
+  author={Zama},
+  year={2022},
+  note={\url{https://github.com/zama-ai/tfhe-rs}},
+}
+```
+
+### Contributing
+
+There are two ways to contribute to TFHE-rs:
+
+- [Open issues](https://github.com/zama-ai/tfhe-rs/issues/new/choose) to report bugs and typos, or to suggest new ideas
+- Request to become an official contributor by emailing [hello@zama.ai](mailto:hello@zama.ai).
+
+Becoming an approved contributor involves signing our Contributor License Agreement (CLA). Only approved contributors can send pull requests, so please make sure to get in touch before you do!
+<br></br>
+
+### License
+This software is distributed under the **BSD-3-Clause-Clear** license. Read [this](LICENSE) for more details.
+
+#### FAQ
+**Is Zamaâ€™s technology free to use?**
+>Zamaâ€™s libraries are free to use under the BSD 3-Clause Clear license only for development, research, prototyping, and experimentation purposes. However, for any commercial use of Zama's open source code, companies must purchase Zamaâ€™s commercial patent license.
+>
+>Everything we do is open source and we are very transparent on what it means for our users, you can read more about how we monetize our open source products at Zama in [this blogpost](https://www.zama.ai/post/open-source).
+
+**What do I need to do if I want to use Zamaâ€™s technology for commercial purposes?**
+>To commercially use Zamaâ€™s technology you need to be granted Zamaâ€™s patent license. Please contact us hello@zama.ai for more information.
+
+**Do you file IP on your technology?**
+>Yes, all Zamaâ€™s technologies are patented.
+
+**Can you customize a solution for my specific use case?**
+>We are open to collaborating and advancing the FHE space with our partners. If you have specific needs, please email us at hello@zama.ai.
+
+<p align="right">
+  <a href="#about" > â†‘ Back to top </a> 
+</p>
+
+
+## Support
+
+<a target="_blank" href="https://community.zama.ai">
+<picture>
+  <source media="(prefers-color-scheme: dark)" srcset="https://github.com/zama-ai/tfhe-rs/assets/157474013/08656d0a-3f44-4126-b8b6-8c601dff5380">
+  <source media="(prefers-color-scheme: light)" srcset="https://github.com/zama-ai/tfhe-rs/assets/157474013/1c9c9308-50ac-4aab-a4b9-469bb8c536a4">
+  <img alt="Support">
+</picture>
+</a>
+
+ðŸŒŸ If you find this project helpful or interesting, please consider giving it a star on GitHub! Your support helps to grow the community and motivates further development. 
+
+<p align="right">
+  <a href="#about" > â†‘ Back to top </a> 
+</p>
\ No newline at end of file
diff --git a/backends/tfhe-cuda-backend/cuda/include/ciphertext.h b/backends/tfhe-cuda-backend/cuda/include/ciphertext.h
index b3978834a..8101e4404 100644
--- a/backends/tfhe-cuda-backend/cuda/include/ciphertext.h
+++ b/backends/tfhe-cuda-backend/cuda/include/ciphertext.h
@@ -3,22 +3,23 @@
 
 #include "stdint.h"
 
-extern "C" {
-void cuda_convert_lwe_ciphertext_vector_to_gpu_64(void *stream,
-                                                  uint32_t gpu_index,
-                                                  void *dest, void const *src,
-                                                  uint32_t number_of_cts,
-                                                  uint32_t lwe_dimension);
-void cuda_convert_lwe_ciphertext_vector_to_cpu_64(void *stream,
-                                                  uint32_t gpu_index,
-                                                  void *dest, void const *src,
-                                                  uint32_t number_of_cts,
-                                                  uint32_t lwe_dimension);
+extern "C"
+{
+    void cuda_convert_lwe_ciphertext_vector_to_gpu_64(void *stream,
+                                                      uint32_t gpu_index,
+                                                      void *dest, void const *src,
+                                                      uint32_t number_of_cts,
+                                                      uint32_t lwe_dimension);
+    void cuda_convert_lwe_ciphertext_vector_to_cpu_64(void *stream,
+                                                      uint32_t gpu_index,
+                                                      void *dest, void const *src,
+                                                      uint32_t number_of_cts,
+                                                      uint32_t lwe_dimension);
 
-void cuda_glwe_sample_extract_64(void *stream, uint32_t gpu_index,
-                                 void *lwe_array_out, void const *glwe_array_in,
-                                 uint32_t const *nth_array, uint32_t num_nths,
-                                 uint32_t glwe_dimension,
-                                 uint32_t polynomial_size);
+    void cuda_glwe_sample_extract_64(void *stream, uint32_t gpu_index,
+                                     void *lwe_array_out, void const *glwe_array_in,
+                                     uint32_t const *nth_array, uint32_t num_nths,
+                                     uint32_t glwe_dimension,
+                                     uint32_t polynomial_size);
 }
 #endif
diff --git a/backends/tfhe-cuda-backend/cuda/include/integer/compression/compression_utilities.h b/backends/tfhe-cuda-backend/cuda/include/integer/compression/compression_utilities.h
index b3ab0acef..e5a358f46 100644
--- a/backends/tfhe-cuda-backend/cuda/include/integer/compression/compression_utilities.h
+++ b/backends/tfhe-cuda-backend/cuda/include/integer/compression/compression_utilities.h
@@ -3,132 +3,143 @@
 
 #include "../integer_utilities.h"
 
-template <typename Torus> struct int_compression {
-  int_radix_params compression_params;
-  uint32_t storage_log_modulus;
-  uint32_t lwe_per_glwe;
-
-  uint32_t body_count;
-
-  // Compression
-  int8_t *fp_ks_buffer;
-  Torus *tmp_lwe;
-  Torus *tmp_glwe_array_out;
-
-  int_compression(cudaStream_t const *streams, uint32_t const *gpu_indexes,
-                  uint32_t gpu_count, int_radix_params compression_params,
-                  uint32_t num_radix_blocks, uint32_t lwe_per_glwe,
-                  uint32_t storage_log_modulus, bool allocate_gpu_memory) {
-    this->compression_params = compression_params;
-    this->lwe_per_glwe = lwe_per_glwe;
-    this->storage_log_modulus = storage_log_modulus;
-    this->body_count = num_radix_blocks;
-
-    if (allocate_gpu_memory) {
-      Torus glwe_accumulator_size = (compression_params.glwe_dimension + 1) *
-                                    compression_params.polynomial_size;
-
-      tmp_lwe = (Torus *)cuda_malloc_async(
-          num_radix_blocks * (compression_params.small_lwe_dimension + 1) *
-              sizeof(Torus),
-          streams[0], gpu_indexes[0]);
-      tmp_glwe_array_out = (Torus *)cuda_malloc_async(
-          lwe_per_glwe * glwe_accumulator_size * sizeof(Torus), streams[0],
-          gpu_indexes[0]);
-
-      scratch_packing_keyswitch_lwe_list_to_glwe_64(
-          streams[0], gpu_indexes[0], &fp_ks_buffer,
-          compression_params.small_lwe_dimension,
-          compression_params.glwe_dimension, compression_params.polynomial_size,
-          num_radix_blocks, true);
+template <typename Torus>
+struct int_compression
+{
+    int_radix_params compression_params;
+    uint32_t storage_log_modulus;
+    uint32_t lwe_per_glwe;
+
+    uint32_t body_count;
+
+    // Compression
+    int8_t *fp_ks_buffer;
+    Torus *tmp_lwe;
+    Torus *tmp_glwe_array_out;
+
+    int_compression(cudaStream_t const *streams, uint32_t const *gpu_indexes,
+                    uint32_t gpu_count, int_radix_params compression_params,
+                    uint32_t num_radix_blocks, uint32_t lwe_per_glwe,
+                    uint32_t storage_log_modulus, bool allocate_gpu_memory)
+    {
+        this->compression_params = compression_params;
+        this->lwe_per_glwe = lwe_per_glwe;
+        this->storage_log_modulus = storage_log_modulus;
+        this->body_count = num_radix_blocks;
+
+        if (allocate_gpu_memory)
+        {
+            Torus glwe_accumulator_size = (compression_params.glwe_dimension + 1) *
+                                          compression_params.polynomial_size;
+
+            tmp_lwe = (Torus *)cuda_malloc_async(
+                num_radix_blocks * (compression_params.small_lwe_dimension + 1) *
+                    sizeof(Torus),
+                streams[0], gpu_indexes[0]);
+            tmp_glwe_array_out = (Torus *)cuda_malloc_async(
+                lwe_per_glwe * glwe_accumulator_size * sizeof(Torus), streams[0],
+                gpu_indexes[0]);
+
+            scratch_packing_keyswitch_lwe_list_to_glwe_64(
+                streams[0], gpu_indexes[0], &fp_ks_buffer,
+                compression_params.small_lwe_dimension,
+                compression_params.glwe_dimension, compression_params.polynomial_size,
+                num_radix_blocks, true);
+        }
+    }
+    void release(cudaStream_t const *streams, uint32_t const *gpu_indexes,
+                 uint32_t gpu_count)
+    {
+        cuda_drop_async(tmp_lwe, streams[0], gpu_indexes[0]);
+        cuda_drop_async(tmp_glwe_array_out, streams[0], gpu_indexes[0]);
+        cleanup_packing_keyswitch_lwe_list_to_glwe(streams[0], gpu_indexes[0],
+                                                   &fp_ks_buffer);
     }
-  }
-  void release(cudaStream_t const *streams, uint32_t const *gpu_indexes,
-               uint32_t gpu_count) {
-    cuda_drop_async(tmp_lwe, streams[0], gpu_indexes[0]);
-    cuda_drop_async(tmp_glwe_array_out, streams[0], gpu_indexes[0]);
-    cleanup_packing_keyswitch_lwe_list_to_glwe(streams[0], gpu_indexes[0],
-                                               &fp_ks_buffer);
-  }
 };
 
-template <typename Torus> struct int_decompression {
-  int_radix_params encryption_params;
-  int_radix_params compression_params;
-
-  uint32_t storage_log_modulus;
-
-  uint32_t num_radix_blocks;
-  uint32_t body_count;
-
-  Torus *tmp_extracted_glwe;
-  Torus *tmp_extracted_lwe;
-  uint32_t *tmp_indexes_array;
-
-  int_radix_lut<Torus> *decompression_rescale_lut;
-
-  int_decompression(cudaStream_t const *streams, uint32_t const *gpu_indexes,
-                    uint32_t gpu_count, int_radix_params encryption_params,
-                    int_radix_params compression_params,
-                    uint32_t num_radix_blocks, uint32_t body_count,
-                    uint32_t storage_log_modulus, bool allocate_gpu_memory) {
-    this->encryption_params = encryption_params;
-    this->compression_params = compression_params;
-    this->storage_log_modulus = storage_log_modulus;
-    this->num_radix_blocks = num_radix_blocks;
-    this->body_count = body_count;
-
-    if (allocate_gpu_memory) {
-      Torus glwe_accumulator_size = (compression_params.glwe_dimension + 1) *
-                                    compression_params.polynomial_size;
-      Torus lwe_accumulator_size = (compression_params.glwe_dimension *
-                                        compression_params.polynomial_size +
-                                    1);
-      decompression_rescale_lut = new int_radix_lut<Torus>(
-          streams, gpu_indexes, gpu_count, encryption_params, 1,
-          num_radix_blocks, allocate_gpu_memory);
-
-      tmp_extracted_glwe = (Torus *)cuda_malloc_async(
-          num_radix_blocks * glwe_accumulator_size * sizeof(Torus), streams[0],
-          gpu_indexes[0]);
-      tmp_indexes_array = (uint32_t *)cuda_malloc_async(
-          num_radix_blocks * sizeof(uint32_t), streams[0], gpu_indexes[0]);
-      tmp_extracted_lwe = (Torus *)cuda_malloc_async(
-          num_radix_blocks * lwe_accumulator_size * sizeof(Torus), streams[0],
-          gpu_indexes[0]);
-
-      // Rescale is done using an identity LUT
-      // Here we do not divide by message_modulus
-      // Example: in the 2_2 case we are mapping a 2 bits message onto a 4 bits
-      // space, we want to keep the original 2 bits value in the 4 bits space,
-      // so we apply the identity and the encoding will rescale it for us.
-      auto decompression_rescale_f = [encryption_params](Torus x) -> Torus {
-        return x;
-      };
-
-      auto effective_compression_message_modulus =
-          encryption_params.carry_modulus;
-      auto effective_compression_carry_modulus = 1;
-
-      generate_device_accumulator_with_encoding<Torus>(
-          streams[0], gpu_indexes[0], decompression_rescale_lut->get_lut(0, 0),
-          encryption_params.glwe_dimension, encryption_params.polynomial_size,
-          effective_compression_message_modulus,
-          effective_compression_carry_modulus,
-          encryption_params.message_modulus, encryption_params.carry_modulus,
-          decompression_rescale_f);
-
-      decompression_rescale_lut->broadcast_lut(streams, gpu_indexes, 0);
+template <typename Torus>
+struct int_decompression
+{
+    int_radix_params encryption_params;
+    int_radix_params compression_params;
+
+    uint32_t storage_log_modulus;
+
+    uint32_t num_radix_blocks;
+    uint32_t body_count;
+
+    Torus *tmp_extracted_glwe;
+    Torus *tmp_extracted_lwe;
+    uint32_t *tmp_indexes_array;
+
+    int_radix_lut<Torus> *decompression_rescale_lut;
+
+    int_decompression(cudaStream_t const *streams, uint32_t const *gpu_indexes,
+                      uint32_t gpu_count, int_radix_params encryption_params,
+                      int_radix_params compression_params,
+                      uint32_t num_radix_blocks, uint32_t body_count,
+                      uint32_t storage_log_modulus, bool allocate_gpu_memory)
+    {
+        this->encryption_params = encryption_params;
+        this->compression_params = compression_params;
+        this->storage_log_modulus = storage_log_modulus;
+        this->num_radix_blocks = num_radix_blocks;
+        this->body_count = body_count;
+
+        if (allocate_gpu_memory)
+        {
+            Torus glwe_accumulator_size = (compression_params.glwe_dimension + 1) *
+                                          compression_params.polynomial_size;
+            Torus lwe_accumulator_size = (compression_params.glwe_dimension *
+                                              compression_params.polynomial_size +
+                                          1);
+            decompression_rescale_lut = new int_radix_lut<Torus>(
+                streams, gpu_indexes, gpu_count, encryption_params, 1,
+                num_radix_blocks, allocate_gpu_memory);
+
+            tmp_extracted_glwe = (Torus *)cuda_malloc_async(
+                num_radix_blocks * glwe_accumulator_size * sizeof(Torus), streams[0],
+                gpu_indexes[0]);
+            tmp_indexes_array = (uint32_t *)cuda_malloc_async(
+                num_radix_blocks * sizeof(uint32_t), streams[0], gpu_indexes[0]);
+            tmp_extracted_lwe = (Torus *)cuda_malloc_async(
+                num_radix_blocks * lwe_accumulator_size * sizeof(Torus), streams[0],
+                gpu_indexes[0]);
+
+            // Rescale is done using an identity LUT
+            // Here we do not divide by message_modulus
+            // Example: in the 2_2 case we are mapping a 2 bits message onto a 4 bits
+            // space, we want to keep the original 2 bits value in the 4 bits space,
+            // so we apply the identity and the encoding will rescale it for us.
+            auto decompression_rescale_f = [encryption_params](Torus x) -> Torus
+            {
+                return x;
+            };
+
+            auto effective_compression_message_modulus =
+                encryption_params.carry_modulus;
+            auto effective_compression_carry_modulus = 1;
+
+            generate_device_accumulator_with_encoding<Torus>(
+                streams[0], gpu_indexes[0], decompression_rescale_lut->get_lut(0, 0),
+                encryption_params.glwe_dimension, encryption_params.polynomial_size,
+                effective_compression_message_modulus,
+                effective_compression_carry_modulus,
+                encryption_params.message_modulus, encryption_params.carry_modulus,
+                decompression_rescale_f);
+
+            decompression_rescale_lut->broadcast_lut(streams, gpu_indexes, 0);
+        }
+    }
+    void release(cudaStream_t const *streams, uint32_t const *gpu_indexes,
+                 uint32_t gpu_count)
+    {
+        cuda_drop_async(tmp_extracted_glwe, streams[0], gpu_indexes[0]);
+        cuda_drop_async(tmp_extracted_lwe, streams[0], gpu_indexes[0]);
+        cuda_drop_async(tmp_indexes_array, streams[0], gpu_indexes[0]);
+
+        decompression_rescale_lut->release(streams, gpu_indexes, gpu_count);
+        delete decompression_rescale_lut;
     }
-  }
-  void release(cudaStream_t const *streams, uint32_t const *gpu_indexes,
-               uint32_t gpu_count) {
-    cuda_drop_async(tmp_extracted_glwe, streams[0], gpu_indexes[0]);
-    cuda_drop_async(tmp_extracted_lwe, streams[0], gpu_indexes[0]);
-    cuda_drop_async(tmp_indexes_array, streams[0], gpu_indexes[0]);
-
-    decompression_rescale_lut->release(streams, gpu_indexes, gpu_count);
-    delete decompression_rescale_lut;
-  }
 };
 #endif
diff --git a/backends/tfhe-cuda-backend/cuda/src/crypto/ciphertext.cu b/backends/tfhe-cuda-backend/cuda/src/crypto/ciphertext.cu
index 90d1ca35f..75a2da2c9 100644
--- a/backends/tfhe-cuda-backend/cuda/src/crypto/ciphertext.cu
+++ b/backends/tfhe-cuda-backend/cuda/src/crypto/ciphertext.cu
@@ -5,73 +5,77 @@ void cuda_convert_lwe_ciphertext_vector_to_gpu_64(void *stream,
                                                   uint32_t gpu_index,
                                                   void *dest, void *src,
                                                   uint32_t number_of_cts,
-                                                  uint32_t lwe_dimension) {
-  cuda_convert_lwe_ciphertext_vector_to_gpu<uint64_t>(
-      static_cast<cudaStream_t>(stream), gpu_index, (uint64_t *)dest,
-      (uint64_t *)src, number_of_cts, lwe_dimension);
+                                                  uint32_t lwe_dimension)
+{
+        cuda_convert_lwe_ciphertext_vector_to_gpu<uint64_t>(
+            static_cast<cudaStream_t>(stream), gpu_index, (uint64_t *)dest,
+            (uint64_t *)src, number_of_cts, lwe_dimension);
 }
 
 void cuda_convert_lwe_ciphertext_vector_to_cpu_64(void *stream,
                                                   uint32_t gpu_index,
                                                   void *dest, void *src,
                                                   uint32_t number_of_cts,
-                                                  uint32_t lwe_dimension) {
-  cuda_convert_lwe_ciphertext_vector_to_cpu<uint64_t>(
-      static_cast<cudaStream_t>(stream), gpu_index, (uint64_t *)dest,
-      (uint64_t *)src, number_of_cts, lwe_dimension);
+                                                  uint32_t lwe_dimension)
+{
+        cuda_convert_lwe_ciphertext_vector_to_cpu<uint64_t>(
+            static_cast<cudaStream_t>(stream), gpu_index, (uint64_t *)dest,
+            (uint64_t *)src, number_of_cts, lwe_dimension);
 }
 
 void cuda_glwe_sample_extract_64(void *stream, uint32_t gpu_index,
                                  void *lwe_array_out, void const *glwe_array_in,
                                  uint32_t const *nth_array, uint32_t num_nths,
                                  uint32_t glwe_dimension,
-                                 uint32_t polynomial_size) {
+                                 uint32_t polynomial_size)
+{
 
-  switch (polynomial_size) {
-  case 256:
-    host_sample_extract<uint64_t, AmortizedDegree<256>>(
-        static_cast<cudaStream_t>(stream), gpu_index, (uint64_t *)lwe_array_out,
-        (uint64_t const *)glwe_array_in, (uint32_t const *)nth_array, num_nths,
-        glwe_dimension);
-    break;
-  case 512:
-    host_sample_extract<uint64_t, AmortizedDegree<512>>(
-        static_cast<cudaStream_t>(stream), gpu_index, (uint64_t *)lwe_array_out,
-        (uint64_t const *)glwe_array_in, (uint32_t const *)nth_array, num_nths,
-        glwe_dimension);
-    break;
-  case 1024:
-    host_sample_extract<uint64_t, AmortizedDegree<1024>>(
-        static_cast<cudaStream_t>(stream), gpu_index, (uint64_t *)lwe_array_out,
-        (uint64_t const *)glwe_array_in, (uint32_t const *)nth_array, num_nths,
-        glwe_dimension);
-    break;
-  case 2048:
-    host_sample_extract<uint64_t, AmortizedDegree<2048>>(
-        static_cast<cudaStream_t>(stream), gpu_index, (uint64_t *)lwe_array_out,
-        (uint64_t const *)glwe_array_in, (uint32_t const *)nth_array, num_nths,
-        glwe_dimension);
-    break;
-  case 4096:
-    host_sample_extract<uint64_t, AmortizedDegree<4096>>(
-        static_cast<cudaStream_t>(stream), gpu_index, (uint64_t *)lwe_array_out,
-        (uint64_t const *)glwe_array_in, (uint32_t const *)nth_array, num_nths,
-        glwe_dimension);
-    break;
-  case 8192:
-    host_sample_extract<uint64_t, AmortizedDegree<8192>>(
-        static_cast<cudaStream_t>(stream), gpu_index, (uint64_t *)lwe_array_out,
-        (uint64_t const *)glwe_array_in, (uint32_t const *)nth_array, num_nths,
-        glwe_dimension);
-    break;
-  case 16384:
-    host_sample_extract<uint64_t, AmortizedDegree<16384>>(
-        static_cast<cudaStream_t>(stream), gpu_index, (uint64_t *)lwe_array_out,
-        (uint64_t const *)glwe_array_in, (uint32_t const *)nth_array, num_nths,
-        glwe_dimension);
-    break;
-  default:
-    PANIC("Cuda error: unsupported polynomial size. Supported "
-          "N's are powers of two in the interval [256..16384].")
-  }
+        switch (polynomial_size)
+        {
+        case 256:
+                host_sample_extract<uint64_t, AmortizedDegree<256>>(
+                    static_cast<cudaStream_t>(stream), gpu_index, (uint64_t *)lwe_array_out,
+                    (uint64_t const *)glwe_array_in, (uint32_t const *)nth_array, num_nths,
+                    glwe_dimension);
+                break;
+        case 512:
+                host_sample_extract<uint64_t, AmortizedDegree<512>>(
+                    static_cast<cudaStream_t>(stream), gpu_index, (uint64_t *)lwe_array_out,
+                    (uint64_t const *)glwe_array_in, (uint32_t const *)nth_array, num_nths,
+                    glwe_dimension);
+                break;
+        case 1024:
+                host_sample_extract<uint64_t, AmortizedDegree<1024>>(
+                    static_cast<cudaStream_t>(stream), gpu_index, (uint64_t *)lwe_array_out,
+                    (uint64_t const *)glwe_array_in, (uint32_t const *)nth_array, num_nths,
+                    glwe_dimension);
+                break;
+        case 2048:
+                host_sample_extract<uint64_t, AmortizedDegree<2048>>(
+                    static_cast<cudaStream_t>(stream), gpu_index, (uint64_t *)lwe_array_out,
+                    (uint64_t const *)glwe_array_in, (uint32_t const *)nth_array, num_nths,
+                    glwe_dimension);
+                break;
+        case 4096:
+                host_sample_extract<uint64_t, AmortizedDegree<4096>>(
+                    static_cast<cudaStream_t>(stream), gpu_index, (uint64_t *)lwe_array_out,
+                    (uint64_t const *)glwe_array_in, (uint32_t const *)nth_array, num_nths,
+                    glwe_dimension);
+                break;
+        case 8192:
+                host_sample_extract<uint64_t, AmortizedDegree<8192>>(
+                    static_cast<cudaStream_t>(stream), gpu_index, (uint64_t *)lwe_array_out,
+                    (uint64_t const *)glwe_array_in, (uint32_t const *)nth_array, num_nths,
+                    glwe_dimension);
+                break;
+        case 16384:
+                host_sample_extract<uint64_t, AmortizedDegree<16384>>(
+                    static_cast<cudaStream_t>(stream), gpu_index, (uint64_t *)lwe_array_out,
+                    (uint64_t const *)glwe_array_in, (uint32_t const *)nth_array, num_nths,
+                    glwe_dimension);
+                break;
+        default:
+                PANIC("Cuda error: unsupported polynomial size. Supported "
+                      "N's are powers of two in the interval [256..16384].")
+        }
 }
diff --git a/backends/tfhe-cuda-backend/cuda/src/integer/compression/compression.cu b/backends/tfhe-cuda-backend/cuda/src/integer/compression/compression.cu
index ac570db93..60d4fbe75 100644
--- a/backends/tfhe-cuda-backend/cuda/src/integer/compression/compression.cu
+++ b/backends/tfhe-cuda-backend/cuda/src/integer/compression/compression.cu
@@ -7,19 +7,20 @@ void scratch_cuda_integer_compress_radix_ciphertext_64(
     uint32_t ks_level, uint32_t ks_base_log, uint32_t num_radix_blocks,
     uint32_t message_modulus, uint32_t carry_modulus, PBS_TYPE pbs_type,
     uint32_t lwe_per_glwe, uint32_t storage_log_modulus,
-    bool allocate_gpu_memory) {
+    bool allocate_gpu_memory)
+{
 
-  int_radix_params compression_params(
-      pbs_type, compression_glwe_dimension, compression_polynomial_size,
-      (compression_glwe_dimension + 1) * compression_polynomial_size,
-      lwe_dimension, ks_level, ks_base_log, 0, 0, 0, message_modulus,
-      carry_modulus);
+    int_radix_params compression_params(
+        pbs_type, compression_glwe_dimension, compression_polynomial_size,
+        (compression_glwe_dimension + 1) * compression_polynomial_size,
+        lwe_dimension, ks_level, ks_base_log, 0, 0, 0, message_modulus,
+        carry_modulus);
 
-  scratch_cuda_compress_integer_radix_ciphertext<uint64_t>(
-      (cudaStream_t *)(streams), gpu_indexes, gpu_count,
-      (int_compression<uint64_t> **)mem_ptr, num_radix_blocks,
-      compression_params, lwe_per_glwe, storage_log_modulus,
-      allocate_gpu_memory);
+    scratch_cuda_compress_integer_radix_ciphertext<uint64_t>(
+        (cudaStream_t *)(streams), gpu_indexes, gpu_count,
+        (int_compression<uint64_t> **)mem_ptr, num_radix_blocks,
+        compression_params, lwe_per_glwe, storage_log_modulus,
+        allocate_gpu_memory);
 }
 void scratch_cuda_integer_decompress_radix_ciphertext_64(
     void *const *streams, uint32_t const *gpu_indexes, uint32_t gpu_count,
@@ -29,62 +30,67 @@ void scratch_cuda_integer_decompress_radix_ciphertext_64(
     uint32_t pbs_level, uint32_t pbs_base_log, uint32_t num_radix_blocks,
     uint32_t message_modulus, uint32_t carry_modulus, PBS_TYPE pbs_type,
     uint32_t storage_log_modulus, uint32_t body_count,
-    bool allocate_gpu_memory) {
+    bool allocate_gpu_memory)
+{
 
-  // Decompression doesn't keyswitch, so big and small dimensions are the same
-  int_radix_params encryption_params(
-      pbs_type, encryption_glwe_dimension, encryption_polynomial_size,
-      lwe_dimension, lwe_dimension, 0, 0, pbs_level, pbs_base_log, 0,
-      message_modulus, carry_modulus);
+    // Decompression doesn't keyswitch, so big and small dimensions are the same
+    int_radix_params encryption_params(
+        pbs_type, encryption_glwe_dimension, encryption_polynomial_size,
+        lwe_dimension, lwe_dimension, 0, 0, pbs_level, pbs_base_log, 0,
+        message_modulus, carry_modulus);
 
-  int_radix_params compression_params(
-      pbs_type, compression_glwe_dimension, compression_polynomial_size,
-      lwe_dimension, compression_glwe_dimension * compression_polynomial_size,
-      0, 0, pbs_level, pbs_base_log, 0, message_modulus, carry_modulus);
+    int_radix_params compression_params(
+        pbs_type, compression_glwe_dimension, compression_polynomial_size,
+        lwe_dimension, compression_glwe_dimension * compression_polynomial_size,
+        0, 0, pbs_level, pbs_base_log, 0, message_modulus, carry_modulus);
 
-  scratch_cuda_integer_decompress_radix_ciphertext<uint64_t>(
-      (cudaStream_t *)(streams), gpu_indexes, gpu_count,
-      (int_decompression<uint64_t> **)mem_ptr, num_radix_blocks, body_count,
-      encryption_params, compression_params, storage_log_modulus,
-      allocate_gpu_memory);
+    scratch_cuda_integer_decompress_radix_ciphertext<uint64_t>(
+        (cudaStream_t *)(streams), gpu_indexes, gpu_count,
+        (int_decompression<uint64_t> **)mem_ptr, num_radix_blocks, body_count,
+        encryption_params, compression_params, storage_log_modulus,
+        allocate_gpu_memory);
 }
 void cuda_integer_compress_radix_ciphertext_64(
     void *const *streams, uint32_t const *gpu_indexes, uint32_t gpu_count,
     void *glwe_array_out, void const *lwe_array_in, void *const *fp_ksk,
-    uint32_t num_nths, int8_t *mem_ptr) {
+    uint32_t num_nths, int8_t *mem_ptr)
+{
 
-  host_integer_compress<uint64_t>(
-      (cudaStream_t *)(streams), gpu_indexes, gpu_count,
-      static_cast<uint64_t *>(glwe_array_out),
-      static_cast<const uint64_t *>(lwe_array_in), (uint64_t *const *)(fp_ksk),
-      num_nths, (int_compression<uint64_t> *)mem_ptr);
+    host_integer_compress<uint64_t>(
+        (cudaStream_t *)(streams), gpu_indexes, gpu_count,
+        static_cast<uint64_t *>(glwe_array_out),
+        static_cast<const uint64_t *>(lwe_array_in), (uint64_t *const *)(fp_ksk),
+        num_nths, (int_compression<uint64_t> *)mem_ptr);
 }
 void cuda_integer_decompress_radix_ciphertext_64(
     void *const *streams, uint32_t const *gpu_indexes, uint32_t gpu_count,
     void *lwe_array_out, void const *glwe_in, uint32_t const *indexes_array,
-    uint32_t indexes_array_size, void *const *bsks, int8_t *mem_ptr) {
+    uint32_t indexes_array_size, void *const *bsks, int8_t *mem_ptr)
+{
 
-  host_integer_decompress<uint64_t>(
-      (cudaStream_t *)(streams), gpu_indexes, gpu_count,
-      static_cast<uint64_t *>(lwe_array_out),
-      static_cast<const uint64_t *>(glwe_in), indexes_array, indexes_array_size,
-      bsks, (int_decompression<uint64_t> *)mem_ptr);
+    host_integer_decompress<uint64_t>(
+        (cudaStream_t *)(streams), gpu_indexes, gpu_count,
+        static_cast<uint64_t *>(lwe_array_out),
+        static_cast<const uint64_t *>(glwe_in), indexes_array, indexes_array_size,
+        bsks, (int_decompression<uint64_t> *)mem_ptr);
 }
 
 void cleanup_cuda_integer_compress_radix_ciphertext_64(
     void *const *streams, uint32_t const *gpu_indexes, uint32_t gpu_count,
-    int8_t **mem_ptr_void) {
+    int8_t **mem_ptr_void)
+{
 
-  int_compression<uint64_t> *mem_ptr =
-      (int_compression<uint64_t> *)(*mem_ptr_void);
-  mem_ptr->release((cudaStream_t *)(streams), gpu_indexes, gpu_count);
+    int_compression<uint64_t> *mem_ptr =
+        (int_compression<uint64_t> *)(*mem_ptr_void);
+    mem_ptr->release((cudaStream_t *)(streams), gpu_indexes, gpu_count);
 }
 
 void cleanup_cuda_integer_decompress_radix_ciphertext_64(
     void *const *streams, uint32_t const *gpu_indexes, uint32_t gpu_count,
-    int8_t **mem_ptr_void) {
+    int8_t **mem_ptr_void)
+{
 
-  int_decompression<uint64_t> *mem_ptr =
-      (int_decompression<uint64_t> *)(*mem_ptr_void);
-  mem_ptr->release((cudaStream_t *)(streams), gpu_indexes, gpu_count);
+    int_decompression<uint64_t> *mem_ptr =
+        (int_decompression<uint64_t> *)(*mem_ptr_void);
+    mem_ptr->release((cudaStream_t *)(streams), gpu_indexes, gpu_count);
 }
diff --git a/backends/tfhe-cuda-backend/cuda/src/integer/compression/compression.cuh b/backends/tfhe-cuda-backend/cuda/src/integer/compression/compression.cuh
index 93fbf33bf..ca2f1750d 100644
--- a/backends/tfhe-cuda-backend/cuda/src/integer/compression/compression.cuh
+++ b/backends/tfhe-cuda-backend/cuda/src/integer/compression/compression.cuh
@@ -14,7 +14,8 @@
 
 template <typename Torus>
 __global__ void pack(Torus *array_out, Torus *array_in, uint32_t log_modulus,
-                     uint32_t num_coeffs, uint32_t in_len, uint32_t out_len) {
+                     uint32_t num_coeffs, uint32_t in_len, uint32_t out_len)
+{
   auto nbits = sizeof(Torus) * 8;
   auto tid = threadIdx.x + blockIdx.x * blockDim.x;
 
@@ -23,7 +24,8 @@ __global__ void pack(Torus *array_out, Torus *array_in, uint32_t log_modulus,
   auto chunk_array_in = array_in + glwe_index * in_len;
   auto chunk_array_out = array_out + glwe_index * out_len;
 
-  if (tid < num_coeffs) {
+  if (tid < num_coeffs)
+  {
 
     auto k = nbits * i / log_modulus;
     auto j = k;
@@ -33,7 +35,8 @@ __global__ void pack(Torus *array_out, Torus *array_in, uint32_t log_modulus,
     auto value = chunk_array_in[j] >> start_shift;
     j++;
 
-    while (j * log_modulus < ((i + 1) * nbits) && j < in_len) {
+    while (j * log_modulus < ((i + 1) * nbits) && j < in_len)
+    {
       auto shift = j * log_modulus - i * nbits;
       value |= chunk_array_in[j] << shift;
       j++;
@@ -46,7 +49,8 @@ __global__ void pack(Torus *array_out, Torus *array_in, uint32_t log_modulus,
 template <typename Torus>
 __host__ void host_pack(cudaStream_t stream, uint32_t gpu_index,
                         Torus *array_out, Torus *array_in, uint32_t num_glwes,
-                        uint32_t num_lwes, int_compression<Torus> *mem_ptr) {
+                        uint32_t num_lwes, int_compression<Torus> *mem_ptr)
+{
   if (array_in == array_out)
     PANIC("Cuda error: Input and output must be different");
 
@@ -84,7 +88,8 @@ host_integer_compress(cudaStream_t const *streams, uint32_t const *gpu_indexes,
                       uint32_t gpu_count, Torus *glwe_array_out,
                       Torus const *lwe_array_in, Torus *const *fp_ksk,
                       uint32_t num_radix_blocks,
-                      int_compression<Torus> *mem_ptr) {
+                      int_compression<Torus> *mem_ptr)
+{
 
   auto compression_params = mem_ptr->compression_params;
   auto input_lwe_dimension = compression_params.small_lwe_dimension;
@@ -114,18 +119,22 @@ host_integer_compress(cudaStream_t const *streams, uint32_t const *gpu_indexes,
 
   auto lwe_subset = lwe_shifted;
   auto glwe_out = tmp_glwe_array_out;
-  while (rem_lwes > 0) {
+  while (rem_lwes > 0)
+  {
     auto chunk_size = min(rem_lwes, mem_ptr->lwe_per_glwe);
 
     if (can_use_pks_fast_path(
             input_lwe_dimension, chunk_size, compression_params.polynomial_size,
-            compression_params.ks_level, compression_params.glwe_dimension)) {
+            compression_params.ks_level, compression_params.glwe_dimension))
+    {
       host_fast_packing_keyswitch_lwe_list_to_glwe<Torus, ulonglong4>(
           streams[0], gpu_indexes[0], glwe_out, lwe_subset, fp_ksk[0],
           fp_ks_buffer, input_lwe_dimension, compression_params.glwe_dimension,
           compression_params.polynomial_size, compression_params.ks_base_log,
           compression_params.ks_level, chunk_size);
-    } else {
+    }
+    else
+    {
       host_packing_keyswitch_lwe_list_to_glwe<Torus>(
           streams[0], gpu_indexes[0], glwe_out, lwe_subset, fp_ksk[0],
           fp_ks_buffer, input_lwe_dimension, compression_params.glwe_dimension,
@@ -153,12 +162,14 @@ host_integer_compress(cudaStream_t const *streams, uint32_t const *gpu_indexes,
 template <typename Torus>
 __global__ void extract(Torus *glwe_array_out, Torus const *array_in,
                         uint32_t index, uint32_t log_modulus,
-                        uint32_t input_len, uint32_t initial_out_len) {
+                        uint32_t input_len, uint32_t initial_out_len)
+{
   auto nbits = sizeof(Torus) * 8;
 
   auto i = threadIdx.x + blockIdx.x * blockDim.x;
   auto chunk_array_in = array_in + index * input_len;
-  if (i < initial_out_len) {
+  if (i < initial_out_len)
+  {
     // Unpack
     Torus mask = ((Torus)1 << log_modulus) - 1;
     auto start = i * log_modulus;
@@ -170,10 +181,13 @@ __global__ void extract(Torus *glwe_array_out, Torus const *array_in,
     auto end_block_inclusive = (end - 1) / nbits;
 
     Torus unpacked_i;
-    if (start_block == end_block_inclusive) {
+    if (start_block == end_block_inclusive)
+    {
       auto single_part = chunk_array_in[start_block] >> start_remainder;
       unpacked_i = single_part & mask;
-    } else {
+    }
+    else
+    {
       auto first_part = chunk_array_in[start_block] >> start_remainder;
       auto second_part = chunk_array_in[start_block + 1]
                          << (nbits - start_remainder);
@@ -191,7 +205,8 @@ template <typename Torus>
 __host__ void host_extract(cudaStream_t stream, uint32_t gpu_index,
                            Torus *glwe_array_out, Torus const *array_in,
                            uint32_t glwe_index,
-                           int_decompression<Torus> *mem_ptr) {
+                           int_decompression<Torus> *mem_ptr)
+{
   if (array_in == glwe_array_out)
     PANIC("Cuda error: Input and output must be different");
 
@@ -236,7 +251,8 @@ __host__ void host_integer_decompress(
     cudaStream_t const *streams, uint32_t const *gpu_indexes,
     uint32_t gpu_count, Torus *d_lwe_array_out, Torus const *d_packed_glwe_in,
     uint32_t const *h_indexes_array, uint32_t indexes_array_size,
-    void *const *d_bsks, int_decompression<Torus> *h_mem_ptr) {
+    void *const *d_bsks, int_decompression<Torus> *h_mem_ptr)
+{
 
   auto d_indexes_array = h_mem_ptr->tmp_indexes_array;
   cuda_memcpy_async_to_gpu(d_indexes_array, (void *)h_indexes_array,
@@ -268,16 +284,20 @@ __host__ void host_integer_decompress(
   host_extract<Torus>(streams[0], gpu_indexes[0], extracted_glwe,
                       d_packed_glwe_in, current_glwe_index, h_mem_ptr);
   glwe_vec.push_back(std::make_pair(0, extracted_glwe));
-  for (int i = 1; i < indexes_array_size; i++) {
+  for (int i = 1; i < indexes_array_size; i++)
+  {
     auto glwe_index = h_indexes_array[i] / lwe_per_glwe;
-    if (glwe_index != current_glwe_index) {
+    if (glwe_index != current_glwe_index)
+    {
       extracted_glwe += glwe_accumulator_size;
       current_glwe_index = glwe_index;
       // Extracts a new GLWE
       host_extract<Torus>(streams[0], gpu_indexes[0], extracted_glwe,
                           d_packed_glwe_in, glwe_index, h_mem_ptr);
       glwe_vec.push_back(std::make_pair(i, extracted_glwe));
-    } else {
+    }
+    else
+    {
       // Updates the index
       glwe_vec.back().first++;
     }
@@ -288,7 +308,8 @@ __host__ void host_integer_decompress(
   auto extracted_lwe = h_mem_ptr->tmp_extracted_lwe;
   uint32_t current_idx = 0;
   auto d_indexes_array_chunk = d_indexes_array;
-  for (const auto &max_idx_and_glwe : glwe_vec) {
+  for (const auto &max_idx_and_glwe : glwe_vec)
+  {
     uint32_t last_idx = max_idx_and_glwe.first;
     extracted_glwe = max_idx_and_glwe.second;
 
@@ -313,7 +334,8 @@ __host__ void host_integer_decompress(
   auto encryption_params = h_mem_ptr->encryption_params;
   auto lut = h_mem_ptr->decompression_rescale_lut;
   auto active_gpu_count = get_active_gpu_count(num_radix_blocks, gpu_count);
-  if (active_gpu_count == 1) {
+  if (active_gpu_count == 1)
+  {
     execute_pbs_async<Torus>(
         streams, gpu_indexes, active_gpu_count, d_lwe_array_out,
         lut->lwe_indexes_out, lut->lut_vec, lut->lut_indexes_vec, extracted_lwe,
@@ -323,7 +345,9 @@ __host__ void host_integer_decompress(
         encryption_params.polynomial_size, encryption_params.pbs_base_log,
         encryption_params.pbs_level, encryption_params.grouping_factor,
         num_radix_blocks, encryption_params.pbs_type, num_many_lut, lut_stride);
-  } else {
+  }
+  else
+  {
     /// For multi GPU execution we create vectors of pointers for inputs and
     /// outputs
     std::vector<Torus *> lwe_array_in_vec = lut->lwe_array_in_vec;
@@ -359,7 +383,8 @@ __host__ void host_integer_decompress(
         encryption_params.big_lwe_dimension + 1);
 
     /// Synchronize all GPUs
-    for (uint i = 0; i < active_gpu_count; i++) {
+    for (uint i = 0; i < active_gpu_count; i++)
+    {
       cuda_synchronize_stream(streams[i], gpu_indexes[i]);
     }
   }
@@ -371,7 +396,8 @@ __host__ void scratch_cuda_compress_integer_radix_ciphertext(
     uint32_t gpu_count, int_compression<Torus> **mem_ptr,
     uint32_t num_radix_blocks, int_radix_params compression_params,
     uint32_t lwe_per_glwe, uint32_t storage_log_modulus,
-    bool allocate_gpu_memory) {
+    bool allocate_gpu_memory)
+{
 
   *mem_ptr = new int_compression<Torus>(
       streams, gpu_indexes, gpu_count, compression_params, num_radix_blocks,
@@ -384,7 +410,8 @@ __host__ void scratch_cuda_integer_decompress_radix_ciphertext(
     uint32_t gpu_count, int_decompression<Torus> **mem_ptr,
     uint32_t num_radix_blocks, uint32_t body_count,
     int_radix_params encryption_params, int_radix_params compression_params,
-    uint32_t storage_log_modulus, bool allocate_gpu_memory) {
+    uint32_t storage_log_modulus, bool allocate_gpu_memory)
+{
 
   *mem_ptr = new int_decompression<Torus>(
       streams, gpu_indexes, gpu_count, encryption_params, compression_params,
diff --git a/backends/tfhe-cuda-backend/cuda/src/pbs/bootstrapping_key.cuh b/backends/tfhe-cuda-backend/cuda/src/pbs/bootstrapping_key.cuh
index 44df19c90..57986119d 100644
--- a/backends/tfhe-cuda-backend/cuda/src/pbs/bootstrapping_key.cuh
+++ b/backends/tfhe-cuda-backend/cuda/src/pbs/bootstrapping_key.cuh
@@ -11,7 +11,8 @@
 
 __device__ inline int get_start_ith_ggsw(int i, uint32_t polynomial_size,
                                          int glwe_dimension,
-                                         uint32_t level_count) {
+                                         uint32_t level_count)
+{
   return i * polynomial_size / 2 * (glwe_dimension + 1) * (glwe_dimension + 1) *
          level_count;
 }
@@ -21,7 +22,8 @@ template <typename T>
 __device__ const T *get_ith_mask_kth_block(const T *ptr, int i, int k,
                                            int level, uint32_t polynomial_size,
                                            int glwe_dimension,
-                                           uint32_t level_count) {
+                                           uint32_t level_count)
+{
   return &ptr[get_start_ith_ggsw(i, polynomial_size, glwe_dimension,
                                  level_count) +
               (level_count - level - 1) * polynomial_size / 2 *
@@ -32,7 +34,8 @@ __device__ const T *get_ith_mask_kth_block(const T *ptr, int i, int k,
 template <typename T>
 __device__ T *get_ith_mask_kth_block(T *ptr, int i, int k, int level,
                                      uint32_t polynomial_size,
-                                     int glwe_dimension, uint32_t level_count) {
+                                     int glwe_dimension, uint32_t level_count)
+{
   return &ptr[get_start_ith_ggsw(i, polynomial_size, glwe_dimension,
                                  level_count) +
               (level_count - level - 1) * polynomial_size / 2 *
@@ -42,7 +45,8 @@ __device__ T *get_ith_mask_kth_block(T *ptr, int i, int k, int level,
 template <typename T>
 __device__ T *get_ith_body_kth_block(T *ptr, int i, int k, int level,
                                      uint32_t polynomial_size,
-                                     int glwe_dimension, uint32_t level_count) {
+                                     int glwe_dimension, uint32_t level_count)
+{
   return &ptr[get_start_ith_ggsw(i, polynomial_size, glwe_dimension,
                                  level_count) +
               (level_count - level - 1) * polynomial_size / 2 *
@@ -55,7 +59,8 @@ __device__ T *get_ith_body_kth_block(T *ptr, int i, int k, int level,
 __device__ inline int get_start_ith_lwe(uint32_t i, uint32_t grouping_factor,
                                         uint32_t polynomial_size,
                                         uint32_t glwe_dimension,
-                                        uint32_t level_count) {
+                                        uint32_t level_count)
+{
   return i * (1 << grouping_factor) * polynomial_size / 2 *
          (glwe_dimension + 1) * (glwe_dimension + 1) * level_count;
 }
@@ -63,7 +68,8 @@ __device__ inline int get_start_ith_lwe(uint32_t i, uint32_t grouping_factor,
 template <typename T>
 __device__ const T *get_multi_bit_ith_lwe_gth_group_kth_block(
     const T *ptr, int g, int i, int k, int level, uint32_t grouping_factor,
-    uint32_t polynomial_size, uint32_t glwe_dimension, uint32_t level_count) {
+    uint32_t polynomial_size, uint32_t glwe_dimension, uint32_t level_count)
+{
   const T *ptr_group =
       ptr + get_start_ith_lwe(i, grouping_factor, polynomial_size,
                               glwe_dimension, level_count);
@@ -77,7 +83,8 @@ void cuda_convert_lwe_programmable_bootstrap_key(cudaStream_t stream,
                                                  uint32_t gpu_index,
                                                  double2 *dest, ST const *src,
                                                  uint32_t polynomial_size,
-                                                 uint32_t total_polynomials) {
+                                                 uint32_t total_polynomials)
+{
   cudaSetDevice(gpu_index);
   int shared_memory_size = sizeof(double) * polynomial_size;
 
@@ -97,10 +104,12 @@ void cuda_convert_lwe_programmable_bootstrap_key(cudaStream_t stream,
 
   constexpr double two_pow_torus_bits = get_two_pow_torus_bits<T>();
   // compress real bsk to complex and divide it on DOUBLE_MAX
-  for (int i = 0; i < total_polynomials; i++) {
+  for (int i = 0; i < total_polynomials; i++)
+  {
     int complex_current_poly_idx = i * polynomial_size / 2;
     int torus_current_poly_idx = i * polynomial_size;
-    for (int j = 0; j < polynomial_size / 2; j++) {
+    for (int j = 0; j < polynomial_size / 2; j++)
+    {
       h_bsk[complex_current_poly_idx + j].x = src[torus_current_poly_idx + j];
       h_bsk[complex_current_poly_idx + j].y =
           src[torus_current_poly_idx + j + polynomial_size / 2];
@@ -112,9 +121,11 @@ void cuda_convert_lwe_programmable_bootstrap_key(cudaStream_t stream,
   cuda_memcpy_async_to_gpu(d_bsk, h_bsk, buffer_size, stream, gpu_index);
 
   double2 *buffer = (double2 *)cuda_malloc_async(0, stream, gpu_index);
-  switch (polynomial_size) {
+  switch (polynomial_size)
+  {
   case 256:
-    if (shared_memory_size <= cuda_get_max_shared_memory(0)) {
+    if (shared_memory_size <= cuda_get_max_shared_memory(0))
+    {
       check_cuda_error(cudaFuncSetAttribute(
           batch_NSMFFT<FFTDegree<AmortizedDegree<256>, ForwardFFT>, FULLSM>,
           cudaFuncAttributeMaxDynamicSharedMemorySize, shared_memory_size));
@@ -124,7 +135,9 @@ void cuda_convert_lwe_programmable_bootstrap_key(cudaStream_t stream,
       batch_NSMFFT<FFTDegree<AmortizedDegree<256>, ForwardFFT>, FULLSM>
           <<<gridSize, blockSize, shared_memory_size, stream>>>(d_bsk, dest,
                                                                 buffer);
-    } else {
+    }
+    else
+    {
       buffer = (double2 *)cuda_malloc_async(
           shared_memory_size * total_polynomials, stream, gpu_index);
       batch_NSMFFT<FFTDegree<AmortizedDegree<256>, ForwardFFT>, NOSM>
@@ -132,7 +145,8 @@ void cuda_convert_lwe_programmable_bootstrap_key(cudaStream_t stream,
     }
     break;
   case 512:
-    if (shared_memory_size <= cuda_get_max_shared_memory(0)) {
+    if (shared_memory_size <= cuda_get_max_shared_memory(0))
+    {
       check_cuda_error(cudaFuncSetAttribute(
           batch_NSMFFT<FFTDegree<AmortizedDegree<512>, ForwardFFT>, FULLSM>,
           cudaFuncAttributeMaxDynamicSharedMemorySize, shared_memory_size));
@@ -142,7 +156,9 @@ void cuda_convert_lwe_programmable_bootstrap_key(cudaStream_t stream,
       batch_NSMFFT<FFTDegree<AmortizedDegree<512>, ForwardFFT>, FULLSM>
           <<<gridSize, blockSize, shared_memory_size, stream>>>(d_bsk, dest,
                                                                 buffer);
-    } else {
+    }
+    else
+    {
       buffer = (double2 *)cuda_malloc_async(
           shared_memory_size * total_polynomials, stream, gpu_index);
       batch_NSMFFT<FFTDegree<AmortizedDegree<512>, ForwardFFT>, NOSM>
@@ -150,7 +166,8 @@ void cuda_convert_lwe_programmable_bootstrap_key(cudaStream_t stream,
     }
     break;
   case 1024:
-    if (shared_memory_size <= cuda_get_max_shared_memory(0)) {
+    if (shared_memory_size <= cuda_get_max_shared_memory(0))
+    {
       check_cuda_error(cudaFuncSetAttribute(
           batch_NSMFFT<FFTDegree<AmortizedDegree<1024>, ForwardFFT>, FULLSM>,
           cudaFuncAttributeMaxDynamicSharedMemorySize, shared_memory_size));
@@ -160,7 +177,9 @@ void cuda_convert_lwe_programmable_bootstrap_key(cudaStream_t stream,
       batch_NSMFFT<FFTDegree<AmortizedDegree<1024>, ForwardFFT>, FULLSM>
           <<<gridSize, blockSize, shared_memory_size, stream>>>(d_bsk, dest,
                                                                 buffer);
-    } else {
+    }
+    else
+    {
       buffer = (double2 *)cuda_malloc_async(
           shared_memory_size * total_polynomials, stream, gpu_index);
       batch_NSMFFT<FFTDegree<AmortizedDegree<1024>, ForwardFFT>, NOSM>
@@ -168,7 +187,8 @@ void cuda_convert_lwe_programmable_bootstrap_key(cudaStream_t stream,
     }
     break;
   case 2048:
-    if (shared_memory_size <= cuda_get_max_shared_memory(0)) {
+    if (shared_memory_size <= cuda_get_max_shared_memory(0))
+    {
       check_cuda_error(cudaFuncSetAttribute(
           batch_NSMFFT<FFTDegree<AmortizedDegree<2048>, ForwardFFT>, FULLSM>,
           cudaFuncAttributeMaxDynamicSharedMemorySize, shared_memory_size));
@@ -178,7 +198,9 @@ void cuda_convert_lwe_programmable_bootstrap_key(cudaStream_t stream,
       batch_NSMFFT<FFTDegree<AmortizedDegree<2048>, ForwardFFT>, FULLSM>
           <<<gridSize, blockSize, shared_memory_size, stream>>>(d_bsk, dest,
                                                                 buffer);
-    } else {
+    }
+    else
+    {
       buffer = (double2 *)cuda_malloc_async(
           shared_memory_size * total_polynomials, stream, gpu_index);
       batch_NSMFFT<FFTDegree<AmortizedDegree<2048>, ForwardFFT>, NOSM>
@@ -186,7 +208,8 @@ void cuda_convert_lwe_programmable_bootstrap_key(cudaStream_t stream,
     }
     break;
   case 4096:
-    if (shared_memory_size <= cuda_get_max_shared_memory(0)) {
+    if (shared_memory_size <= cuda_get_max_shared_memory(0))
+    {
       check_cuda_error(cudaFuncSetAttribute(
           batch_NSMFFT<FFTDegree<AmortizedDegree<4096>, ForwardFFT>, FULLSM>,
           cudaFuncAttributeMaxDynamicSharedMemorySize, shared_memory_size));
@@ -196,7 +219,9 @@ void cuda_convert_lwe_programmable_bootstrap_key(cudaStream_t stream,
       batch_NSMFFT<FFTDegree<AmortizedDegree<4096>, ForwardFFT>, FULLSM>
           <<<gridSize, blockSize, shared_memory_size, stream>>>(d_bsk, dest,
                                                                 buffer);
-    } else {
+    }
+    else
+    {
       buffer = (double2 *)cuda_malloc_async(
           shared_memory_size * total_polynomials, stream, gpu_index);
       batch_NSMFFT<FFTDegree<AmortizedDegree<4096>, ForwardFFT>, NOSM>
@@ -204,7 +229,8 @@ void cuda_convert_lwe_programmable_bootstrap_key(cudaStream_t stream,
     }
     break;
   case 8192:
-    if (shared_memory_size <= cuda_get_max_shared_memory(0)) {
+    if (shared_memory_size <= cuda_get_max_shared_memory(0))
+    {
       check_cuda_error(cudaFuncSetAttribute(
           batch_NSMFFT<FFTDegree<AmortizedDegree<8192>, ForwardFFT>, FULLSM>,
           cudaFuncAttributeMaxDynamicSharedMemorySize, shared_memory_size));
@@ -214,7 +240,9 @@ void cuda_convert_lwe_programmable_bootstrap_key(cudaStream_t stream,
       batch_NSMFFT<FFTDegree<AmortizedDegree<8192>, ForwardFFT>, FULLSM>
           <<<gridSize, blockSize, shared_memory_size, stream>>>(d_bsk, dest,
                                                                 buffer);
-    } else {
+    }
+    else
+    {
       buffer = (double2 *)cuda_malloc_async(
           shared_memory_size * total_polynomials, stream, gpu_index);
       batch_NSMFFT<FFTDegree<AmortizedDegree<8192>, ForwardFFT>, NOSM>
@@ -222,7 +250,8 @@ void cuda_convert_lwe_programmable_bootstrap_key(cudaStream_t stream,
     }
     break;
   case 16384:
-    if (shared_memory_size <= cuda_get_max_shared_memory(0)) {
+    if (shared_memory_size <= cuda_get_max_shared_memory(0))
+    {
       check_cuda_error(cudaFuncSetAttribute(
           batch_NSMFFT<FFTDegree<AmortizedDegree<16384>, ForwardFFT>, FULLSM>,
           cudaFuncAttributeMaxDynamicSharedMemorySize, shared_memory_size));
@@ -232,7 +261,9 @@ void cuda_convert_lwe_programmable_bootstrap_key(cudaStream_t stream,
       batch_NSMFFT<FFTDegree<AmortizedDegree<16384>, ForwardFFT>, FULLSM>
           <<<gridSize, blockSize, shared_memory_size, stream>>>(d_bsk, dest,
                                                                 buffer);
-    } else {
+    }
+    else
+    {
       buffer = (double2 *)cuda_malloc_async(
           shared_memory_size * total_polynomials, stream, gpu_index);
       batch_NSMFFT<FFTDegree<AmortizedDegree<16384>, ForwardFFT>, NOSM>
diff --git a/format.sh b/format.sh
new file mode 100755
index 000000000..5de67e5db
--- /dev/null
+++ b/format.sh
@@ -0,0 +1,21 @@
+#!/bin/bash
+
+# Get the list of modified files (excluding deleted files)
+modified_files=$(git diff --name-only --diff-filter=ACM)
+
+# Filter out only the Rust files
+rust_files=$(echo "$modified_files" | grep '\.rs$')
+
+# Check if there are any Rust files to format
+if [ -z "$rust_files" ]; then
+  echo "No modified Rust files to format."
+  exit 0
+fi
+
+# Apply cargo fmt to each Rust file
+for file in $rust_files; do
+  echo "Formatting $file"
+  rustfmt $file
+done
+
+echo "Formatting complete."
\ No newline at end of file
diff --git a/params/boolean/.gitignore b/params/boolean/.gitignore
new file mode 100644
index 000000000..c96a04f00
--- /dev/null
+++ b/params/boolean/.gitignore
@@ -0,0 +1,2 @@
+*
+!.gitignore
\ No newline at end of file
diff --git a/params/shortint/.gitignore b/params/shortint/.gitignore
new file mode 100644
index 000000000..c96a04f00
--- /dev/null
+++ b/params/shortint/.gitignore
@@ -0,0 +1,2 @@
+*
+!.gitignore
\ No newline at end of file
diff --git a/scripts/copy_benchmarks.sh b/scripts/copy_benchmarks.sh
new file mode 100755
index 000000000..4159e5a31
--- /dev/null
+++ b/scripts/copy_benchmarks.sh
@@ -0,0 +1,46 @@
+#!/bin/bash
+# Belfort benchmark utility script for copying latest benchmark to Criterion
+
+BENCH_PATH="/home/benches/tfhe-rs"
+LATEST_PATH="$BENCH_PATH/latest"
+TARGET_PATH="target/criterion/integer__fpga"
+
+# Create directories if they don't exist
+mkdir -p "$LATEST_PATH"
+mkdir -p "$TARGET_PATH"
+
+# Using find to locate and remove directories older than 365 days
+find "$BENCH_PATH" -mindepth 1 -maxdepth 1 -type d -mtime +365 -not -name "latest" -exec rm -rf {} \;
+
+# Check if LATEST_PATH has contents
+if [ -z "$(ls -A $LATEST_PATH)" ]; then
+    echo "Warning: $LATEST_PATH is empty or does not exist. Skipping copy operation."
+    exit 0
+fi
+
+# Find all immediate subdirectories in the LATEST_PATH
+for dir in "$LATEST_PATH"/*; do
+    if [ -d "$dir" ]; then
+        # Get just the directory name
+        dirname=$(basename "$dir")
+        
+        # Create target directory if it doesn't exist
+        mkdir -p "$TARGET_PATH/$dirname"
+        
+        # Copy contents of Criterion's base, change and new estimates
+        for subdir in base change new; do
+            target_dir="$TARGET_PATH/$dirname/$subdir"
+            mkdir -p $target_dir
+            cp -R "$dir/$subdir/estimates.json" "$target_dir/estimates.json"
+            echo "Copied $dirname/$subdir to $target_dir"
+        done
+    fi
+done
+
+# Create new directory
+TFHE_RS_VERSION=$(grep '^version = ' tfhe/Cargo.toml | sed 's/version = "\(.*\)"/\1/')
+NEW_TFHE_DIR="$BENCH_PATH/v$TFHE_RS_VERSION-$(date +%y_%m_%d)"
+mkdir -p $NEW_TFHE_DIR
+
+# Move current latest directory to new directory
+cp -R "$LATEST_PATH"/* $NEW_TFHE_DIR
\ No newline at end of file
diff --git a/tfhe/Cargo.toml b/tfhe/Cargo.toml
index 2f050f638..2d55ee7f8 100644
--- a/tfhe/Cargo.toml
+++ b/tfhe/Cargo.toml
@@ -51,6 +51,7 @@ strum = { version = "0.26", features = ["derive"] }
 
 [build-dependencies]
 cbindgen = { version = "0.26.0", optional = true }
+bindgen = "0.70.1"
 
 [dependencies]
 tfhe-csprng = { version = "0.5.0", path = "../tfhe-csprng", features = [
@@ -65,16 +66,17 @@ tfhe-fft = { version = "0.7.0", path = "../tfhe-fft", features = [
 ] }
 tfhe-ntt = { version = "0.4.0", path = "../tfhe-ntt" }
 pulp = { workspace = true, features = ["default"] }
-tfhe-cuda-backend = { version = "0.7.0", path = "../backends/tfhe-cuda-backend", optional = true }
+# tfhe-cuda-backend = { version = "0.7.0", path = "../backends/tfhe-cuda-backend", optional = true }
 aligned-vec = { workspace = true, features = ["default", "serde"] }
 dyn-stack = { workspace = true, features = ["default"] }
 paste = "1.0.7"
+log = "0.4.19"
 fs2 = { version = "0.4.3", optional = true }
 # Used for OPRF in shortint
 sha3 = { version = "0.10", optional = true }
 itertools = { workspace = true }
 rand_core = { version = "0.6.4", features = ["std"] }
-tfhe-zk-pok = { version = "0.4.0", path = "../tfhe-zk-pok", optional = true }
+# tfhe-zk-pok = { version = "0.4.0", path = "../tfhe-zk-pok", optional = true }
 tfhe-versionable = { version = "0.4.0", path = "../utils/tfhe-versionable" }
 
 # wasm deps
@@ -89,14 +91,20 @@ getrandom = { version = "0.2.8", optional = true }
 bytemuck = { workspace = true }
 
 [features]
+default = ["boolean", "integer"]
 boolean = []
 shortint = ["dep:sha3"]
 integer = ["shortint"]
 strings = ["integer"]
 internal-keycache = ["dep:fs2"]
-gpu = ["dep:tfhe-cuda-backend"]
-zk-pok = ["dep:tfhe-zk-pok"]
 
+
+fpga = []
+emulate_fpga = []
+# gpu = ["dep:tfhe-cuda-backend"]
+gpu = []
+# zk-pok = ["dep:tfhe-zk-pok"]
+zk-pok = []
 pbs-stats = []
 noise-asserts = []
 
@@ -257,6 +265,36 @@ path = "benches/utilities.rs"
 harness = false
 required-features = ["boolean", "shortint", "integer", "internal-keycache"]
 
+[[bench]]
+name = "fpga-integer"
+path = "benches/fpga/integer.rs"
+harness = false
+required-features = [
+    "integer",
+    "shortint",
+    "boolean",
+    "fpga",
+    "internal-keycache",
+]
+
+[[bench]]
+name = "fpga-erc20"
+path = "benches/fpga/erc20.rs"
+harness = false
+required-features = [
+    "integer",
+    "shortint",
+    "boolean",
+    "fpga",
+    "internal-keycache",
+]
+
+[[bench]]
+name = "fpga-throughput"
+path = "benches/fpga/throughput.rs"
+harness = false
+required-features = ["shortint", "boolean", "fpga", "internal-keycache"]
+
 # Examples used as tools
 
 [[example]]
diff --git a/tfhe/benches/fpga/compare_benchmarks.py b/tfhe/benches/fpga/compare_benchmarks.py
new file mode 100644
index 000000000..56151b0a7
--- /dev/null
+++ b/tfhe/benches/fpga/compare_benchmarks.py
@@ -0,0 +1,68 @@
+"""Generate performance comparison report from benchmark results."""
+
+import os
+from datetime import datetime
+from helpers import BASE_BENCH_OUTPUT_PATH, format_median, get_median_data
+
+
+def format_performance_change(change):
+    """Format performance change with color indicator.
+
+    Args:
+        change: Percentage change in performance
+
+    Returns:
+        Formatted string with emoji indicator
+    """
+    change = change * 100
+    if change <= -2:  # Improvement of 2% or more
+        return f"ðŸŸ¢ {change:+.1f}%"
+    elif change >= 2:  # Regression of 2% or more
+        return f"ðŸ”´ {change:+.1f}%"
+
+
+def generate_report(base_path):
+    """Generate performance comparison report.
+
+    Args:
+        base_path: Path to benchmark results directory
+    """
+    report_file = os.path.join(base_path, "performance_report.md")
+    same_performance = True
+
+    with open(report_file, "w") as f:
+        f.write(f"# Performance Report\n\n")
+        f.write(f"Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
+
+        for param_file in sorted(os.listdir(base_path)):
+            if not param_file.startswith("Param_"):
+                continue
+
+            param_name = param_file.replace(".md", "").replace("Param_", "")
+            f.write(f"## {param_name}\n\n")
+
+            for folder in sorted(os.listdir(base_path)):
+                if not (folder.endswith("bit") and param_name in folder):
+                    continue
+
+                change_median = get_median_data(folder, "change")
+
+                if change_median and abs(change_median) > 0.02:
+                    base_median = get_median_data(folder, "base")
+                    new_median = get_median_data(folder, "new")
+
+                    same_performance = False
+
+                    f.write(f"### {folder}\n")
+                    f.write("| Previous | New | Change\n")
+                    f.write("|--------|-------|-------|\n")
+                    f.write(
+                        f"| {format_median(base_median)} | {format_median(new_median)} | {format_performance_change(change_median)} \n\n"
+                    )
+
+        if same_performance:
+            f.write("Performance hasn't changed with regard to the previous run.\n")
+
+
+if __name__ == "__main__":
+    generate_report(BASE_BENCH_OUTPUT_PATH)
diff --git a/tfhe/benches/fpga/erc20.rs b/tfhe/benches/fpga/erc20.rs
new file mode 100644
index 000000000..67afe2aeb
--- /dev/null
+++ b/tfhe/benches/fpga/erc20.rs
@@ -0,0 +1,120 @@
+use criterion::measurement::WallTime;
+use criterion::{black_box, criterion_group, BenchmarkGroup, Criterion};
+use std::env;
+use tfhe::integer::fpga::BelfortServerKey;
+use tfhe::prelude::*;
+use tfhe::{set_server_key, ClientKey, ConfigBuilder, FheUint64};
+
+const BENCH_GROUP_NAME: &str = "erc20";
+const BENCH_SAMPLE_SIZE: usize = 10;
+const BENCH_MEASUREMENT_TIME: u64 = 180;
+const BENCH_FPGA_COUNTS: [usize; 2] = [1, 2];
+
+fn erc20_transaction(
+    amount: &FheUint64,
+    balance: &FheUint64,
+    balance_to: &FheUint64,
+    balance_from: &FheUint64,
+) -> (FheUint64, FheUint64) {
+    let transfer_value = amount
+        .le(balance)
+        .select(amount, &FheUint64::encrypt_trivial(0u64));
+
+    let new_balance_to = balance_to + &transfer_value;
+    let new_balance_from = balance_from - &transfer_value;
+
+    (new_balance_to, new_balance_from)
+}
+
+fn bench_erc20(
+    bench_group: &mut BenchmarkGroup<'_, WallTime>,
+    client_key: &ClientKey,
+    bench_id: &str,
+) {
+    bench_group.bench_function(bench_id, |b| {
+        let balance = FheUint64::encrypt(120u64, client_key);
+        let amount = FheUint64::encrypt(42u64, client_key);
+
+        let mut balance_to = FheUint64::encrypt(0u64, client_key);
+        let mut balance_from = balance.clone();
+
+        b.iter(|| {
+            (balance_to, balance_from) = black_box(erc20_transaction(
+                &amount,
+                &balance,
+                &balance_to,
+                &balance_from,
+            ));
+        });
+    });
+}
+
+fn bench_erc20_on_cpu(c: &mut Criterion) {
+    let mut bench_group = c.benchmark_group(BENCH_GROUP_NAME);
+    bench_group
+        .sample_size(BENCH_SAMPLE_SIZE)
+        .measurement_time(std::time::Duration::from_secs(BENCH_MEASUREMENT_TIME));
+
+    let config = ConfigBuilder::default().build();
+
+    let client_key = ClientKey::generate(config);
+    let server_key = client_key.generate_server_key();
+
+    set_server_key(server_key.clone());
+
+    let bench_id: &str = "cpu";
+
+    bench_erc20(&mut bench_group, &client_key, bench_id);
+}
+
+fn bench_erc20_on_fpga(c: &mut Criterion) {
+    let mut bench_group = c.benchmark_group(BENCH_GROUP_NAME);
+    bench_group
+        .sample_size(BENCH_SAMPLE_SIZE)
+        .measurement_time(std::time::Duration::from_secs(BENCH_MEASUREMENT_TIME));
+
+    let config = ConfigBuilder::default().build();
+
+    let client_key = ClientKey::generate(config);
+    let server_key = client_key.generate_server_key();
+    let mut fpga_key = BelfortServerKey::from(&server_key);
+
+    for fpga_count in BENCH_FPGA_COUNTS {
+        let fpga_indexes = (0..fpga_count).collect();
+        fpga_key.connect_to(fpga_indexes);
+        set_server_key(fpga_key.clone());
+
+        let bench_id: String = format!("fpga::{fpga_count}");
+
+        bench_erc20(&mut bench_group, &client_key, &bench_id);
+
+        fpga_key.disconnect();
+    }
+}
+
+criterion_group!(bench_fpga, bench_erc20_on_fpga);
+criterion_group!(bench_cpu, bench_erc20_on_cpu);
+
+fn main() {
+    match env::var("__TFHE_RS_BENCH_OP_FLAVOR") {
+        Ok(val) => {
+            match val.to_lowercase().as_str() {
+                "default" | "only_fpga" => {
+                    bench_fpga();
+                }
+                "only_cpu" => {
+                    bench_cpu();
+                }
+                "all" => {
+                    bench_fpga();
+                    bench_cpu();
+                }
+                _ => {
+                    panic!("unknown benchmark operations flavor");
+                }
+            };
+        }
+        Err(_) => {}
+    };
+    Criterion::default().configure_from_args().final_summary();
+}
diff --git a/tfhe/benches/fpga/helpers.py b/tfhe/benches/fpga/helpers.py
new file mode 100644
index 000000000..c84e9c557
--- /dev/null
+++ b/tfhe/benches/fpga/helpers.py
@@ -0,0 +1,42 @@
+import json
+import os
+
+# Define global constants
+BENCH_OUTPUT_RELATIVE_PATH = "../../../target/criterion/integer__fpga/"
+BASE_BENCH_OUTPUT_PATH = os.path.abspath(
+    os.path.join(os.path.dirname(__file__), BENCH_OUTPUT_RELATIVE_PATH)
+)
+
+
+def format_median(median):
+    """Format median time value.
+
+    Args:
+        median: median given in microseconds
+
+    Returns:
+        Formatted string in ms
+    """
+    return f"{median/1000:.3f} ms"
+
+
+def get_median_data(folder, subfolder):
+    """Read median data in nanoseconds from benchmark results file.
+
+    Args:
+        folder: top-level folder containing the estimates.json file
+        subfolder: either "new", "base", "change" depending on what type of estimate is required
+
+    Returns:
+        Median point estimate in micro or None if file cannot be read
+    """
+    file_path = os.path.join(
+        BASE_BENCH_OUTPUT_PATH, folder, subfolder, "estimates.json"
+    )
+    try:
+        with open(file_path, "r") as f:
+            data = json.load(f)
+        return data.get("median", {}).get("point_estimate", None) / 1_000
+    except (FileNotFoundError, KeyError) as e:
+        print(f"Error reading {file_path}: {e}")
+        return None
diff --git a/tfhe/benches/fpga/integer.rs b/tfhe/benches/fpga/integer.rs
new file mode 100644
index 000000000..af6171e93
--- /dev/null
+++ b/tfhe/benches/fpga/integer.rs
@@ -0,0 +1,849 @@
+#![allow(dead_code)]
+
+use criterion::{criterion_group, Criterion};
+use itertools::{Itertools, Product};
+use rand::prelude::*;
+use std::env;
+use std::vec::IntoIter;
+use tfhe::integer::fpga::BelfortServerKey;
+use tfhe::integer::keycache::KEY_CACHE;
+use tfhe::integer::{IntegerKeyKind, RadixCiphertext, U256};
+use tfhe::shortint::parameters::*;
+use tfhe::shortint::Ciphertext;
+
+const BENCH_GROUP_NAME: &str = "integer::fpga";
+const BENCH_SAMPLE_SIZE: usize = 10;
+const BENCH_MEASUREMENT_TIME: u64 = 60;
+
+type ScalarType = U256;
+
+fn gen_random_u256(rng: &mut ThreadRng) -> U256 {
+    let clearlow = rng.gen::<u128>();
+    let clearhigh = rng.gen::<u128>();
+
+    tfhe::integer::U256::from((clearlow, clearhigh))
+}
+
+fn get_short_param_name(param: ClassicPBSParameters) -> &'static str {
+    match param {
+        PARAM_MESSAGE_2_CARRY_2_KS_PBS => "M2C2",
+        _ => panic!("Unexpected param"),
+    }
+}
+
+////////////////////////////////////////////////////////////////////////////////
+// An iterator that yields a succession of combinations of parameters and
+// a num_block to achieve a certain bit_size ciphertext in radix decomposition
+
+struct ParamsAndConfigsIter {
+    params_and_configs:
+        Product<IntoIter<ClassicPBSParameters>, Product<IntoIter<usize>, IntoIter<usize>>>,
+}
+
+impl Default for ParamsAndConfigsIter {
+    fn default() -> Self {
+        let default_bench_bit_sizes = vec![8, 32, 64];
+        let default_bench_fpga_counts = vec![1, 4];
+        let default_bench_params = vec![PARAM_MESSAGE_2_CARRY_2_KS_PBS];
+
+        let params = default_bench_params.into_iter();
+        let bit_sizes = default_bench_bit_sizes.into_iter();
+        let fpga_counts = default_bench_fpga_counts.into_iter();
+        let configs = bit_sizes.cartesian_product(fpga_counts);
+
+        let params_and_configs = params.cartesian_product(configs);
+
+        Self { params_and_configs }
+    }
+}
+
+impl Iterator for ParamsAndConfigsIter {
+    type Item = (ClassicPBSParameters, usize, usize, usize);
+
+    fn next(&mut self) -> Option<Self::Item> {
+        let (param, (bit_size, fpga_count)) = self.params_and_configs.next()?;
+        let num_block =
+            (bit_size as f64 / (param.message_modulus.0 as f64).log(2.0)).ceil() as usize;
+
+        Some((param, num_block, bit_size, fpga_count))
+    }
+}
+
+////////////////////////////////////////////////////////////////////////////////
+// Bench implementations
+
+fn bench_fpga_key_univariate_function_clean_inputs<F>(c: &mut Criterion, op_name: &str, op: F)
+where
+    F: Fn(&BelfortServerKey, &mut RadixCiphertext),
+{
+    let mut bench_group = c.benchmark_group(BENCH_GROUP_NAME);
+    bench_group
+        .sample_size(BENCH_SAMPLE_SIZE)
+        .measurement_time(std::time::Duration::from_secs(BENCH_MEASUREMENT_TIME));
+
+    let mut rng = rand::thread_rng();
+
+    for (param, num_block, bit_size, fpga_count) in ParamsAndConfigsIter::default() {
+        let param_name = get_short_param_name(param);
+
+        let (cks, sks) = KEY_CACHE.get_from_params(param, IntegerKeyKind::Radix);
+
+        let mut fpga_key = BelfortServerKey::from(&sks);
+        let fpga_indexes = (0..fpga_count).collect();
+        fpga_key.connect_to(fpga_indexes);
+
+        let bench_id = format!("{op_name}::{param_name}::{fpga_count}fpga::{bit_size}bit");
+        bench_group.bench_function(&bench_id, |b| {
+            let encrypt_one_value = || {
+                let clear_0 = gen_random_u256(&mut rng);
+
+                cks.encrypt_radix(clear_0, num_block)
+            };
+
+            b.iter_batched(
+                encrypt_one_value,
+                |mut ct_0| {
+                    op(&fpga_key, &mut ct_0);
+                },
+                criterion::BatchSize::SmallInput,
+            )
+        });
+
+        fpga_key.disconnect();
+    }
+
+    bench_group.finish()
+}
+
+fn bench_fpga_key_bivariate_function_clean_inputs<F>(c: &mut Criterion, op_name: &str, op: F)
+where
+    F: Fn(&BelfortServerKey, &mut RadixCiphertext, &mut RadixCiphertext),
+{
+    let mut bench_group = c.benchmark_group(BENCH_GROUP_NAME);
+    bench_group
+        .sample_size(BENCH_SAMPLE_SIZE)
+        .measurement_time(std::time::Duration::from_secs(BENCH_MEASUREMENT_TIME));
+    let mut rng = rand::thread_rng();
+
+    for (param, num_block, bit_size, fpga_count) in ParamsAndConfigsIter::default() {
+        let param_name = get_short_param_name(param);
+
+        let (cks, sks) = KEY_CACHE.get_from_params(param, IntegerKeyKind::Radix);
+        let mut fpga_key = BelfortServerKey::from(&sks);
+        let fpga_indexes = (0..fpga_count).collect();
+        fpga_key.connect_to(fpga_indexes);
+
+        let bench_id = format!("{op_name}::{param_name}::{fpga_count}fpga::{bit_size}bit");
+        bench_group.bench_function(&bench_id, |b| {
+            let encrypt_two_values = || {
+                let clear_0 = gen_random_u256(&mut rng);
+                let clear_1 = gen_random_u256(&mut rng);
+
+                let ct_0 = cks.encrypt_radix(clear_0, num_block);
+                let ct_1 = cks.encrypt_radix(clear_1, num_block);
+
+                (ct_0, ct_1)
+            };
+
+            b.iter_batched(
+                encrypt_two_values,
+                |(mut ct_0, mut ct_1)| {
+                    op(&fpga_key, &mut ct_0, &mut ct_1);
+                },
+                criterion::BatchSize::SmallInput,
+            )
+        });
+
+        fpga_key.disconnect();
+    }
+
+    bench_group.finish()
+}
+
+fn bench_fpga_key_bivariate_scalar_function_clean_inputs<F>(c: &mut Criterion, op_name: &str, op: F)
+where
+    F: Fn(&BelfortServerKey, &mut RadixCiphertext, ScalarType),
+{
+    let mut bench_group = c.benchmark_group(BENCH_GROUP_NAME);
+    bench_group
+        .sample_size(BENCH_SAMPLE_SIZE)
+        .measurement_time(std::time::Duration::from_secs(BENCH_MEASUREMENT_TIME));
+    let mut rng = rand::thread_rng();
+
+    for (param, num_block, bit_size, fpga_count) in ParamsAndConfigsIter::default() {
+        if bit_size > ScalarType::BITS as usize {
+            break;
+        }
+        let param_name = get_short_param_name(param);
+
+        let (cks, sks) = KEY_CACHE.get_from_params(param, IntegerKeyKind::Radix);
+
+        let mut fpga_key = BelfortServerKey::from(&sks);
+        let fpga_indexes = (0..fpga_count).collect();
+        fpga_key.connect_to(fpga_indexes);
+
+        let max_value_for_bit_size = ScalarType::MAX >> (ScalarType::BITS as usize - bit_size);
+
+        let bench_id = format!("{op_name}::{param_name}::{fpga_count}fpga::{bit_size}bit");
+        bench_group.bench_function(&bench_id, |b| {
+            let encrypt_one_value = || {
+                let clear_0 = gen_random_u256(&mut rng);
+                let clear_1 = gen_random_u256(&mut rng) & max_value_for_bit_size;
+
+                let ct_0 = cks.encrypt_radix(clear_0, num_block);
+
+                (ct_0, clear_1)
+            };
+
+            b.iter_batched(
+                encrypt_one_value,
+                |(mut ct_0, clear_1)| {
+                    op(&fpga_key, &mut ct_0, clear_1);
+                },
+                criterion::BatchSize::SmallInput,
+            )
+        });
+
+        fpga_key.disconnect();
+    }
+
+    bench_group.finish()
+}
+
+fn bench_fpga_key_univariate_function_dirty_inputs<F>(c: &mut Criterion, op_name: &str, op: F)
+where
+    F: Fn(&BelfortServerKey, &mut RadixCiphertext),
+{
+    let mut bench_group = c.benchmark_group(BENCH_GROUP_NAME);
+    bench_group
+        .sample_size(BENCH_SAMPLE_SIZE)
+        .measurement_time(std::time::Duration::from_secs(BENCH_MEASUREMENT_TIME));
+
+    let mut rng = rand::thread_rng();
+
+    for (param, num_block, bit_size, fpga_count) in ParamsAndConfigsIter::default() {
+        let param_name = get_short_param_name(param);
+        let (cks, sks) = KEY_CACHE.get_from_params(param, IntegerKeyKind::Radix);
+
+        let mut fpga_key = BelfortServerKey::from(&sks);
+        let fpga_indexes = (0..fpga_count).collect();
+        fpga_key.connect_to(fpga_indexes);
+
+        let bench_id = format!("{op_name}::{param_name}::{fpga_count}fpga::{bit_size}bit");
+        bench_group.bench_function(&bench_id, |b| {
+            let encrypt_one_value = || {
+                let clear_0 = gen_random_u256(&mut rng);
+                let mut ct_0 = cks.encrypt_radix(clear_0, num_block);
+
+                // Raise the degree, so as to ensure worst case path in operations
+                let mut carry_mod = param.carry_modulus.0;
+                while carry_mod > 0 {
+                    // Raise the degree, so as to ensure worst case path in operations
+                    let clear_2 = gen_random_u256(&mut rng);
+                    let ct_2 = cks.encrypt_radix(clear_2, num_block);
+                    fpga_key.unchecked_add_assign(&mut ct_0, &ct_2);
+
+                    carry_mod -= 1;
+                }
+
+                ct_0
+            };
+
+            b.iter_batched(
+                encrypt_one_value,
+                |mut ct_0| {
+                    op(&fpga_key, &mut ct_0);
+                },
+                criterion::BatchSize::SmallInput,
+            )
+        });
+        fpga_key.disconnect();
+    }
+
+    bench_group.finish()
+}
+
+fn bench_fpga_key_bivariate_function_dirty_inputs<F>(c: &mut Criterion, op_name: &str, op: F)
+where
+    F: Fn(&BelfortServerKey, &mut RadixCiphertext, &mut RadixCiphertext),
+{
+    let mut bench_group = c.benchmark_group(BENCH_GROUP_NAME);
+    bench_group
+        .sample_size(BENCH_SAMPLE_SIZE)
+        .measurement_time(std::time::Duration::from_secs(BENCH_MEASUREMENT_TIME));
+    let mut rng = rand::thread_rng();
+
+    for (param, num_block, bit_size, fpga_count) in ParamsAndConfigsIter::default() {
+        let param_name = get_short_param_name(param);
+
+        let (cks, sks) = KEY_CACHE.get_from_params(param, IntegerKeyKind::Radix);
+        let mut fpga_key = BelfortServerKey::from(&sks);
+        let fpga_indexes = (0..fpga_count).collect();
+        fpga_key.connect_to(fpga_indexes);
+
+        let bench_id = format!("{op_name}::{param_name}::{fpga_count}fpga::{bit_size}bit");
+        bench_group.bench_function(&bench_id, |b| {
+            let encrypt_two_values = || {
+                let clear_0 = gen_random_u256(&mut rng);
+                let clear_1 = gen_random_u256(&mut rng);
+
+                let mut ct_0 = cks.encrypt_radix(clear_0, num_block);
+                let mut ct_1 = cks.encrypt_radix(clear_1, num_block);
+
+                // Raise the degree, so as to ensure worst case path in operations
+                let mut carry_mod = param.carry_modulus.0;
+                while carry_mod > 0 {
+                    // Raise the degree, so as to ensure worst case path in operations
+                    let clear_2 = gen_random_u256(&mut rng);
+                    let ct_2 = cks.encrypt_radix(clear_2, num_block);
+                    fpga_key.unchecked_add_assign(&mut ct_0, &ct_2);
+                    fpga_key.unchecked_add_assign(&mut ct_1, &ct_2);
+
+                    carry_mod -= 1;
+                }
+
+                (ct_0, ct_1)
+            };
+
+            b.iter_batched(
+                encrypt_two_values,
+                |(mut ct_0, mut ct_1)| {
+                    op(&fpga_key, &mut ct_0, &mut ct_1);
+                },
+                criterion::BatchSize::SmallInput,
+            )
+        });
+
+        fpga_key.disconnect();
+    }
+
+    bench_group.finish()
+}
+
+fn bench_fpga_key_bivariate_scalar_function_dirty_inputs<F>(c: &mut Criterion, op_name: &str, op: F)
+where
+    F: Fn(&BelfortServerKey, &mut RadixCiphertext, ScalarType),
+{
+    let mut bench_group = c.benchmark_group(BENCH_GROUP_NAME);
+    bench_group
+        .sample_size(BENCH_SAMPLE_SIZE)
+        .measurement_time(std::time::Duration::from_secs(BENCH_MEASUREMENT_TIME));
+    let mut rng = rand::thread_rng();
+
+    for (param, num_block, bit_size, fpga_count) in ParamsAndConfigsIter::default() {
+        let param_name = get_short_param_name(param);
+        let (cks, sks) = KEY_CACHE.get_from_params(param, IntegerKeyKind::Radix);
+
+        let mut fpga_key = BelfortServerKey::from(&sks);
+        let fpga_indexes = (0..fpga_count).collect();
+        fpga_key.connect_to(fpga_indexes);
+
+        let max_value_for_bit_size = ScalarType::MAX >> (ScalarType::BITS as usize - bit_size);
+
+        let bench_id = format!("{op_name}::{param_name}::{fpga_count}fpga::{bit_size}bit");
+        bench_group.bench_function(&bench_id, |b| {
+            let encrypt_one_value = || {
+                let clear_0 = gen_random_u256(&mut rng);
+                let mut ct_0 = cks.encrypt_radix(clear_0, num_block);
+
+                // Raise the degree, so as to ensure worst case path in operations
+                let mut carry_mod = param.carry_modulus.0;
+                while carry_mod > 0 {
+                    // Raise the degree, so as to ensure worst case path in operations
+                    let clearlow = rng.gen::<u128>();
+                    let clearhigh = rng.gen::<u128>();
+                    let clear_2 = tfhe::integer::U256::from((clearlow, clearhigh));
+                    let ct_2 = cks.encrypt_radix(clear_2, num_block);
+                    fpga_key.unchecked_add_assign(&mut ct_0, &ct_2);
+
+                    carry_mod -= 1;
+                }
+
+                let clear_1 = gen_random_u256(&mut rng) & max_value_for_bit_size;
+
+                (ct_0, clear_1)
+            };
+
+            b.iter_batched(
+                encrypt_one_value,
+                |(mut ct_0, clear_1)| {
+                    op(&fpga_key, &mut ct_0, clear_1);
+                },
+                criterion::BatchSize::SmallInput,
+            )
+        });
+
+        fpga_key.disconnect();
+    }
+
+    bench_group.finish()
+}
+
+fn bench_fpga_key_bivariate_function_dirty_inputs_with_index<F>(
+    c: &mut Criterion,
+    op_name: &str,
+    op: F,
+) where
+    F: Fn(&BelfortServerKey, &mut RadixCiphertext, &mut Ciphertext, usize),
+{
+    let mut bench_group = c.benchmark_group(BENCH_GROUP_NAME);
+    bench_group
+        .sample_size(BENCH_SAMPLE_SIZE)
+        .measurement_time(std::time::Duration::from_secs(BENCH_MEASUREMENT_TIME));
+    let mut rng = rand::thread_rng();
+
+    for (param, num_block, bit_size, fpga_count) in ParamsAndConfigsIter::default() {
+        let param_name = get_short_param_name(param);
+        let (cks, sks) = KEY_CACHE.get_from_params(param, IntegerKeyKind::Radix);
+
+        let mut fpga_key = BelfortServerKey::from(&sks);
+        fpga_key.connect();
+
+        let bench_id = format!("{op_name}::{param_name}::{fpga_count}fpga::{bit_size}bit");
+        bench_group.bench_function(&bench_id, |b| {
+            let encrypt_values = || {
+                let clear_0 = gen_random_u256(&mut rng);
+                let mut ct_0 = cks.encrypt_radix(clear_0, num_block);
+
+                let clear_1 = rng.gen::<u64>();
+                let ct_1 = cks.encrypt_one_block(clear_1);
+
+                let index = rng.gen_range(0..4);
+
+                // Raise the degree, so as to ensure worst case path in operations
+                let mut carry_mod = param.carry_modulus.0;
+                while carry_mod > 0 {
+                    // Raise the degree, so as to ensure worst case path in operations
+                    let clearlow = rng.gen::<u128>();
+                    let clearhigh = rng.gen::<u128>();
+                    let clear_2 = tfhe::integer::U256::from((clearlow, clearhigh));
+                    let ct_2 = cks.encrypt_radix(clear_2, num_block);
+                    fpga_key.unchecked_add_assign(&mut ct_0, &ct_2);
+
+                    carry_mod -= 1;
+                }
+
+                (ct_0, ct_1, index)
+            };
+
+            b.iter_batched(
+                encrypt_values,
+                |(mut ct_0, mut ct_1, index)| {
+                    op(&fpga_key, &mut ct_0, &mut ct_1, index);
+                },
+                criterion::BatchSize::SmallInput,
+            )
+        });
+
+        fpga_key.disconnect();
+    }
+
+    bench_group.finish()
+}
+
+fn bench_fpga_key_bivariate_function_with_index<F>(c: &mut Criterion, op_name: &str, op: F)
+where
+    F: Fn(&BelfortServerKey, &mut RadixCiphertext, &mut Ciphertext, usize),
+{
+    let mut bench_group = c.benchmark_group(BENCH_GROUP_NAME);
+    bench_group
+        .sample_size(BENCH_SAMPLE_SIZE)
+        .measurement_time(std::time::Duration::from_secs(BENCH_MEASUREMENT_TIME));
+    let mut rng = rand::thread_rng();
+
+    for (param, num_block, bit_size, fpga_count) in ParamsAndConfigsIter::default() {
+        let param_name = get_short_param_name(param);
+        let (cks, sks) = KEY_CACHE.get_from_params(param, IntegerKeyKind::Radix);
+
+        let mut fpga_key = BelfortServerKey::from(&sks);
+        fpga_key.connect();
+
+        let bench_id = format!("{op_name}::{param_name}::{fpga_count}fpga::{bit_size}bit");
+        bench_group.bench_function(&bench_id, |b| {
+            let encrypt_values = || {
+                let clear_0 = gen_random_u256(&mut rng);
+                let ct_0 = cks.encrypt_radix(clear_0, num_block);
+
+                let clear_1 = rng.gen::<u64>();
+                let ct_1 = cks.encrypt_one_block(clear_1);
+
+                let index = rng.gen_range(0..4);
+
+                (ct_0, ct_1, index)
+            };
+
+            b.iter_batched(
+                encrypt_values,
+                |(mut ct_0, mut ct_1, index)| {
+                    op(&fpga_key, &mut ct_0, &mut ct_1, index);
+                },
+                criterion::BatchSize::SmallInput,
+            )
+        });
+
+        fpga_key.disconnect();
+    }
+
+    bench_group.finish()
+}
+
+fn bench_if_then_else(c: &mut Criterion) {
+    let op_name = "if_then_else";
+
+    let mut bench_group = c.benchmark_group(BENCH_GROUP_NAME);
+    bench_group
+        .sample_size(BENCH_SAMPLE_SIZE)
+        .measurement_time(std::time::Duration::from_secs(BENCH_MEASUREMENT_TIME));
+    let mut rng = rand::thread_rng();
+
+    for (param, num_block, bit_size, fpga_count) in ParamsAndConfigsIter::default() {
+        let param_name = get_short_param_name(param);
+
+        let (cks, sks) = KEY_CACHE.get_from_params(param, IntegerKeyKind::Radix);
+
+        let mut fpga_key = BelfortServerKey::from(&sks);
+        let fpga_indexes = (0..fpga_count).collect();
+        fpga_key.connect_to(fpga_indexes);
+
+        let bench_id = format!("{op_name}::{param_name}::{fpga_count}fpga::{bit_size}bit");
+        bench_group.bench_function(&bench_id, |b| {
+            let encrypt_tree_values = || {
+                let clear_0 = gen_random_u256(&mut rng);
+                let ct_0 = cks.encrypt_radix(clear_0, num_block);
+
+                let clear_1 = gen_random_u256(&mut rng);
+                let ct_1 = cks.encrypt_radix(clear_1, num_block);
+
+                let cond = sks.create_trivial_boolean_block(rng.gen_bool(0.5));
+
+                (cond, ct_0, ct_1)
+            };
+
+            b.iter_batched(
+                encrypt_tree_values,
+                |(condition, true_ct, false_ct)| {
+                    fpga_key.if_then_else(&condition, &true_ct, &false_ct)
+                },
+                criterion::BatchSize::SmallInput,
+            )
+        });
+
+        fpga_key.disconnect();
+    }
+
+    bench_group.finish()
+}
+
+////////////////////////////////////////////////////////////////////////////////
+// Bench definition macros
+
+macro_rules! bench_univariate_fn_with_clean_inputs (
+    ($method:ident) => {
+        fn $method(c: &mut Criterion) {
+            bench_fpga_key_univariate_function_clean_inputs(
+                c,
+                stringify!($method),
+                |fpga_key, lhs| { fpga_key.$method(lhs); }
+            );
+        }
+    }
+);
+
+macro_rules! bench_bivariate_fn_with_clean_inputs (
+    ($method:ident) => {
+        fn $method(c: &mut Criterion) {
+            bench_fpga_key_bivariate_function_clean_inputs(
+                c,
+                stringify!($method),
+                |fpga_key, lhs, rhs| {fpga_key.$method(lhs, rhs); }
+            );
+        }
+    }
+);
+
+macro_rules! bench_scalar_bivariate_fn_with_clean_inputs (
+    ($method:ident) => {
+        fn $method(c: &mut Criterion) {
+            bench_fpga_key_bivariate_scalar_function_clean_inputs(
+                c,
+                stringify!($method),
+                |fpga_key, lhs, rhs| {fpga_key.$method(lhs, rhs); }
+            );
+        }
+    }
+);
+
+macro_rules! bench_univariate_fn_with_dirty_inputs (
+    ($method:ident) => {
+        fn $method(c: &mut Criterion) {
+            bench_fpga_key_univariate_function_dirty_inputs(
+                c,
+                stringify!($method),
+                |fpga_key, lhs| { fpga_key.$method(lhs); }
+            );
+        }
+    }
+);
+
+macro_rules! bench_bivariate_fn_with_dirty_inputs (
+    ($method:ident) => {
+        fn $method(c: &mut Criterion) {
+            bench_fpga_key_bivariate_function_dirty_inputs(
+                c,
+                stringify!($method),
+                |fpga_key, lhs, rhs| {fpga_key.$method(lhs, rhs); }
+            );
+        }
+    }
+);
+
+macro_rules! bench_scalar_bivariate_fn_with_dirty_inputs (
+    ($method:ident) => {
+        fn $method(c: &mut Criterion) {
+            bench_fpga_key_bivariate_scalar_function_dirty_inputs(
+                c,
+                stringify!($method),
+                |fpga_key, lhs, rhs| {fpga_key.$method(lhs, rhs); }
+            );
+        }
+    }
+);
+
+macro_rules! bench_bivariate_fn_with_index (
+    ($method:ident) => {
+        fn $method(c: &mut Criterion) {
+            bench_fpga_key_bivariate_function_with_index(
+                c,
+                stringify!($method),
+                |fpga_key, lhs, rhs, index| {fpga_key.$method(lhs, rhs, index); }
+            );
+        }
+    }
+);
+
+macro_rules! bench_bivariate_fn_with_dirty_inputs_with_index (
+    ($method:ident) => {
+        fn $method(c: &mut Criterion) {
+            bench_fpga_key_bivariate_function_dirty_inputs_with_index(
+                c,
+                stringify!($method),
+                |fpga_key, lhs, rhs, index| {fpga_key.$method(lhs, rhs, index); }
+            );
+        }
+    }
+);
+
+////////////////////////////////////////////////////////////////////////////////
+// Benches for Default Ops
+
+bench_univariate_fn_with_dirty_inputs!(full_propagate);
+
+bench_bivariate_fn_with_clean_inputs!(add);
+bench_bivariate_fn_with_clean_inputs!(sub);
+bench_univariate_fn_with_clean_inputs!(neg);
+bench_bivariate_fn_with_clean_inputs!(mul);
+bench_bivariate_fn_with_clean_inputs!(div);
+
+bench_bivariate_fn_with_clean_inputs!(eq);
+bench_bivariate_fn_with_clean_inputs!(ne);
+bench_bivariate_fn_with_clean_inputs!(gt);
+bench_bivariate_fn_with_clean_inputs!(ge);
+bench_bivariate_fn_with_clean_inputs!(lt);
+bench_bivariate_fn_with_clean_inputs!(le);
+bench_bivariate_fn_with_clean_inputs!(max);
+bench_bivariate_fn_with_clean_inputs!(min);
+
+bench_bivariate_fn_with_clean_inputs!(bitand);
+bench_bivariate_fn_with_clean_inputs!(bitor);
+bench_bivariate_fn_with_clean_inputs!(bitxor);
+bench_univariate_fn_with_clean_inputs!(bitnot);
+
+bench_bivariate_fn_with_clean_inputs!(right_shift);
+bench_bivariate_fn_with_clean_inputs!(left_shift);
+bench_bivariate_fn_with_clean_inputs!(rotate_right);
+bench_bivariate_fn_with_clean_inputs!(rotate_left);
+
+bench_univariate_fn_with_clean_inputs!(leading_zeros);
+bench_univariate_fn_with_clean_inputs!(leading_ones);
+bench_univariate_fn_with_clean_inputs!(trailing_zeros);
+bench_univariate_fn_with_clean_inputs!(trailing_ones);
+
+bench_bivariate_fn_with_index!(block_mul);
+
+bench_scalar_bivariate_fn_with_clean_inputs!(scalar_add);
+bench_scalar_bivariate_fn_with_clean_inputs!(scalar_sub);
+bench_scalar_bivariate_fn_with_clean_inputs!(scalar_mul);
+bench_scalar_bivariate_fn_with_clean_inputs!(scalar_eq);
+bench_scalar_bivariate_fn_with_clean_inputs!(scalar_ne);
+
+bench_scalar_bivariate_fn_with_clean_inputs!(scalar_bitand);
+bench_scalar_bivariate_fn_with_clean_inputs!(scalar_bitor);
+bench_scalar_bivariate_fn_with_clean_inputs!(scalar_bitxor);
+
+bench_scalar_bivariate_fn_with_clean_inputs!(scalar_right_shift);
+bench_scalar_bivariate_fn_with_clean_inputs!(scalar_left_shift);
+bench_scalar_bivariate_fn_with_clean_inputs!(scalar_rotate_right);
+bench_scalar_bivariate_fn_with_clean_inputs!(scalar_rotate_left);
+
+////////////////////////////////////////////////////////////////////////////////
+// Benches for Smart Ops
+
+bench_bivariate_fn_with_dirty_inputs!(smart_add);
+bench_bivariate_fn_with_dirty_inputs!(smart_sub);
+bench_univariate_fn_with_dirty_inputs!(smart_neg);
+bench_bivariate_fn_with_dirty_inputs!(smart_mul);
+bench_bivariate_fn_with_dirty_inputs!(smart_div);
+
+bench_bivariate_fn_with_dirty_inputs!(smart_eq);
+bench_bivariate_fn_with_dirty_inputs!(smart_ne);
+bench_bivariate_fn_with_dirty_inputs!(smart_gt);
+bench_bivariate_fn_with_dirty_inputs!(smart_ge);
+bench_bivariate_fn_with_dirty_inputs!(smart_lt);
+bench_bivariate_fn_with_dirty_inputs!(smart_le);
+bench_bivariate_fn_with_dirty_inputs!(smart_max);
+bench_bivariate_fn_with_dirty_inputs!(smart_min);
+
+bench_bivariate_fn_with_dirty_inputs!(smart_bitand);
+bench_bivariate_fn_with_dirty_inputs!(smart_bitor);
+bench_bivariate_fn_with_dirty_inputs!(smart_bitxor);
+
+bench_bivariate_fn_with_dirty_inputs!(smart_right_shift);
+bench_bivariate_fn_with_dirty_inputs!(smart_left_shift);
+bench_bivariate_fn_with_dirty_inputs!(smart_rotate_right);
+bench_bivariate_fn_with_dirty_inputs!(smart_rotate_left);
+
+bench_bivariate_fn_with_dirty_inputs_with_index!(smart_block_mul);
+
+bench_scalar_bivariate_fn_with_dirty_inputs!(smart_scalar_add);
+bench_scalar_bivariate_fn_with_dirty_inputs!(smart_scalar_sub);
+bench_scalar_bivariate_fn_with_dirty_inputs!(smart_scalar_mul);
+bench_scalar_bivariate_fn_with_dirty_inputs!(smart_scalar_eq);
+bench_scalar_bivariate_fn_with_dirty_inputs!(smart_scalar_ne);
+
+bench_scalar_bivariate_fn_with_dirty_inputs!(smart_scalar_bitand);
+bench_scalar_bivariate_fn_with_dirty_inputs!(smart_scalar_bitor);
+bench_scalar_bivariate_fn_with_dirty_inputs!(smart_scalar_bitxor);
+
+bench_scalar_bivariate_fn_with_dirty_inputs!(smart_scalar_rotate_right);
+bench_scalar_bivariate_fn_with_dirty_inputs!(smart_scalar_rotate_left);
+
+////////////////////////////////////////////////////////////////////////////////
+// Default Benchmark Groups
+
+criterion_group!(default_negation, neg);
+criterion_group!(default_addsub, add, sub);
+criterion_group!(default_mult, mul, block_mul, smart_block_mul);
+criterion_group!(default_equalities, eq, ne);
+criterion_group!(default_comparisons, gt, ge, lt, le);
+criterion_group!(default_max_min, max, min);
+criterion_group!(default_bitwise_ops, bitand, bitor, bitxor, bitnot);
+criterion_group!(default_div_rem, div,);
+criterion_group!(default_shifts, right_shift, left_shift);
+criterion_group!(default_rotations, rotate_right, rotate_left);
+criterion_group!(
+    default_leading_trailing,
+    leading_zeros,
+    leading_ones,
+    trailing_zeros,
+    trailing_ones
+);
+criterion_group!(
+    default_scalar,
+    scalar_add,
+    scalar_sub,
+    scalar_mul,
+    scalar_eq,
+    scalar_ne,
+    scalar_bitand,
+    scalar_bitor,
+    scalar_bitxor,
+    scalar_right_shift,
+    scalar_left_shift,
+    scalar_rotate_right,
+    scalar_rotate_left
+);
+// criterion_group!(default_log2, ...);
+// criterion_group!(default_select, ...);
+
+////////////////////////////////////////////////////////////////////////////////
+// Smart Benchmark Groups
+
+criterion_group!(smart_negation, smart_neg);
+criterion_group!(smart_addsub, smart_add, smart_sub);
+criterion_group!(smart_mult, smart_mul);
+criterion_group!(smart_equalities, smart_eq, smart_ne);
+criterion_group!(smart_comparisons, smart_gt, smart_ge, smart_lt, smart_le);
+criterion_group!(smart_max_min, smart_max, smart_min);
+criterion_group!(smart_bitwise_ops, smart_bitand, smart_bitor, smart_bitxor);
+criterion_group!(smart_div_rem, smart_div);
+criterion_group!(smart_shifts, smart_right_shift, smart_left_shift);
+criterion_group!(smart_rotations, smart_rotate_right, smart_rotate_left);
+criterion_group!(
+    smart_scalar,
+    smart_scalar_add,
+    smart_scalar_sub,
+    smart_scalar_mul,
+    smart_scalar_eq,
+    smart_scalar_ne,
+    smart_scalar_bitand,
+    smart_scalar_bitor,
+    smart_scalar_bitxor,
+    smart_scalar_rotate_right,
+    smart_scalar_rotate_left
+);
+
+////////////////////////////////////////////////////////////////////////////////
+// Misc Benchmark Groups
+
+criterion_group!(misc_ops, full_propagate);
+
+////////////////////////////////////////////////////////////////////////////////
+
+fn go_through_fpga_bench_groups(val: &str) {
+    match val.to_lowercase().as_str() {
+        "default" => {
+            default_negation();
+            default_addsub();
+            default_mult();
+            default_equalities();
+            default_comparisons();
+            default_max_min();
+            default_bitwise_ops();
+            default_div_rem();
+            default_shifts();
+            default_rotations();
+            default_leading_trailing();
+            default_scalar();
+        }
+        "smart" => {
+            smart_negation();
+            smart_addsub();
+            smart_mult();
+            smart_equalities();
+            smart_comparisons();
+            smart_max_min();
+            smart_bitwise_ops();
+            smart_div_rem();
+            smart_shifts();
+            smart_rotations();
+            smart_scalar();
+        }
+        "misc" => {
+            misc_ops();
+        }
+        _ => {
+            panic!("unknown benchmark operations flavor");
+        }
+    };
+}
+
+fn main() {
+    match env::var("__TFHE_RS_BENCH_OP_FLAVOR") {
+        Ok(val) => {
+            go_through_fpga_bench_groups(&val);
+        }
+        Err(_) => {}
+    };
+
+    Criterion::default().configure_from_args().final_summary();
+}
diff --git a/tfhe/benches/fpga/plot_throughput.py b/tfhe/benches/fpga/plot_throughput.py
new file mode 100644
index 000000000..a7206a31d
--- /dev/null
+++ b/tfhe/benches/fpga/plot_throughput.py
@@ -0,0 +1,194 @@
+import os
+from helpers import get_median_data
+import matplotlib.pyplot as plt
+import numpy as np
+
+# Define global constants
+BENCH_THROUGHPUT_RELATIVE_PATH = "../../../target/criterion/fpga__throughput/"
+BASE_PATH = os.path.abspath(
+    os.path.join(os.path.dirname(__file__), BENCH_THROUGHPUT_RELATIVE_PATH)
+)
+
+
+# Extract parameter name, FPGA count, and pack size from folder names.
+def extract_info():
+    bench_results = []
+
+    for folder_name in os.listdir(BASE_PATH):
+        sub_folder_path = os.path.join(BASE_PATH, folder_name)
+        if (
+            os.path.isdir(sub_folder_path)
+            and "__FpgaCount" in folder_name
+            and "__PackSize" in folder_name
+        ):
+            parts = folder_name.split("__")
+            parameter_name = "__".join(parts[:-2])
+            fpga_count = parts[-2].replace("FpgaCount", "")
+            pack_size = parts[-1].replace("PackSize", "")
+            bench_results.append(
+                {
+                    "parameter_name": parameter_name,
+                    "fpga_count": fpga_count,
+                    "pack_size": pack_size,
+                }
+            )
+
+    return bench_results
+
+
+# Group pack sizes by parameter name and FPGA count.
+def filter_and_list_pack_sizes(bench_results):
+    filtered_info = {}
+    for info in bench_results:
+        key = (info["parameter_name"], info["fpga_count"])
+        if key not in filtered_info:
+            filtered_info[key] = []
+        filtered_info[key].append(info["pack_size"])
+    return filtered_info
+
+
+# Plot pack sizes vs. median results on both linear and log scales for X-axis, with a table of data on the right, for each parameter set.
+def plot_data(filtered_info):
+
+    # Define a colormap for different FPGA counts
+    cmap = plt.colormaps.get_cmap("tab20")
+
+    # Group by parameter name
+    parameter_groups = {}
+    for key, pack_sizes in filtered_info.items():
+        parameter_name, fpga_count = key
+        if parameter_name not in parameter_groups:
+            parameter_groups[parameter_name] = {}
+        parameter_groups[parameter_name][fpga_count] = pack_sizes
+
+    # Plot each parameter name
+    for parameter_name, fpga_data in parameter_groups.items():
+        plt.figure(figsize=(21, 7))  # Wider figure to accommodate the table
+
+        # Initialize subplots: Linear scale, Log scale, and Table
+        ax1 = plt.subplot(1, 3, 1)
+        ax2 = plt.subplot(1, 3, 2)
+        ax3 = plt.subplot(1, 3, 3)
+
+        # Collect data for the table
+        table_data = []
+        column_labels = ["Pack Size"] + [
+            f"FPGA Count {fc}" for fc in sorted(fpga_data.keys())
+        ]
+
+        # Collect unique pack sizes
+        all_pack_sizes = set()
+        for pack_sizes in fpga_data.values():
+            all_pack_sizes.update(pack_sizes)
+        all_pack_sizes = sorted(map(int, all_pack_sizes))
+
+        # Create the table data structure
+        for pack_size in all_pack_sizes:
+            row = [pack_size]
+            for fpga_count in sorted(fpga_data.keys()):
+                json_folder = os.path.join(
+                    BASE_PATH,
+                    f"{parameter_name}__FpgaCount{fpga_count}__PackSize{pack_size}",
+                )
+                median_point_estimate = get_median_data(json_folder, "new")
+                row.append(
+                    f"{median_point_estimate:.2f}"
+                    if median_point_estimate is not None
+                    else "N/A"
+                )
+            table_data.append(row)
+
+        # Get list of colors from the colormap
+        fpga_count_len = len(fpga_data.keys())
+        colors = [cmap(i) for i in np.linspace(0, 1, fpga_count_len)]
+
+        # Plot each FPGA count
+        for idx, (fpga_count, pack_sizes) in enumerate(fpga_data.items()):
+            x = []
+            y = []
+
+            for pack_size in pack_sizes:
+                json_folder = os.path.join(
+                    BASE_PATH,
+                    f"{parameter_name}__FpgaCount{fpga_count}__PackSize{pack_size}",
+                )
+
+                median_point_estimate = get_median_data(json_folder, "new")
+                if median_point_estimate is not None:
+                    x.append(int(pack_size))
+                    y.append(median_point_estimate)
+
+            if x and y:
+                # Sort x and corresponding y
+                sorted_indices = sorted(range(len(x)), key=lambda i: x[i])
+                x_sorted = [x[i] for i in sorted_indices]
+                y_sorted = [y[i] for i in sorted_indices]
+
+                # Plot with linear X scale
+                ax1.plot(
+                    x_sorted,
+                    y_sorted,
+                    marker="o",
+                    linestyle="-",
+                    color=colors[idx],
+                    label=f"FPGA Count {fpga_count}",
+                )
+                ax1.set_xlabel("Pack Size")
+                ax1.set_ylabel("Median Result (us)")
+                ax1.set_title(f"{parameter_name} - Linear Scale")
+                ax1.grid(True)
+                ax1.legend()
+
+                # Plot with log X scale
+                ax2.plot(
+                    x_sorted,
+                    y_sorted,
+                    marker="o",
+                    linestyle="-",
+                    color=colors[idx],
+                    label=f"FPGA Count {fpga_count}",
+                )
+                ax2.set_xlabel("Pack Size")
+                ax2.set_ylabel("Median Result (us)")
+                ax2.set_title(f"{parameter_name} - Log Scale")
+                ax2.set_xscale("log")
+                ax2.grid(True)
+                ax2.legend()
+
+        # Add a table of data
+        ax3.axis("off")  # Hide the axis for the table subplot
+        table = ax3.table(
+            cellText=table_data,
+            colLabels=column_labels,
+            cellLoc="center",
+            loc="center",
+            bbox=[0.05, 0.1, 0.9, 0.8],
+        )  # Adjust bbox for position and size
+        table.auto_set_font_size(False)
+        table.set_fontsize(8)
+
+        # Add table title
+        ax3.text(
+            0.5,
+            1.05,
+            "KSPBS Execution Times (in us)",
+            ha="center",
+            va="center",
+            fontsize=10,
+            weight="bold",
+            transform=ax3.transAxes,
+        )
+
+        # Save the figure with plots for the parameter name
+        png_file_path = os.path.join(BASE_PATH, f"{parameter_name}.png")
+        plt.tight_layout()
+        plt.savefig(png_file_path)
+        plt.close()
+        print(f"Saved plot to {png_file_path}")
+
+
+# Main execution
+if __name__ == "__main__":
+    bench_results = extract_info()
+    filtered_info = filter_and_list_pack_sizes(bench_results)
+    plot_data(filtered_info)
diff --git a/tfhe/benches/fpga/report_integers.py b/tfhe/benches/fpga/report_integers.py
new file mode 100644
index 000000000..1a4eb0bee
--- /dev/null
+++ b/tfhe/benches/fpga/report_integers.py
@@ -0,0 +1,163 @@
+import os
+import re
+from datetime import datetime
+from collections import defaultdict
+from helpers import format_median, get_median_data, BASE_BENCH_OUTPUT_PATH
+
+
+# Extract parameter name, FPGA count, ... from folder names
+def extract_info():
+    bench_results = []
+
+    def extract_number(s):
+        match = re.search(r"\d+", s)
+        return int(match.group()) if match else None
+
+    for folder_name in os.listdir(BASE_BENCH_OUTPUT_PATH):
+        sub_folder_path = os.path.join(BASE_BENCH_OUTPUT_PATH, folder_name)
+
+        if (
+            os.path.isdir(sub_folder_path)
+            and "fpga" in folder_name
+            and "bit" in folder_name
+        ):
+            parts = folder_name.split("__")
+            operation_name = parts[0]
+            parameter_name = parts[1]
+            fpga_count = extract_number(parts[2])
+            bit_length = extract_number(parts[3])
+            creation_time = datetime.fromtimestamp(os.path.getctime(sub_folder_path))
+            bench_results.append(
+                {
+                    "operation_name": operation_name,
+                    "parameter_name": parameter_name,
+                    "fpga_count": fpga_count,
+                    "bit_length": bit_length,
+                    "creation_date": creation_time.strftime("%Y-%m-%d %H:%M:%S"),
+                }
+            )
+
+    return bench_results
+
+
+def get_operation_names(bench_results):
+    return sorted({result["operation_name"] for result in bench_results})
+
+
+def get_parameter_names(bench_results):
+    return sorted({result["parameter_name"] for result in bench_results})
+
+
+def get_fpga_counts(bench_results):
+    return sorted({result["fpga_count"] for result in bench_results})
+
+
+def get_bit_lengths(bench_results):
+    return sorted({result["bit_length"] for result in bench_results})
+
+
+# Main execution
+if __name__ == "__main__":
+
+    bench_results = extract_info()
+
+    operation_names = get_operation_names(bench_results)
+    parameter_names = get_parameter_names(bench_results)
+    fpga_counts = get_fpga_counts(bench_results)
+    bit_lengths = get_bit_lengths(bench_results)
+
+    os.makedirs(BASE_BENCH_OUTPUT_PATH, exist_ok=True)
+
+    for parameter_name in parameter_names:
+
+        markdown_file = os.path.join(
+            BASE_BENCH_OUTPUT_PATH, f"Param_{parameter_name}.md"
+        )
+
+        with open(markdown_file, "w") as md_file:
+
+            md_file.write(f"# Benchmarks for {parameter_name}\n\n")
+
+            for fpga_count in fpga_counts:
+
+                table_data = []
+
+                for operation_name in operation_names:
+
+                    for bit_length in bit_lengths:
+
+                        log_folder = os.path.join(
+                            BASE_BENCH_OUTPUT_PATH,
+                            f"{operation_name}__{parameter_name}__{fpga_count}fpga__{bit_length}bit",
+                        )
+                        log_folder_creation_time = datetime.fromtimestamp(
+                            os.path.getctime(log_folder)
+                        ).strftime("%Y-%m-%d %H:%M:%S")
+
+                        median = get_median_data(log_folder, "new")
+
+                        table_data.append(
+                            {
+                                "operation_name": operation_name,
+                                "bit_length": bit_length,
+                                "log": median,
+                                "creation_time": log_folder_creation_time,
+                            }
+                        )
+
+                # Print the results
+                # In the order of creation time, other wise alphabetical order of
+                # operation names are make a weird table, with add at top sub at
+                # bottom, unrelated ops in between.
+
+                sorted_data = [
+                    [item["operation_name"], item["bit_length"], item["log"]]
+                    for item in sorted(table_data, key=lambda x: (x["creation_time"]))
+                ]
+
+                operation_logs = defaultdict(lambda: {})
+                for operation, bit_length, log in sorted_data:
+                    operation_logs[operation][bit_length] = log
+
+                markdown_table = f"## FPGA Count: {fpga_count}\n\n"
+
+                markdown_table += (
+                    "| Operation | "
+                    + " | ".join(
+                        [
+                            f"{bit_length}-bit"
+                            for bit_length in sorted(
+                                operation_logs[next(iter(operation_logs))].keys()
+                            )
+                        ]
+                    )
+                    + " |\n"
+                )
+                markdown_table += "|-----------|"
+                markdown_table += (
+                    ":| ".join(
+                        [
+                            "---"
+                            for _ in sorted(
+                                operation_logs[next(iter(operation_logs))].keys()
+                            )
+                        ]
+                    )
+                    + ":|\n"
+                )
+
+                for operation, logs in operation_logs.items():
+                    markdown_table += (
+                        f"| {operation} | "
+                        + " | ".join(
+                            [
+                                format_median(logs.get(bit_length, ""))
+                                for bit_length in sorted(logs.keys())
+                            ]
+                        )
+                        + " |\n"
+                    )
+
+                markdown_table += "\n\n"
+
+                md_file.write(markdown_table)
diff --git a/tfhe/benches/fpga/throughput.rs b/tfhe/benches/fpga/throughput.rs
new file mode 100644
index 000000000..103d27013
--- /dev/null
+++ b/tfhe/benches/fpga/throughput.rs
@@ -0,0 +1,160 @@
+use criterion::{black_box, criterion_group, Criterion};
+use std::env;
+use tfhe::core_crypto::fpga::lookup_vector::LookupVector;
+
+use tfhe::core_crypto::fpga::keyswitch_bootstrap::KeyswitchBootstrapPacked;
+use tfhe::core_crypto::fpga::utils::Connect;
+use tfhe::core_crypto::fpga::BelfortFpgaUtils;
+
+use tfhe::boolean::ciphertext::Ciphertext as BooleanCiphertext;
+use tfhe::boolean::client_key::ClientKey as BooleanClientKey;
+use tfhe::boolean::parameters::{BooleanParameters, DEFAULT_PARAMETERS_KS_PBS};
+use tfhe::boolean::server_key::ServerKey as BooleanServerKey;
+
+use tfhe::keycache::NamedParam;
+use tfhe::shortint::ciphertext::Ciphertext as ShortintCiphertext;
+use tfhe::shortint::client_key::ClientKey as ShortintClientKey;
+use tfhe::shortint::parameters::{ClassicPBSParameters, PARAM_MESSAGE_2_CARRY_2_KS_PBS};
+use tfhe::shortint::server_key::ServerKey as ShortintServerKey;
+
+const BOOLEAN_PARAMS: BooleanParameters = DEFAULT_PARAMETERS_KS_PBS;
+const SHORTINT_PARAMS: ClassicPBSParameters = PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+const PACK_SIZES: [usize; 18] = [
+    1, 2, 3, 4, 6, 8, 10, 12, 16, 24, 32, 48, 64, 96, 128, 256, 512, 1024,
+];
+const FPGA_COUNTS: [usize; 3] = [1, 2, 4];
+
+fn bench_boolean_throughput(c: &mut Criterion) {
+    let params = BOOLEAN_PARAMS;
+    let pack_sizes = PACK_SIZES.to_vec();
+    let fpga_counts = FPGA_COUNTS.to_vec();
+
+    let mut bench_group = c.benchmark_group("fpga::throughput");
+
+    let params_name = params.name();
+
+    let cks = BooleanClientKey::new(&params);
+    let sks = BooleanServerKey::new(&cks);
+
+    let mut fpga_utils = BelfortFpgaUtils::default();
+    for fpga_count in fpga_counts {
+        let fpga_indexes = (0..fpga_count).collect();
+        fpga_utils.connect_to(&sks, fpga_indexes);
+
+        for pack_size in pack_sizes.clone() {
+            let id = format!("{params_name}::FpgaCount{fpga_count}::PackSize{pack_size}");
+
+            let mut ciphertexts: Vec<BooleanCiphertext> =
+                (0..pack_size).map(|_| cks.encrypt(true)).collect();
+
+            let luts: &[LookupVector] = (0..pack_size).map(|_| LookupVector::boolean()).collect();
+
+            bench_group.bench_function(&id, |b| {
+                b.iter(|| black_box(fpga_utils.keyswitch_bootstrap_packed(&mut ciphertexts, &luts)))
+            });
+        }
+
+        fpga_utils.disconnect();
+    }
+}
+
+fn bench_shortint_throughput(c: &mut Criterion) {
+    let params = SHORTINT_PARAMS;
+    let pack_sizes = PACK_SIZES.to_vec();
+    let fpga_counts = FPGA_COUNTS.to_vec();
+
+    let mut bench_group = c.benchmark_group("fpga::throughput");
+
+    let params_name = params.name();
+
+    let cks = ShortintClientKey::new(params);
+    let sks = ShortintServerKey::new(&cks);
+
+    let mut fpga_utils = BelfortFpgaUtils::default();
+
+    for fpga_count in fpga_counts {
+        let fpga_indexes = (0..fpga_count).collect();
+        fpga_utils.connect_to(&sks, fpga_indexes);
+
+        for pack_size in pack_sizes.clone() {
+            let id = format!("{params_name}::FpgaCount{fpga_count}::PackSize{pack_size}");
+
+            let mut ciphertexts: Vec<ShortintCiphertext> =
+                (0..pack_size).map(|_| cks.encrypt(1)).collect();
+
+            let identity_lut = {
+                let func = |x| x;
+                sks.generate_lookup_vector(&func)
+            };
+
+            let luts: Vec<LookupVector> = (0..pack_size).map(|_| identity_lut).collect();
+
+            bench_group.bench_function(&id, |b| {
+                b.iter(|| black_box(fpga_utils.keyswitch_bootstrap_packed(&mut ciphertexts, &luts)))
+            });
+        }
+
+        fpga_utils.disconnect();
+    }
+}
+
+fn bench_shortint_throughput_cpu(c: &mut Criterion) {
+    let params = SHORTINT_PARAMS;
+    let pack_sizes = PACK_SIZES.to_vec();
+
+    let mut bench_group = c.benchmark_group("fpga::throughput");
+
+    let params_name = params.name();
+
+    let cks = ShortintClientKey::new(params);
+    let sks = ShortintServerKey::new(&cks);
+
+    for pack_size in pack_sizes.clone() {
+        let id = format!("{params_name}::FpgaCount0::PackSize{pack_size}");
+
+        let mut ciphertexts: Vec<ShortintCiphertext> =
+            (0..pack_size).map(|_| cks.encrypt(1)).collect();
+
+        let identity_lut = {
+            let func = |x| x;
+            sks.generate_lookup_vector(&func)
+        };
+
+        let luts: Vec<LookupVector> = (0..pack_size).map(|_| identity_lut).collect();
+
+        bench_group.bench_function(&id, |b| {
+            b.iter(|| black_box(sks.apply_lookup_vector_packed_assign(&mut ciphertexts, &luts)))
+        });
+    }
+}
+
+criterion_group!(bench_boolean, bench_boolean_throughput);
+criterion_group!(bench_shortint, bench_shortint_throughput);
+criterion_group!(bench_shortint_cpu, bench_shortint_throughput_cpu);
+
+fn main() {
+    match env::var("__TFHE_RS_BENCH_OP_FLAVOR") {
+        Ok(val) => {
+            match val.to_lowercase().as_str() {
+                "default" | "only_shortint" => {
+                    bench_shortint();
+                }
+                "only_boolean" => {
+                    bench_boolean();
+                }
+                "all" => {
+                    bench_shortint();
+                    bench_boolean();
+                }
+                "cpu" => {
+                    bench_shortint_cpu();
+                }
+                _ => {
+                    panic!("unknown benchmark operations flavor");
+                }
+            };
+        }
+        Err(_) => {}
+    };
+    Criterion::default().configure_from_args().final_summary();
+}
diff --git a/tfhe/benches/integer/bench.rs b/tfhe/benches/integer/bench.rs
index d6ead085b..621fa5afd 100644
--- a/tfhe/benches/integer/bench.rs
+++ b/tfhe/benches/integer/bench.rs
@@ -1056,26 +1056,7 @@ define_server_key_bench_scalar_default_fn!(
     display_name: not_equal,
     rng_func: default_scalar
 );
-define_server_key_bench_scalar_default_fn!(
-    method_name: scalar_le_parallelized,
-    display_name: less_or_equal,
-    rng_func: default_scalar
-);
-define_server_key_bench_scalar_default_fn!(
-    method_name: scalar_lt_parallelized,
-    display_name: less_than,
-    rng_func: default_scalar
-);
-define_server_key_bench_scalar_default_fn!(
-    method_name: scalar_ge_parallelized,
-    display_name: greater_or_equal,
-    rng_func: default_scalar
-);
-define_server_key_bench_scalar_default_fn!(
-    method_name: scalar_gt_parallelized,
-    display_name: greater_than,
-    rng_func: default_scalar
-);
+
 define_server_key_bench_scalar_default_fn!(
     method_name: scalar_max_parallelized,
     display_name: max,
@@ -2573,9 +2554,7 @@ criterion_group!(
 criterion_group!(
     default_parallelized_ops,
     neg_parallelized,
-    abs_parallelized,
     add_parallelized,
-    unsigned_overflowing_add_parallelized,
     sub_parallelized,
     unsigned_overflowing_sub_parallelized,
     mul_parallelized,
@@ -2602,16 +2581,20 @@ criterion_group!(
     count_ones_parallelized,
 );
 
+criterion_group!(default_parallelized_ops_comp, if_then_else_parallelized,);
+
 criterion_group!(
-    default_parallelized_ops_comp,
+    default_dedup_ops,
+    add_parallelized,
+    mul_parallelized,
+    div_rem_parallelized,
+    bitand_parallelized,
+    bitnot,
+    left_shift_parallelized,
+    rotate_left_parallelized,
     max_parallelized,
-    min_parallelized,
     eq_parallelized,
-    ne_parallelized,
-    lt_parallelized,
-    le_parallelized,
     gt_parallelized,
-    ge_parallelized,
     if_then_else_parallelized,
 );
 
@@ -2667,26 +2650,11 @@ criterion_group!(
 criterion_group!(
     default_scalar_parallelized_ops,
     scalar_add_parallelized,
-    unsigned_overflowing_scalar_add_parallelized,
     scalar_sub_parallelized,
-    unsigned_overflowing_scalar_sub_parallelized,
-    scalar_mul_parallelized,
-    scalar_div_parallelized,
-    scalar_rem_parallelized,
-    // scalar_div_rem_parallelized,
-    scalar_left_shift_parallelized,
-    scalar_right_shift_parallelized,
-    scalar_rotate_left_parallelized,
-    scalar_rotate_right_parallelized,
-    scalar_bitand_parallelized,
-    scalar_bitor_parallelized,
-    scalar_bitxor_parallelized,
 );
 
 criterion_group!(
     default_scalar_parallelized_ops_comp,
-    scalar_eq_parallelized,
-    scalar_ne_parallelized,
     scalar_lt_parallelized,
     scalar_le_parallelized,
     scalar_gt_parallelized,
@@ -2886,7 +2854,7 @@ fn go_through_gpu_bench_groups(val: &str) {
 fn go_through_cpu_bench_groups(val: &str) {
     match val.to_lowercase().as_str() {
         "default" => {
-            default_parallelized_ops();
+            //default_parallelized_ops();
             default_parallelized_ops_comp();
             default_scalar_parallelized_ops();
             default_scalar_parallelized_ops_comp();
diff --git a/tfhe/build.rs b/tfhe/build.rs
index ee078e570..54f70615e 100644
--- a/tfhe/build.rs
+++ b/tfhe/build.rs
@@ -1,3 +1,5 @@
+extern crate bindgen;
+
 #[cfg(all(feature = "__c_api", not(feature = "__force_skip_cbindgen")))]
 fn gen_c_api() {
     use std::env;
@@ -79,5 +81,40 @@ fn gen_c_api() {
 
 fn main() {
     #[cfg(all(feature = "__c_api", not(feature = "__force_skip_cbindgen")))]
-    gen_c_api()
+    gen_c_api();
+
+    #[cfg(feature = "fpga")]
+    {
+        use std::env;
+
+        let belfort_home = env::var("BELFORT_HOME").ok();
+        let xrt_home = env::var("XILINX_XRT").ok();
+
+        let mut ld_library_path = String::new();
+
+        if let Some(path) = &belfort_home {
+            let belfort_lib_path = format!("{}/interface/lib", path);
+            println!("cargo:rustc-link-search={}", belfort_lib_path);
+            println!("cargo:rustc-link-lib=interfacelib");
+
+            ld_library_path.push_str(&belfort_lib_path);
+            ld_library_path.push(':');
+        } else {
+            panic!("FPGA feature is enabled, but BELFORT_HOME is not set!");
+        }
+
+        if let Some(path) = &xrt_home {
+            let xrt_lib_path = format!("{}/lib", path);
+            println!("cargo:rustc-link-search={}", xrt_lib_path);
+            println!("cargo:rustc-link-lib=xrt_coreutil");
+
+            ld_library_path.push_str(&xrt_lib_path);
+            ld_library_path.push(':');
+        }
+
+        if !ld_library_path.is_empty() {
+            ld_library_path.push_str("$LD_LIBRARY_PATH");
+            println!("cargo:rustc-env=LD_LIBRARY_PATH={}", ld_library_path);
+        }
+    }
 }
diff --git a/tfhe/c_api_tests/test_boolean_keygen.c b/tfhe/c_api_tests/test_boolean_keygen.c
index 4fcb6f240..b5883444f 100644
--- a/tfhe/c_api_tests/test_boolean_keygen.c
+++ b/tfhe/c_api_tests/test_boolean_keygen.c
@@ -1,4 +1,4 @@
-#include "tfhe.h"
+#include <tfhe.h>
 #include <assert.h>
 #include <inttypes.h>
 #include <stdio.h>
diff --git a/tfhe/c_api_tests/test_boolean_server_key.c b/tfhe/c_api_tests/test_boolean_server_key.c
index 3e2ec9373..6d271ff56 100644
--- a/tfhe/c_api_tests/test_boolean_server_key.c
+++ b/tfhe/c_api_tests/test_boolean_server_key.c
@@ -1,4 +1,4 @@
-#include "tfhe.h"
+#include <tfhe.h>
 #include <assert.h>
 #include <inttypes.h>
 #include <stdio.h>
diff --git a/tfhe/c_api_tests/test_high_level_zk.c b/tfhe/c_api_tests/test_high_level_zk.c
index 093dfbf48..c620c5477 100644
--- a/tfhe/c_api_tests/test_high_level_zk.c
+++ b/tfhe/c_api_tests/test_high_level_zk.c
@@ -1,4 +1,4 @@
-#include "tfhe.h"
+#include <tfhe.h>
 #include <assert.h>
 #include <stdlib.h>
 
diff --git a/tfhe/c_api_tests/test_micro_bench_and.c b/tfhe/c_api_tests/test_micro_bench_and.c
index 936474b5b..a0c5f31c7 100644
--- a/tfhe/c_api_tests/test_micro_bench_and.c
+++ b/tfhe/c_api_tests/test_micro_bench_and.c
@@ -1,4 +1,4 @@
-#include "tfhe.h"
+#include <tfhe.h>
 #include <assert.h>
 #include <inttypes.h>
 #include <stdio.h>
diff --git a/tfhe/c_api_tests/test_shortint_keygen.c b/tfhe/c_api_tests/test_shortint_keygen.c
index c603c802f..926b804a5 100644
--- a/tfhe/c_api_tests/test_shortint_keygen.c
+++ b/tfhe/c_api_tests/test_shortint_keygen.c
@@ -1,4 +1,4 @@
-#include "tfhe.h"
+#include <tfhe.h>
 #include <assert.h>
 #include <inttypes.h>
 #include <stdio.h>
diff --git a/tfhe/c_api_tests/test_shortint_pbs.c b/tfhe/c_api_tests/test_shortint_pbs.c
index c960aecf9..9e5aa1a98 100644
--- a/tfhe/c_api_tests/test_shortint_pbs.c
+++ b/tfhe/c_api_tests/test_shortint_pbs.c
@@ -1,4 +1,4 @@
-#include "tfhe.h"
+#include <tfhe.h>
 #include <assert.h>
 #include <inttypes.h>
 #include <stdio.h>
diff --git a/tfhe/c_api_tests/test_shortint_server_key.c b/tfhe/c_api_tests/test_shortint_server_key.c
index 9622e9714..8e57e005d 100644
--- a/tfhe/c_api_tests/test_shortint_server_key.c
+++ b/tfhe/c_api_tests/test_shortint_server_key.c
@@ -1,4 +1,4 @@
-#include "tfhe.h"
+#include <tfhe.h>
 #include <assert.h>
 #include <inttypes.h>
 #include <stdio.h>
diff --git a/tfhe/docs/guides/debug.md b/tfhe/docs/guides/debug.md
new file mode 100644
index 000000000..c6b942052
--- /dev/null
+++ b/tfhe/docs/guides/debug.md
@@ -0,0 +1,72 @@
+# Debugging FHE Code
+
+Since tfhe-rs 0.5, [trivial ciphertexts](./trivial_ciphertext.md) have another application.
+They can be used to allow debugging via a debugger or print statements as well as speeding-up execution time
+so that you won't have to spend minutes waiting for execution to progress.
+
+This can greatly improve the pace at which one develops FHE applications.
+
+{% hint style="warning" %}
+Keep in mind that trivial ciphertexts are not secure at all, thus an application released/deployed in production
+must never receive trivial ciphertext from a client.
+{% endhint %}
+
+
+## Example
+
+To use this feature, simply call your circuits/functions with trivially encrypted values (made using `encrypt_trivial`)
+instead of real encryptions (made using `encrypt`)
+
+```rust
+use tfhe::prelude::*;
+use tfhe::{set_server_key, generate_keys, ConfigBuilder, FheUint128};
+
+
+fn mul_all(a: &FheUint128, b: &FheUint128, c: &FheUint128) -> FheUint128 {
+    // Use the debug format ('{:?}'), if you don't want to unwrap()
+    // and panic if the value is not a trivial.
+    println!(
+        "a: {:?}, b: {:?}, c: {:?}", 
+        a.try_decrypt_trivial::<u128>(),
+        b.try_decrypt_trivial::<u128>(),
+        c.try_decrypt_trivial::<u128>(),
+    );
+    let tmp = a * b;
+    
+    println!("a * b = {:?}", tmp.try_decrypt_trivial::<u128>());
+
+    tmp * c
+}
+
+
+fn main() {
+    let (cks, sks) = generate_keys(ConfigBuilder::default().build());
+    
+    set_server_key(sks);
+    
+    let a = FheUint128::encrypt_trivial(1234u128);
+    let b = FheUint128::encrypt_trivial(4567u128);
+    let c = FheUint128::encrypt_trivial(89101112u128);
+    
+    // since all inputs are trivially encrypted, this is going to be
+    // much faster
+    let result = mul_all(&a, &b, &c);
+}
+```
+
+This example is going to print.
+```text
+a: Ok(1234), b: Ok(4567), c: Ok(89101112)
+a * b = Ok(5635678)
+```
+
+If any input to `mul_all` is not a trivial ciphertexts, the computations would be done 100% in FHE, and the program
+would output:
+
+```text
+a: Err(NotTrivialCiphertextError), b: Err(NotTrivialCiphertextError), c: Err(NotTrivialCiphertextError)
+a * b = Err(NotTrivialCiphertextError)
+```
+
+Using trivial encryptions as input, the example runs in **980 ms** on a standard 12 cores laptop, using real encryptions
+it would run in **7.5 seconds** on a 128-core machine.
diff --git a/tfhe/examples/sha256.rs b/tfhe/examples/sha256.rs
index dbc518275..21027473f 100644
--- a/tfhe/examples/sha256.rs
+++ b/tfhe/examples/sha256.rs
@@ -226,6 +226,10 @@ fn main() -> Result<(), std::io::Error> {
             });
             set_server_key(server_key);
         }
+        #[cfg(feature = "fpga")]
+        (Device::Fpga, true) => todo!(),
+        #[cfg(feature = "fpga")]
+        (Device::Fpga, false) => todo!(),
     }
     println!("key gen end");
 
diff --git a/tfhe/js_on_wasm_tests/test-hlapi-unsigned.js b/tfhe/js_on_wasm_tests/test-hlapi-unsigned.js
index f71da7014..337c474df 100644
--- a/tfhe/js_on_wasm_tests/test-hlapi-unsigned.js
+++ b/tfhe/js_on_wasm_tests/test-hlapi-unsigned.js
@@ -21,6 +21,7 @@ const {
 const {
     randomBytes,
 } = require('node:crypto');
+const {FheUint2048} = require("../pkg");
 
 const U256_MAX = BigInt("115792089237316195423570985008687907853269984665640564039457584007913129639935");
 const U128_MAX = BigInt("340282366920938463463374607431768211455");
diff --git a/tfhe/src/boolean/engine/bootstrapping.rs b/tfhe/src/boolean/engine/bootstrapping.rs
index 10b2316ed..8d86bdfdb 100644
--- a/tfhe/src/boolean/engine/bootstrapping.rs
+++ b/tfhe/src/boolean/engine/bootstrapping.rs
@@ -323,7 +323,7 @@ impl CompressedServerKey {
 }
 
 /// Perform ciphertext bootstraps on the CPU
-pub(crate) struct Bootstrapper {
+pub struct Bootstrapper {
     memory: Memory,
     /// A structure containing two CSPRNGs to generate material for encryption like public masks
     /// and secret errors.
@@ -445,7 +445,7 @@ impl Bootstrapper {
         }
     }
 
-    pub(crate) fn bootstrap(
+    pub fn bootstrap(
         &mut self,
         input: &LweCiphertextOwned<u32>,
         server_key: &ServerKey,
@@ -487,6 +487,26 @@ impl Bootstrapper {
         )
     }
 
+    pub fn keyswitch(
+        &mut self,
+        input: &LweCiphertextOwned<u32>,
+        server_key: &ServerKey,
+    ) -> LweCiphertextOwned<u32> {
+        // Allocate the output of the KS
+        let mut output = LweCiphertext::new(
+            0u32,
+            server_key
+                .bootstrapping_key
+                .input_lwe_dimension()
+                .to_lwe_size(),
+            input.ciphertext_modulus(),
+        );
+
+        keyswitch_lwe_ciphertext(&server_key.key_switching_key, input, &mut output);
+
+        output
+    }
+
     pub(crate) fn bootstrap_keyswitch(
         &mut self,
         mut ciphertext: LweCiphertextOwned<u32>,
diff --git a/tfhe/src/boolean/engine/fpga.rs b/tfhe/src/boolean/engine/fpga.rs
new file mode 100644
index 000000000..ba68622c5
--- /dev/null
+++ b/tfhe/src/boolean/engine/fpga.rs
@@ -0,0 +1,201 @@
+use itertools::izip;
+
+use crate::boolean::ciphertext::Ciphertext;
+use crate::boolean::engine::bootstrapping::ServerKey;
+use crate::boolean::engine::{
+    lwe_ciphertext_add, lwe_ciphertext_cleartext_mul_assign, lwe_ciphertext_opposite_assign,
+    lwe_ciphertext_plaintext_add_assign,
+};
+use crate::boolean::prelude::BinaryBooleanGates;
+use crate::boolean::{PLAINTEXT_FALSE, PLAINTEXT_TRUE};
+use crate::core_crypto::entities::*;
+use crate::core_crypto::fpga::keyswitch_bootstrap::KeyswitchBootstrapPacked;
+use crate::core_crypto::fpga::lookup_vector::LookupVector;
+use crate::core_crypto::fpga::utils::Connect;
+use crate::core_crypto::fpga::BelfortFpgaUtils;
+
+#[derive(Clone)]
+pub enum Gate {
+    AND,
+    OR,
+    XOR,
+    NAND,
+    NOR,
+    XNOR,
+}
+
+#[derive(Clone)]
+pub struct BelfortBooleanServerKey {
+    pub key: ServerKey,
+    pub fpga_utils: BelfortFpgaUtils,
+}
+
+impl BelfortBooleanServerKey {
+    // Construct
+
+    pub fn default(cpu_key: ServerKey) -> Self {
+        Self {
+            key: cpu_key,
+            fpga_utils: BelfortFpgaUtils::default(),
+        }
+    }
+
+    pub fn connect(&mut self) {
+        self.fpga_utils.connect(&self.key);
+    }
+
+    pub fn connect_to(&mut self, fpga_indexes: Vec<usize>) {
+        self.fpga_utils.connect_to(&self.key, fpga_indexes);
+    }
+
+    pub fn disconnect(&mut self) {
+        self.fpga_utils.disconnect();
+    }
+
+    pub fn packed_gates(
+        &self,
+        gates: &Vec<Gate>,
+        cts_left: &Vec<&Ciphertext>,
+        cts_right: &Vec<&Ciphertext>,
+    ) -> Vec<Ciphertext> {
+        assert!(gates.len() == cts_left.len());
+        assert!(gates.len() == cts_right.len());
+
+        let server_key = &self.key;
+
+        let lwe_size = server_key
+            .key_switching_key
+            .input_key_lwe_dimension()
+            .to_lwe_size();
+
+        let mut cts_pack = Vec::<Ciphertext>::new();
+
+        for (ct_left, ct_right, gate) in izip!(cts_left, cts_right, gates) {
+            match (*ct_left, *ct_right) {
+                (Ciphertext::Encrypted(ct_left_ct), Ciphertext::Encrypted(ct_right_ct)) => {
+                    let mut buffer_lwe_before_pbs =
+                        LweCiphertext::new(0u32, lwe_size, ct_left_ct.ciphertext_modulus());
+
+                    lwe_ciphertext_add(&mut buffer_lwe_before_pbs, ct_left_ct, ct_right_ct);
+
+                    match gate {
+                        Gate::AND => {
+                            // compute the linear combination for AND: ct_left + ct_right +
+                            // (0,...,0,-1/8) ct_left + ct_right
+                            lwe_ciphertext_plaintext_add_assign(
+                                &mut buffer_lwe_before_pbs,
+                                Plaintext(PLAINTEXT_FALSE),
+                            );
+                        }
+                        Gate::OR => {
+                            // Compute the linear combination for OR: ct_left + ct_right +
+                            // (0,...,0,+1/8) ct_left + ct_right
+                            lwe_ciphertext_plaintext_add_assign(
+                                &mut buffer_lwe_before_pbs,
+                                Plaintext(PLAINTEXT_TRUE),
+                            );
+                        }
+                        Gate::XOR => {
+                            // Compute the linear combination for XOR: 2*(ct_left + ct_right) +
+                            // (0,...,0,1/4) ct_left + ct_right
+                            lwe_ciphertext_plaintext_add_assign(
+                                &mut buffer_lwe_before_pbs,
+                                Plaintext(PLAINTEXT_TRUE),
+                            );
+                            //* 2
+                            lwe_ciphertext_cleartext_mul_assign(
+                                &mut buffer_lwe_before_pbs,
+                                Cleartext(2u32),
+                            );
+                        }
+                        Gate::NAND => {
+                            // Compute the linear combination for NAND: - ct_left - ct_right +
+                            // (0,...,0,1/8) ct_left + ct_right
+                            lwe_ciphertext_opposite_assign(&mut buffer_lwe_before_pbs);
+                            // + 1/8
+                            lwe_ciphertext_plaintext_add_assign(
+                                &mut buffer_lwe_before_pbs,
+                                Plaintext(PLAINTEXT_TRUE),
+                            );
+                        }
+                        Gate::NOR => {
+                            // Compute the linear combination for NOR: - ct_left - ct_right +
+                            // (0,...,0,-1/8) ct_left + ct_right
+
+                            lwe_ciphertext_opposite_assign(&mut buffer_lwe_before_pbs);
+                            // - 1/8
+                            lwe_ciphertext_plaintext_add_assign(
+                                &mut buffer_lwe_before_pbs,
+                                Plaintext(PLAINTEXT_FALSE),
+                            );
+                        }
+                        Gate::XNOR => {
+                            // Compute the linear combination for XNOR: 2*(-ct_left - ct_right +
+                            // (0,...,0,-1/8)) ct_left + ct_right
+
+                            lwe_ciphertext_plaintext_add_assign(
+                                &mut buffer_lwe_before_pbs,
+                                Plaintext(PLAINTEXT_TRUE),
+                            );
+                            // compute the negation
+                            lwe_ciphertext_opposite_assign(&mut buffer_lwe_before_pbs);
+
+                            //* 2
+                            lwe_ciphertext_cleartext_mul_assign(
+                                &mut buffer_lwe_before_pbs,
+                                Cleartext(2u32),
+                            );
+                        }
+                    }
+
+                    cts_pack.push(Ciphertext::Encrypted(buffer_lwe_before_pbs));
+                }
+                (Ciphertext::Trivial(message_left), Ciphertext::Trivial(message_right)) => {
+                    let ct: Ciphertext = match gate {
+                        Gate::AND => Ciphertext::Trivial(*message_left && *message_right),
+                        Gate::OR => Ciphertext::Trivial(*message_left || *message_right),
+                        Gate::XOR => Ciphertext::Trivial(*message_left ^ *message_right),
+                        Gate::NAND => Ciphertext::Trivial(!(*message_left && *message_right)),
+                        Gate::NOR => Ciphertext::Trivial(!*message_left || *message_right),
+                        Gate::XNOR => Ciphertext::Trivial(!(*message_left ^ *message_right)),
+                    };
+
+                    cts_pack.push(ct);
+                }
+                (Ciphertext::Encrypted(_), Ciphertext::Trivial(message_right)) => {
+                    let ct: Ciphertext = match gate {
+                        Gate::AND => server_key.and(*ct_left, *message_right),
+                        Gate::OR => server_key.or(*ct_left, *message_right),
+                        Gate::XOR => server_key.xor(*ct_left, *message_right),
+                        Gate::NAND => server_key.nand(*ct_left, *message_right),
+                        Gate::NOR => server_key.nor(*ct_left, *message_right),
+                        Gate::XNOR => server_key.xnor(*ct_left, *message_right),
+                    };
+
+                    cts_pack.push(ct);
+                }
+                (Ciphertext::Trivial(message_left), Ciphertext::Encrypted(_)) => {
+                    let ct: Ciphertext = match gate {
+                        Gate::AND => server_key.and(*message_left, *ct_right),
+                        Gate::OR => server_key.or(*message_left, *ct_right),
+                        Gate::XOR => server_key.xor(*message_left, *ct_right),
+                        Gate::NAND => server_key.nand(*message_left, *ct_right),
+                        Gate::NOR => server_key.nor(*message_left, *ct_right),
+                        Gate::XNOR => server_key.xnor(*message_left, *ct_right),
+                    };
+
+                    cts_pack.push(ct);
+                }
+            }
+        }
+
+        let luts: Vec<LookupVector> = (0..cts_pack.len())
+            .map(|_| LookupVector::boolean())
+            .collect();
+
+        self.fpga_utils
+            .keyswitch_bootstrap_packed(&mut cts_pack, &luts);
+
+        cts_pack
+    }
+}
diff --git a/tfhe/src/boolean/engine/mod.rs b/tfhe/src/boolean/engine/mod.rs
index aa3696e37..d0534d7b3 100644
--- a/tfhe/src/boolean/engine/mod.rs
+++ b/tfhe/src/boolean/engine/mod.rs
@@ -18,6 +18,7 @@ use crate::core_crypto::seeders::new_seeder;
 use std::cell::RefCell;
 
 pub mod bootstrapping;
+pub mod fpga;
 
 #[cfg(test)]
 mod tests;
@@ -42,7 +43,7 @@ pub(crate) trait BinaryGatesAssignEngine<L, R, K> {
 
 /// Trait to be able to access thread_local
 /// engines in a generic way
-pub(crate) trait WithThreadLocalEngine {
+pub trait WithThreadLocalEngine {
     fn with_thread_local_mut<R, F>(func: F) -> R
     where
         F: FnOnce(&mut Self) -> R;
@@ -60,7 +61,7 @@ pub struct BooleanEngine {
     /// A structure containing two CSPRNGs to generate material for encryption like public masks
     /// and secret errors.
     ///
-    /// The [`EncryptionRandomGenerator`] contains two CSPRNGs, one publicly seeded used to
+    /// The [`EncryptionRandomGenerator`] contains two CSPRNGs, one publicly seeded used rto
     /// generate mask coefficients and one privately seeded used to generate errors during
     /// encryption.
     encryption_generator: EncryptionRandomGenerator<DefaultRandomGenerator>,
diff --git a/tfhe/src/boolean/server_key/mod.rs b/tfhe/src/boolean/server_key/mod.rs
index 493125a22..b4407e9e9 100644
--- a/tfhe/src/boolean/server_key/mod.rs
+++ b/tfhe/src/boolean/server_key/mod.rs
@@ -15,6 +15,8 @@ use crate::boolean::engine::{
     BinaryGatesAssignEngine, BinaryGatesEngine, BooleanEngine, WithThreadLocalEngine,
 };
 
+use crate::boolean::engine::fpga::BelfortBooleanServerKey;
+
 pub trait BinaryBooleanGates<L, R> {
     fn and(&self, ct_left: L, ct_right: R) -> Ciphertext;
     fn nand(&self, ct_left: L, ct_right: R) -> Ciphertext;
@@ -161,3 +163,9 @@ impl CompressedServerKey {
         BooleanEngine::with_thread_local_mut(|engine| engine.create_compressed_server_key(cks))
     }
 }
+
+impl From<ServerKey> for BelfortBooleanServerKey {
+    fn from(value: ServerKey) -> Self {
+        Self::default(value)
+    }
+}
diff --git a/tfhe/src/core_crypto/entities/polynomial.rs b/tfhe/src/core_crypto/entities/polynomial.rs
index 05d64122c..e03da7061 100644
--- a/tfhe/src/core_crypto/entities/polynomial.rs
+++ b/tfhe/src/core_crypto/entities/polynomial.rs
@@ -5,7 +5,7 @@ use tfhe_versionable::Versionize;
 use crate::core_crypto::backward_compatibility::entities::polynomial::PolynomialVersions;
 use crate::core_crypto::commons::parameters::*;
 use crate::core_crypto::commons::traits::*;
-use std::ops::{Index, IndexMut};
+use std::ops::{Deref, DerefMut, Index, IndexMut};
 
 /// A [`polynomial`](`Polynomial`).
 #[derive(Clone, Copy, Debug, PartialEq, Eq, serde::Serialize, serde::Deserialize, Versionize)]
@@ -152,6 +152,20 @@ where
     }
 }
 
+impl<C: Container> Deref for Polynomial<C> {
+    type Target = [C::Element];
+
+    fn deref(&self) -> &Self::Target {
+        self.as_ref()
+    }
+}
+
+impl<C: ContainerMut> DerefMut for Polynomial<C> {
+    fn deref_mut(&mut self) -> &mut Self::Target {
+        self.as_mut()
+    }
+}
+
 /// Metadata used in the [`CreateFrom`] implementation to create [`Polynomial`] entities.
 #[derive(Clone, Copy)]
 pub struct PolynomialCreationMetadata {}
diff --git a/tfhe/src/core_crypto/fpga/keyswitch_bootstrap.rs b/tfhe/src/core_crypto/fpga/keyswitch_bootstrap.rs
new file mode 100644
index 000000000..491946c63
--- /dev/null
+++ b/tfhe/src/core_crypto/fpga/keyswitch_bootstrap.rs
@@ -0,0 +1,90 @@
+use super::lookup_vector::LookupVector;
+use super::{Accelerators, InterfaceStatusT, PbsTypeT};
+use crate::boolean::ciphertext::Ciphertext as BooleanCiphertext;
+pub use crate::core_crypto::commons::parameters::CiphertextModulus;
+use crate::core_crypto::fpga::BelfortFpgaUtils;
+use crate::shortint::ciphertext::{Ciphertext as ShortintCiphertext, NoiseLevel};
+
+extern "C" {
+    pub fn pbs(
+        accelerators: Accelerators,
+        ciphertext_ptrs: *const *mut u64,
+        luts: *const u64,
+        pbs_types: *const PbsTypeT,
+        pack_size: usize,
+        fpga_indexes: *const usize,
+        fpga_indexes_length: usize,
+    ) -> InterfaceStatusT;
+}
+
+pub trait KeyswitchBootstrapPacked<Ciphertext> {
+    fn keyswitch_bootstrap_packed(
+        &self,
+        ciphertexts: &mut Vec<Ciphertext>,
+        lookup_vectors: &[LookupVector],
+    );
+}
+
+impl KeyswitchBootstrapPacked<BooleanCiphertext> for BelfortFpgaUtils {
+    fn keyswitch_bootstrap_packed(
+        &self,
+        _ciphertexts: &mut Vec<BooleanCiphertext>,
+        _lookup_vectors: &[LookupVector],
+    ) {
+        panic!("FPGA acceleration is excluded on boolean!");
+    }
+}
+
+impl KeyswitchBootstrapPacked<ShortintCiphertext> for BelfortFpgaUtils {
+    fn keyswitch_bootstrap_packed(
+        &self,
+        ciphertexts: &mut Vec<ShortintCiphertext>,
+        lookup_vectors: &[LookupVector],
+    ) {
+        let ciphertext_ptrs: Vec<*mut u64> = ciphertexts
+            .iter_mut()
+            .map(|ciphertext| ciphertext.ct.as_mut().as_mut_ptr())
+            .collect();
+
+        let luts: Vec<u64> = lookup_vectors.iter().map(|l| l.compressed).collect();
+
+        let pbs_types: Vec<PbsTypeT> = ciphertexts
+            .iter()
+            .map(|ciphertext| {
+                if ciphertext.is_trivial() {
+                    PbsTypeT::PbsSkipped
+                } else {
+                    PbsTypeT::PbsRequired
+                }
+            })
+            .collect();
+
+        let pack_size = luts.len();
+
+        let fpga_indexes = &self.fpga_indexes;
+
+        unsafe {
+            let status = pbs(
+                self.accelerators,
+                ciphertext_ptrs.as_ptr(),
+                luts.as_ptr(),
+                pbs_types.as_ptr(),
+                pack_size,
+                fpga_indexes.as_ptr(),
+                fpga_indexes.len(),
+            );
+
+            assert!(
+                status == InterfaceStatusT::InterfaceSuccess,
+                "Failed to execute on FPGA! Status {status:?}"
+            )
+        }
+
+        for (ciphertext, lut) in ciphertexts.iter_mut().zip(lookup_vectors.iter()) {
+            if !ciphertext.is_trivial() {
+                ciphertext.noise_level = NoiseLevel::NOMINAL;
+                ciphertext.degree = lut.degree;
+            }
+        }
+    }
+}
diff --git a/tfhe/src/core_crypto/fpga/lookup_vector.rs b/tfhe/src/core_crypto/fpga/lookup_vector.rs
new file mode 100644
index 000000000..83fcdab3f
--- /dev/null
+++ b/tfhe/src/core_crypto/fpga/lookup_vector.rs
@@ -0,0 +1,51 @@
+use crate::shortint::ciphertext::Degree;
+
+#[derive(Clone, Copy, Debug)]
+pub struct LookupVector {
+    pub compressed: u64,
+    pub degree: Degree,
+}
+
+impl LookupVector {
+    pub fn new(vector: &[u64]) -> Self {
+        let max_value = vector.iter().max().unwrap();
+        let compressed = Self::compress(vector);
+        let degree = Degree::new(*max_value);
+
+        Self { compressed, degree }
+    }
+
+    pub fn new_with_max(vector: &[u64], degree: u64) -> Self {
+        let compressed = Self::compress(vector);
+        let degree = Degree::new(degree);
+
+        Self { compressed, degree }
+    }
+
+    fn compress(vector: &[u64]) -> u64 {
+        let log2_modulus = vector.len().ilog2() as usize;
+        vector
+            .iter()
+            .enumerate()
+            .map(|(index, &value)| value << (index * log2_modulus))
+            .sum()
+    }
+
+    pub fn decompress(&self, modulus: usize) -> Vec<u64> {
+        let log2_modulus = modulus.ilog2() as usize;
+        let mut vector = Vec::with_capacity(modulus);
+        for i in 0..modulus {
+            let shifted_value = self.compressed >> (i * log2_modulus);
+            let element = shifted_value & ((1u64 << log2_modulus) - 1);
+            vector.push(element);
+        }
+        vector
+    }
+
+    pub fn boolean() -> Self {
+        Self {
+            compressed: 0,
+            degree: Degree::new(0),
+        }
+    }
+}
diff --git a/tfhe/src/core_crypto/fpga/mod.rs b/tfhe/src/core_crypto/fpga/mod.rs
new file mode 100644
index 000000000..cd0cbf815
--- /dev/null
+++ b/tfhe/src/core_crypto/fpga/mod.rs
@@ -0,0 +1,51 @@
+pub mod keyswitch_bootstrap;
+pub mod lookup_vector;
+pub mod utils;
+
+use std::os::raw::c_void;
+use std::ptr;
+
+////////////////////////////////////////////////////////////////////////////////
+
+pub type Accelerators = *mut c_void;
+
+pub struct BelfortFpgaLuts;
+
+////////////////////////////////////////////////////////////////////////////////
+
+#[repr(C)]
+#[derive(Debug, Copy, Clone, PartialEq, Eq)]
+pub enum InterfaceStatusT {
+    InterfaceSuccess = 0,
+    InterfaceFailureXrt = 1,
+    InterfaceFailureMalloc = 2,
+    InterfaceFailureDimension = 3,
+}
+
+#[repr(C)]
+#[derive(Debug, Copy, Clone, PartialEq, Eq)]
+pub enum PbsTypeT {
+    PbsSkipped = 0,
+    PbsRequired = 1,
+}
+
+////////////////////////////////////////////////////////////////////////////////
+
+#[derive(Clone, Debug)]
+pub struct BelfortFpgaUtils {
+    pub accelerators: Accelerators,
+    pub is_connected: bool,
+    pub fpga_indexes: Vec<usize>,
+}
+
+unsafe impl Send for BelfortFpgaUtils {}
+
+impl std::default::Default for BelfortFpgaUtils {
+    fn default() -> Self {
+        Self {
+            accelerators: ptr::null_mut(),
+            is_connected: false,
+            fpga_indexes: vec![],
+        }
+    }
+}
diff --git a/tfhe/src/core_crypto/fpga/utils.rs b/tfhe/src/core_crypto/fpga/utils.rs
new file mode 100644
index 000000000..16ea5793b
--- /dev/null
+++ b/tfhe/src/core_crypto/fpga/utils.rs
@@ -0,0 +1,172 @@
+use super::InterfaceStatusT;
+use crate::boolean::server_key::ServerKey as BooleanServerKey;
+use crate::core_crypto::fpga::{Accelerators, BelfortFpgaUtils};
+use crate::core_crypto::prelude::*;
+use crate::shortint::server_key::{ServerKey as ShortintServerKey, ShortintBootstrappingKey};
+use tfhe_fft::c64;
+
+extern "C" {
+    pub fn connect(fpga_indexes: *mut *mut usize, fpga_count: *mut usize) -> Accelerators;
+    pub fn connect_to(fpga_indexes: *const usize, fpga_count: usize) -> Accelerators;
+    pub fn disconnect(accelerator: Accelerators) -> InterfaceStatusT;
+    pub fn tx_ksk_to_fpga(accelerator: Accelerators, ksk_ptr: *const u64) -> InterfaceStatusT;
+    pub fn tx_bsk_to_fpga(accelerator: Accelerators, bsk_ptr: *const c64) -> InterfaceStatusT;
+}
+
+////////////////////////////////////////////////////////////////////////////////
+
+pub trait Connect<Serverkey> {
+    fn connect(&mut self, cpu_key: &Serverkey);
+
+    fn connect_to(&mut self, cpu_key: &Serverkey, fpga_indexes: Vec<usize>);
+}
+
+impl Connect<BooleanServerKey> for BelfortFpgaUtils {
+    fn connect(&mut self, _cpu_key: &BooleanServerKey) {
+        panic!("FPGA acceleration is excluded on boolean!");
+    }
+
+    fn connect_to(&mut self, _cpu_key: &BooleanServerKey, _fpga_indexes: Vec<usize>) {
+        panic!("FPGA acceleration is excluded on boolean!");
+    }
+}
+
+impl Connect<ShortintServerKey> for BelfortFpgaUtils {
+    fn connect(&mut self, cpu_key: &ShortintServerKey) {
+        if self.is_connected {
+            return;
+        }
+
+        assert!(
+            !(cpu_key.pbs_order == PBSOrder::BootstrapKeyswitch),
+            "Packed BootstrapKeyswitch is not supported"
+        );
+
+        let bootstrapping_key = &cpu_key.bootstrapping_key;
+        let key_switching_key = &cpu_key.key_switching_key;
+
+        let bsk = match bootstrapping_key {
+            ShortintBootstrappingKey::Classic(flbko) => flbko,
+            ShortintBootstrappingKey::MultiBit { .. } => {
+                panic!("Multibit BSK is not supported in FPGA!")
+            }
+        };
+
+        let ksk = key_switching_key;
+
+        self.connect_to_all_fpgas(bsk, ksk);
+    }
+
+    fn connect_to(&mut self, cpu_key: &ShortintServerKey, fpga_indexes: Vec<usize>) {
+        if self.is_connected {
+            return;
+        }
+
+        assert!(
+            !(cpu_key.pbs_order == PBSOrder::BootstrapKeyswitch),
+            "Packed BootstrapKeyswitch is not supported"
+        );
+
+        let bootstrapping_key = &cpu_key.bootstrapping_key;
+        let bsk = match bootstrapping_key {
+            ShortintBootstrappingKey::Classic(flbko) => flbko,
+            ShortintBootstrappingKey::MultiBit { .. } => {
+                panic!("Multibit BSK is not supported in FPGA!")
+            }
+        };
+
+        let ksk = &cpu_key.key_switching_key;
+
+        self.connect_to_indexed_fpgas(bsk, ksk, fpga_indexes);
+    }
+}
+
+impl BelfortFpgaUtils {
+    fn connect_to_all_fpgas(
+        &mut self,
+        bsk: &FourierLweBootstrapKeyOwned,
+        ksk: &LweKeyswitchKey<Vec<u64>>,
+    ) {
+        let ksk_vector: Vec<u64> = ksk.clone().into_container();
+        let bsk_vector: Vec<c64> = bsk.clone().data().to_vec();
+
+        let fpga_indexes: Vec<usize>;
+        let mut fpga_count: usize = 0;
+
+        unsafe {
+            let mut fpga_vec_ptr: *mut usize = std::ptr::null_mut();
+
+            self.accelerators = connect(&mut fpga_vec_ptr, &mut fpga_count);
+
+            assert!(
+                !self.accelerators.is_null(),
+                "Failed to connect accelerator"
+            );
+
+            assert!(
+                tx_ksk_to_fpga(self.accelerators, ksk_vector.as_ptr())
+                    == InterfaceStatusT::InterfaceSuccess,
+                "Failed to send ksk to accelerator"
+            );
+
+            assert!(
+                tx_bsk_to_fpga(self.accelerators, bsk_vector.as_ptr())
+                    == InterfaceStatusT::InterfaceSuccess,
+                "Failed to send bsk to accelerator"
+            );
+
+            fpga_indexes = Vec::from_raw_parts(fpga_vec_ptr, fpga_count, fpga_count);
+        }
+
+        self.fpga_indexes = fpga_indexes;
+        self.is_connected = true;
+    }
+
+    fn connect_to_indexed_fpgas(
+        &mut self,
+        bsk: &FourierLweBootstrapKeyOwned,
+        ksk: &LweKeyswitchKey<Vec<u64>>,
+        fpga_indexes: Vec<usize>,
+    ) {
+        let ksk_vector: Vec<u64> = ksk.clone().into_container();
+        let bsk_vector: Vec<c64> = bsk.clone().data().to_vec();
+
+        let fpga_count = fpga_indexes.len();
+
+        unsafe {
+            self.accelerators = connect_to(fpga_indexes.as_ptr(), fpga_count);
+            assert!(
+                !self.accelerators.is_null(),
+                "Failed to connect accelerator"
+            );
+
+            assert!(
+                tx_ksk_to_fpga(self.accelerators, ksk_vector.as_ptr())
+                    == InterfaceStatusT::InterfaceSuccess,
+                "Failed to send ksk to accelerator"
+            );
+
+            assert!(
+                tx_bsk_to_fpga(self.accelerators, bsk_vector.as_ptr())
+                    == InterfaceStatusT::InterfaceSuccess,
+                "Failed to send bsk to accelerator"
+            );
+        }
+
+        self.fpga_indexes = fpga_indexes;
+        self.is_connected = true;
+    }
+
+    pub fn disconnect(&mut self) {
+        if self.is_connected {
+            unsafe {
+                assert!(
+                    !(disconnect(self.accelerators) != InterfaceStatusT::InterfaceSuccess),
+                    "Failed to disconnect accelerator"
+                );
+
+                self.is_connected = false;
+            }
+        }
+    }
+}
diff --git a/tfhe/src/core_crypto/mod.rs b/tfhe/src/core_crypto/mod.rs
index a15ef7c01..e4d69e007 100644
--- a/tfhe/src/core_crypto/mod.rs
+++ b/tfhe/src/core_crypto/mod.rs
@@ -20,6 +20,8 @@ pub mod fft_impl;
 
 #[cfg(feature = "gpu")]
 pub mod gpu;
+// #[cfg(feature = "fpga")]
+pub mod fpga;
 #[cfg(test)]
 pub mod keycache;
 
diff --git a/tfhe/src/core_crypto/probe_time.rs b/tfhe/src/core_crypto/probe_time.rs
new file mode 100644
index 000000000..071be62f7
--- /dev/null
+++ b/tfhe/src/core_crypto/probe_time.rs
@@ -0,0 +1,37 @@
+use std::time::{SystemTime, UNIX_EPOCH};
+
+const NUM_PROBES: usize = 16;
+pub const MAX_MEASUREMENTS_PER_PROBE: usize = 512;
+
+pub static mut EPOCH: SystemTime = UNIX_EPOCH;
+pub static mut TIME_STAMPS: [[SystemTime; NUM_PROBES]; MAX_MEASUREMENTS_PER_PROBE] =
+    [[UNIX_EPOCH; NUM_PROBES]; MAX_MEASUREMENTS_PER_PROBE];
+pub static mut PROBE_NAMES: [&str; NUM_PROBES] = ["NONAME"; NUM_PROBES];
+pub static mut PROBE_INDEX: usize = 0;
+pub static mut EXECUTION_INDEX: usize = 0;
+
+#[macro_export]
+macro_rules! probe_time {
+    ($probe_name:expr) => {
+        unsafe {
+            TIME_STAMPS[EXECUTION_INDEX][PROBE_INDEX] = SystemTime::now();
+            PROBE_NAMES[PROBE_INDEX] = $probe_name;
+            PROBE_INDEX += 1;
+            EPOCH = SystemTime::now();
+        }
+    };
+}
+
+#[macro_export]
+macro_rules! probe_time_init {
+    ($measurement_index:expr) => {
+        unsafe {
+            EXECUTION_INDEX = $measurement_index;
+            PROBE_INDEX = 0;
+            TIME_STAMPS[EXECUTION_INDEX][PROBE_INDEX] = SystemTime::now();
+            PROBE_NAMES[PROBE_INDEX] = "Init";
+            PROBE_INDEX += 1;
+            EPOCH = SystemTime::now();
+        }
+    };
+}
diff --git a/tfhe/src/high_level_api/array/cpu/integers.rs b/tfhe/src/high_level_api/array/cpu/integers.rs
index dc9a639b9..aabbf8137 100644
--- a/tfhe/src/high_level_api/array/cpu/integers.rs
+++ b/tfhe/src/high_level_api/array/cpu/integers.rs
@@ -2,10 +2,14 @@
 //! where the values and computations are always done on CPU
 use super::super::helpers::{create_sub_mut_slice_with_bound, create_sub_slice_with_bound};
 use super::super::traits::{ArithmeticArrayBackend, BitwiseArrayBackend, ClearBitwiseArrayBackend};
+#[cfg(feature = "fpga")]
+use crate::array::fpga::integers::par_map_fpga_op_on_pair_of_elements;
 use crate::core_crypto::prelude::{SignedNumeric, UnsignedNumeric};
 use crate::high_level_api::array::{
     ArrayBackend, FheArrayBase, FheBackendArray, FheBackendArraySlice, FheBackendArraySliceMut,
 };
+#[cfg(feature = "fpga")]
+use crate::BelfortServerKey;
 
 use crate::array::traits::{
     BackendDataContainer, BackendDataContainerMut, ClearArithmeticArrayBackend, TensorSlice,
@@ -72,14 +76,18 @@ where
     })
 }
 
+#[allow(unreachable_code)]
 impl<T> ArithmeticArrayBackend for CpuIntegerArrayBackend<T>
 where
-    T: IntegerRadixCiphertext,
+    T: IntegerRadixCiphertext + 'static,
 {
     fn add_slices<'a>(
         lhs: TensorSlice<'_, Self::Slice<'a>>,
         rhs: TensorSlice<'_, Self::Slice<'a>>,
     ) -> Self::Owned {
+        #[cfg(feature = "fpga")]
+        return par_map_fpga_op_on_pair_of_elements(lhs, rhs, BelfortServerKey::add);
+
         par_map_sks_op_on_pair_of_elements(lhs, rhs, crate::integer::ServerKey::add_parallelized)
     }
 
@@ -87,6 +95,9 @@ where
         lhs: TensorSlice<'_, Self::Slice<'a>>,
         rhs: TensorSlice<'_, Self::Slice<'a>>,
     ) -> Self::Owned {
+        #[cfg(feature = "fpga")]
+        return par_map_fpga_op_on_pair_of_elements(lhs, rhs, BelfortServerKey::sub);
+
         par_map_sks_op_on_pair_of_elements(lhs, rhs, crate::integer::ServerKey::sub_parallelized)
     }
 
@@ -94,6 +105,9 @@ where
         lhs: TensorSlice<'_, Self::Slice<'a>>,
         rhs: TensorSlice<'_, Self::Slice<'a>>,
     ) -> Self::Owned {
+        #[cfg(feature = "fpga")]
+        return par_map_fpga_op_on_pair_of_elements(lhs, rhs, BelfortServerKey::mul);
+
         par_map_sks_op_on_pair_of_elements(lhs, rhs, crate::integer::ServerKey::mul_parallelized)
     }
 
@@ -101,6 +115,9 @@ where
         lhs: TensorSlice<'_, Self::Slice<'a>>,
         rhs: TensorSlice<'_, Self::Slice<'a>>,
     ) -> Self::Owned {
+        #[cfg(feature = "fpga")]
+        return par_map_fpga_op_on_pair_of_elements(lhs, rhs, BelfortServerKey::div);
+
         par_map_sks_op_on_pair_of_elements(lhs, rhs, crate::integer::ServerKey::div_parallelized)
     }
 
@@ -108,6 +125,9 @@ where
         lhs: TensorSlice<'_, Self::Slice<'a>>,
         rhs: TensorSlice<'_, Self::Slice<'a>>,
     ) -> Self::Owned {
+        #[cfg(feature = "fpga")]
+        return par_map_fpga_op_on_pair_of_elements(lhs, rhs, BelfortServerKey::rem);
+
         par_map_sks_op_on_pair_of_elements(lhs, rhs, crate::integer::ServerKey::rem_parallelized)
     }
 }
@@ -260,14 +280,18 @@ where
     }
 }
 
+#[allow(unreachable_code)]
 impl<T> BitwiseArrayBackend for CpuIntegerArrayBackend<T>
 where
-    T: IntegerRadixCiphertext,
+    T: IntegerRadixCiphertext + 'static,
 {
     fn bitand<'a>(
         lhs: TensorSlice<'_, Self::Slice<'a>>,
         rhs: TensorSlice<'_, Self::Slice<'a>>,
     ) -> Self::Owned {
+        #[cfg(feature = "fpga")]
+        return par_map_fpga_op_on_pair_of_elements(lhs, rhs, BelfortServerKey::bitand);
+
         par_map_sks_op_on_pair_of_elements(lhs, rhs, crate::integer::ServerKey::bitand_parallelized)
     }
 
@@ -275,6 +299,9 @@ where
         lhs: TensorSlice<'_, Self::Slice<'a>>,
         rhs: TensorSlice<'_, Self::Slice<'a>>,
     ) -> Self::Owned {
+        #[cfg(feature = "fpga")]
+        return par_map_fpga_op_on_pair_of_elements(lhs, rhs, BelfortServerKey::bitor);
+
         par_map_sks_op_on_pair_of_elements(lhs, rhs, crate::integer::ServerKey::bitor_parallelized)
     }
 
@@ -282,6 +309,9 @@ where
         lhs: TensorSlice<'_, Self::Slice<'a>>,
         rhs: TensorSlice<'_, Self::Slice<'a>>,
     ) -> Self::Owned {
+        #[cfg(feature = "fpga")]
+        return par_map_fpga_op_on_pair_of_elements(lhs, rhs, BelfortServerKey::bitxor);
+
         par_map_sks_op_on_pair_of_elements(lhs, rhs, crate::integer::ServerKey::bitxor_parallelized)
     }
 
diff --git a/tfhe/src/high_level_api/array/dynamic/booleans.rs b/tfhe/src/high_level_api/array/dynamic/booleans.rs
index ff8354105..69e99f321 100644
--- a/tfhe/src/high_level_api/array/dynamic/booleans.rs
+++ b/tfhe/src/high_level_api/array/dynamic/booleans.rs
@@ -113,6 +113,10 @@ where
         Some(Device::CudaGpu) => {
             panic!("Not supported by Cuda devices")
         }
+        #[cfg(feature = "fpga")]
+        Some(Device::Fpga) => {
+            panic!("Not supported by FPGA devices")
+        }
         None => {
             panic!("{}", crate::high_level_api::errors::UninitializedServerKey);
         }
@@ -140,6 +144,10 @@ where
         Some(Device::CudaGpu) => {
             panic!("Not supported by Cuda devices")
         }
+        #[cfg(feature = "fpga")]
+        Some(Device::Fpga) => {
+            panic!("Not supported by FPGA devices")
+        }
         None => {
             panic!("{}", crate::high_level_api::errors::UninitializedServerKey);
         }
@@ -174,6 +182,10 @@ where
         Some(Device::CudaGpu) => {
             panic!("Not supported by Cuda devices")
         }
+        #[cfg(feature = "fpga")]
+        Some(Device::Fpga) => {
+            panic!("Not supported by FPGA devices")
+        }
         None => {
             panic!("{}", crate::high_level_api::errors::UninitializedServerKey);
         }
diff --git a/tfhe/src/high_level_api/array/dynamic/signed.rs b/tfhe/src/high_level_api/array/dynamic/signed.rs
index 77763b491..b71808364 100644
--- a/tfhe/src/high_level_api/array/dynamic/signed.rs
+++ b/tfhe/src/high_level_api/array/dynamic/signed.rs
@@ -196,6 +196,10 @@ where
         Some(Device::CudaGpu) => {
             panic!("Not supported by Cuda devices")
         }
+        #[cfg(feature = "fpga")]
+        Some(Device::Fpga) => {
+            panic!("Not supported by FPGA devices")
+        }
         None => {
             panic!("{}", crate::high_level_api::errors::UninitializedServerKey);
         }
@@ -223,6 +227,10 @@ where
         Some(Device::CudaGpu) => {
             panic!("Not supported by Cuda devices")
         }
+        #[cfg(feature = "fpga")]
+        Some(Device::Fpga) => {
+            panic!("Not supported by FPGA devices")
+        }
         None => {
             panic!("{}", crate::high_level_api::errors::UninitializedServerKey);
         }
@@ -347,6 +355,10 @@ where
         Some(Device::CudaGpu) => {
             panic!("Not supported by Cuda devices")
         }
+        #[cfg(feature = "fpga")]
+        Some(Device::Fpga) => {
+            panic!("Not supported by FPGA devices")
+        }
         None => {
             panic!("{}", crate::high_level_api::errors::UninitializedServerKey);
         }
diff --git a/tfhe/src/high_level_api/array/dynamic/unsigned.rs b/tfhe/src/high_level_api/array/dynamic/unsigned.rs
index 149e03706..bdaecec0b 100644
--- a/tfhe/src/high_level_api/array/dynamic/unsigned.rs
+++ b/tfhe/src/high_level_api/array/dynamic/unsigned.rs
@@ -198,6 +198,20 @@ where
             );
             InnerUintArray::Cpu(result)
         }
+        #[cfg(feature = "fpga")]
+        Some(Device::Fpga) => {
+            let lhs_cpu_cow = lhs.slice.on_cpu();
+            let rhs_cpu_cow = rhs.slice.on_cpu();
+
+            let lhs_cpu_slice: &[RadixCiphertext] = lhs_cpu_cow.borrow();
+            let rhs_cpu_slice: &[RadixCiphertext] = rhs_cpu_cow.borrow();
+
+            let result = cpu_fn(
+                TensorSlice::new(lhs_cpu_slice, lhs.dims),
+                TensorSlice::new(rhs_cpu_slice, rhs.dims),
+            );
+            InnerUintArray::Cpu(result)
+        }
         #[cfg(feature = "gpu")]
         Some(Device::CudaGpu) => {
             panic!("Not supported by Cuda devices")
@@ -229,6 +243,10 @@ where
         Some(Device::CudaGpu) => {
             panic!("Not supported by Cuda devices")
         }
+        #[cfg(feature = "fpga")]
+        Some(Device::Fpga) => {
+            panic!("Not supported by FPGA devices")
+        }
         None => {
             panic!("{}", crate::high_level_api::errors::UninitializedServerKey);
         }
@@ -353,6 +371,10 @@ where
         Some(Device::CudaGpu) => {
             panic!("Not supported by Cuda devices")
         }
+        #[cfg(feature = "fpga")]
+        Some(Device::Fpga) => {
+            panic!("Not supported by FPGA devices")
+        }
         None => {
             panic!("{}", crate::high_level_api::errors::UninitializedServerKey);
         }
diff --git a/tfhe/src/high_level_api/array/fpga/integers.rs b/tfhe/src/high_level_api/array/fpga/integers.rs
new file mode 100644
index 000000000..e6e7f180d
--- /dev/null
+++ b/tfhe/src/high_level_api/array/fpga/integers.rs
@@ -0,0 +1,99 @@
+use crate::array::traits::TensorSlice;
+use crate::high_level_api::global_state;
+use crate::integer::IntegerRadixCiphertext;
+use crate::BelfortServerKey;
+use std::sync::mpsc::{channel, Sender};
+use std::sync::Arc;
+use std::thread;
+
+struct OperationPackage<T, F>
+where
+    T: IntegerRadixCiphertext,
+    F: Fn(&BelfortServerKey, &T, &T) -> T + Send + Sync,
+{
+    idx: usize,
+    left: T,
+    right: T,
+    operation: Arc<F>,
+}
+
+#[inline]
+#[track_caller]
+pub(crate) fn par_map_fpga_op_on_pair_of_elements<'a, T, F>(
+    lhs: TensorSlice<'a, &'a [T]>,
+    rhs: TensorSlice<'a, &'a [T]>,
+    op: F,
+) -> Vec<T>
+where
+    T: IntegerRadixCiphertext + 'static,
+    F: Send + Sync + Fn(&BelfortServerKey, &T, &T) -> T + 'static,
+{
+    let size: usize = lhs.dims.shape().iter().product();
+
+    global_state::with_fpga_internal_keys(|key| {
+        let num_fpgas = key.fpga_utils.fpga_indexes.len();
+        let (tx_res, rx_res) = channel::<(usize, T)>();
+        let op = Arc::new(op);
+
+        let threads: Vec<_> = generate_threads(key, &tx_res);
+
+        lhs.iter()
+            .zip(rhs.iter())
+            .enumerate()
+            .for_each(|(idx, (lhs_ct, rhs_ct))| {
+                let thread: &Sender<OperationPackage<T, F>> = &threads[idx % num_fpgas];
+                let package = OperationPackage {
+                    idx,
+                    left: lhs_ct.clone(),
+                    right: rhs_ct.clone(),
+                    operation: Arc::clone(&op),
+                };
+                let _ = thread.send(package);
+            });
+
+        let mut results: Vec<Option<T>> = vec![None; size];
+        let mut counter = 0;
+        for (idx, partial_res) in rx_res {
+            counter += 1;
+            results[idx] = Some(partial_res);
+            if counter >= size {
+                break;
+            }
+        }
+
+        // Drop all sender channels to signal completion
+        drop(tx_res);
+        drop(threads);
+
+        results.into_iter().flatten().collect()
+    })
+}
+
+fn generate_threads<T, F>(
+    fpga_key: &BelfortServerKey,
+    result_sender: &Sender<(usize, T)>,
+) -> Vec<Sender<OperationPackage<T, F>>>
+where
+    T: IntegerRadixCiphertext + 'static,
+    F: Send + Sync + Fn(&BelfortServerKey, &T, &T) -> T + 'static,
+{
+    let fpga_indexes = fpga_key.fpga_utils.fpga_indexes.clone();
+    fpga_indexes
+        .into_iter()
+        .map(|i| {
+            let (tx, rx) = channel::<OperationPackage<T, F>>();
+            let res_sender = result_sender.clone();
+            let mut thread_key = fpga_key.clone();
+
+            thread::spawn(move || {
+                thread_key.fpga_utils.fpga_indexes = vec![i];
+
+                while let Ok(p) = rx.recv() {
+                    let result = (p.operation)(&thread_key, &p.left, &p.right);
+                    let _ = res_sender.send((p.idx, result));
+                }
+            });
+            tx
+        })
+        .collect()
+}
diff --git a/tfhe/src/high_level_api/array/fpga/mod.rs b/tfhe/src/high_level_api/array/fpga/mod.rs
new file mode 100644
index 000000000..bd196331e
--- /dev/null
+++ b/tfhe/src/high_level_api/array/fpga/mod.rs
@@ -0,0 +1,4 @@
+pub(crate) mod integers;
+
+#[cfg(test)]
+mod tests;
diff --git a/tfhe/src/high_level_api/array/fpga/tests/mod.rs b/tfhe/src/high_level_api/array/fpga/tests/mod.rs
new file mode 100644
index 000000000..225691b2d
--- /dev/null
+++ b/tfhe/src/high_level_api/array/fpga/tests/mod.rs
@@ -0,0 +1,16 @@
+use crate::{generate_keys, set_server_key, BelfortServerKey, ClientKey, ConfigBuilder};
+
+#[cfg(test)]
+mod test_arrays;
+
+fn setup_default_fpga() -> (ClientKey, BelfortServerKey) {
+    let config = ConfigBuilder::default().build();
+    let (ck, sk) = generate_keys(config);
+    let mut fpga_key = BelfortServerKey::from(&sk);
+    // Connect to all accelerators
+    fpga_key.connect();
+    // Store the key internally, so the other threads can access it
+    set_server_key(fpga_key.clone());
+
+    (ck, fpga_key)
+}
diff --git a/tfhe/src/high_level_api/array/fpga/tests/test_arrays.rs b/tfhe/src/high_level_api/array/fpga/tests/test_arrays.rs
new file mode 100644
index 000000000..8572fad71
--- /dev/null
+++ b/tfhe/src/high_level_api/array/fpga/tests/test_arrays.rs
@@ -0,0 +1,72 @@
+use super::setup_default_fpga;
+use crate::array::cpu::integers::CpuUintArrayBackend;
+use crate::array::dynamic::DynUintBackend;
+use crate::array::tests::{bitand_test_case, bitor_test_case};
+use crate::prelude::*;
+use crate::{CpuFheUint32Array, FheUint32Array, FheUint32Id};
+use rand::prelude::*;
+use rand::thread_rng;
+
+macro_rules! fpga_arrays_test {
+    ($test_name:ident, $test_case:ident, $($type_param:ty),+) => {
+        #[test]
+        fn $test_name() {
+            let (ck, mut fpga_key) = setup_default_fpga();
+            $test_case::<$($type_param),+>(&ck);
+            fpga_key.disconnect();
+        }
+    };
+}
+
+fpga_arrays_test!(
+    test_fpga_arrays_bitand,
+    bitand_test_case,
+    FheUint32Id,
+    CpuUintArrayBackend,
+    u32
+);
+fpga_arrays_test!(
+    test_fpga_only_bitor,
+    bitor_test_case,
+    CpuFheUint32Array,
+    u32
+);
+fpga_arrays_test!(
+    test_fpga_dyn_bitand,
+    bitand_test_case,
+    FheUint32Id,
+    DynUintBackend,
+    u32
+);
+
+#[test]
+fn test_single_dimension() {
+    let (ck, mut fpga_key) = setup_default_fpga();
+
+    let mut rng = thread_rng();
+
+    let num_elems = 5;
+
+    let clear_xs = (0..num_elems).map(|_| rng.gen::<u32>()).collect::<Vec<_>>();
+    let clear_ys = (0..num_elems).map(|_| rng.gen::<u32>()).collect::<Vec<_>>();
+
+    let xs = FheUint32Array::try_encrypt(clear_xs.as_slice(), &ck).unwrap();
+    let ys = FheUint32Array::try_encrypt(clear_ys.as_slice(), &ck).unwrap();
+
+    let range = 1..3;
+    let xss = xs.slice(&[range.clone()]);
+    let yss = ys.slice(&[range.clone()]);
+
+    let zs = xss + yss;
+
+    let clear_zs: Vec<u32> = zs.decrypt(&ck);
+    for (z, (x, y)) in clear_zs.into_iter().zip(
+        clear_xs[range.clone()]
+            .iter()
+            .copied()
+            .zip(clear_ys[range].iter().copied()),
+    ) {
+        assert_eq!(z, x.wrapping_add(y));
+    }
+    fpga_key.disconnect();
+}
diff --git a/tfhe/src/high_level_api/array/mod.rs b/tfhe/src/high_level_api/array/mod.rs
index 9c5e1936a..8dca1f1fa 100644
--- a/tfhe/src/high_level_api/array/mod.rs
+++ b/tfhe/src/high_level_api/array/mod.rs
@@ -1,6 +1,8 @@
 mod clear_ops;
 mod cpu;
 mod dynamic;
+#[cfg(feature = "fpga")]
+mod fpga;
 #[cfg(feature = "gpu")]
 mod gpu;
 mod helpers;
@@ -364,6 +366,8 @@ pub fn fhe_uint_array_eq<Id: FheUintId>(lhs: &[FheUint<Id>], rhs: &[FheUint<Id>]
                 .all_eq_slices_parallelized(&tmp_lhs, &tmp_rhs);
             FheBool::new(result, cpu_key.tag.clone())
         }
+        #[cfg(feature = "fpga")]
+        InternalServerKey::Belfort(_fpga_key) => panic!("Not implemented!"),
         #[cfg(feature = "gpu")]
         InternalServerKey::Cuda(gpu_key) => with_thread_local_cuda_streams(|streams| {
             let tmp_lhs = lhs
@@ -401,6 +405,8 @@ pub fn fhe_uint_array_contains_sub_slice<Id: FheUintId>(
                 .contains_sub_slice_parallelized(&tmp_lhs, &tmp_pattern);
             FheBool::new(result, cpu_key.tag.clone())
         }
+        #[cfg(feature = "fpga")]
+        InternalServerKey::Belfort(_fpga_key) => panic!("Not implemented!"),
         #[cfg(feature = "gpu")]
         InternalServerKey::Cuda(gpu_key) => with_thread_local_cuda_streams(|streams| {
             let tmp_lhs = lhs
diff --git a/tfhe/src/high_level_api/array/tests/mod.rs b/tfhe/src/high_level_api/array/tests/mod.rs
index bc0d6ca56..f09766359 100644
--- a/tfhe/src/high_level_api/array/tests/mod.rs
+++ b/tfhe/src/high_level_api/array/tests/mod.rs
@@ -47,7 +47,7 @@ fn setup_default_gpu() -> ClientKey {
     ck
 }
 
-fn bitand_test_case<Id, Backend, Clear>(ck: &ClientKey)
+pub(crate) fn bitand_test_case<Id, Backend, Clear>(ck: &ClientKey)
 where
     Id: FheId,
     Backend: crate::high_level_api::array::ArrayBackend,
@@ -118,7 +118,7 @@ where
     }
 }
 
-fn bitor_test_case<Array, Clear>(ck: &ClientKey)
+pub(crate) fn bitor_test_case<Array, Clear>(ck: &ClientKey)
 where
     Standard: Distribution<Clear>,
     Clear: BitOr<Clear, Output = Clear> + Copy + Eq + Debug,
@@ -184,7 +184,7 @@ where
     }
 }
 
-fn bitxor_test_case<Array, Clear>(ck: &ClientKey)
+pub(crate) fn bitxor_test_case<Array, Clear>(ck: &ClientKey)
 where
     Standard: Distribution<Clear>,
     Clear: Copy + BitXor<Clear, Output = Clear> + Eq + Debug,
@@ -250,7 +250,7 @@ where
     }
 }
 
-fn bitand_scalar_slice_test_case<Array, Clear>(ck: &ClientKey)
+pub(crate) fn bitand_scalar_slice_test_case<Array, Clear>(ck: &ClientKey)
 where
     Standard: Distribution<Clear>,
     Clear: Copy + BitAnd<Clear, Output = Clear> + Eq + Debug,
diff --git a/tfhe/src/high_level_api/booleans/base.rs b/tfhe/src/high_level_api/booleans/base.rs
index 63f6e5cd4..241af139d 100644
--- a/tfhe/src/high_level_api/booleans/base.rs
+++ b/tfhe/src/high_level_api/booleans/base.rs
@@ -201,6 +201,15 @@ where
                 );
                 FheUint::new(inner, cpu_sks.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                let inner = fpga_key.if_then_else(
+                    &ct_condition.ciphertext.on_cpu(),
+                    &*ct_then.ciphertext.on_cpu(),
+                    &*ct_else.ciphertext.on_cpu(),
+                );
+                FheUint::new(inner, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner = cuda_key.key.key.if_then_else(
@@ -244,6 +253,16 @@ impl<Id: FheIntId> IfThenElse<FheInt<Id>> for FheBool {
                 );
                 FheInt::new(new_ct, key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let new_ct = fpga_key.if_then_else(
+                    &ct_condition.ciphertext.on_cpu(),
+                    &*ct_then.ciphertext.on_cpu(),
+                    &*ct_else.ciphertext.on_cpu(),
+                );
+                FheInt::new(new_ct, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(_) => {
                 panic!("Cuda devices do not support signed integers")
@@ -264,6 +283,16 @@ impl IfThenElse<Self> for FheBool {
                 );
                 Self::new(new_ct, key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA Implementation
+                let new_ct = fpga_key.pbs_key().if_then_else_parallelized(
+                    &ct_condition.ciphertext.on_cpu(),
+                    &*ct_then.ciphertext.on_cpu(),
+                    &*ct_else.ciphertext.on_cpu(),
+                );
+                Self::new(new_ct, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(_) => {
                 panic!("Cuda devices do not support signed integers")
@@ -305,6 +334,16 @@ where
                 let ciphertext = InnerBoolean::Cpu(BooleanBlock::new_unchecked(inner));
                 Self::new(ciphertext, key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let inner = fpga_key.pbs_key().key.equal(
+                    self.ciphertext.on_cpu().as_ref(),
+                    other.borrow().ciphertext.on_cpu().as_ref(),
+                );
+                let ciphertext = InnerBoolean::Cpu(BooleanBlock::new_unchecked(inner));
+                Self::new(ciphertext, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner = cuda_key.key.key.eq(
@@ -347,6 +386,16 @@ where
                 let ciphertext = InnerBoolean::Cpu(BooleanBlock::new_unchecked(inner));
                 Self::new(ciphertext, key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let inner = fpga_key.pbs_key().key.not_equal(
+                    self.ciphertext.on_cpu().as_ref(),
+                    other.borrow().ciphertext.on_cpu().as_ref(),
+                );
+                let ciphertext = InnerBoolean::Cpu(BooleanBlock::new_unchecked(inner));
+                Self::new(ciphertext, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner = cuda_key.key.key.ne(
@@ -392,6 +441,18 @@ impl FheEq<bool> for FheBool {
                     key.tag.clone(),
                 )
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let inner = fpga_key
+                    .pbs_key()
+                    .key
+                    .scalar_equal(self.ciphertext.on_cpu().as_ref(), u8::from(other));
+                (
+                    InnerBoolean::Cpu(BooleanBlock::new_unchecked(inner)),
+                    fpga_key.tag.clone(),
+                )
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner = cuda_key.key.key.scalar_eq(
@@ -435,6 +496,18 @@ impl FheEq<bool> for FheBool {
                     key.tag.clone(),
                 )
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let inner = fpga_key
+                    .pbs_key()
+                    .key
+                    .scalar_not_equal(self.ciphertext.on_cpu().as_ref(), u8::from(other));
+                (
+                    InnerBoolean::Cpu(BooleanBlock::new_unchecked(inner)),
+                    fpga_key.tag.clone(),
+                )
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner = cuda_key.key.key.scalar_ne(
@@ -509,6 +582,14 @@ where
                     .boolean_bitand(&self.ciphertext.on_cpu(), &rhs.borrow().ciphertext.on_cpu());
                 (InnerBoolean::Cpu(inner_ct), key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let inner_ct = fpga_key
+                    .pbs_key()
+                    .boolean_bitand(&self.ciphertext.on_cpu(), &rhs.borrow().ciphertext.on_cpu());
+                (InnerBoolean::Cpu(inner_ct), fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_ct = cuda_key.key.key.bitand(
@@ -594,6 +675,18 @@ where
                     key.tag.clone(),
                 )
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let inner_ct = fpga_key.pbs_key().key.bitor(
+                    self.ciphertext.on_cpu().as_ref(),
+                    rhs.borrow().ciphertext.on_cpu().as_ref(),
+                );
+                (
+                    InnerBoolean::Cpu(BooleanBlock::new_unchecked(inner_ct)),
+                    fpga_key.tag.clone(),
+                )
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_ct = cuda_key.key.key.bitor(
@@ -678,6 +771,18 @@ where
                     key.tag.clone(),
                 )
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let inner_ct = fpga_key.pbs_key().key.bitxor(
+                    self.ciphertext.on_cpu().as_ref(),
+                    rhs.borrow().ciphertext.on_cpu().as_ref(),
+                );
+                (
+                    InnerBoolean::Cpu(BooleanBlock::new_unchecked(inner_ct)),
+                    fpga_key.tag.clone(),
+                )
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_ct = cuda_key.key.key.bitxor(
@@ -754,6 +859,18 @@ impl BitAnd<bool> for &FheBool {
                     key.tag.clone(),
                 )
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let inner_ct = fpga_key
+                    .pbs_key()
+                    .key
+                    .scalar_bitand(self.ciphertext.on_cpu().as_ref(), u8::from(rhs));
+                (
+                    InnerBoolean::Cpu(BooleanBlock::new_unchecked(inner_ct)),
+                    fpga_key.tag.clone(),
+                )
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_ct = cuda_key.key.key.scalar_bitand(
@@ -830,6 +947,17 @@ impl BitOr<bool> for &FheBool {
                     key.tag.clone(),
                 )
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                let inner_ct = fpga_key
+                    .pbs_key()
+                    .key
+                    .scalar_bitor(self.ciphertext.on_cpu().as_ref(), u8::from(rhs));
+                (
+                    InnerBoolean::Cpu(BooleanBlock::new_unchecked(inner_ct)),
+                    fpga_key.tag.clone(),
+                )
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_ct = cuda_key.key.key.scalar_bitor(
@@ -906,6 +1034,18 @@ impl BitXor<bool> for &FheBool {
                     key.tag.clone(),
                 )
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let inner_ct = fpga_key
+                    .pbs_key()
+                    .key
+                    .scalar_bitxor(self.ciphertext.on_cpu().as_ref(), u8::from(rhs));
+                (
+                    InnerBoolean::Cpu(BooleanBlock::new_unchecked(inner_ct)),
+                    fpga_key.tag.clone(),
+                )
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_ct = cuda_key.key.key.scalar_bitxor(
@@ -1110,6 +1250,14 @@ where
                     &rhs.ciphertext.on_cpu().0,
                 );
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                fpga_key.pbs_key().key.bitand_assign(
+                    &mut self.ciphertext.as_cpu_mut().0,
+                    &rhs.ciphertext.on_cpu().0,
+                );
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 cuda_key.key.key.bitand_assign(
@@ -1153,6 +1301,14 @@ where
                     &rhs.ciphertext.on_cpu().0,
                 );
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                fpga_key.pbs_key().key.bitor_assign(
+                    &mut self.ciphertext.as_cpu_mut().0,
+                    &rhs.ciphertext.on_cpu().0,
+                );
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 cuda_key.key.key.bitor_assign(
@@ -1196,6 +1352,14 @@ where
                     &rhs.ciphertext.on_cpu().0,
                 );
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                fpga_key.pbs_key().key.bitxor_assign(
+                    &mut self.ciphertext.as_cpu_mut().0,
+                    &rhs.ciphertext.on_cpu().0,
+                );
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 cuda_key.key.key.bitxor_assign(
@@ -1233,6 +1397,14 @@ impl BitAndAssign<bool> for FheBool {
                     .key
                     .scalar_bitand_assign(&mut self.ciphertext.as_cpu_mut().0, u8::from(rhs));
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                fpga_key
+                    .pbs_key()
+                    .key
+                    .scalar_bitand_assign(&mut self.ciphertext.as_cpu_mut().0, u8::from(rhs));
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 cuda_key.key.key.scalar_bitand_assign(
@@ -1270,6 +1442,14 @@ impl BitOrAssign<bool> for FheBool {
                     .key
                     .scalar_bitor_assign(&mut self.ciphertext.as_cpu_mut().0, u8::from(rhs));
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                fpga_key
+                    .pbs_key()
+                    .key
+                    .scalar_bitor_assign(&mut self.ciphertext.as_cpu_mut().0, u8::from(rhs));
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 cuda_key.key.key.scalar_bitor_assign(
@@ -1302,8 +1482,16 @@ impl BitXorAssign<bool> for FheBool {
     /// ```
     fn bitxor_assign(&mut self, rhs: bool) {
         global_state::with_internal_keys(|key| match key {
-            InternalServerKey::Cpu(key) => {
-                key.pbs_key()
+            InternalServerKey::Cpu(ServerKey { key, .. }) => {
+                key.key
+                    .key
+                    .scalar_bitxor_assign(&mut self.ciphertext.as_cpu_mut().0, u8::from(rhs));
+            }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                fpga_key
+                    .pbs_key()
                     .key
                     .scalar_bitxor_assign(&mut self.ciphertext.as_cpu_mut().0, u8::from(rhs));
             }
@@ -1370,6 +1558,12 @@ impl std::ops::Not for &FheBool {
                 let inner = key.pbs_key().boolean_bitnot(&self.ciphertext.on_cpu());
                 (InnerBoolean::Cpu(inner), key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let inner = fpga_key.pbs_key().boolean_bitnot(&self.ciphertext.on_cpu());
+                (InnerBoolean::Cpu(inner), fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner = cuda_key
diff --git a/tfhe/src/high_level_api/booleans/encrypt.rs b/tfhe/src/high_level_api/booleans/encrypt.rs
index c339a2b8d..f603fd5a0 100644
--- a/tfhe/src/high_level_api/booleans/encrypt.rs
+++ b/tfhe/src/high_level_api/booleans/encrypt.rs
@@ -89,6 +89,11 @@ impl FheTryTrivialEncrypt<bool> for FheBool {
                 let ct = InnerBoolean::Cpu(key.pbs_key().create_trivial_boolean_block(value));
                 (ct, key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                let ct = InnerBoolean::Cpu(fpga_key.pbs_key().create_trivial_boolean_block(value));
+                (ct, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner: CudaUnsignedRadixCiphertext =
diff --git a/tfhe/src/high_level_api/booleans/inner.rs b/tfhe/src/high_level_api/booleans/inner.rs
index 669675eda..c8c80f88d 100644
--- a/tfhe/src/high_level_api/booleans/inner.rs
+++ b/tfhe/src/high_level_api/booleans/inner.rs
@@ -188,6 +188,10 @@ impl InnerBoolean {
             (Self::Cpu(_), Device::Cpu) => {
                 // Nothing to do, we already are on the correct device
             }
+            #[cfg(feature = "fpga")]
+            (Self::Cpu(_), Device::Fpga) => {
+                panic!("No CPU->FPGA implementation")
+            }
             #[cfg(feature = "gpu")]
             (Self::Cuda(_), Device::CudaGpu) => {
                 // Nothing to do, we already are on the correct device
diff --git a/tfhe/src/high_level_api/booleans/oprf.rs b/tfhe/src/high_level_api/booleans/oprf.rs
index 4546cfda8..1dc314d7e 100644
--- a/tfhe/src/high_level_api/booleans/oprf.rs
+++ b/tfhe/src/high_level_api/booleans/oprf.rs
@@ -30,6 +30,15 @@ impl FheBool {
 
                 Self::new(BooleanBlock(ct), key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                let ct = fpga_key
+                    .pbs_key()
+                    .key
+                    .generate_oblivious_pseudo_random(seed, 1);
+
+                Self::new(BooleanBlock(ct), fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(_) => {
                 todo!("Cuda devices do not yet support oblivious pseudo random generation")
diff --git a/tfhe/src/high_level_api/booleans/tests.rs b/tfhe/src/high_level_api/booleans/tests.rs
index e6127628b..762bfff86 100644
--- a/tfhe/src/high_level_api/booleans/tests.rs
+++ b/tfhe/src/high_level_api/booleans/tests.rs
@@ -727,7 +727,7 @@ mod gpu {
 
     fn setup_gpu_default() -> ClientKey {
         let config = ConfigBuilder::default().build();
-        let cks = crate::ClientKey::generate(config);
+        let cks = ClientKey::generate(config);
         let csks = crate::CompressedServerKey::new(&cks);
 
         let server_keys = csks.decompress_to_gpu();
diff --git a/tfhe/src/high_level_api/compact_list.rs b/tfhe/src/high_level_api/compact_list.rs
index 836865de8..36d8666c9 100644
--- a/tfhe/src/high_level_api/compact_list.rs
+++ b/tfhe/src/high_level_api/compact_list.rs
@@ -8,6 +8,8 @@ use crate::core_crypto::commons::math::random::{Deserialize, Serialize};
 use crate::core_crypto::prelude::Numeric;
 use crate::high_level_api::global_state;
 use crate::high_level_api::keys::InternalServerKey;
+#[cfg(feature = "fpga")]
+use crate::high_level_api::keys::ServerKey;
 use crate::high_level_api::traits::Tagged;
 use crate::integer::ciphertext::{Compactable, DataKind, Expandable};
 use crate::integer::encryption::KnowsMessageModulus;
@@ -141,6 +143,14 @@ impl CompactCiphertextList {
                     inner,
                     tag: self.tag.clone(),
                 }),
+            #[cfg(feature = "fpga")]
+            Some(InternalServerKey::Belfort(fpga_key)) => self
+                .inner
+                .expand(ServerKey::from(fpga_key).integer_compact_ciphertext_list_expansion_mode())
+                .map(|inner| CompactCiphertextListExpander {
+                    inner,
+                    tag: self.tag.clone(),
+                }),
             #[cfg(feature = "gpu")]
             Some(_) => Err(crate::Error::new("Expected a CPU server key".to_string())),
         })
diff --git a/tfhe/src/high_level_api/compressed_ciphertext_list.rs b/tfhe/src/high_level_api/compressed_ciphertext_list.rs
index 7492a134a..478f45f8e 100644
--- a/tfhe/src/high_level_api/compressed_ciphertext_list.rs
+++ b/tfhe/src/high_level_api/compressed_ciphertext_list.rs
@@ -158,6 +158,8 @@ impl CompressedCiphertextListBuilder {
                         }
                     })
             }
+            #[cfg(feature = "fpga")]
+            Some(InternalServerKey::Belfort(_fpga_key)) => panic!("Not implemented!"),
             #[cfg(feature = "gpu")]
             Some(InternalServerKey::Cuda(cuda_key)) => {
                 let mut cuda_radixes = vec![];
diff --git a/tfhe/src/high_level_api/global_state.rs b/tfhe/src/high_level_api/global_state.rs
index c134eda58..91a501c5d 100644
--- a/tfhe/src/high_level_api/global_state.rs
+++ b/tfhe/src/high_level_api/global_state.rs
@@ -8,6 +8,9 @@ use crate::high_level_api::keys::{InternalServerKey, ServerKey};
 use crate::integer::gpu::CudaServerKey;
 use std::cell::RefCell;
 
+#[cfg(feature = "fpga")]
+use super::BelfortServerKey;
+
 /// We store the internal keys as thread local, meaning each thread has its own set of keys.
 ///
 /// This means that the user can do computations in multiple threads
@@ -118,6 +121,8 @@ pub(in crate::high_level_api) fn device_of_internal_keys() -> Option<crate::Devi
         let cell = keys.borrow();
         Some(match cell.as_ref()? {
             InternalServerKey::Cpu(_) => crate::Device::Cpu,
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(_) => crate::Device::Fpga,
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(_) => crate::Device::CudaGpu,
         })
@@ -131,6 +136,8 @@ pub(in crate::high_level_api) fn tag_of_internal_server_key() -> crate::Result<c
         let cell = keys.borrow();
         Ok(match cell.as_ref().ok_or(UninitializedServerKey)? {
             InternalServerKey::Cpu(cpu_key) => cpu_key.tag.clone(),
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => fpga_key.tag.clone(),
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => cuda_key.tag.clone(),
         })
@@ -151,6 +158,34 @@ where
             .unwrap_display();
         match key {
             InternalServerKey::Cpu(key) => func(key),
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(key) => func(&key.into()),
+            #[cfg(feature = "gpu")]
+            InternalServerKey::Cuda(_) => {
+                panic!("Cpu key requested but only cuda key is available")
+            }
+        }
+    })
+}
+
+#[inline]
+#[cfg(feature = "fpga")]
+pub(crate) fn with_fpga_internal_keys<T, F>(func: F) -> T
+where
+    F: FnOnce(&BelfortServerKey) -> T,
+{
+    // Should use `with_borrow` when its stabilized
+    INTERNAL_KEYS.with(|keys| {
+        let maybe_key = &*keys.borrow();
+        let key = maybe_key
+            .as_ref()
+            .ok_or(UninitializedServerKey)
+            .unwrap_display();
+        match key {
+            InternalServerKey::Belfort(key) => func(key),
+            InternalServerKey::Cpu(_) => {
+                panic!("Fpga key requested but only cpu key is available")
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(_) => {
                 panic!("Cpu key requested but only cuda key is available")
diff --git a/tfhe/src/high_level_api/integers/oprf.rs b/tfhe/src/high_level_api/integers/oprf.rs
index 4ee3ec104..bd89ad82a 100644
--- a/tfhe/src/high_level_api/integers/oprf.rs
+++ b/tfhe/src/high_level_api/integers/oprf.rs
@@ -34,6 +34,18 @@ impl<Id: FheUintId> FheUint<Id> {
 
                 Self::new(ct, key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let ct = fpga_key
+                    .pbs_key()
+                    .par_generate_oblivious_pseudo_random_unsigned_integer(
+                        seed,
+                        Id::num_blocks(fpga_key.key.message_modulus()) as u64,
+                    );
+
+                Self::new(ct, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(_) => {
                 todo!("Cuda devices do not yet support oblivious pseudo random generation")
@@ -74,6 +86,19 @@ impl<Id: FheUintId> FheUint<Id> {
 
                 Self::new(ct, key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let ct = fpga_key
+                    .pbs_key()
+                    .par_generate_oblivious_pseudo_random_unsigned_integer_bounded(
+                        seed,
+                        random_bits_count,
+                        Id::num_blocks(fpga_key.key.message_modulus()) as u64,
+                    );
+
+                Self::new(ct, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(_) => {
                 todo!("Cuda devices do not yet support oblivious pseudo random generation")
@@ -114,6 +139,17 @@ impl<Id: FheIntId> FheInt<Id> {
                     );
                 Self::new(ct, key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA Implementation
+                let ct = fpga_key
+                    .pbs_key()
+                    .par_generate_oblivious_pseudo_random_signed_integer(
+                        seed,
+                        Id::num_blocks(fpga_key.key.message_modulus()) as u64,
+                    );
+                Self::new(ct, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(_) => {
                 todo!("Cuda devices do not yet support oblivious pseudo random generation")
@@ -156,6 +192,19 @@ impl<Id: FheIntId> FheInt<Id> {
 
                 Self::new(ct, key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let ct = fpga_key
+                    .pbs_key()
+                    .par_generate_oblivious_pseudo_random_signed_integer_bounded(
+                        seed,
+                        random_bits_count,
+                        Id::num_blocks(fpga_key.key.message_modulus()) as u64,
+                    );
+
+                Self::new(ct, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(_) => {
                 todo!("Cuda devices do not yet support oblivious pseudo random generation")
diff --git a/tfhe/src/high_level_api/integers/signed/base.rs b/tfhe/src/high_level_api/integers/signed/base.rs
index e0c6c9351..7b3dc4a15 100644
--- a/tfhe/src/high_level_api/integers/signed/base.rs
+++ b/tfhe/src/high_level_api/integers/signed/base.rs
@@ -185,6 +185,14 @@ where
                     .abs_parallelized(&*self.ciphertext.on_cpu());
                 Self::new(ciphertext, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let ciphertext = fpga_key
+                    .pbs_key()
+                    .abs_parallelized(&*self.ciphertext.on_cpu());
+                Self::new(ciphertext, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(_) => {
                 panic!("Cuda devices does not support abs yet")
@@ -217,6 +225,14 @@ where
                     .is_even_parallelized(&*self.ciphertext.on_cpu());
                 FheBool::new(result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let result = fpga_key
+                    .pbs_key()
+                    .is_even_parallelized(&*self.ciphertext.on_cpu());
+                FheBool::new(result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let result = cuda_key
@@ -253,6 +269,14 @@ where
                     .is_odd_parallelized(&*self.ciphertext.on_cpu());
                 FheBool::new(result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let result = fpga_key
+                    .pbs_key()
+                    .is_odd_parallelized(&*self.ciphertext.on_cpu());
+                FheBool::new(result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let result = cuda_key.key.key.is_odd(&*self.ciphertext.on_gpu(), streams);
@@ -290,6 +314,15 @@ where
                 );
                 crate::FheUint32::new(result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                let result = fpga_key.leading_zeros(&*self.ciphertext.on_cpu());
+                let result = fpga_key.pbs_key().cast_to_unsigned(
+                    result,
+                    crate::FheUint32Id::num_blocks(fpga_key.pbs_key().message_modulus()),
+                );
+                crate::FheUint32::new(result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let result = cuda_key
@@ -335,6 +368,18 @@ where
                 );
                 crate::FheUint32::new(result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let result = fpga_key
+                    .pbs_key()
+                    .leading_ones_parallelized(&*self.ciphertext.on_cpu());
+                let result = fpga_key.pbs_key().cast_to_unsigned(
+                    result,
+                    crate::FheUint32Id::num_blocks(fpga_key.pbs_key().message_modulus()),
+                );
+                crate::FheUint32::new(result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let result = cuda_key
@@ -380,6 +425,18 @@ where
                 );
                 crate::FheUint32::new(result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let result = fpga_key
+                    .pbs_key()
+                    .trailing_zeros_parallelized(&*self.ciphertext.on_cpu());
+                let result = fpga_key.pbs_key().cast_to_unsigned(
+                    result,
+                    crate::FheUint32Id::num_blocks(fpga_key.pbs_key().message_modulus()),
+                );
+                crate::FheUint32::new(result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let result = cuda_key
@@ -425,6 +482,18 @@ where
                 );
                 crate::FheUint32::new(result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let result = fpga_key
+                    .pbs_key()
+                    .trailing_ones_parallelized(&*self.ciphertext.on_cpu());
+                let result = fpga_key.pbs_key().cast_to_unsigned(
+                    result,
+                    crate::FheUint32Id::num_blocks(fpga_key.pbs_key().message_modulus()),
+                );
+                crate::FheUint32::new(result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let result = cuda_key
@@ -471,6 +540,18 @@ where
                 );
                 crate::FheUint32::new(result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let result = fpga_key
+                    .pbs_key()
+                    .count_ones_parallelized(&*self.ciphertext.on_cpu());
+                let result = fpga_key.pbs_key().cast_to_unsigned(
+                    result,
+                    crate::FheUint32Id::num_blocks(fpga_key.pbs_key().message_modulus()),
+                );
+                crate::FheUint32::new(result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(_) => {
                 panic!("Cuda devices do not support count_ones yet");
@@ -508,6 +589,18 @@ where
                 );
                 crate::FheUint32::new(result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let result = fpga_key
+                    .pbs_key()
+                    .count_zeros_parallelized(&*self.ciphertext.on_cpu());
+                let result = fpga_key.pbs_key().cast_to_unsigned(
+                    result,
+                    crate::FheUint32Id::num_blocks(fpga_key.pbs_key().message_modulus()),
+                );
+                crate::FheUint32::new(result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(_) => {
                 panic!("Cuda devices do not support count_zeros yet");
@@ -546,6 +639,18 @@ where
                 );
                 crate::FheUint32::new(result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let result = fpga_key
+                    .pbs_key()
+                    .ilog2_parallelized(&*self.ciphertext.on_cpu());
+                let result = fpga_key.pbs_key().cast_to_unsigned(
+                    result,
+                    crate::FheUint32Id::num_blocks(fpga_key.pbs_key().message_modulus()),
+                );
+                crate::FheUint32::new(result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let result = cuda_key.key.key.ilog2(&*self.ciphertext.on_gpu(), streams);
@@ -597,6 +702,21 @@ where
                     FheBool::new(is_ok, cpu_key.tag.clone()),
                 )
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let (result, is_ok) = fpga_key
+                    .pbs_key()
+                    .checked_ilog2_parallelized(&*self.ciphertext.on_cpu());
+                let result = fpga_key.pbs_key().cast_to_unsigned(
+                    result,
+                    crate::FheUint32Id::num_blocks(fpga_key.pbs_key().message_modulus()),
+                );
+                (
+                    crate::FheUint32::new(result, fpga_key.tag.clone()),
+                    FheBool::new(is_ok, fpga_key.tag.clone()),
+                )
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let (result, is_ok) = cuda_key
@@ -683,6 +803,15 @@ where
 
                 Self::new(sk.reverse_bits_parallelized(&*ct), cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let sk = &fpga_key.pbs_key();
+
+                let ct = self.ciphertext.on_cpu();
+
+                Self::new(sk.reverse_bits_parallelized(&*ct), fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(_) => {
                 panic!("Cuda devices do not support reverse yet");
@@ -722,6 +851,15 @@ where
                     .cast_to_signed(input.ciphertext.into_cpu(), target_num_blocks);
                 Self::new(new_ciphertext, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let target_num_blocks = IntoId::num_blocks(fpga_key.key.message_modulus());
+                let new_ciphertext = fpga_key
+                    .pbs_key()
+                    .cast_to_signed(input.ciphertext.into_cpu(), target_num_blocks);
+                Self::new(new_ciphertext, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let target_num_blocks = IntoId::num_blocks(cuda_key.message_modulus());
@@ -767,6 +905,15 @@ where
                 );
                 Self::new(new_ciphertext, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let new_ciphertext = fpga_key.pbs_key().cast_to_signed(
+                    input.ciphertext.on_cpu().to_owned(),
+                    IntoId::num_blocks(fpga_key.key.message_modulus()),
+                );
+                Self::new(new_ciphertext, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let new_ciphertext = cuda_key.key.key.cast_to_signed(
@@ -814,6 +961,19 @@ where
                 );
                 Self::new(ciphertext, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO FPGA Implementation
+                let ciphertext = input
+                    .ciphertext
+                    .on_cpu()
+                    .into_owned()
+                    .into_radix::<crate::integer::SignedRadixCiphertext>(
+                    Id::num_blocks(fpga_key.key.message_modulus()),
+                    fpga_key.pbs_key(),
+                );
+                Self::new(ciphertext, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner = cuda_key.key.key.cast_to_signed(
diff --git a/tfhe/src/high_level_api/integers/signed/inner.rs b/tfhe/src/high_level_api/integers/signed/inner.rs
index dfcc9e156..1a029239c 100644
--- a/tfhe/src/high_level_api/integers/signed/inner.rs
+++ b/tfhe/src/high_level_api/integers/signed/inner.rs
@@ -190,6 +190,10 @@ impl RadixCiphertext {
             (Self::Cpu(_), Device::Cpu) => {
                 // Nothing to do, we already are on the correct device
             }
+            #[cfg(feature = "fpga")]
+            (Self::Cpu(_), Device::Fpga) => {
+                panic!("No CPU->FPGA implementation")
+            }
             #[cfg(feature = "gpu")]
             (Self::Cuda(_), Device::CudaGpu) => {
                 // Nothing to do, we already are on the correct device
diff --git a/tfhe/src/high_level_api/integers/signed/ops.rs b/tfhe/src/high_level_api/integers/signed/ops.rs
index 4da473b75..431049217 100644
--- a/tfhe/src/high_level_api/integers/signed/ops.rs
+++ b/tfhe/src/high_level_api/integers/signed/ops.rs
@@ -66,6 +66,26 @@ where
                         |ct| Self::new(ct, cpu_key.tag.clone()),
                     )
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let ciphertexts = iter
+                    .map(|elem| elem.ciphertext.on_cpu().to_owned())
+                    .collect::<Vec<_>>();
+                fpga_key
+                    .pbs_key()
+                    .sum_ciphertexts_parallelized(ciphertexts.iter())
+                    .map_or_else(
+                        || {
+                            let radix: crate::integer::SignedRadixCiphertext =
+                                fpga_key.pbs_key().create_trivial_zero_radix(Id::num_blocks(
+                                    fpga_key.key.message_modulus(),
+                                ));
+                            Self::new(radix, fpga_key.tag.clone())
+                        },
+                        |ct| Self::new(ct, fpga_key.tag.clone()),
+                    )
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(_) => {
                 panic!("Cuda devices do not support sum of signed integers");
@@ -107,6 +127,14 @@ where
                     .max_parallelized(&*self.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
                 Self::new(inner_result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let inner_result = fpga_key
+                    .pbs_key()
+                    .max_parallelized(&*self.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
+                Self::new(inner_result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_result = cuda_key.key.key.max(
@@ -153,6 +181,14 @@ where
                     .min_parallelized(&*self.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
                 Self::new(inner_result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let inner_result = fpga_key
+                    .pbs_key()
+                    .min_parallelized(&*self.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
+                Self::new(inner_result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_result = cuda_key.key.key.min(
@@ -210,6 +246,14 @@ where
                     .eq_parallelized(&*self.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
                 FheBool::new(inner_result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let inner_result = fpga_key
+                    .pbs_key()
+                    .eq_parallelized(&*self.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
+                FheBool::new(inner_result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_result = cuda_key.key.key.eq(
@@ -249,6 +293,14 @@ where
                     .ne_parallelized(&*self.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
                 FheBool::new(inner_result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let inner_result = fpga_key
+                    .pbs_key()
+                    .ne_parallelized(&*self.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
+                FheBool::new(inner_result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_result = cuda_key.key.key.ne(
@@ -314,6 +366,14 @@ where
                     .lt_parallelized(&*self.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
                 FheBool::new(inner_result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let inner_result = fpga_key
+                    .pbs_key()
+                    .lt_parallelized(&*self.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
+                FheBool::new(inner_result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_result = cuda_key.key.key.lt(
@@ -353,6 +413,13 @@ where
                     .le_parallelized(&*self.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
                 FheBool::new(inner_result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                let inner_result = fpga_key
+                    .pbs_key()
+                    .le_parallelized(&*self.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
+                FheBool::new(inner_result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_result = cuda_key.key.key.le(
@@ -392,6 +459,14 @@ where
                     .gt_parallelized(&*self.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
                 FheBool::new(inner_result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let inner_result = fpga_key
+                    .pbs_key()
+                    .gt_parallelized(&*self.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
+                FheBool::new(inner_result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_result = cuda_key.key.key.gt(
@@ -431,6 +506,13 @@ where
                     .ge_parallelized(&*self.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
                 FheBool::new(inner_result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                let inner_result = fpga_key
+                    .pbs_key()
+                    .ge_parallelized(&*self.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
+                FheBool::new(inner_result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_result = cuda_key.key.key.ge(
@@ -513,6 +595,17 @@ where
                     FheInt::<Id>::new(r, cpu_key.tag.clone()),
                 )
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let (q, r) = fpga_key
+                    .pbs_key()
+                    .div_rem_parallelized(&*self.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
+                (
+                    FheInt::<Id>::new(q, fpga_key.tag.clone()),
+                    FheInt::<Id>::new(r, fpga_key.tag.clone()),
+                )
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(_) => {
                 panic!("Cuda devices does not support division yet")
@@ -588,6 +681,14 @@ generic_integer_impl_operation!(
                         .add_parallelized(&*lhs.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
                     FheInt::new(inner_result, cpu_key.tag.clone())
                 },
+            #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                    let inner_result = fpga_key
+                        .pbs_key()
+                        .add_parallelized(&*lhs.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
+                    FheInt::new(inner_result, fpga_key.tag.clone())
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     with_thread_local_cuda_streams(|streams| {
@@ -631,6 +732,13 @@ generic_integer_impl_operation!(
                         .sub_parallelized(&*lhs.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
                     FheInt::new(inner_result, cpu_key.tag.clone())
                 },
+                #[cfg(feature = "fpga")]
+                InternalServerKey::Belfort(fpga_key) => {
+                    let inner_result = fpga_key
+                        .pbs_key()
+                        .sub_parallelized(&*lhs.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
+                    FheInt::new(inner_result, fpga_key.tag.clone())
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     with_thread_local_cuda_streams(|streams| {
@@ -674,6 +782,14 @@ generic_integer_impl_operation!(
                         .mul_parallelized(&*lhs.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
                     FheInt::new(inner_result, cpu_key.tag.clone())
                 },
+                #[cfg(feature = "fpga")]
+                InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                    let inner_result = fpga_key
+                        .pbs_key()
+                        .mul_parallelized(&*lhs.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
+                    FheInt::new(inner_result, fpga_key.tag.clone())
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                      with_thread_local_cuda_streams(|streams| {
@@ -715,6 +831,14 @@ generic_integer_impl_operation!(
                         .bitand_parallelized(&*lhs.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
                     FheInt::new(inner_result, cpu_key.tag.clone())
                 },
+                #[cfg(feature = "fpga")]
+                InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                    let inner_result = fpga_key
+                        .pbs_key()
+                        .bitand_parallelized(&*lhs.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
+                    FheInt::new(inner_result, fpga_key.tag.clone())
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                      with_thread_local_cuda_streams(|streams| {
@@ -750,12 +874,20 @@ generic_integer_impl_operation!(
     implem: {
         |lhs: &FheInt<_>, rhs: &FheInt<_>| {
             global_state::with_internal_keys(|key| match key {
-                InternalServerKey::Cpu(cpu_key) => {
+                InternalServerKey::Cpu(cpu_key)=> {
                     let inner_result = cpu_key
                         .pbs_key()
                         .bitor_parallelized(&*lhs.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
                     FheInt::new(inner_result, cpu_key.tag.clone())
                 },
+                #[cfg(feature = "fpga")]
+                InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                    let inner_result = fpga_key
+                        .pbs_key()
+                        .bitor_parallelized(&*lhs.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
+                    FheInt::new(inner_result, fpga_key.tag.clone())
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                      with_thread_local_cuda_streams(|streams| {
@@ -797,6 +929,14 @@ generic_integer_impl_operation!(
                         .bitxor_parallelized(&*lhs.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
                     FheInt::new(inner_result, cpu_key.tag.clone())
                 },
+                #[cfg(feature = "fpga")]
+                InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                    let inner_result = fpga_key
+                        .pbs_key()
+                        .bitxor_parallelized(&*lhs.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
+                    FheInt::new(inner_result, fpga_key.tag.clone())
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                      with_thread_local_cuda_streams(|streams| {
@@ -846,6 +986,14 @@ generic_integer_impl_operation!(
                         .div_parallelized(&*lhs.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
                     FheInt::new(inner_result, cpu_key.tag.clone())
                 },
+                #[cfg(feature = "fpga")]
+                InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                    let inner_result = fpga_key
+                        .pbs_key()
+                        .div_parallelized(&*lhs.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
+                    FheInt::new(inner_result, fpga_key.tag.clone())
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(_cuda_key) => {
                     panic!("Division '/' is not yet supported by Cuda devices")
@@ -892,6 +1040,14 @@ generic_integer_impl_operation!(
                         .rem_parallelized(&*lhs.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
                     FheInt::new(inner_result, cpu_key.tag.clone())
                 },
+                #[cfg(feature = "fpga")]
+                InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                    let inner_result = fpga_key
+                        .pbs_key()
+                        .rem_parallelized(&*lhs.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
+                    FheInt::new(inner_result, fpga_key.tag.clone())
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(_cuda_key) => {
                     panic!("Remainder/Modulo '%' is not yet supported by Cuda devices")
@@ -1001,6 +1157,14 @@ generic_integer_impl_shift_rotate!(
                             .left_shift_parallelized(&*lhs.ciphertext.on_cpu(), &rhs.ciphertext.on_cpu());
                         FheInt::new(ciphertext, cpu_key.tag.clone())
                     }
+                    #[cfg(feature = "fpga")]
+                    InternalServerKey::Belfort(fpga_key) => {
+                        // TODO: FPGA implementation
+                        let ciphertext = fpga_key
+                            .pbs_key()
+                            .left_shift_parallelized(&*lhs.ciphertext.on_cpu(), &rhs.ciphertext.on_cpu());
+                        FheInt::new(ciphertext, fpga_key.tag.clone())
+                    }
                     #[cfg(feature = "gpu")]
                     InternalServerKey::Cuda(cuda_key) => {
                          with_thread_local_cuda_streams(|streams| {
@@ -1040,10 +1204,18 @@ generic_integer_impl_shift_rotate!(
             global_state::with_internal_keys(|key| {
                 match key {
                     InternalServerKey::Cpu(cpu_key) => {
-                        let ciphertext = cpu_key
+                                let ciphertext = cpu_key
+                                    .pbs_key()
+                                    .right_shift_parallelized(&*lhs.ciphertext.on_cpu(), &rhs.ciphertext.on_cpu());
+                                FheInt::new(ciphertext, cpu_key.tag.clone())
+                            }
+                    #[cfg(feature = "fpga")]
+                    InternalServerKey::Belfort(fpga_key) => {
+                    // TODO: FPGA implementation
+                        let ciphertext = fpga_key
                             .pbs_key()
                             .right_shift_parallelized(&*lhs.ciphertext.on_cpu(), &rhs.ciphertext.on_cpu());
-                        FheInt::new(ciphertext, cpu_key.tag.clone())
+                        FheInt::new(ciphertext, fpga_key.tag.clone())
                     }
                     #[cfg(feature = "gpu")]
                     InternalServerKey::Cuda(cuda_key) => {
@@ -1089,6 +1261,14 @@ generic_integer_impl_shift_rotate!(
                             .rotate_left_parallelized(&*lhs.ciphertext.on_cpu(), &rhs.ciphertext.on_cpu());
                         FheInt::new(ciphertext, cpu_key.tag.clone())
                     }
+                    #[cfg(feature = "fpga")]
+                    InternalServerKey::Belfort(fpga_key) => {
+                    // TODO: FPGA implementation
+                        let ciphertext = fpga_key
+                            .pbs_key()
+                            .rotate_left_parallelized(&*lhs.ciphertext.on_cpu(), &rhs.ciphertext.on_cpu());
+                        FheInt::new(ciphertext, fpga_key.tag.clone())
+                    }
                     #[cfg(feature = "gpu")]
                     InternalServerKey::Cuda(cuda_key) => {
                          with_thread_local_cuda_streams(|streams| {
@@ -1133,6 +1313,14 @@ generic_integer_impl_shift_rotate!(
                             .rotate_right_parallelized(&*lhs.ciphertext.on_cpu(), &rhs.ciphertext.on_cpu());
                         FheInt::new(ciphertext, cpu_key.tag.clone())
                     }
+                #[cfg(feature = "fpga")]
+                InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                        let ciphertext = fpga_key
+                            .pbs_key()
+                            .rotate_right_parallelized(&*lhs.ciphertext.on_cpu(), &rhs.ciphertext.on_cpu());
+                        FheInt::new(ciphertext, fpga_key.tag.clone())
+                    }
                     #[cfg(feature = "gpu")]
                     InternalServerKey::Cuda(cuda_key) => {
                          with_thread_local_cuda_streams(|streams| {
@@ -1183,6 +1371,14 @@ where
                     &*rhs.ciphertext.on_cpu(),
                 );
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                fpga_key.pbs_key().add_assign_parallelized(
+                    self.ciphertext.as_cpu_mut(),
+                    &*rhs.ciphertext.on_cpu(),
+                );
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => {
                 crate::high_level_api::global_state::with_thread_local_cuda_streams(|streams| {
@@ -1230,6 +1426,14 @@ where
                     &*rhs.ciphertext.on_cpu(),
                 );
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                fpga_key.pbs_key().sub_assign_parallelized(
+                    self.ciphertext.as_cpu_mut(),
+                    &*rhs.ciphertext.on_cpu(),
+                );
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => {
                 crate::high_level_api::global_state::with_thread_local_cuda_streams(|streams| {
@@ -1277,6 +1481,14 @@ where
                     &*rhs.ciphertext.on_cpu(),
                 );
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                fpga_key.pbs_key().mul_assign_parallelized(
+                    self.ciphertext.as_cpu_mut(),
+                    &*rhs.ciphertext.on_cpu(),
+                );
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => {
                 crate::high_level_api::global_state::with_thread_local_cuda_streams(|streams| {
@@ -1322,6 +1534,14 @@ where
                     &*rhs.ciphertext.on_cpu(),
                 );
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                fpga_key.pbs_key().bitand_assign_parallelized(
+                    self.ciphertext.as_cpu_mut(),
+                    &*rhs.ciphertext.on_cpu(),
+                );
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => {
                 crate::high_level_api::global_state::with_thread_local_cuda_streams(|streams| {
@@ -1367,6 +1587,14 @@ where
                     &*rhs.ciphertext.on_cpu(),
                 );
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                fpga_key.pbs_key().bitor_assign_parallelized(
+                    self.ciphertext.as_cpu_mut(),
+                    &*rhs.ciphertext.on_cpu(),
+                );
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => {
                 crate::high_level_api::global_state::with_thread_local_cuda_streams(|streams| {
@@ -1412,6 +1640,14 @@ where
                     &*rhs.ciphertext.on_cpu(),
                 );
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                fpga_key.pbs_key().bitxor_assign_parallelized(
+                    self.ciphertext.as_cpu_mut(),
+                    &*rhs.ciphertext.on_cpu(),
+                );
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => {
                 crate::high_level_api::global_state::with_thread_local_cuda_streams(|streams| {
@@ -1462,6 +1698,14 @@ where
                     &*rhs.ciphertext.on_cpu(),
                 );
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                fpga_key.pbs_key().div_assign_parallelized(
+                    self.ciphertext.as_cpu_mut(),
+                    &*rhs.ciphertext.on_cpu(),
+                );
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(_) => {
                 panic!("Cuda devices do not support division");
@@ -1506,6 +1750,14 @@ where
                     &*rhs.ciphertext.on_cpu(),
                 );
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                fpga_key.pbs_key().rem_assign_parallelized(
+                    self.ciphertext.as_cpu_mut(),
+                    &*rhs.ciphertext.on_cpu(),
+                );
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(_) => {
                 panic!("Cuda devices do not support remainder");
@@ -1555,6 +1807,14 @@ where
                     &rhs.ciphertext.on_cpu(),
                 );
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                fpga_key.pbs_key().left_shift_assign_parallelized(
+                    self.ciphertext.as_cpu_mut(),
+                    &rhs.ciphertext.on_cpu(),
+                );
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => {
                 with_thread_local_cuda_streams(|streams| {
@@ -1609,6 +1869,14 @@ where
                     &rhs.ciphertext.on_cpu(),
                 );
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                fpga_key.pbs_key().right_shift_assign_parallelized(
+                    self.ciphertext.as_cpu_mut(),
+                    &rhs.ciphertext.on_cpu(),
+                );
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => {
                 with_thread_local_cuda_streams(|streams| {
@@ -1664,6 +1932,13 @@ where
                     &rhs.ciphertext.on_cpu(),
                 );
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                fpga_key.pbs_key().rotate_left_assign_parallelized(
+                    self.ciphertext.as_cpu_mut(),
+                    &rhs.ciphertext.on_cpu(),
+                );
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => {
                 with_thread_local_cuda_streams(|streams| {
@@ -1719,6 +1994,14 @@ where
                     &rhs.ciphertext.on_cpu(),
                 );
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                fpga_key.pbs_key().rotate_right_assign_parallelized(
+                    self.ciphertext.as_cpu_mut(),
+                    &rhs.ciphertext.on_cpu(),
+                );
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => {
                 with_thread_local_cuda_streams(|streams| {
@@ -1792,6 +2075,14 @@ where
                     .neg_parallelized(&*self.ciphertext.on_cpu());
                 FheInt::new(ciphertext, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let ciphertext = fpga_key
+                    .pbs_key()
+                    .neg_parallelized(&*self.ciphertext.on_cpu());
+                FheInt::new(ciphertext, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_result = cuda_key.key.key.neg(&*self.ciphertext.on_gpu(), streams);
@@ -1858,6 +2149,12 @@ where
                 let ciphertext = cpu_key.pbs_key().bitnot(&*self.ciphertext.on_cpu());
                 FheInt::new(ciphertext, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let ciphertext = fpga_key.pbs_key().bitnot(&*self.ciphertext.on_cpu());
+                FheInt::new(ciphertext, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_result = cuda_key.key.key.bitnot(&*self.ciphertext.on_gpu(), streams);
diff --git a/tfhe/src/high_level_api/integers/signed/overflowing_ops.rs b/tfhe/src/high_level_api/integers/signed/overflowing_ops.rs
index c628ba039..1b3adb53e 100644
--- a/tfhe/src/high_level_api/integers/signed/overflowing_ops.rs
+++ b/tfhe/src/high_level_api/integers/signed/overflowing_ops.rs
@@ -52,6 +52,17 @@ where
                     FheBool::new(overflow, cpu_key.tag.clone()),
                 )
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                let (result, overflow) = fpga_key.pbs_key().signed_overflowing_add_parallelized(
+                    &self.ciphertext.on_cpu(),
+                    &other.ciphertext.on_cpu(),
+                );
+                (
+                    FheInt::new(result, fpga_key.tag.clone()),
+                    FheBool::new(overflow, fpga_key.tag.clone()),
+                )
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let (result, overflow) = cuda_key.key.key.signed_overflowing_add(
@@ -148,6 +159,17 @@ where
                     FheBool::new(overflow, cpu_key.tag.clone()),
                 )
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA Implementation
+                let (result, overflow) = fpga_key
+                    .pbs_key()
+                    .signed_overflowing_scalar_add_parallelized(&self.ciphertext.on_cpu(), other);
+                (
+                    FheInt::new(result, fpga_key.tag.clone()),
+                    FheBool::new(overflow, fpga_key.tag.clone()),
+                )
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let (result, overflow) = cuda_key.key.key.signed_overflowing_scalar_add(
@@ -282,6 +304,18 @@ where
                     FheBool::new(overflow, cpu_key.tag.clone()),
                 )
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let (result, overflow) = fpga_key.pbs_key().signed_overflowing_sub_parallelized(
+                    &self.ciphertext.on_cpu(),
+                    &other.ciphertext.on_cpu(),
+                );
+                (
+                    FheInt::new(result, fpga_key.tag.clone()),
+                    FheBool::new(overflow, fpga_key.tag.clone()),
+                )
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let (result, overflow) = cuda_key.key.key.signed_overflowing_sub(
@@ -377,6 +411,17 @@ where
                     FheBool::new(overflow, cpu_key.tag.clone()),
                 )
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let (result, overflow) = fpga_key
+                    .pbs_key()
+                    .signed_overflowing_scalar_sub_parallelized(&self.ciphertext.on_cpu(), other);
+                (
+                    FheInt::new(result, fpga_key.tag.clone()),
+                    FheBool::new(overflow, fpga_key.tag.clone()),
+                )
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let (result, overflow) = cuda_key.key.key.signed_overflowing_scalar_sub(
@@ -473,6 +518,18 @@ where
                     FheBool::new(overflow, cpu_key.tag.clone()),
                 )
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let (result, overflow) = fpga_key.pbs_key().signed_overflowing_mul_parallelized(
+                    &self.ciphertext.on_cpu(),
+                    &other.ciphertext.on_cpu(),
+                );
+                (
+                    FheInt::new(result, fpga_key.tag.clone()),
+                    FheBool::new(overflow, fpga_key.tag.clone()),
+                )
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(_) => {
                 todo!("Cuda devices do not support signed integer");
diff --git a/tfhe/src/high_level_api/integers/signed/scalar_ops.rs b/tfhe/src/high_level_api/integers/signed/scalar_ops.rs
index cb79e4ffb..d6b6d4005 100644
--- a/tfhe/src/high_level_api/integers/signed/scalar_ops.rs
+++ b/tfhe/src/high_level_api/integers/signed/scalar_ops.rs
@@ -53,6 +53,14 @@ where
                     .scalar_max_parallelized(&*self.ciphertext.on_cpu(), rhs);
                 Self::new(inner_result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let inner_result = fpga_key
+                    .pbs_key()
+                    .scalar_max_parallelized(&*self.ciphertext.on_cpu(), rhs);
+                Self::new(inner_result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => {
                 crate::high_level_api::global_state::with_thread_local_cuda_streams(|streams| {
@@ -101,6 +109,14 @@ where
                     .scalar_min_parallelized(&*self.ciphertext.on_cpu(), rhs);
                 Self::new(inner_result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let inner_result = fpga_key
+                    .pbs_key()
+                    .scalar_min_parallelized(&*self.ciphertext.on_cpu(), rhs);
+                Self::new(inner_result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => {
                 crate::high_level_api::global_state::with_thread_local_cuda_streams(|streams| {
@@ -148,6 +164,14 @@ where
                     .scalar_eq_parallelized(&*self.ciphertext.on_cpu(), rhs);
                 FheBool::new(inner_result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let inner_result = fpga_key
+                    .pbs_key()
+                    .scalar_eq_parallelized(&*self.ciphertext.on_cpu(), rhs);
+                FheBool::new(inner_result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => {
                 crate::high_level_api::global_state::with_thread_local_cuda_streams(|streams| {
@@ -189,6 +213,14 @@ where
                     .scalar_ne_parallelized(&*self.ciphertext.on_cpu(), rhs);
                 FheBool::new(inner_result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let inner_result = fpga_key
+                    .pbs_key()
+                    .scalar_ne_parallelized(&*self.ciphertext.on_cpu(), rhs);
+                FheBool::new(inner_result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => {
                 crate::high_level_api::global_state::with_thread_local_cuda_streams(|streams| {
@@ -235,6 +267,14 @@ where
                     .scalar_lt_parallelized(&*self.ciphertext.on_cpu(), rhs);
                 FheBool::new(inner_result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let inner_result = fpga_key
+                    .pbs_key()
+                    .scalar_lt_parallelized(&*self.ciphertext.on_cpu(), rhs);
+                FheBool::new(inner_result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => {
                 crate::high_level_api::global_state::with_thread_local_cuda_streams(|streams| {
@@ -275,6 +315,14 @@ where
                     .scalar_le_parallelized(&*self.ciphertext.on_cpu(), rhs);
                 FheBool::new(inner_result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let inner_result = fpga_key
+                    .pbs_key()
+                    .scalar_le_parallelized(&*self.ciphertext.on_cpu(), rhs);
+                FheBool::new(inner_result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => {
                 crate::high_level_api::global_state::with_thread_local_cuda_streams(|streams| {
@@ -315,6 +363,14 @@ where
                     .scalar_gt_parallelized(&*self.ciphertext.on_cpu(), rhs);
                 FheBool::new(inner_result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let inner_result = fpga_key
+                    .pbs_key()
+                    .scalar_gt_parallelized(&*self.ciphertext.on_cpu(), rhs);
+                FheBool::new(inner_result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => {
                 crate::high_level_api::global_state::with_thread_local_cuda_streams(|streams| {
@@ -355,6 +411,14 @@ where
                     .scalar_ge_parallelized(&*self.ciphertext.on_cpu(), rhs);
                 FheBool::new(inner_result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let inner_result = fpga_key
+                    .pbs_key()
+                    .scalar_ge_parallelized(&*self.ciphertext.on_cpu(), rhs);
+                FheBool::new(inner_result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => {
                 crate::high_level_api::global_state::with_thread_local_cuda_streams(|streams| {
@@ -406,6 +470,17 @@ macro_rules! generic_integer_impl_scalar_div_rem {
                                     <$concrete_type>::new(r, cpu_key.tag.clone())
                                 )
                             }
+                            #[cfg(feature = "fpga")]
+                            InternalServerKey::Belfort(fpga_key) => {
+                            // TODO: FPGA implementation
+                                let (q, r) = fpga_key
+                                    .pbs_key()
+                                    .signed_scalar_div_rem_parallelized(&*self.ciphertext.on_cpu(), rhs);
+                                (
+                                    <$concrete_type>::new(q, fpga_key.tag.clone()),
+                                    <$concrete_type>::new(r, fpga_key.tag.clone())
+                                )
+                            }
                             #[cfg(feature = "gpu")]
                             InternalServerKey::Cuda(cuda_key) => {
                                 let (inner_q, inner_r) = with_thread_local_cuda_streams(|streams| {
@@ -460,6 +535,14 @@ generic_integer_impl_scalar_operation!(
                         .scalar_add_parallelized(&*lhs.ciphertext.on_cpu(), rhs);
                     RadixCiphertext::Cpu(inner_result)
                 },
+            #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                                    // TODO: FPGA implementation
+                    let inner_result = fpga_key
+                        .pbs_key()
+                        .scalar_add_parallelized(&*lhs.ciphertext.on_cpu(), rhs);
+                    RadixCiphertext::Cpu(inner_result)
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     let inner_result = with_thread_local_cuda_streams(|streams| {
@@ -493,7 +576,15 @@ generic_integer_impl_scalar_operation!(
         |lhs: &FheInt<_>, rhs| {
             global_state::with_internal_keys(|key| match key {
                 InternalServerKey::Cpu(cpu_key) => {
-                    let inner_result = cpu_key
+                        let inner_result = cpu_key
+                            .pbs_key()
+                            .scalar_sub_parallelized(&*lhs.ciphertext.on_cpu(), rhs);
+                        RadixCiphertext::Cpu(inner_result)
+                    },
+            #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                    let inner_result = fpga_key
                         .pbs_key()
                         .scalar_sub_parallelized(&*lhs.ciphertext.on_cpu(), rhs);
                     RadixCiphertext::Cpu(inner_result)
@@ -530,12 +621,20 @@ generic_integer_impl_scalar_operation!(
     implem: {
         |lhs: &FheInt<_>, rhs| {
             global_state::with_internal_keys(|key| match key {
-                InternalServerKey::Cpu(cpu_key) => {
+                InternalServerKey::Cpu(cpu_key)=> {
                     let inner_result = cpu_key
                         .pbs_key()
                         .scalar_mul_parallelized(&*lhs.ciphertext.on_cpu(), rhs);
                     RadixCiphertext::Cpu(inner_result)
                 },
+            #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                    let inner_result = fpga_key
+                        .pbs_key()
+                        .scalar_mul_parallelized(&*lhs.ciphertext.on_cpu(), rhs);
+                    RadixCiphertext::Cpu(inner_result)
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     let inner_result = with_thread_local_cuda_streams(|streams| {
@@ -574,6 +673,14 @@ generic_integer_impl_scalar_operation!(
                         .scalar_bitand_parallelized(&*lhs.ciphertext.on_cpu(), rhs);
                     RadixCiphertext::Cpu(inner_result)
                 },
+            #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                    let inner_result = fpga_key
+                        .pbs_key()
+                        .scalar_bitand_parallelized(&*lhs.ciphertext.on_cpu(), rhs);
+                    RadixCiphertext::Cpu(inner_result)
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     let inner_result = with_thread_local_cuda_streams(|streams| {
@@ -612,6 +719,14 @@ generic_integer_impl_scalar_operation!(
                         .scalar_bitor_parallelized(&*lhs.ciphertext.on_cpu(), rhs);
                     RadixCiphertext::Cpu(inner_result)
                 },
+            #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                                    // TODO: FPGA implementation
+                    let inner_result = fpga_key
+                        .pbs_key()
+                        .scalar_bitor_parallelized(&*lhs.ciphertext.on_cpu(), rhs);
+                    RadixCiphertext::Cpu(inner_result)
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     let inner_result = with_thread_local_cuda_streams(|streams| {
@@ -644,13 +759,22 @@ generic_integer_impl_scalar_operation!(
     implem: {
         |lhs: &FheInt<_>, rhs| {
             global_state::with_internal_keys(|key| match key {
-                InternalServerKey::Cpu(cpu_key) => {
+                InternalServerKey::Cpu(cpu_key)=> {
                     let inner_result = cpu_key
                         .pbs_key()
                         .scalar_bitxor_parallelized(&*lhs.ciphertext.on_cpu(), rhs);
                     RadixCiphertext::Cpu(inner_result)
                 },
 
+            #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                    let inner_result = fpga_key
+                        .pbs_key()
+                        .scalar_bitxor_parallelized(&*lhs.ciphertext.on_cpu(), rhs);
+                    RadixCiphertext::Cpu(inner_result)
+                },
+
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     let inner_result = with_thread_local_cuda_streams(|streams| {
@@ -683,12 +807,20 @@ generic_integer_impl_scalar_operation!(
     implem: {
         |lhs: &FheInt<_>, rhs| {
             global_state::with_internal_keys(|key| match key {
-                InternalServerKey::Cpu(cpu_key) => {
+                InternalServerKey::Cpu(cpu_key)=> {
                     let inner_result = cpu_key
                         .pbs_key()
                         .scalar_left_shift_parallelized(&*lhs.ciphertext.on_cpu(), rhs);
                     RadixCiphertext::Cpu(inner_result)
                 },
+            #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                    let inner_result = fpga_key
+                        .pbs_key()
+                        .scalar_left_shift_parallelized(&*lhs.ciphertext.on_cpu(), rhs);
+                    RadixCiphertext::Cpu(inner_result)
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     let inner_result = with_thread_local_cuda_streams(|streams| {
@@ -727,6 +859,14 @@ generic_integer_impl_scalar_operation!(
                         .scalar_right_shift_parallelized(&*lhs.ciphertext.on_cpu(), rhs);
                     RadixCiphertext::Cpu(inner_result)
                 },
+            #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                    let inner_result = fpga_key
+                        .pbs_key()
+                        .scalar_right_shift_parallelized(&*lhs.ciphertext.on_cpu(), rhs);
+                    RadixCiphertext::Cpu(inner_result)
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     let inner_result = with_thread_local_cuda_streams(|streams| {
@@ -765,6 +905,14 @@ generic_integer_impl_scalar_operation!(
                         .scalar_rotate_left_parallelized(&*lhs.ciphertext.on_cpu(), rhs);
                     RadixCiphertext::Cpu(inner_result)
                 },
+            #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                    let inner_result = fpga_key
+                        .pbs_key()
+                        .scalar_rotate_left_parallelized(&*lhs.ciphertext.on_cpu(), rhs);
+                    RadixCiphertext::Cpu(inner_result)
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     let inner_result = with_thread_local_cuda_streams(|streams| {
@@ -797,12 +945,20 @@ generic_integer_impl_scalar_operation!(
     implem: {
         |lhs: &FheInt<_>, rhs| {
             global_state::with_internal_keys(|key| match key {
-                InternalServerKey::Cpu(cpu_key) => {
+                InternalServerKey::Cpu(cpu_key)=> {
                     let inner_result = cpu_key
                         .pbs_key()
                         .scalar_rotate_right_parallelized(&*lhs.ciphertext.on_cpu(), rhs);
                     RadixCiphertext::Cpu(inner_result)
                 },
+            #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                    let inner_result = fpga_key
+                        .pbs_key()
+                        .scalar_rotate_right_parallelized(&*lhs.ciphertext.on_cpu(), rhs);
+                    RadixCiphertext::Cpu(inner_result)
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     let inner_result = with_thread_local_cuda_streams(|streams| {
@@ -841,6 +997,14 @@ generic_integer_impl_scalar_operation!(
                         .signed_scalar_div_parallelized(&lhs.ciphertext.on_cpu(), rhs);
                     RadixCiphertext::Cpu(inner_result)
                 },
+            #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                    let inner_result = fpga_key
+                        .pbs_key()
+                        .signed_scalar_div_parallelized(&lhs.ciphertext.on_cpu(), rhs);
+                    RadixCiphertext::Cpu(inner_result)
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     let inner_result = with_thread_local_cuda_streams(|streams| {
@@ -873,12 +1037,20 @@ generic_integer_impl_scalar_operation!(
     implem: {
         |lhs: &FheInt<_>, rhs| {
             global_state::with_internal_keys(|key| match key {
-                InternalServerKey::Cpu(cpu_key) => {
+                InternalServerKey::Cpu(cpu_key)=> {
                     let inner_result = cpu_key
                         .pbs_key()
                         .signed_scalar_rem_parallelized(&lhs.ciphertext.on_cpu(), rhs);
                     RadixCiphertext::Cpu(inner_result)
                 },
+            #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                    let inner_result = fpga_key
+                        .pbs_key()
+                        .signed_scalar_rem_parallelized(&lhs.ciphertext.on_cpu(), rhs);
+                    RadixCiphertext::Cpu(inner_result)
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     let inner_result = with_thread_local_cuda_streams(|streams| {
@@ -968,6 +1140,17 @@ generic_integer_impl_scalar_left_operation!(
                         .sub_assign_parallelized(&mut result, &*rhs.ciphertext.on_cpu());
                     RadixCiphertext::Cpu(result)
                 },
+            #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                    let mut result = fpga_key
+                        .pbs_key()
+                        .create_trivial_radix(lhs, rhs.ciphertext.on_cpu().blocks().len());
+                    fpga_key
+                        .pbs_key()
+                        .sub_assign_parallelized(&mut result, &*rhs.ciphertext.on_cpu());
+                    RadixCiphertext::Cpu(result)
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(_cuda_key) => {
                     with_thread_local_cuda_streams(|_stream| {
@@ -1196,11 +1379,18 @@ generic_integer_impl_scalar_operation_assign!(
     implem: {
         |lhs: &mut FheInt<_>, rhs| {
             global_state::with_internal_keys(|key| match key {
-                InternalServerKey::Cpu(cpu_key) => {
+                InternalServerKey::Cpu(cpu_key)=> {
                     cpu_key
                         .pbs_key()
                         .scalar_add_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
                 },
+            #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                fpga_key
+                        .pbs_key()
+                        .scalar_add_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     with_thread_local_cuda_streams(|streams| {
@@ -1253,11 +1443,18 @@ generic_integer_impl_scalar_operation_assign!(
     implem: {
         |lhs: &mut FheInt<_>, rhs| {
             global_state::with_internal_keys(|key| match key {
-                InternalServerKey::Cpu(cpu_key) => {
+                InternalServerKey::Cpu(cpu_key)=> {
                     cpu_key
                         .pbs_key()
                         .scalar_sub_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
                 },
+            #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                fpga_key
+                        .pbs_key()
+                        .scalar_sub_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     with_thread_local_cuda_streams(|streams| {
@@ -1288,11 +1485,18 @@ generic_integer_impl_scalar_operation_assign!(
     implem: {
         |lhs: &mut FheInt<_>, rhs| {
             global_state::with_internal_keys(|key| match key {
-                InternalServerKey::Cpu(cpu_key) => {
+                InternalServerKey::Cpu(cpu_key)=> {
                     cpu_key
                         .pbs_key()
                         .scalar_mul_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
                 },
+            #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                fpga_key
+                        .pbs_key()
+                        .scalar_mul_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     with_thread_local_cuda_streams(|streams| {
@@ -1328,6 +1532,13 @@ generic_integer_impl_scalar_operation_assign!(
                         .pbs_key()
                         .scalar_bitand_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
                 },
+            #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                fpga_key
+                        .pbs_key()
+                        .scalar_bitand_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     with_thread_local_cuda_streams(|streams| {
@@ -1363,6 +1574,13 @@ generic_integer_impl_scalar_operation_assign!(
                         .pbs_key()
                         .scalar_bitor_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
                 },
+            #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                fpga_key
+                        .pbs_key()
+                        .scalar_bitor_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     with_thread_local_cuda_streams(|streams| {
@@ -1398,6 +1616,13 @@ generic_integer_impl_scalar_operation_assign!(
                         .pbs_key()
                         .scalar_bitxor_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
                 },
+            #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                fpga_key
+                        .pbs_key()
+                        .scalar_bitxor_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     with_thread_local_cuda_streams(|streams| {
@@ -1433,6 +1658,13 @@ generic_integer_impl_scalar_operation_assign!(
                         .pbs_key()
                         .scalar_left_shift_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
                 },
+            #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                fpga_key
+                        .pbs_key()
+                        .scalar_left_shift_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     with_thread_local_cuda_streams(|streams| {
@@ -1468,6 +1700,13 @@ generic_integer_impl_scalar_operation_assign!(
                         .pbs_key()
                         .scalar_right_shift_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
                 },
+            #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                fpga_key
+                        .pbs_key()
+                        .scalar_right_shift_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     with_thread_local_cuda_streams(|streams| {
@@ -1502,7 +1741,14 @@ generic_integer_impl_scalar_operation_assign!(
                     cpu_key
                         .pbs_key()
                         .scalar_rotate_left_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
-                },
+                }
+                #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                fpga_key
+                        .pbs_key()
+                        .scalar_rotate_left_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
+                }
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     with_thread_local_cuda_streams(|streams| {
@@ -1537,7 +1783,14 @@ generic_integer_impl_scalar_operation_assign!(
                     cpu_key
                         .pbs_key()
                         .scalar_rotate_right_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
-                },
+                }
+                #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                    // TODO: FPGA implementation
+                    fpga_key
+                        .pbs_key()
+                        .scalar_rotate_right_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
+                }
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     with_thread_local_cuda_streams(|streams| {
@@ -1572,6 +1825,13 @@ generic_integer_impl_scalar_operation_assign!(
                     cpu_key
                         .pbs_key()
                         .signed_scalar_div_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
+                }
+                #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                    // TODO: FPGA implementation
+                    fpga_key
+                        .pbs_key()
+                        .signed_scalar_div_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
                 },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(_) => {
@@ -1601,10 +1861,17 @@ generic_integer_impl_scalar_operation_assign!(
         |lhs: &mut FheInt<_>, rhs| {
             global_state::with_internal_keys(|key| match key {
                 InternalServerKey::Cpu(cpu_key) => {
-                    cpu_key
+                        cpu_key
+                            .pbs_key()
+                            .signed_scalar_rem_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
+                    }
+                #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                    // TODO: FPGA implementation
+                    fpga_key
                         .pbs_key()
                         .signed_scalar_rem_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
-                },
+                }
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(_) => {
                     panic!("RemAssign '%=' with clear value is not yet supported by Cuda devices")
diff --git a/tfhe/src/high_level_api/integers/unsigned/base.rs b/tfhe/src/high_level_api/integers/unsigned/base.rs
index d79bafe82..cd4abd591 100644
--- a/tfhe/src/high_level_api/integers/unsigned/base.rs
+++ b/tfhe/src/high_level_api/integers/unsigned/base.rs
@@ -223,6 +223,14 @@ where
                     .is_even_parallelized(&*self.ciphertext.on_cpu());
                 FheBool::new(result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let result = fpga_key
+                    .pbs_key()
+                    .is_even_parallelized(&*self.ciphertext.on_cpu());
+                FheBool::new(result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let result = cuda_key
@@ -259,6 +267,14 @@ where
                     .is_odd_parallelized(&*self.ciphertext.on_cpu());
                 FheBool::new(result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let result = fpga_key
+                    .pbs_key()
+                    .is_odd_parallelized(&*self.ciphertext.on_cpu());
+                FheBool::new(result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let result = cuda_key.key.key.is_odd(&*self.ciphertext.on_gpu(), streams);
@@ -389,6 +405,18 @@ where
                 );
                 super::FheUint32::new(result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let result = fpga_key
+                    .pbs_key()
+                    .leading_zeros_parallelized(&*self.ciphertext.on_cpu());
+                let result = fpga_key.pbs_key().cast_to_unsigned(
+                    result,
+                    super::FheUint32Id::num_blocks(fpga_key.pbs_key().message_modulus()),
+                );
+                super::FheUint32::new(result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let result = cuda_key
@@ -434,6 +462,18 @@ where
                 );
                 super::FheUint32::new(result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let result = fpga_key
+                    .pbs_key()
+                    .leading_ones_parallelized(&*self.ciphertext.on_cpu());
+                let result = fpga_key.pbs_key().cast_to_unsigned(
+                    result,
+                    super::FheUint32Id::num_blocks(fpga_key.pbs_key().message_modulus()),
+                );
+                super::FheUint32::new(result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let result = cuda_key
@@ -479,6 +519,18 @@ where
                 );
                 super::FheUint32::new(result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let result = fpga_key
+                    .pbs_key()
+                    .trailing_zeros_parallelized(&*self.ciphertext.on_cpu());
+                let result = fpga_key.pbs_key().cast_to_unsigned(
+                    result,
+                    super::FheUint32Id::num_blocks(fpga_key.pbs_key().message_modulus()),
+                );
+                super::FheUint32::new(result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let result = cuda_key
@@ -524,6 +576,18 @@ where
                 );
                 super::FheUint32::new(result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let result = fpga_key
+                    .pbs_key()
+                    .trailing_ones_parallelized(&*self.ciphertext.on_cpu());
+                let result = fpga_key.pbs_key().cast_to_unsigned(
+                    result,
+                    super::FheUint32Id::num_blocks(fpga_key.pbs_key().message_modulus()),
+                );
+                super::FheUint32::new(result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let result = cuda_key
@@ -570,6 +634,18 @@ where
                 );
                 super::FheUint32::new(result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let result = fpga_key
+                    .pbs_key()
+                    .count_ones_parallelized(&*self.ciphertext.on_cpu());
+                let result = fpga_key.pbs_key().cast_to_unsigned(
+                    result,
+                    super::FheUint32Id::num_blocks(fpga_key.pbs_key().message_modulus()),
+                );
+                super::FheUint32::new(result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(_) => {
                 panic!("Cuda devices do not support count_ones yet");
@@ -607,6 +683,17 @@ where
                 );
                 super::FheUint32::new(result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                let result = fpga_key
+                    .pbs_key()
+                    .count_zeros_parallelized(&*self.ciphertext.on_cpu());
+                let result = fpga_key.pbs_key().cast_to_unsigned(
+                    result,
+                    super::FheUint32Id::num_blocks(fpga_key.pbs_key().message_modulus()),
+                );
+                super::FheUint32::new(result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(_) => {
                 panic!("Cuda devices do not support count_zeros yet");
@@ -645,6 +732,18 @@ where
                 );
                 super::FheUint32::new(result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let result = fpga_key
+                    .pbs_key()
+                    .ilog2_parallelized(&*self.ciphertext.on_cpu());
+                let result = fpga_key.pbs_key().cast_to_unsigned(
+                    result,
+                    super::FheUint32Id::num_blocks(fpga_key.pbs_key().message_modulus()),
+                );
+                super::FheUint32::new(result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let result = cuda_key.key.key.ilog2(&*self.ciphertext.on_gpu(), streams);
@@ -696,6 +795,21 @@ where
                     FheBool::new(is_ok, cpu_key.tag.clone()),
                 )
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let (result, is_ok) = fpga_key
+                    .pbs_key()
+                    .checked_ilog2_parallelized(&*self.ciphertext.on_cpu());
+                let result = fpga_key.pbs_key().cast_to_unsigned(
+                    result,
+                    super::FheUint32Id::num_blocks(fpga_key.pbs_key().message_modulus()),
+                );
+                (
+                    super::FheUint32::new(result, fpga_key.tag.clone()),
+                    FheBool::new(is_ok, fpga_key.tag.clone()),
+                )
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let (result, is_ok) = cuda_key
@@ -778,6 +892,25 @@ where
                     Err(crate::Error::new("Output type does not have enough bits to represent all possible output values".to_string()))
                 }
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let (result, matched) = fpga_key
+                    .pbs_key()
+                    .match_value_parallelized(&self.ciphertext.on_cpu(), matches);
+                let target_num_blocks = OutId::num_blocks(fpga_key.key.message_modulus());
+                if target_num_blocks >= result.blocks.len() {
+                    let result = fpga_key
+                        .pbs_key()
+                        .cast_to_unsigned(result, target_num_blocks);
+                    Ok((
+                        FheUint::new(result, fpga_key.tag.clone()),
+                        FheBool::new(matched, fpga_key.tag.clone()),
+                    ))
+                } else {
+                    Err(crate::Error::new("Output type does not have enough bits to represent all possible output values".to_string()))
+                }
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let (result, matched) =
@@ -856,6 +989,24 @@ where
                     Err(crate::Error::new("Output type does not have enough bits to represent all possible output values".to_string()))
                 }
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let result = fpga_key.pbs_key().match_value_or_parallelized(
+                    &self.ciphertext.on_cpu(),
+                    matches,
+                    or_value,
+                );
+                let target_num_blocks = OutId::num_blocks(fpga_key.key.message_modulus());
+                if target_num_blocks >= result.blocks.len() {
+                    let result = fpga_key
+                        .pbs_key()
+                        .cast_to_unsigned(result, target_num_blocks);
+                    Ok(FheUint::new(result, fpga_key.tag.clone()))
+                } else {
+                    Err(crate::Error::new("Output type does not have enough bits to represent all possible output values".to_string()))
+                }
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let result = cuda_key.key.key.match_value_or(
@@ -903,6 +1054,15 @@ where
 
                 Self::new(sk.reverse_bits_parallelized(&*ct), cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let sk = &fpga_key.pbs_key();
+
+                let ct = self.ciphertext.on_cpu();
+
+                Self::new(sk.reverse_bits_parallelized(&*ct), fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(_) => {
                 panic!("Cuda devices do not support reverse yet");
@@ -925,6 +1085,12 @@ where
                     sks.pbs_key().key.carry_modulus,
                     sks.pbs_key().key.message_modulus,
                 ),
+                #[cfg(feature = "fpga")]
+                InternalServerKey::Belfort(fpga_key) => (
+                    // TODO: FPGA implementation
+                    fpga_key.pbs_key().key.carry_modulus,
+                    fpga_key.pbs_key().key.message_modulus,
+                ),
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => (
                     cuda_key.key.key.carry_modulus,
@@ -1007,6 +1173,15 @@ where
                 );
                 Self::new(casted, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let casted = fpga_key.pbs_key().cast_to_unsigned(
+                    input.ciphertext.into_cpu(),
+                    IntoId::num_blocks(fpga_key.key.message_modulus()),
+                );
+                Self::new(casted, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let casted = cuda_key.key.key.cast_to_unsigned(
@@ -1051,15 +1226,24 @@ where
                 );
                 Self::new(casted, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let casted = fpga_key.pbs_key().cast_to_unsigned(
+                    input.ciphertext.on_cpu().to_owned(),
+                    IntoId::num_blocks(fpga_key.key.message_modulus()),
+                );
+                Self::new(casted, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
-            InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
+            InternalServerKey::Cuda(_) => {
                 let casted = cuda_key.key.key.cast_to_unsigned(
                     input.ciphertext.into_gpu(),
                     IntoId::num_blocks(cuda_key.message_modulus()),
                     streams,
                 );
                 Self::new(casted, cuda_key.tag.clone())
-            }),
+            }
         })
     }
 }
@@ -1095,6 +1279,16 @@ where
                     .into_radix(Id::num_blocks(cpu_key.message_modulus()), cpu_key.pbs_key());
                 Self::new(ciphertext, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let ciphertext: crate::integer::RadixCiphertext =
+                    input.ciphertext.on_cpu().into_owned().into_radix(
+                        Id::num_blocks(fpga_key.key.message_modulus()),
+                        fpga_key.pbs_key(),
+                    );
+                Self::new(ciphertext, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner = cuda_key.key.key.cast_to_unsigned(
diff --git a/tfhe/src/high_level_api/integers/unsigned/encrypt.rs b/tfhe/src/high_level_api/integers/unsigned/encrypt.rs
index 593e580e6..5cea59a9d 100644
--- a/tfhe/src/high_level_api/integers/unsigned/encrypt.rs
+++ b/tfhe/src/high_level_api/integers/unsigned/encrypt.rs
@@ -114,6 +114,14 @@ where
                     .create_trivial_radix(value, Id::num_blocks(key.message_modulus()));
                 Ok(Self::new(ciphertext, key.tag.clone()))
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let ciphertext: crate::integer::RadixCiphertext = fpga_key
+                    .pbs_key()
+                    .create_trivial_radix(value, Id::num_blocks(fpga_key.key.message_modulus()));
+                Ok(Self::new(ciphertext, fpga_key.tag.clone()))
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner: CudaUnsignedRadixCiphertext = cuda_key.key.key.create_trivial_radix(
diff --git a/tfhe/src/high_level_api/integers/unsigned/inner.rs b/tfhe/src/high_level_api/integers/unsigned/inner.rs
index 8ef5e2888..c801db11b 100644
--- a/tfhe/src/high_level_api/integers/unsigned/inner.rs
+++ b/tfhe/src/high_level_api/integers/unsigned/inner.rs
@@ -194,6 +194,10 @@ impl RadixCiphertext {
             (Self::Cpu(_), Device::Cpu) => {
                 // Nothing to do, we already are on the correct device
             }
+            #[cfg(feature = "fpga")]
+            (Self::Cpu(_), Device::Fpga) => {
+                // Nothing to do, FPGA uses the same RadixCiphertext as CPU
+            }
             #[cfg(feature = "gpu")]
             (Self::Cuda(_), Device::CudaGpu) => {
                 // Nothing to do, we already are on the correct device
diff --git a/tfhe/src/high_level_api/integers/unsigned/ops.rs b/tfhe/src/high_level_api/integers/unsigned/ops.rs
index 78f28bb27..fb961ee8b 100644
--- a/tfhe/src/high_level_api/integers/unsigned/ops.rs
+++ b/tfhe/src/high_level_api/integers/unsigned/ops.rs
@@ -72,6 +72,25 @@ where
                         |ct| Self::new(ct, cpu_key.tag.clone()),
                     )
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let ciphertexts = iter.map(|elem| elem.ciphertext.into_cpu()).collect();
+                fpga_key
+                    .pbs_key()
+                    .unchecked_sum_ciphertexts_vec_parallelized(ciphertexts)
+                    .map_or_else(
+                        || {
+                            Self::new(
+                                RadixCiphertext::Cpu(fpga_key.pbs_key().create_trivial_zero_radix(
+                                    Id::num_blocks(fpga_key.key.message_modulus()),
+                                )),
+                                fpga_key.tag.clone(),
+                            )
+                        },
+                        |ct| Self::new(ct, fpga_key.tag.clone()),
+                    )
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let cts = iter
@@ -150,6 +169,30 @@ where
                         |ct| Self::new(ct, cpu_key.tag.clone()),
                     )
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let ciphertexts = iter
+                    .map(|elem| elem.ciphertext.on_cpu().to_owned())
+                    .collect();
+                let msg_mod = fpga_key.pbs_key().message_modulus();
+                fpga_key
+                    .pbs_key()
+                    .unchecked_sum_ciphertexts_vec_parallelized(ciphertexts)
+                    .map_or_else(
+                        || {
+                            Self::new(
+                                RadixCiphertext::Cpu(
+                                    fpga_key
+                                        .pbs_key()
+                                        .create_trivial_zero_radix(Id::num_blocks(msg_mod)),
+                                ),
+                                fpga_key.tag.clone(),
+                            )
+                        },
+                        |ct| Self::new(ct, fpga_key.tag.clone()),
+                    )
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => {
                 with_thread_local_cuda_streams(|streams| {
@@ -221,6 +264,12 @@ where
                     .max_parallelized(&*self.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
                 Self::new(inner_result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                let inner_result =
+                    fpga_key.max(&*self.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
+                Self::new(inner_result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_result = cuda_key.key.key.max(
@@ -267,6 +316,12 @@ where
                     .min_parallelized(&*self.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
                 Self::new(inner_result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                let inner_result =
+                    fpga_key.min(&*self.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
+                Self::new(inner_result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_result = cuda_key.key.key.min(
@@ -324,6 +379,12 @@ where
                     .eq_parallelized(&*self.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
                 FheBool::new(inner_result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                let inner_result =
+                    fpga_key.eq(&*self.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
+                FheBool::new(inner_result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_result = cuda_key.key.key.eq(
@@ -363,6 +424,12 @@ where
                     .ne_parallelized(&*self.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
                 FheBool::new(inner_result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                let inner_result =
+                    fpga_key.ne(&*self.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
+                FheBool::new(inner_result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_result = cuda_key.key.key.ne(
@@ -428,6 +495,12 @@ where
                     .lt_parallelized(&*self.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
                 FheBool::new(inner_result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                let inner_result =
+                    fpga_key.lt(&*self.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
+                FheBool::new(inner_result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_result = cuda_key.key.key.lt(
@@ -467,6 +540,12 @@ where
                     .le_parallelized(&*self.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
                 FheBool::new(inner_result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                let inner_result =
+                    fpga_key.le(&*self.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
+                FheBool::new(inner_result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_result = cuda_key.key.key.le(
@@ -506,6 +585,12 @@ where
                     .gt_parallelized(&*self.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
                 FheBool::new(inner_result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                let inner_result =
+                    fpga_key.gt(&*self.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
+                FheBool::new(inner_result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_result = cuda_key.key.key.gt(
@@ -545,6 +630,12 @@ where
                     .ge_parallelized(&*self.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
                 FheBool::new(inner_result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                let inner_result =
+                    fpga_key.ge(&*self.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
+                FheBool::new(inner_result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_result = cuda_key.key.key.ge(
@@ -628,6 +719,15 @@ where
                     FheUint::<Id>::new(r, cpu_key.tag.clone()),
                 )
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                let (q, r) =
+                    fpga_key.div_rem(&*self.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
+                (
+                    FheUint::<Id>::new(q, fpga_key.tag.clone()),
+                    FheUint::<Id>::new(r, fpga_key.tag.clone()),
+                )
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_result = cuda_key.key.key.div_rem(
@@ -707,12 +807,17 @@ generic_integer_impl_operation!(
     implem: {
         |lhs: &FheUint<_>, rhs: &FheUint<_>| {
             global_state::with_internal_keys(|key| match key {
-                InternalServerKey::Cpu(cpu_key) => {
+                InternalServerKey::Cpu(cpu_key)=> {
                     let inner_result = cpu_key
                         .pbs_key()
                         .add_parallelized(&*lhs.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
                     FheUint::new(inner_result, cpu_key.tag.clone())
                 },
+                #[cfg(feature = "fpga")]
+                InternalServerKey::Belfort(fpga_key) => {
+                    let inner_result = fpga_key.add(&*lhs.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
+                    FheUint::new(inner_result, fpga_key.tag.clone())
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     with_thread_local_cuda_streams(|streams| {
@@ -756,6 +861,11 @@ generic_integer_impl_operation!(
                         .sub_parallelized(&*lhs.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
                     FheUint::new(inner_result, cpu_key.tag.clone())
                 },
+                #[cfg(feature = "fpga")]
+                InternalServerKey::Belfort(fpga_key) => {
+                    let inner_result = fpga_key.sub(&*lhs.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
+                    FheUint::new(inner_result, fpga_key.tag.clone())
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     with_thread_local_cuda_streams(|streams| {
@@ -799,9 +909,14 @@ generic_integer_impl_operation!(
                         .mul_parallelized(&*lhs.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
                     FheUint::new(inner_result, cpu_key.tag.clone())
                 },
+                #[cfg(feature = "fpga")]
+                InternalServerKey::Belfort(fpga_key) => {
+                    let inner_result = fpga_key.mul(&*lhs.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
+                    FheUint::new(inner_result, fpga_key.tag.clone())
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
-                     with_thread_local_cuda_streams(|streams| {
+                    with_thread_local_cuda_streams(|streams| {
                         let inner_result = cuda_key.key.key
                             .mul(&*lhs.ciphertext.on_gpu(), &*rhs.ciphertext.on_gpu(), streams);
                         FheUint::new(inner_result, cuda_key.tag.clone())
@@ -840,9 +955,15 @@ generic_integer_impl_operation!(
                         .bitand_parallelized(&*lhs.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
                     FheUint::new(inner_result, cpu_key.tag.clone())
                 },
+                #[cfg(feature = "fpga")]
+                InternalServerKey::Belfort(fpga_key) => {
+                    let inner_result =
+                        fpga_key.bitand(&*lhs.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
+                    FheUint::new(inner_result, fpga_key.tag.clone())
+                }
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
-                     with_thread_local_cuda_streams(|streams| {
+                    with_thread_local_cuda_streams(|streams| {
                         let inner_result = cuda_key.key.key
                             .bitand(&*lhs.ciphertext.on_gpu(), &*rhs.ciphertext.on_gpu(), streams);
                         FheUint::new(inner_result, cuda_key.tag.clone())
@@ -881,9 +1002,15 @@ generic_integer_impl_operation!(
                         .bitor_parallelized(&*lhs.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
                     FheUint::new(inner_result, cpu_key.tag.clone())
                 },
+                #[cfg(feature = "fpga")]
+                InternalServerKey::Belfort(fpga_key) => {
+                    let inner_result =
+                        fpga_key.bitor(&*lhs.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
+                    FheUint::new(inner_result, fpga_key.tag.clone())
+                }
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
-                     with_thread_local_cuda_streams(|streams| {
+                    with_thread_local_cuda_streams(|streams| {
                         let inner_result = cuda_key.key.key
                             .bitor(&*lhs.ciphertext.on_gpu(), &*rhs.ciphertext.on_gpu(), streams);
                         FheUint::new(inner_result, cuda_key.tag.clone())
@@ -922,9 +1049,15 @@ generic_integer_impl_operation!(
                         .bitxor_parallelized(&*lhs.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
                     FheUint::new(inner_result, cpu_key.tag.clone())
                 },
+                #[cfg(feature = "fpga")]
+                InternalServerKey::Belfort(fpga_key) => {
+                    let inner_result =
+                        fpga_key.bitxor(&*lhs.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
+                    FheUint::new(inner_result, fpga_key.tag.clone())
+                }
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
-                     with_thread_local_cuda_streams(|streams| {
+                    with_thread_local_cuda_streams(|streams| {
                         let inner_result = cuda_key.key.key
                             .bitxor(&*lhs.ciphertext.on_gpu(), &*rhs.ciphertext.on_gpu(), streams);
                         FheUint::new(inner_result, cuda_key.tag.clone())
@@ -971,6 +1104,12 @@ generic_integer_impl_operation!(
                         .div_parallelized(&*lhs.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
                     FheUint::new(inner_result, cpu_key.tag.clone())
                 },
+                #[cfg(feature = "fpga")]
+                InternalServerKey::Belfort(fpga_key) => {
+                    let inner_result =
+                        fpga_key.div(&*lhs.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
+                    FheUint::new(inner_result, fpga_key.tag.clone())
+                }
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                     let inner_result =
@@ -1022,6 +1161,12 @@ generic_integer_impl_operation!(
                         .rem_parallelized(&*lhs.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
                     FheUint::new(inner_result, cpu_key.tag.clone())
                 },
+                #[cfg(feature = "fpga")]
+                InternalServerKey::Belfort(fpga_key) => {
+                    let inner_result =
+                        fpga_key.rem(&*lhs.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
+                    FheUint::new(inner_result, fpga_key.tag.clone())
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                     let inner_result =
@@ -1136,9 +1281,15 @@ generic_integer_impl_shift_rotate!(
                             .left_shift_parallelized(&*lhs.ciphertext.on_cpu(), &rhs.ciphertext.on_cpu());
                         FheUint::new(ciphertext, cpu_key.tag.clone())
                     }
+                    #[cfg(feature = "fpga")]
+                    InternalServerKey::Belfort(fpga_key) => {
+                        let inner_result =
+                            fpga_key.left_shift(&*lhs.ciphertext.on_cpu(), &rhs.ciphertext.on_cpu());
+                        FheUint::new(inner_result, fpga_key.tag.clone())
+                    }
                     #[cfg(feature = "gpu")]
                     InternalServerKey::Cuda(cuda_key) => {
-                         with_thread_local_cuda_streams(|streams| {
+                        with_thread_local_cuda_streams(|streams| {
                             let inner_result = cuda_key.key.key
                                 .left_shift(&*lhs.ciphertext.on_gpu(), &rhs.ciphertext.on_gpu(), streams);
                             FheUint::new(inner_result, cuda_key.tag.clone())
@@ -1180,9 +1331,15 @@ generic_integer_impl_shift_rotate!(
                             .right_shift_parallelized(&*lhs.ciphertext.on_cpu(), &rhs.ciphertext.on_cpu());
                         FheUint::new(ciphertext, cpu_key.tag.clone())
                     }
+                    #[cfg(feature = "fpga")]
+                    InternalServerKey::Belfort(fpga_key) => {
+                        let inner_result =
+                            fpga_key.right_shift(&*lhs.ciphertext.on_cpu(), &rhs.ciphertext.on_cpu());
+                        FheUint::new(inner_result, fpga_key.tag.clone())
+                    }
                     #[cfg(feature = "gpu")]
                     InternalServerKey::Cuda(cuda_key) => {
-                         with_thread_local_cuda_streams(|streams| {
+                        with_thread_local_cuda_streams(|streams| {
                             let inner_result = cuda_key.key.key
                                 .right_shift(&*lhs.ciphertext.on_gpu(), &rhs.ciphertext.on_gpu(), streams);
                             FheUint::new(inner_result, cuda_key.tag.clone())
@@ -1224,9 +1381,15 @@ generic_integer_impl_shift_rotate!(
                             .rotate_left_parallelized(&*lhs.ciphertext.on_cpu(), &rhs.ciphertext.on_cpu());
                         FheUint::new(ciphertext, cpu_key.tag.clone())
                     }
+                    #[cfg(feature = "fpga")]
+                    InternalServerKey::Belfort(fpga_key) => {
+                        let inner_result =
+                            fpga_key.rotate_left(&*lhs.ciphertext.on_cpu(), &rhs.ciphertext.on_cpu());
+                        FheUint::new(inner_result, fpga_key.tag.clone())
+                    }
                     #[cfg(feature = "gpu")]
                     InternalServerKey::Cuda(cuda_key) => {
-                         with_thread_local_cuda_streams(|streams| {
+                        with_thread_local_cuda_streams(|streams| {
                             let inner_result = cuda_key.key.key
                                 .rotate_left(&*lhs.ciphertext.on_gpu(), &rhs.ciphertext.on_gpu(), streams);
                             FheUint::new(inner_result, cuda_key.tag.clone())
@@ -1268,6 +1431,12 @@ generic_integer_impl_shift_rotate!(
                             .rotate_right_parallelized(&*lhs.ciphertext.on_cpu(), &rhs.ciphertext.on_cpu());
                         FheUint::new(ciphertext, cpu_key.tag.clone())
                     }
+                    #[cfg(feature = "fpga")]
+                    InternalServerKey::Belfort(fpga_key) => {
+                        let inner_result =
+                            fpga_key.rotate_right(&*lhs.ciphertext.on_cpu(), &rhs.ciphertext.on_cpu());
+                        FheUint::new(inner_result, fpga_key.tag.clone())
+                    }
                     #[cfg(feature = "gpu")]
                     InternalServerKey::Cuda(cuda_key) => {
                          with_thread_local_cuda_streams(|streams| {
@@ -1318,6 +1487,10 @@ where
                     &*rhs.ciphertext.on_cpu(),
                 );
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                fpga_key.add_assign(self.ciphertext.as_cpu_mut(), &*rhs.ciphertext.on_cpu());
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 cuda_key.key.key.add_assign(
@@ -1363,6 +1536,13 @@ where
                     &*rhs.ciphertext.on_cpu(),
                 );
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                fpga_key.pbs_key().sub_assign_parallelized(
+                    self.ciphertext.as_cpu_mut(),
+                    &*rhs.ciphertext.on_cpu(),
+                );
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 cuda_key.key.key.sub_assign(
@@ -1408,6 +1588,14 @@ where
                     &*rhs.ciphertext.on_cpu(),
                 );
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                fpga_key.pbs_key().mul_assign_parallelized(
+                    self.ciphertext.as_cpu_mut(),
+                    &*rhs.ciphertext.on_cpu(),
+                );
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 cuda_key.key.key.mul_assign(
@@ -1451,6 +1639,10 @@ where
                     &*rhs.ciphertext.on_cpu(),
                 );
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                fpga_key.bitand_assign(self.ciphertext.as_cpu_mut(), &*rhs.ciphertext.on_cpu());
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 cuda_key.key.key.bitand_assign(
@@ -1494,6 +1686,10 @@ where
                     &*rhs.ciphertext.on_cpu(),
                 );
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                fpga_key.bitor_assign(self.ciphertext.as_cpu_mut(), &*rhs.ciphertext.on_cpu());
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 cuda_key.key.key.bitor_assign(
@@ -1537,6 +1733,10 @@ where
                     &*rhs.ciphertext.on_cpu(),
                 );
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                fpga_key.bitxor_assign(self.ciphertext.as_cpu_mut(), &*rhs.ciphertext.on_cpu());
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 cuda_key.key.key.bitxor_assign(
@@ -1585,6 +1785,10 @@ where
                     &*rhs.ciphertext.on_cpu(),
                 );
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                fpga_key.div_assign(self.ciphertext.as_cpu_mut(), &*rhs.ciphertext.on_cpu());
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 cuda_key.key.key.div_assign(
@@ -1633,6 +1837,10 @@ where
                     &*rhs.ciphertext.on_cpu(),
                 );
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                fpga_key.rem_assign(self.ciphertext.as_cpu_mut(), &*rhs.ciphertext.on_cpu());
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 cuda_key.key.key.rem_assign(
@@ -1686,6 +1894,10 @@ where
                     &rhs.ciphertext.on_cpu(),
                 );
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                fpga_key.left_shift_assign(self.ciphertext.as_cpu_mut(), &rhs.ciphertext.on_cpu());
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => {
                 with_thread_local_cuda_streams(|streams| {
@@ -1740,6 +1952,10 @@ where
                     &rhs.ciphertext.on_cpu(),
                 );
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                fpga_key.right_shift_assign(self.ciphertext.as_cpu_mut(), &rhs.ciphertext.on_cpu());
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => {
                 with_thread_local_cuda_streams(|streams| {
@@ -1795,6 +2011,10 @@ where
                     &rhs.ciphertext.on_cpu(),
                 );
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                fpga_key.rotate_left_assign(self.ciphertext.as_cpu_mut(), &rhs.ciphertext.on_cpu());
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => {
                 with_thread_local_cuda_streams(|streams| {
@@ -1850,6 +2070,11 @@ where
                     &rhs.ciphertext.on_cpu(),
                 );
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                fpga_key
+                    .rotate_right_assign(self.ciphertext.as_cpu_mut(), &rhs.ciphertext.on_cpu());
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => {
                 with_thread_local_cuda_streams(|streams| {
@@ -1931,6 +2156,14 @@ where
                     .neg_parallelized(&*self.ciphertext.on_cpu());
                 FheUint::new(ciphertext, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let ciphertext = fpga_key
+                    .pbs_key()
+                    .neg_parallelized(&*self.ciphertext.on_cpu());
+                FheUint::new(ciphertext, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_result = cuda_key.key.key.neg(&*self.ciphertext.on_gpu(), streams);
@@ -1997,6 +2230,11 @@ where
                 let ciphertext = cpu_key.pbs_key().bitnot(&*self.ciphertext.on_cpu());
                 FheUint::new(ciphertext, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                let inner_result = fpga_key.bitnot(&*self.ciphertext.on_cpu());
+                FheUint::new(inner_result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_result = cuda_key.key.key.bitnot(&*self.ciphertext.on_gpu(), streams);
diff --git a/tfhe/src/high_level_api/integers/unsigned/overflowing_ops.rs b/tfhe/src/high_level_api/integers/unsigned/overflowing_ops.rs
index 309aae827..36244c419 100644
--- a/tfhe/src/high_level_api/integers/unsigned/overflowing_ops.rs
+++ b/tfhe/src/high_level_api/integers/unsigned/overflowing_ops.rs
@@ -52,6 +52,18 @@ where
                     FheBool::new(overflow, cpu_key.tag.clone()),
                 )
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let (result, overflow) = fpga_key.pbs_key().unsigned_overflowing_add_parallelized(
+                    &self.ciphertext.on_cpu(),
+                    &other.ciphertext.on_cpu(),
+                );
+                (
+                    FheUint::new(result, fpga_key.tag.clone()),
+                    FheBool::new(overflow, fpga_key.tag.clone()),
+                )
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_result = cuda_key.key.key.unsigned_overflowing_add(
@@ -148,6 +160,17 @@ where
                     FheBool::new(overflow, cpu_key.tag.clone()),
                 )
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let (result, overflow) = fpga_key
+                    .pbs_key()
+                    .unsigned_overflowing_scalar_add_parallelized(&self.ciphertext.on_cpu(), other);
+                (
+                    FheUint::new(result, fpga_key.tag.clone()),
+                    FheBool::new(overflow, fpga_key.tag.clone()),
+                )
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_result = cuda_key.key.key.unsigned_overflowing_scalar_add(
@@ -284,6 +307,18 @@ where
                     FheBool::new(overflow, cpu_key.tag.clone()),
                 )
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let (result, overflow) = fpga_key.pbs_key().unsigned_overflowing_sub_parallelized(
+                    &self.ciphertext.on_cpu(),
+                    &other.ciphertext.on_cpu(),
+                );
+                (
+                    FheUint::new(result, fpga_key.tag.clone()),
+                    FheBool::new(overflow, fpga_key.tag.clone()),
+                )
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_result = cuda_key.key.key.unsigned_overflowing_sub(
@@ -380,6 +415,17 @@ where
                     FheBool::new(overflow, cpu_key.tag.clone()),
                 )
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let (result, overflow) = fpga_key
+                    .pbs_key()
+                    .unsigned_overflowing_scalar_sub_parallelized(&self.ciphertext.on_cpu(), other);
+                (
+                    FheUint::new(result, fpga_key.tag.clone()),
+                    FheBool::new(overflow, fpga_key.tag.clone()),
+                )
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(_) => {
                 panic!("Cuda devices do not support overflowing_add yet");
@@ -467,6 +513,18 @@ where
                     FheBool::new(overflow, cpu_key.tag.clone()),
                 )
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let (result, overflow) = fpga_key.pbs_key().unsigned_overflowing_mul_parallelized(
+                    &self.ciphertext.on_cpu(),
+                    &other.ciphertext.on_cpu(),
+                );
+                (
+                    FheUint::new(result, fpga_key.tag.clone()),
+                    FheBool::new(overflow, fpga_key.tag.clone()),
+                )
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(_) => {
                 todo!("Cuda devices do not support overflowing_mul");
diff --git a/tfhe/src/high_level_api/integers/unsigned/scalar_ops.rs b/tfhe/src/high_level_api/integers/unsigned/scalar_ops.rs
index 7c35e50df..4a1cf2c75 100644
--- a/tfhe/src/high_level_api/integers/unsigned/scalar_ops.rs
+++ b/tfhe/src/high_level_api/integers/unsigned/scalar_ops.rs
@@ -60,6 +60,11 @@ where
                     .scalar_eq_parallelized(&*self.ciphertext.on_cpu(), rhs);
                 FheBool::new(inner_result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                let inner_result = fpga_key.scalar_eq(&*self.ciphertext.on_cpu(), rhs);
+                FheBool::new(inner_result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_result =
@@ -99,6 +104,11 @@ where
                     .scalar_ne_parallelized(&*self.ciphertext.on_cpu(), rhs);
                 FheBool::new(inner_result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                let inner_result = fpga_key.scalar_ne(&*self.ciphertext.on_cpu(), rhs);
+                FheBool::new(inner_result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_result =
@@ -144,6 +154,14 @@ where
                     .scalar_lt_parallelized(&*self.ciphertext.on_cpu(), rhs);
                 FheBool::new(inner_result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let inner_result = fpga_key
+                    .pbs_key()
+                    .scalar_lt_parallelized(&*self.ciphertext.on_cpu(), rhs);
+                FheBool::new(inner_result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_result =
@@ -183,6 +201,14 @@ where
                     .scalar_le_parallelized(&*self.ciphertext.on_cpu(), rhs);
                 FheBool::new(inner_result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let inner_result = fpga_key
+                    .pbs_key()
+                    .scalar_le_parallelized(&*self.ciphertext.on_cpu(), rhs);
+                FheBool::new(inner_result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_result =
@@ -222,6 +248,14 @@ where
                     .scalar_gt_parallelized(&*self.ciphertext.on_cpu(), rhs);
                 FheBool::new(inner_result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let inner_result = fpga_key
+                    .pbs_key()
+                    .scalar_gt_parallelized(&*self.ciphertext.on_cpu(), rhs);
+                FheBool::new(inner_result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_result =
@@ -261,6 +295,14 @@ where
                     .scalar_ge_parallelized(&*self.ciphertext.on_cpu(), rhs);
                 FheBool::new(inner_result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let inner_result = fpga_key
+                    .pbs_key()
+                    .scalar_ge_parallelized(&*self.ciphertext.on_cpu(), rhs);
+                FheBool::new(inner_result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_result =
@@ -308,6 +350,14 @@ where
                     .scalar_max_parallelized(&*self.ciphertext.on_cpu(), rhs);
                 Self::new(inner_result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let inner_result = fpga_key
+                    .pbs_key()
+                    .scalar_max_parallelized(&*self.ciphertext.on_cpu(), rhs);
+                Self::new(inner_result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_result =
@@ -355,6 +405,14 @@ where
                     .scalar_min_parallelized(&*self.ciphertext.on_cpu(), rhs);
                 Self::new(inner_result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let inner_result = fpga_key
+                    .pbs_key()
+                    .scalar_min_parallelized(&*self.ciphertext.on_cpu(), rhs);
+                Self::new(inner_result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_result =
@@ -410,6 +468,14 @@ where
                     .scalar_bitslice_parallelized(&self.ciphertext.on_cpu(), range)?;
                 Ok(FheUint::new(result, cpu_key.tag.clone()))
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let result = fpga_key
+                    .pbs_key()
+                    .scalar_bitslice_parallelized(&self.ciphertext.on_cpu(), range)?;
+                Ok(FheUint::new(result, fpga_key.tag.clone()))
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(_) => {
                 panic!("Cuda devices do not support bitslice yet");
@@ -492,12 +558,20 @@ macro_rules! generic_integer_impl_scalar_div_rem {
                                         <$concrete_type>::new(r, cpu_key.tag.clone())
                                     )
                                 }
+                                #[cfg(feature = "fpga")]
+                                InternalServerKey::Belfort(fpga_key) => {
+                                    let (q, r) = fpga_key.pbs_key().scalar_div_rem_parallelized(&*self.ciphertext.on_cpu(), rhs);
+                                    (
+                                        <$concrete_type>::new(q, fpga_key.tag.clone()),
+                                        <$concrete_type>::new(r, fpga_key.tag.clone())
+                                    )
+                                }
                                 #[cfg(feature = "gpu")]
                                 InternalServerKey::Cuda(cuda_key) => {
                                     let (inner_q, inner_r) = with_thread_local_cuda_streams(|streams| {
                                         cuda_key.key.key.scalar_div_rem(
                                             &*self.ciphertext.on_gpu(), rhs, streams
-                                            )
+                                        )
                                     });
                                     let (q, r) = (RadixCiphertext::Cuda(inner_q), RadixCiphertext::Cuda(inner_r));
                                     (
@@ -513,6 +587,7 @@ macro_rules! generic_integer_impl_scalar_div_rem {
         )* // Closing first repeating pattern
     };
 }
+
 generic_integer_impl_scalar_div_rem!(
     fhe_and_scalar_type:
         (super::FheUint2, u8),
@@ -587,6 +662,14 @@ generic_integer_impl_scalar_operation!(
                         .scalar_add_parallelized(&*lhs.ciphertext.on_cpu(), rhs);
                     RadixCiphertext::Cpu(inner_result)
                 },
+                #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                    // TODO: FPGA implementation
+                    let inner_result = fpga_key
+                        .pbs_key()
+                        .scalar_add_parallelized(&*lhs.ciphertext.on_cpu(), rhs);
+                    RadixCiphertext::Cpu(inner_result)
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     let inner_result = with_thread_local_cuda_streams(|streams| {
@@ -622,12 +705,20 @@ generic_integer_impl_scalar_operation!(
     implem: {
         |lhs: &FheUint<_>, rhs| {
             global_state::with_internal_keys(|key| match key {
-                InternalServerKey::Cpu(cpu_key) => {
+                InternalServerKey::Cpu(cpu_key)=> {
                     let inner_result = cpu_key
                         .pbs_key()
                         .scalar_sub_parallelized(&*lhs.ciphertext.on_cpu(), rhs);
                     RadixCiphertext::Cpu(inner_result)
-                },
+                }
+                #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                    // TODO: FPGA implementation
+                    let inner_result = fpga_key
+                        .pbs_key()
+                        .scalar_sub_parallelized(&*lhs.ciphertext.on_cpu(), rhs);
+                    RadixCiphertext::Cpu(inner_result)
+                }
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     let inner_result = with_thread_local_cuda_streams(|streams| {
@@ -669,6 +760,12 @@ generic_integer_impl_scalar_operation!(
                         .scalar_mul_parallelized(&*lhs.ciphertext.on_cpu(), rhs);
                     RadixCiphertext::Cpu(inner_result)
                 },
+                #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                    let inner_result =
+                        fpga_key.scalar_mul(&*lhs.ciphertext.on_cpu(), rhs);
+                    RadixCiphertext::Cpu(inner_result)
+                }
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     let inner_result = with_thread_local_cuda_streams(|streams| {
@@ -710,6 +807,12 @@ generic_integer_impl_scalar_operation!(
                         .scalar_bitand_parallelized(&*lhs.ciphertext.on_cpu(), rhs);
                     RadixCiphertext::Cpu(inner_result)
                 },
+                #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                    let inner_result =
+                        fpga_key.scalar_bitand(&*lhs.ciphertext.on_cpu(), rhs);
+                    RadixCiphertext::Cpu(inner_result)
+                }
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     let inner_result = with_thread_local_cuda_streams(|streams| {
@@ -751,6 +854,12 @@ generic_integer_impl_scalar_operation!(
                         .scalar_bitor_parallelized(&*lhs.ciphertext.on_cpu(), rhs);
                     RadixCiphertext::Cpu(inner_result)
                 },
+                #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                    let inner_result =
+                        fpga_key.scalar_bitor(&*lhs.ciphertext.on_cpu(), rhs);
+                    RadixCiphertext::Cpu(inner_result)
+                }
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     let inner_result = with_thread_local_cuda_streams(|streams| {
@@ -792,7 +901,12 @@ generic_integer_impl_scalar_operation!(
                         .scalar_bitxor_parallelized(&*lhs.ciphertext.on_cpu(), rhs);
                     RadixCiphertext::Cpu(inner_result)
                 },
-
+                #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                    let inner_result =
+                        fpga_key.scalar_bitxor(&*lhs.ciphertext.on_cpu(), rhs);
+                    RadixCiphertext::Cpu(inner_result)
+                }
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     let inner_result = with_thread_local_cuda_streams(|streams| {
@@ -834,6 +948,12 @@ generic_integer_impl_scalar_operation!(
                         .scalar_left_shift_parallelized(&*lhs.ciphertext.on_cpu(), rhs);
                     RadixCiphertext::Cpu(inner_result)
                 },
+                #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                    let inner_result =
+                        fpga_key.scalar_left_shift(&*lhs.ciphertext.on_cpu(), rhs);
+                    RadixCiphertext::Cpu(inner_result)
+                }
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     let inner_result = with_thread_local_cuda_streams(|streams| {
@@ -875,6 +995,12 @@ generic_integer_impl_scalar_operation!(
                         .scalar_right_shift_parallelized(&*lhs.ciphertext.on_cpu(), rhs);
                     RadixCiphertext::Cpu(inner_result)
                 },
+                #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                    let inner_result =
+                        fpga_key.scalar_right_shift(&*lhs.ciphertext.on_cpu(), rhs);
+                    RadixCiphertext::Cpu(inner_result)
+                }
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     let inner_result = with_thread_local_cuda_streams(|streams| {
@@ -916,6 +1042,12 @@ generic_integer_impl_scalar_operation!(
                         .scalar_rotate_left_parallelized(&*lhs.ciphertext.on_cpu(), rhs);
                     RadixCiphertext::Cpu(inner_result)
                 },
+                #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                    let inner_result =
+                        fpga_key.scalar_rotate_left(&*lhs.ciphertext.on_cpu(), rhs);
+                    RadixCiphertext::Cpu(inner_result)
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     let inner_result = with_thread_local_cuda_streams(|streams| {
@@ -957,6 +1089,12 @@ generic_integer_impl_scalar_operation!(
                         .scalar_rotate_right_parallelized(&*lhs.ciphertext.on_cpu(), rhs);
                     RadixCiphertext::Cpu(inner_result)
                 },
+                #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                    let inner_result =
+                        fpga_key.scalar_rotate_right(&*lhs.ciphertext.on_cpu(), rhs);
+                    RadixCiphertext::Cpu(inner_result)
+                }
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     let inner_result = with_thread_local_cuda_streams(|streams| {
@@ -998,6 +1136,12 @@ generic_integer_impl_scalar_operation!(
                         .scalar_div_parallelized(&lhs.ciphertext.on_cpu(), rhs);
                     RadixCiphertext::Cpu(inner_result)
                 },
+                #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                    let inner_result =
+                        fpga_key.scalar_div(&lhs.ciphertext.on_cpu(), rhs);
+                    RadixCiphertext::Cpu(inner_result)
+                }
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     let inner_result = with_thread_local_cuda_streams(|streams| {
@@ -1039,6 +1183,12 @@ generic_integer_impl_scalar_operation!(
                         .scalar_rem_parallelized(&lhs.ciphertext.on_cpu(), rhs);
                     RadixCiphertext::Cpu(inner_result)
                 },
+                #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                    let inner_result =
+                        fpga_key.scalar_rem(&lhs.ciphertext.on_cpu(), rhs);
+                    RadixCiphertext::Cpu(inner_result)
+                }
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     let inner_result = with_thread_local_cuda_streams(|streams| {
@@ -1201,6 +1351,17 @@ generic_integer_impl_scalar_left_operation!(
                         .sub_assign_parallelized(&mut result, &*rhs.ciphertext.on_cpu());
                     RadixCiphertext::Cpu(result)
                 },
+                #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                    // TODO: FPGA implementation
+                    let mut result = fpga_key
+                        .pbs_key()
+                        .create_trivial_radix(lhs, rhs.ciphertext.on_cpu().blocks().len());
+                    fpga_key
+                        .pbs_key()
+                        .sub_assign_parallelized(&mut result, &*rhs.ciphertext.on_cpu());
+                    RadixCiphertext::Cpu(result)
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     with_thread_local_cuda_streams(|streams| {
@@ -1479,6 +1640,13 @@ generic_integer_impl_scalar_operation_assign!(
                         .pbs_key()
                         .scalar_add_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
                 },
+                #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                    // TODO: FPGA implementation
+                    fpga_key
+                        .pbs_key()
+                        .scalar_add_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     with_thread_local_cuda_streams(|streams| {
@@ -1539,6 +1707,13 @@ generic_integer_impl_scalar_operation_assign!(
                         .pbs_key()
                         .scalar_sub_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
                 },
+                #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                    // TODO: FPGA implementation
+                    fpga_key
+                        .pbs_key()
+                        .scalar_sub_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     with_thread_local_cuda_streams(|streams| {
@@ -1577,6 +1752,10 @@ generic_integer_impl_scalar_operation_assign!(
                         .pbs_key()
                         .scalar_mul_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
                 },
+                #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                    fpga_key.scalar_mul_assign(lhs.ciphertext.as_cpu_mut(), rhs);
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     with_thread_local_cuda_streams(|streams| {
@@ -1615,6 +1794,10 @@ generic_integer_impl_scalar_operation_assign!(
                         .pbs_key()
                         .scalar_bitand_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
                 },
+                #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                    fpga_key.scalar_bitand_assign(lhs.ciphertext.as_cpu_mut(), rhs);
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     with_thread_local_cuda_streams(|streams| {
@@ -1653,6 +1836,10 @@ generic_integer_impl_scalar_operation_assign!(
                         .pbs_key()
                         .scalar_bitor_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
                 },
+                #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                    fpga_key.scalar_bitor_assign(lhs.ciphertext.as_cpu_mut(), rhs);
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     with_thread_local_cuda_streams(|streams| {
@@ -1691,6 +1878,10 @@ generic_integer_impl_scalar_operation_assign!(
                         .pbs_key()
                         .scalar_bitxor_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
                 },
+                #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                    fpga_key.scalar_bitxor_assign(lhs.ciphertext.as_cpu_mut(), rhs);
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     with_thread_local_cuda_streams(|streams| {
@@ -1729,6 +1920,10 @@ generic_integer_impl_scalar_operation_assign!(
                         .pbs_key()
                         .scalar_left_shift_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
                 },
+                #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                    fpga_key.scalar_left_shift_assign(lhs.ciphertext.as_cpu_mut(), rhs);
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     with_thread_local_cuda_streams(|streams| {
@@ -1767,6 +1962,10 @@ generic_integer_impl_scalar_operation_assign!(
                         .pbs_key()
                         .scalar_right_shift_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
                 },
+                #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                    fpga_key.scalar_right_shift_assign(lhs.ciphertext.as_cpu_mut(), rhs);
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     with_thread_local_cuda_streams(|streams| {
@@ -1805,6 +2004,10 @@ generic_integer_impl_scalar_operation_assign!(
                         .pbs_key()
                         .scalar_rotate_left_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
                 },
+                #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                    fpga_key.scalar_rotate_left_assign(lhs.ciphertext.as_cpu_mut(), rhs);
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     with_thread_local_cuda_streams(|streams| {
@@ -1843,6 +2046,10 @@ generic_integer_impl_scalar_operation_assign!(
                         .pbs_key()
                         .scalar_rotate_right_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
                 },
+                #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                    fpga_key.scalar_rotate_right_assign(lhs.ciphertext.as_cpu_mut(), rhs);
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     with_thread_local_cuda_streams(|streams| {
@@ -1881,6 +2088,10 @@ generic_integer_impl_scalar_operation_assign!(
                         .pbs_key()
                         .scalar_div_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
                 },
+                #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                    fpga_key.scalar_div_assign(lhs.ciphertext.as_cpu_mut(), rhs);
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(_) => {
                     panic!("DivAssign '/=' with clear value is not yet supported by Cuda devices")
@@ -1916,6 +2127,10 @@ generic_integer_impl_scalar_operation_assign!(
                         .pbs_key()
                         .scalar_rem_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
                 },
+                #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                    fpga_key.scalar_rem_assign(lhs.ciphertext.as_cpu_mut(), rhs);
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(_) => {
                     panic!("RemAssign '%=' with clear value is not yet supported by Cuda devices")
diff --git a/tfhe/src/high_level_api/keys/mod.rs b/tfhe/src/high_level_api/keys/mod.rs
index c803b4557..47337be60 100644
--- a/tfhe/src/high_level_api/keys/mod.rs
+++ b/tfhe/src/high_level_api/keys/mod.rs
@@ -2,7 +2,7 @@ mod client;
 mod public;
 mod server;
 
-mod inner;
+pub mod inner;
 mod key_switching_key;
 
 use crate::high_level_api::config::Config;
@@ -10,6 +10,8 @@ pub use client::ClientKey;
 pub(crate) use inner::CompactPrivateKey;
 pub use key_switching_key::KeySwitchingKey;
 pub use public::{CompactPublicKey, CompressedCompactPublicKey, CompressedPublicKey, PublicKey};
+#[cfg(feature = "fpga")]
+pub use server::BelfortServerKey;
 #[cfg(feature = "gpu")]
 pub use server::CudaServerKey;
 pub(crate) use server::InternalServerKey;
diff --git a/tfhe/src/high_level_api/keys/server.rs b/tfhe/src/high_level_api/keys/server.rs
index e360482ce..b1c7ebf95 100644
--- a/tfhe/src/high_level_api/keys/server.rs
+++ b/tfhe/src/high_level_api/keys/server.rs
@@ -122,6 +122,16 @@ impl ServerKey {
     }
 }
 
+#[cfg(feature = "fpga")]
+impl From<&BelfortServerKey> for ServerKey {
+    fn from(fpga_key: &BelfortServerKey) -> Self {
+        Self {
+            key: fpga_key.key.clone(),
+            tag: fpga_key.tag.clone(),
+        }
+    }
+}
+
 impl Tagged for ServerKey {
     fn tag(&self) -> &Tag {
         &self.tag
@@ -347,10 +357,27 @@ impl Tagged for CudaServerKey {
     }
 }
 
+#[cfg(feature = "gpu")]
+impl Tagged for CudaServerKey {
+    fn tag(&self) -> &Tag {
+        &self.tag
+    }
+
+    fn tag_mut(&mut self) -> &mut Tag {
+        &mut self.tag
+    }
+}
+
+// Use BelfortServerKey from
+#[cfg(feature = "fpga")]
+pub use crate::integer::fpga::BelfortServerKey;
+
 pub enum InternalServerKey {
     Cpu(ServerKey),
     #[cfg(feature = "gpu")]
     Cuda(CudaServerKey),
+    #[cfg(feature = "fpga")]
+    Belfort(BelfortServerKey),
 }
 
 impl From<ServerKey> for InternalServerKey {
@@ -358,6 +385,7 @@ impl From<ServerKey> for InternalServerKey {
         Self::Cpu(value)
     }
 }
+
 #[cfg(feature = "gpu")]
 impl From<CudaServerKey> for InternalServerKey {
     fn from(value: CudaServerKey) -> Self {
@@ -365,6 +393,13 @@ impl From<CudaServerKey> for InternalServerKey {
     }
 }
 
+#[cfg(feature = "fpga")]
+impl From<BelfortServerKey> for InternalServerKey {
+    fn from(value: BelfortServerKey) -> Self {
+        Self::Belfort(value)
+    }
+}
+
 use crate::high_level_api::keys::inner::IntegerServerKeyConformanceParams;
 
 impl ParameterSetConformant for ServerKey {
diff --git a/tfhe/src/high_level_api/mod.rs b/tfhe/src/high_level_api/mod.rs
index 99d925b1f..ddd0f9cb8 100644
--- a/tfhe/src/high_level_api/mod.rs
+++ b/tfhe/src/high_level_api/mod.rs
@@ -52,6 +52,8 @@ pub use config::{Config, ConfigBuilder};
 pub use global_state::{set_server_key, unset_server_key, with_server_key_as_context};
 
 pub use integers::{CompressedFheInt, CompressedFheUint, FheInt, FheUint, IntegerId};
+#[cfg(feature = "fpga")]
+pub use keys::BelfortServerKey;
 #[cfg(feature = "gpu")]
 pub use keys::CudaServerKey;
 pub use keys::{
@@ -109,7 +111,7 @@ mod config;
 mod errors;
 mod global_state;
 mod integers;
-mod keys;
+pub(crate) mod keys;
 #[cfg(feature = "strings")]
 mod strings;
 mod traits;
@@ -132,6 +134,8 @@ pub enum Device {
     Cpu,
     #[cfg(feature = "gpu")]
     CudaGpu,
+    #[cfg(feature = "fpga")]
+    Fpga,
 }
 
 #[derive(Copy, Clone, PartialEq, Eq, Debug)]
diff --git a/tfhe/src/high_level_api/tests/tags_on_entities.rs b/tfhe/src/high_level_api/tests/tags_on_entities.rs
index ce8195860..054b53181 100644
--- a/tfhe/src/high_level_api/tests/tags_on_entities.rs
+++ b/tfhe/src/high_level_api/tests/tags_on_entities.rs
@@ -12,6 +12,9 @@ use crate::{
 };
 use rand::random;
 
+#[cfg(feature = "fpga")]
+use crate::BelfortServerKey;
+
 #[test]
 fn test_tag_propagation_cpu() {
     test_tag_propagation(
@@ -212,6 +215,12 @@ fn test_tag_propagation(
 
             set_server_key(sks);
         }
+        #[cfg(feature = "fpga")]
+        Device::Fpga => {
+            let sks = ServerKey::new(&cks);
+            let fpga_key = BelfortServerKey::from(&sks);
+            assert_eq!(fpga_key.tag(), cks.tag());
+        }
     }
 
     // Check encrypting regular ct with client key
diff --git a/tfhe/src/integer/ciphertext/compact_list.rs b/tfhe/src/integer/ciphertext/compact_list.rs
index b7910ff56..7ce36565b 100644
--- a/tfhe/src/integer/ciphertext/compact_list.rs
+++ b/tfhe/src/integer/ciphertext/compact_list.rs
@@ -1015,6 +1015,16 @@ impl IntegerProvenCompactCiphertextListConformanceParams {
     pub fn from_public_key_encryption_parameters_and_crs_parameters(
         value: CompactPublicKeyEncryptionParameters,
         crs: &CompactPkeCrs,
+    ) -> Self {
+        Self::from_public_key_encryption_parameters_and_crs_parameters(
+            value,
+            crs_params.public_params(),
+        )
+    }
+
+    pub fn from_public_key_encryption_parameters_and_crs_parameters(
+        value: CompactPublicKeyEncryptionParameters,
+        crs_params: &crate::zk::CompactPkePublicParams,
     ) -> Self {
         Self {
             encryption_lwe_dimension: value.encryption_lwe_dimension,
diff --git a/tfhe/src/integer/fpga/mod.rs b/tfhe/src/integer/fpga/mod.rs
new file mode 100644
index 000000000..9e69b178f
--- /dev/null
+++ b/tfhe/src/integer/fpga/mod.rs
@@ -0,0 +1,2 @@
+pub mod server_key;
+pub use server_key::BelfortServerKey;
diff --git a/tfhe/src/integer/fpga/server_key/comparator.rs b/tfhe/src/integer/fpga/server_key/comparator.rs
new file mode 100644
index 000000000..f8792e10f
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/comparator.rs
@@ -0,0 +1,1295 @@
+use crate::core_crypto::algorithms::{
+    lwe_ciphertext_plaintext_sub_assign, lwe_ciphertext_sub_assign,
+};
+use crate::core_crypto::fpga::lookup_vector::LookupVector;
+use crate::core_crypto::prelude::Plaintext;
+use crate::integer::block_decomposition::{BlockDecomposer, DecomposableInto};
+use crate::integer::ciphertext::boolean_value::BooleanBlock;
+use crate::integer::ciphertext::IntegerRadixCiphertext;
+use crate::integer::fpga::server_key::BelfortServerKey;
+use crate::integer::server_key::comparator::*;
+use crate::shortint::ciphertext::Degree;
+use crate::shortint::Ciphertext;
+
+/// Simple enum to select which comparison we are performing
+#[derive(PartialEq, Eq, Clone)]
+pub enum ComparisonSelector {
+    Gt,
+    Ge,
+    Lt,
+    Le,
+    None,
+}
+
+/// struct to compare integers
+///
+/// This struct keeps in memory the LUTs that are used
+/// during the comparisons and min/max algorithms
+pub struct Comparator<'a> {
+    pub(crate) server_key: &'a BelfortServerKey,
+    // name of the lut to get the sign of (a - b), used as the backbone of comparisons
+    sign_lut: LookupVector,
+    // name of the lut used to reduce 2 comparison blocks into 1
+    comparison_reduction_lut: LookupVector,
+    // names of the lookup tablse for the lhs/rhs operands in min/max operations
+    lhs_lut: LookupVector,
+    rhs_lut: LookupVector,
+}
+
+impl<'a> Comparator<'a> {
+    const IS_INFERIOR: u64 = 0;
+    const IS_EQUAL: u64 = 1;
+    const IS_SUPERIOR: u64 = 2;
+
+    /// Creates a new Comparator for the given ServerKey
+    ///
+    /// # Panics
+    ///
+    /// panics if the message space + carry space is inferior to 4 bits
+    pub fn new(server_key: &'a BelfortServerKey) -> Self {
+        let shortint_key = &server_key.key.key.key;
+        assert!(
+            shortint_key.message_modulus.0 * shortint_key.carry_modulus.0 >= 16,
+            "At least 4 bits of space (message + carry) are required to be able to do comparisons"
+        );
+
+        let lut_is_non_zero = {
+            let func = |x| u64::from(x != 0);
+            shortint_key.generate_lookup_vector(&func)
+        };
+        let lut_reduce_two_orderings = {
+            let func = |x| {
+                let msb = (x >> 2) & 3_u64;
+                let lsb = x & 3;
+
+                if msb == 1 {
+                    lsb
+                } else {
+                    msb
+                }
+            };
+            shortint_key.generate_lookup_vector(&func)
+        };
+        let lut_lhs_min_max = {
+            let func = |x| if x < 4 { x } else { 0 };
+            shortint_key.generate_lookup_vector(&func)
+        };
+        let lut_rhs_min_max = {
+            let func = |x: u64| if x >= 4 { x - 4 } else { 0 };
+            shortint_key.generate_lookup_vector(&func)
+        };
+
+        Self {
+            server_key,
+            sign_lut: lut_is_non_zero,
+            comparison_reduction_lut: lut_reduce_two_orderings,
+            lhs_lut: lut_lhs_min_max,
+            rhs_lut: lut_rhs_min_max,
+        }
+    }
+
+    /// Takes 2 ciphertexts and packs them together assigning to high
+    ///
+    /// This requires the block parameters to have enough room for two ciphertexts,
+    /// so at least as many carry modulus as the message modulus
+    ///
+    /// Expects the carry buffer to be empty
+    fn pack_block_assign(&self, low: &Ciphertext, high: &mut Ciphertext) {
+        self.server_key.key.key.pack_block_assign(low, high);
+    }
+
+    /// This function compares two blocks
+    /// of two signed radix ciphertext which hold the 'sign' bit
+    /// (so the two most significant blocks).
+    ///
+    /// As for the blocks which holds the sign bit, the comparison
+    /// is different than for regular blocks.
+    fn compare_blocks_with_sign_bit(
+        &self,
+        lhs_block: &Ciphertext,
+        rhs_block: &Ciphertext,
+    ) -> Ciphertext {
+        let mut result = lhs_block.clone();
+
+        let shortint_key = &self.server_key.key.key.key;
+
+        self.pack_block_assign(rhs_block, &mut result);
+
+        let mut result_vec = vec![result];
+
+        let lut_compare_with_sign_bits = {
+            let func = |x: u64, y: u64| {
+                let sign_bit_pos = shortint_key.message_modulus.0.ilog2() - 1;
+
+                let x_sign_bit = x >> sign_bit_pos;
+                let y_sign_bit = y >> sign_bit_pos;
+
+                if x_sign_bit == y_sign_bit {
+                    match x.cmp(&y) {
+                        std::cmp::Ordering::Less => Self::IS_INFERIOR,
+                        std::cmp::Ordering::Equal => Self::IS_EQUAL,
+                        std::cmp::Ordering::Greater => Self::IS_SUPERIOR,
+                    }
+                } else {
+                    match x.cmp(&y) {
+                        std::cmp::Ordering::Less => Self::IS_SUPERIOR,
+                        std::cmp::Ordering::Equal => Self::IS_EQUAL,
+                        std::cmp::Ordering::Greater => Self::IS_INFERIOR,
+                    }
+                }
+            };
+            shortint_key.generate_lookup_vector_bivariate(&func)
+        };
+
+        self.server_key
+            .apply_same_lookup_vector_packed_assign(&mut result_vec, lut_compare_with_sign_bits);
+
+        result_vec[0].clone()
+    }
+
+    fn reduce_sign_block(x: u64) -> u64 {
+        let relevant_bits: u64 = 3;
+
+        // Zero out irrelevant bits
+        let msb = (x >> 2) & relevant_bits;
+        let lsb = x & relevant_bits;
+
+        if msb == Self::IS_EQUAL {
+            lsb
+        } else {
+            msb
+        }
+    }
+
+    /// Takes a chunk of 2 ciphertexts and packs them together in a new ciphertext
+    ///
+    /// The first element of the chunk are the low bits, the second are the high bits
+    ///
+    /// This requires the block parameters to have enough room for two ciphertexts,
+    /// so at least as many carry modulus as the message modulus
+    ///
+    /// Expects the carry buffer to be empty
+    fn pack_block_chunk(&self, chunk: &[Ciphertext]) -> Ciphertext {
+        self.server_key.key.key.pack_block_chunk(chunk)
+    }
+
+    /// lhs will be assigned
+    /// - 0 if lhs < rhs
+    /// - 1 if lhs == rhs
+    /// - 2 if lhs > rhs
+    fn compare_blocks_pack(&self, lhs: &[Ciphertext], rhs: &[Ciphertext]) -> Vec<Ciphertext> {
+        let lhs_chunks_len = lhs.len() / 2;
+        let lhs_chunks_iter = lhs.chunks_exact(2);
+        let rhs_chunks_iter = rhs.chunks_exact(2);
+
+        let (last_lhs_block, last_rhs_block) =
+            (lhs_chunks_iter.remainder(), rhs_chunks_iter.remainder());
+
+        let mut chunks: Vec<Ciphertext> = lhs_chunks_iter
+            .chain(rhs_chunks_iter)
+            .map(|chunk| self.pack_block_chunk(chunk))
+            .collect();
+
+        let shortint_key = &self.server_key.key.key.key;
+        let identity_lut = shortint_key.generate_lookup_vector(&|x| x);
+
+        self.server_key
+            .apply_same_lookup_vector_packed_assign(&mut chunks, identity_lut);
+
+        let mut rhs_chunks = chunks.split_off(lhs_chunks_len);
+        let mut lhs_chunks = chunks;
+
+        // If there are remaining blocks, append them to the concatenated vectors
+        if !last_lhs_block.is_empty() && !last_rhs_block.is_empty() {
+            lhs_chunks.push(last_lhs_block[0].clone());
+            rhs_chunks.push(last_rhs_block[0].clone());
+        };
+
+        // When rhs > lhs, the subtraction will overflow, and the bit of padding will be set to 1
+        // meaning that the output of the pbs will be the negative (modulo message space)
+        //
+        // Example:
+        // lhs: 1, rhs: 3, message modulus: 4, carry modulus 4
+        // lhs - rhs = -2 % (4 * 4) = 14 = 1|1110 (padding_bit|b4b3b2b1)
+        // Since there was an overflow the bit of padding is 1 and not 0.
+        // When applying the LUT for an input value of 14 we would expect 1,
+        // but since the bit of padding is 1, we will get -1 modulus our message space,
+        // so (-1) % (4 * 4) = 15 = 1|1111
+        // We then add one and get 0 = 0|0000
+
+        // Here we need the true lwe sub, not the one that comes from shortint.
+        lhs_chunks
+            .iter_mut()
+            .zip(rhs_chunks.iter())
+            .for_each(|(lhs_block, rhs_block)| {
+                lwe_ciphertext_sub_assign(&mut lhs_block.ct, &rhs_block.ct);
+                lhs_block.set_noise_level(
+                    lhs_block.noise_level() + rhs_block.noise_level(),
+                    shortint_key.max_noise_level,
+                );
+            });
+
+        self.server_key
+            .apply_same_lookup_vector_packed_assign(&mut lhs_chunks, self.sign_lut);
+
+        // Here Lhs can have the following values: (-1) % (message modulus * carry modulus), 0, 1
+        // So the output values after the addition will be: 0, 1, 2
+        for lhs_block in lhs_chunks.iter_mut() {
+            shortint_key.unchecked_scalar_add_assign(lhs_block, 1);
+        }
+
+        lhs_chunks
+    }
+
+    /// Reduces a vec containing shortint blocks that encrypts a sign
+    /// (inferior, equal, superior) to one single shortint block containing the
+    /// final sign
+    fn reduce_signs_pack(
+        &self,
+        mut sign_blocks: Vec<Ciphertext>,
+        selector: &ComparisonSelector,
+    ) -> Ciphertext {
+        while sign_blocks.len() > 2 {
+            let mut sign_blocks_packed: Vec<Ciphertext> = sign_blocks
+                .chunks_exact(2)
+                .map(|chunk: &[Ciphertext]| self.pack_block_chunk(chunk))
+                .collect();
+
+            self.server_key.apply_same_lookup_vector_packed_assign(
+                &mut sign_blocks_packed,
+                self.comparison_reduction_lut,
+            );
+
+            if (sign_blocks.len() % 2) == 1 {
+                sign_blocks_packed.push(sign_blocks.last().unwrap().clone());
+            }
+
+            sign_blocks.clear();
+            sign_blocks.extend(sign_blocks_packed);
+        }
+
+        let shortint_key = &self.server_key.key.key.key;
+
+        let lut: LookupVector;
+        let mut result: Ciphertext;
+
+        if sign_blocks.len() == 2 {
+            lut = {
+                let func = match selector {
+                    ComparisonSelector::Gt => |x| {
+                        let result = Comparator::reduce_sign_block(x);
+                        u64::from(result == Self::IS_SUPERIOR)
+                    },
+                    ComparisonSelector::Ge => |x| {
+                        let result = Comparator::reduce_sign_block(x);
+
+                        u64::from(result == Self::IS_SUPERIOR || result == Self::IS_EQUAL)
+                    },
+                    ComparisonSelector::Lt => |x| {
+                        let result = Comparator::reduce_sign_block(x);
+
+                        u64::from(result == Self::IS_INFERIOR)
+                    },
+                    ComparisonSelector::Le => |x| {
+                        let result = Comparator::reduce_sign_block(x);
+
+                        u64::from(result == Self::IS_INFERIOR || result == Self::IS_EQUAL)
+                    },
+                    ComparisonSelector::None => |x| {
+                        let msb = (x >> 2) & 3_u64;
+                        let lsb = x & 3;
+
+                        if msb == Self::IS_EQUAL {
+                            lsb
+                        } else {
+                            msb
+                        }
+                    },
+                };
+                shortint_key.generate_lookup_vector(&func)
+            };
+
+            result = sign_blocks[1].clone();
+            self.pack_block_assign(&sign_blocks[0], &mut result);
+        } else {
+            lut = {
+                let func = match selector {
+                    ComparisonSelector::Gt => |x| {
+                        let result = x % 3;
+
+                        u64::from(result == Self::IS_SUPERIOR)
+                    },
+                    ComparisonSelector::Ge => |x| {
+                        let result = x % 3;
+
+                        u64::from(result == Self::IS_SUPERIOR || result == Self::IS_EQUAL)
+                    },
+                    ComparisonSelector::Lt => |x| {
+                        let result = x % 3;
+
+                        u64::from(result == Self::IS_INFERIOR)
+                    },
+                    ComparisonSelector::Le => |x| {
+                        let result = x % 3;
+
+                        u64::from(result == Self::IS_INFERIOR || result == Self::IS_EQUAL)
+                    },
+                    ComparisonSelector::None => |x| x % 3,
+                };
+                shortint_key.generate_lookup_vector(&func)
+            };
+
+            result = sign_blocks[0].clone();
+        };
+
+        let mut result_vec = vec![result];
+
+        self.server_key
+            .apply_same_lookup_vector_packed_assign(&mut result_vec, lut);
+
+        result_vec[0].clone()
+    }
+
+    /// Reduces a vec containing shortint blocks that encrypts a sign
+    /// (inferior, equal, superior) to one single shortint block containing the
+    /// final sign based on min/max luts    
+    fn reduce_signs_for_min_max_pack(&self, mut sign_blocks: Vec<Ciphertext>) -> Ciphertext {
+        while sign_blocks.len() > 2 {
+            let mut sign_blocks_packed: Vec<Ciphertext> = sign_blocks
+                .chunks_exact(2)
+                .map(|chunk: &[Ciphertext]| self.pack_block_chunk(chunk))
+                .collect();
+
+            self.server_key.apply_same_lookup_vector_packed_assign(
+                &mut sign_blocks_packed,
+                self.comparison_reduction_lut,
+            );
+
+            if (sign_blocks.len() % 2) == 1 {
+                sign_blocks_packed.push(sign_blocks.last().unwrap().clone());
+            }
+
+            sign_blocks.clear();
+            sign_blocks.extend(sign_blocks_packed);
+        }
+
+        let shortint_key = &self.server_key.key.key.key;
+
+        let lut: LookupVector;
+        let mut result: Ciphertext;
+
+        if sign_blocks.len() == 2 {
+            lut = {
+                let func_two_blocks_min_max = |x| {
+                    let result = Comparator::reduce_sign_block(x);
+
+                    if result == 0 {
+                        shortint_key.message_modulus.0
+                    } else {
+                        0
+                    }
+                };
+                shortint_key.generate_lookup_vector(&func_two_blocks_min_max)
+            };
+
+            result = sign_blocks[1].clone();
+        } else {
+            lut = {
+                let func_one_block_min_max = |x| {
+                    let result = x % 3;
+
+                    if result == 0 {
+                        shortint_key.message_modulus.0
+                    } else {
+                        0
+                    }
+                };
+                shortint_key.generate_lookup_vector(&func_one_block_min_max)
+            };
+
+            result = sign_blocks[0].clone();
+        };
+
+        self.pack_block_assign(&sign_blocks[0], &mut result);
+
+        let mut result_vec = vec![result];
+
+        self.server_key
+            .apply_same_lookup_vector_packed_assign(&mut result_vec, lut);
+
+        result_vec[0].clone()
+    }
+
+    /// returns:
+    ///
+    /// - 0 if lhs < rhs
+    /// - 1 if lhs == rhs
+    /// - 2 if lhs > rhs
+    ///
+    /// Expects the carry buffers to be empty
+    ///
+    /// Requires that the RadixCiphertext block have 4 bits minimum (carry + message)    
+    fn unchecked_compare<T>(&self, lhs: &T, rhs: &T, selector: &ComparisonSelector) -> Ciphertext
+    where
+        T: IntegerRadixCiphertext,
+    {
+        assert_eq!(lhs.blocks().len(), rhs.blocks().len());
+
+        let comparisons = if T::IS_SIGNED {
+            let (lhs_last_block, lhs_ls_blocks) = lhs.blocks().split_last().unwrap();
+            let (rhs_last_block, rhs_ls_blocks) = rhs.blocks().split_last().unwrap();
+
+            let mut tmp_comparisons = self.compare_blocks_pack(lhs_ls_blocks, rhs_ls_blocks);
+
+            let last_block_cmp = self.compare_blocks_with_sign_bit(lhs_last_block, rhs_last_block);
+
+            tmp_comparisons.push(last_block_cmp);
+
+            tmp_comparisons
+        } else {
+            self.compare_blocks_pack(lhs.blocks(), rhs.blocks())
+        };
+
+        self.reduce_signs_pack(comparisons, selector)
+    }
+
+    fn smart_compare<T>(
+        &self,
+        lhs: &mut T,
+        rhs: &mut T,
+        selector: &ComparisonSelector,
+    ) -> Ciphertext
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.server_key
+            .conditional_full_propagate_bivariate(lhs, rhs);
+
+        self.unchecked_compare(lhs, rhs, selector)
+    }
+
+    /// Expects the carry buffers to be empty
+    fn unchecked_compare_for_min_max<T>(&self, lhs: &T, rhs: &T) -> Ciphertext
+    where
+        T: IntegerRadixCiphertext,
+    {
+        assert_eq!(lhs.blocks().len(), rhs.blocks().len());
+
+        let comparisons = if T::IS_SIGNED {
+            let (lhs_last_block, lhs_ls_blocks) = lhs.blocks().split_last().unwrap();
+            let (rhs_last_block, rhs_ls_blocks) = rhs.blocks().split_last().unwrap();
+
+            let mut tmp_comparisons = self.compare_blocks_pack(lhs_ls_blocks, rhs_ls_blocks);
+
+            let last_block_cmp = self.compare_blocks_with_sign_bit(lhs_last_block, rhs_last_block);
+
+            tmp_comparisons.push(last_block_cmp);
+
+            tmp_comparisons
+        } else {
+            self.compare_blocks_pack(lhs.blocks(), rhs.blocks())
+        };
+
+        self.reduce_signs_for_min_max_pack(comparisons)
+    }
+
+    /// Expects the carry buffers to be empty
+    fn unchecked_min_or_max<T>(&self, lhs: &T, rhs: &T, selector: MinMaxSelector) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let (lhs_lut, rhs_lut) = match selector {
+            MinMaxSelector::Max => (self.lhs_lut, self.rhs_lut),
+            MinMaxSelector::Min => (self.rhs_lut, self.lhs_lut),
+        };
+
+        let offset = self.unchecked_compare_for_min_max(lhs, rhs);
+        let shortint_server_key = &self.server_key.key.key.key;
+
+        let lhs_blocks: Vec<Ciphertext> = lhs
+            .blocks()
+            .iter()
+            .map(|block| shortint_server_key.unchecked_add(block, &offset))
+            .collect();
+
+        let rhs_blocks: Vec<Ciphertext> = rhs
+            .blocks()
+            .iter()
+            .map(|block| shortint_server_key.unchecked_add(block, &offset))
+            .collect();
+
+        let mut lhs_rhs_blocks: Vec<Ciphertext> = lhs_blocks
+            .iter()
+            .chain(rhs_blocks.iter())
+            .cloned()
+            .collect();
+
+        let mut luts: Vec<LookupVector> = vec![lhs_lut; lhs_blocks.len()];
+        luts.append(&mut vec![rhs_lut; rhs_blocks.len()]);
+
+        self.server_key
+            .apply_lookup_vector_packed_assign(&mut lhs_rhs_blocks, &luts);
+
+        let (lhs_blocks, rhs_blocks) = lhs_rhs_blocks.split_at(lhs.blocks().len());
+
+        let result = lhs_blocks
+            .iter()
+            .zip(rhs_blocks.iter())
+            .map(|(lhs_block, rhs_block)| {
+                let mut result = shortint_server_key.unchecked_add(lhs_block, rhs_block);
+                // We know that one of either blocks is 0
+                result.degree = Degree::new(shortint_server_key.message_modulus.0 - 1);
+                result
+            })
+            .collect();
+
+        T::from_blocks(result)
+    }
+
+    fn smart_min_or_max<T>(&self, lhs: &mut T, rhs: &mut T, selector: MinMaxSelector) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.server_key
+            .conditional_full_propagate_bivariate(lhs, rhs);
+        self.unchecked_min_or_max(lhs, rhs, selector)
+    }
+
+    //======================================
+    // Unchecked operations
+    //======================================
+
+    pub fn unchecked_gt<T>(&self, lhs: &T, rhs: &T) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let comparison = self.unchecked_compare(lhs, rhs, &ComparisonSelector::Gt);
+        BooleanBlock::new_unchecked(comparison)
+    }
+
+    pub fn unchecked_ge<T>(&self, lhs: &T, rhs: &T) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let comparison = self.unchecked_compare(lhs, rhs, &ComparisonSelector::Ge);
+        BooleanBlock::new_unchecked(comparison)
+    }
+
+    pub fn unchecked_lt<T>(&self, lhs: &T, rhs: &T) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let comparison = self.unchecked_compare(lhs, rhs, &ComparisonSelector::Lt);
+        BooleanBlock::new_unchecked(comparison)
+    }
+
+    pub fn unchecked_le<T>(&self, lhs: &T, rhs: &T) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let comparison = self.unchecked_compare(lhs, rhs, &ComparisonSelector::Le);
+        BooleanBlock::new_unchecked(comparison)
+    }
+
+    pub fn unchecked_max<T>(&self, lhs: &T, rhs: &T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.unchecked_min_or_max(lhs, rhs, MinMaxSelector::Max)
+    }
+
+    pub fn unchecked_min<T>(&self, lhs: &T, rhs: &T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.unchecked_min_or_max(lhs, rhs, MinMaxSelector::Min)
+    }
+
+    //======================================
+    // Smart operations
+    //======================================
+
+    pub fn smart_gt<T>(&self, lhs: &mut T, rhs: &mut T) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let comparison = self.smart_compare(lhs, rhs, &ComparisonSelector::Gt);
+        BooleanBlock::new_unchecked(comparison)
+    }
+
+    pub fn smart_ge<T>(&self, lhs: &mut T, rhs: &mut T) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let comparison = self.smart_compare(lhs, rhs, &ComparisonSelector::Ge);
+        BooleanBlock::new_unchecked(comparison)
+    }
+
+    pub fn smart_lt<T>(&self, lhs: &mut T, rhs: &mut T) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let comparison = self.smart_compare(lhs, rhs, &ComparisonSelector::Lt);
+        BooleanBlock::new_unchecked(comparison)
+    }
+
+    pub fn smart_le<T>(&self, lhs: &mut T, rhs: &mut T) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let comparison = self.smart_compare(lhs, rhs, &ComparisonSelector::Le);
+        BooleanBlock::new_unchecked(comparison)
+    }
+
+    pub fn smart_max<T>(&self, lhs: &mut T, rhs: &mut T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.smart_min_or_max(lhs, rhs, MinMaxSelector::Max)
+    }
+
+    pub fn smart_min<T>(&self, lhs: &mut T, rhs: &mut T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.smart_min_or_max(lhs, rhs, MinMaxSelector::Min)
+    }
+
+    //======================================
+    // Default operations
+    //======================================
+
+    pub fn gt<T>(&self, lhs: &T, rhs: &T) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut tmp_lhs;
+        let mut tmp_rhs;
+
+        let (lhs, rhs) = match (lhs.block_carries_are_empty(), rhs.block_carries_are_empty()) {
+            (true, true) => (lhs, rhs),
+            (true, false) => {
+                tmp_rhs = rhs.clone();
+                self.server_key.full_propagate(&mut tmp_rhs);
+                (lhs, &tmp_rhs)
+            }
+            (false, true) => {
+                tmp_lhs = lhs.clone();
+                self.server_key.full_propagate(&mut tmp_lhs);
+                (&tmp_lhs, rhs)
+            }
+            (false, false) => {
+                tmp_lhs = lhs.clone();
+                tmp_rhs = rhs.clone();
+
+                self.server_key.full_propagate(&mut tmp_lhs);
+                self.server_key.full_propagate(&mut tmp_rhs);
+
+                (&tmp_lhs, &tmp_rhs)
+            }
+        };
+
+        self.unchecked_gt(lhs, rhs)
+    }
+
+    pub fn ge<T>(&self, lhs: &T, rhs: &T) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut tmp_lhs;
+        let mut tmp_rhs;
+
+        let (lhs, rhs) = match (lhs.block_carries_are_empty(), rhs.block_carries_are_empty()) {
+            (true, true) => (lhs, rhs),
+            (true, false) => {
+                tmp_rhs = rhs.clone();
+                self.server_key.full_propagate(&mut tmp_rhs);
+                (lhs, &tmp_rhs)
+            }
+            (false, true) => {
+                tmp_lhs = lhs.clone();
+                self.server_key.full_propagate(&mut tmp_lhs);
+                (&tmp_lhs, rhs)
+            }
+            (false, false) => {
+                tmp_lhs = lhs.clone();
+                tmp_rhs = rhs.clone();
+
+                self.server_key.full_propagate(&mut tmp_lhs);
+                self.server_key.full_propagate(&mut tmp_rhs);
+
+                (&tmp_lhs, &tmp_rhs)
+            }
+        };
+
+        self.unchecked_ge(lhs, rhs)
+    }
+
+    pub fn lt<T>(&self, lhs: &T, rhs: &T) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut tmp_lhs;
+        let mut tmp_rhs;
+
+        let (lhs, rhs) = match (lhs.block_carries_are_empty(), rhs.block_carries_are_empty()) {
+            (true, true) => (lhs, rhs),
+            (true, false) => {
+                tmp_rhs = rhs.clone();
+                self.server_key.full_propagate(&mut tmp_rhs);
+                (lhs, &tmp_rhs)
+            }
+            (false, true) => {
+                tmp_lhs = lhs.clone();
+                self.server_key.full_propagate(&mut tmp_lhs);
+                (&tmp_lhs, rhs)
+            }
+            (false, false) => {
+                tmp_lhs = lhs.clone();
+                tmp_rhs = rhs.clone();
+
+                self.server_key.full_propagate(&mut tmp_lhs);
+                self.server_key.full_propagate(&mut tmp_rhs);
+
+                (&tmp_lhs, &tmp_rhs)
+            }
+        };
+
+        self.unchecked_lt(lhs, rhs)
+    }
+
+    pub fn le<T>(&self, lhs: &T, rhs: &T) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut tmp_lhs;
+        let mut tmp_rhs;
+
+        let (lhs, rhs) = match (lhs.block_carries_are_empty(), rhs.block_carries_are_empty()) {
+            (true, true) => (lhs, rhs),
+            (true, false) => {
+                tmp_rhs = rhs.clone();
+                self.server_key.full_propagate(&mut tmp_rhs);
+                (lhs, &tmp_rhs)
+            }
+            (false, true) => {
+                tmp_lhs = lhs.clone();
+                self.server_key.full_propagate(&mut tmp_lhs);
+                (&tmp_lhs, rhs)
+            }
+            (false, false) => {
+                tmp_lhs = lhs.clone();
+                tmp_rhs = rhs.clone();
+
+                self.server_key.full_propagate(&mut tmp_lhs);
+                self.server_key.full_propagate(&mut tmp_rhs);
+
+                (&tmp_lhs, &tmp_rhs)
+            }
+        };
+
+        self.unchecked_le(lhs, rhs)
+    }
+
+    pub fn max<T>(&self, lhs: &T, rhs: &T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut tmp_lhs;
+        let mut tmp_rhs;
+
+        let (lhs, rhs) = match (lhs.block_carries_are_empty(), rhs.block_carries_are_empty()) {
+            (true, true) => (lhs, rhs),
+            (true, false) => {
+                tmp_rhs = rhs.clone();
+                self.server_key.full_propagate(&mut tmp_rhs);
+                (lhs, &tmp_rhs)
+            }
+            (false, true) => {
+                tmp_lhs = lhs.clone();
+                self.server_key.full_propagate(&mut tmp_lhs);
+                (&tmp_lhs, rhs)
+            }
+            (false, false) => {
+                tmp_lhs = lhs.clone();
+                tmp_rhs = rhs.clone();
+
+                self.server_key.full_propagate(&mut tmp_lhs);
+                self.server_key.full_propagate(&mut tmp_rhs);
+
+                (&tmp_lhs, &tmp_rhs)
+            }
+        };
+
+        self.unchecked_max(lhs, rhs)
+    }
+
+    pub fn min<T>(&self, lhs: &T, rhs: &T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut tmp_lhs;
+        let mut tmp_rhs;
+
+        let (lhs, rhs) = match (lhs.block_carries_are_empty(), rhs.block_carries_are_empty()) {
+            (true, true) => (lhs, rhs),
+            (true, false) => {
+                tmp_rhs = rhs.clone();
+                self.server_key.full_propagate(&mut tmp_rhs);
+                (lhs, &tmp_rhs)
+            }
+            (false, true) => {
+                tmp_lhs = lhs.clone();
+                self.server_key.full_propagate(&mut tmp_lhs);
+                (&tmp_lhs, rhs)
+            }
+            (false, false) => {
+                tmp_lhs = lhs.clone();
+                tmp_rhs = rhs.clone();
+
+                self.server_key.full_propagate(&mut tmp_lhs);
+                self.server_key.full_propagate(&mut tmp_rhs);
+
+                (&tmp_lhs, &tmp_rhs)
+            }
+        };
+
+        self.unchecked_min(lhs, rhs)
+    }
+
+    //======================================
+    // Unchecked operations
+    //======================================
+    pub fn unchecked_scalar_gt<T, Scalar>(&self, lhs: &T, rhs: Scalar) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+    {
+        self.unchecked_scalar_compare_handler(lhs, rhs, ComparisonSelector::Gt, |x| {
+            u64::from(x == Self::IS_SUPERIOR)
+        })
+    }
+
+    pub fn unchecked_scalar_ge<T, Scalar>(&self, lhs: &T, rhs: Scalar) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+    {
+        self.unchecked_scalar_compare_handler(lhs, rhs, ComparisonSelector::Ge, |x| {
+            u64::from(x == Self::IS_SUPERIOR || x == Self::IS_EQUAL)
+        })
+    }
+
+    pub fn unchecked_scalar_lt<T, Scalar>(&self, lhs: &T, rhs: Scalar) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+    {
+        self.unchecked_scalar_compare_handler(lhs, rhs, ComparisonSelector::Lt, |x| {
+            u64::from(x == Self::IS_INFERIOR)
+        })
+    }
+
+    pub fn unchecked_scalar_le<T, Scalar>(&self, lhs: &T, rhs: Scalar) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+    {
+        self.unchecked_scalar_compare_handler(lhs, rhs, ComparisonSelector::Le, |x| {
+            u64::from(x == Self::IS_SUPERIOR || x == Self::IS_EQUAL)
+        })
+    }
+
+    pub fn scalar_gt<T, Scalar>(&self, lhs: &T, rhs: Scalar) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+    {
+        self.default_scalar_compare_parallelized(lhs, rhs, ComparisonSelector::Gt, |x| {
+            u64::from(x == Self::IS_SUPERIOR)
+        })
+    }
+
+    pub fn scalar_ge<T, Scalar>(&self, lhs: &T, rhs: Scalar) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+    {
+        self.default_scalar_compare_parallelized(lhs, rhs, ComparisonSelector::Ge, |x| {
+            u64::from(x == Self::IS_SUPERIOR || x == Self::IS_EQUAL)
+        })
+    }
+
+    pub fn scalar_lt<T, Scalar>(&self, lhs: &T, rhs: Scalar) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+    {
+        self.default_scalar_compare_parallelized(lhs, rhs, ComparisonSelector::Lt, |x| {
+            u64::from(x == Self::IS_INFERIOR)
+        })
+    }
+
+    pub fn scalar_le<T, Scalar>(&self, lhs: &T, rhs: Scalar) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+    {
+        self.default_scalar_compare_parallelized(lhs, rhs, ComparisonSelector::Le, |x| {
+            u64::from(x == Self::IS_INFERIOR || x == Self::IS_EQUAL)
+        })
+    }
+
+    pub fn unchecked_scalar_compare_handler<T, Scalar, F>(
+        &self,
+        lhs: &T,
+        rhs: Scalar,
+        selector: ComparisonSelector,
+        sign_result_handler_fn: F,
+    ) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+        F: Fn(u64) -> u64 + Sync,
+    {
+        let comparison = self.unchecked_scalar_compare(lhs, rhs, selector, sign_result_handler_fn);
+        BooleanBlock::new_unchecked(comparison)
+    }
+    fn default_scalar_compare_parallelized<T, Scalar, F>(
+        &self,
+        lhs: &T,
+        rhs: Scalar,
+        selector: ComparisonSelector,
+        sign_result_handler_fn: F,
+    ) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+        F: Fn(u64) -> u64 + Sync,
+    {
+        let mut tmp_lhs;
+        let lhs = if lhs.block_carries_are_empty() {
+            lhs
+        } else {
+            tmp_lhs = lhs.clone();
+            self.server_key.full_propagate(&mut tmp_lhs);
+            &tmp_lhs
+        };
+        self.unchecked_scalar_compare_handler(lhs, rhs, selector, sign_result_handler_fn)
+    }
+    fn unchecked_scalar_compare<T, Scalar, F>(
+        &self,
+        lhs: &T,
+        rhs: Scalar,
+        selector: ComparisonSelector,
+        sign_result_handler_fn: F,
+    ) -> Ciphertext
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+        F: Fn(u64) -> u64 + Sync,
+    {
+        // TODO: change this for signed integers,
+        // Look up radix_parallel/scalar_comparison.rs
+        self.unsigned_unchecked_scalar_compare_blocks(
+            lhs.blocks(),
+            rhs,
+            selector,
+            sign_result_handler_fn,
+        )
+    }
+
+    fn unsigned_unchecked_scalar_compare_blocks<Scalar, F>(
+        &self,
+        lhs_blocks: &[Ciphertext],
+        rhs: Scalar,
+        selector: ComparisonSelector,
+        sign_result_handler_fn: F,
+    ) -> Ciphertext
+    where
+        Scalar: DecomposableInto<u64>,
+        F: Fn(u64) -> u64 + Sync,
+    {
+        assert!(!lhs_blocks.is_empty());
+        let shortint_key = &self.server_key.key.key.key;
+        if rhs < Scalar::ZERO {
+            // lhs_blocks represent an unsigned (always >= 0)
+            return shortint_key.create_trivial(sign_result_handler_fn(Self::IS_SUPERIOR));
+        }
+
+        let message_modulus = shortint_key.message_modulus.0;
+
+        let mut scalar_blocks =
+            BlockDecomposer::with_early_stop_at_zero(rhs, message_modulus.ilog2())
+                .iter_as::<u64>()
+                .map(|x| x as u8)
+                .collect::<Vec<_>>();
+
+        // scalar is obviously bigger if it has non-zero
+        // blocks  after lhs's last block
+        let is_scalar_obviously_bigger = scalar_blocks
+            .get(lhs_blocks.len()..)
+            .is_some_and(|sub_slice| sub_slice.iter().any(|&scalar_block| scalar_block != 0));
+        if is_scalar_obviously_bigger {
+            return shortint_key.create_trivial(sign_result_handler_fn(Self::IS_INFERIOR));
+        }
+        // If we are sill here, that means scalar_blocks above
+        // num_blocks are 0s, we can remove them
+        // as we will handle them separately.
+        scalar_blocks.truncate(lhs_blocks.len());
+
+        let (least_significant_blocks, most_significant_blocks) =
+            lhs_blocks.split_at(scalar_blocks.len());
+
+        let lut_selection = |selector: ComparisonSelector| {
+            let func = match selector {
+                ComparisonSelector::Gt => |lsb, msb| {
+                    let msb = if msb == 1 {
+                        Self::IS_EQUAL
+                    } else {
+                        Self::IS_SUPERIOR
+                    };
+                    let x = (msb << 2) + lsb;
+                    let m = (x >> 2) & 3_u64;
+                    let l = x & 3;
+                    let final_sign = if m == Self::IS_EQUAL { l } else { m };
+                    u64::from(final_sign == Self::IS_SUPERIOR)
+                },
+                ComparisonSelector::Ge => |lsb, msb| {
+                    let msb = if msb == 1 {
+                        Self::IS_EQUAL
+                    } else {
+                        Self::IS_SUPERIOR
+                    };
+                    let x = (msb << 2) + lsb;
+                    let m = (x >> 2) & 3_u64;
+                    let l = x & 3;
+                    let final_sign = if m == Self::IS_EQUAL { l } else { m };
+                    u64::from(final_sign == Self::IS_SUPERIOR || final_sign == Self::IS_EQUAL)
+                },
+                ComparisonSelector::Lt => |lsb, msb| {
+                    let msb = if msb == 1 {
+                        Self::IS_EQUAL
+                    } else {
+                        Self::IS_SUPERIOR
+                    };
+                    let x = (msb << 2) + lsb;
+                    let m = (x >> 2) & 3_u64;
+                    let l = x & 3;
+                    let final_sign = if m == Self::IS_EQUAL { l } else { m };
+                    u64::from(final_sign == Self::IS_INFERIOR)
+                },
+                ComparisonSelector::Le => |lsb, msb| {
+                    let msb = if msb == 1 {
+                        Self::IS_EQUAL
+                    } else {
+                        Self::IS_SUPERIOR
+                    };
+                    let x = (msb << 2) + lsb;
+                    let m = (x >> 2) & 3_u64;
+                    let l = x & 3;
+                    let final_sign = if m == Self::IS_EQUAL { l } else { m };
+                    u64::from(final_sign == Self::IS_INFERIOR || final_sign == Self::IS_EQUAL)
+                },
+                ComparisonSelector::None => |lsb, msb| {
+                    let msb = if msb == 1 {
+                        Self::IS_EQUAL
+                    } else {
+                        Self::IS_SUPERIOR
+                    };
+                    let x = (msb << 2) + lsb;
+                    let m = (x >> 2) & 3_u64;
+                    let l = x & 3;
+                    if m == Self::IS_EQUAL {
+                        l
+                    } else {
+                        m
+                    }
+                },
+            };
+
+            shortint_key.generate_lookup_vector_bivariate(&func)
+        };
+
+        // Reducing the signs is the bottleneck of the comparison algorithms,
+        // however if the scalar case there is an improvement:
+        //
+        // The idea is to reduce the number of signs block we have to
+        // reduce. We can do that by splitting the comparison problem in two parts.
+        //
+        // - One part where we compute the signs block between the scalar with just enough blocks
+        //   from the ciphertext that can represent the scalar value
+        //
+        // - The other part is to compare the ciphertext blocks not considered for the sign
+        //   computation with zero, and create a single sign block from that.
+        //
+        // The smaller the scalar value is compared to the ciphertext num bits encrypted,
+        // the more the comparisons with zeros we have to do,
+        // and the less signs block we will have to reduce.
+        //
+        // This will create a speedup as comparing a bunch of blocks with 0
+        // is faster
+
+        match (
+            least_significant_blocks.is_empty(),
+            most_significant_blocks.is_empty(),
+        ) {
+            (false, false) => {
+                // We have to handle both part of the work described above
+
+                let (lsb_sign, are_all_msb_equal_to_zero) = (
+                    {
+                        let lsb_signs = self.unchecked_scalar_block_slice_compare_parallelized(
+                            least_significant_blocks,
+                            &scalar_blocks,
+                        );
+
+                        self.reduce_signs_pack(lsb_signs, &ComparisonSelector::None)
+                    },
+                    self.server_key.are_all_blocks_zero(most_significant_blocks),
+                );
+
+                let lut = lut_selection(selector);
+
+                let mut prepared_blocks = self
+                    .server_key
+                    .prepare_bivariate(&mut [lsb_sign], &[are_all_msb_equal_to_zero]);
+
+                self.server_key
+                    .apply_lookup_vector_packed_assign(&mut prepared_blocks, &[lut]);
+
+                prepared_blocks[0].clone()
+            }
+            (false, true) => {
+                // We only have to do the regular comparison
+                // And not the part where we compare most significant blocks with zeros
+
+                let signs = self.unchecked_scalar_block_slice_compare_parallelized(
+                    least_significant_blocks,
+                    &scalar_blocks,
+                );
+
+                self.reduce_signs_pack(signs, &selector)
+            }
+            (true, false) => {
+                // We only have to compare blocks with zero
+                // means scalar is zero
+                let are_all_msb_equal_to_zero =
+                    self.server_key.are_all_blocks_zero(most_significant_blocks);
+
+                let lut = lut_selection(selector);
+                let luts = vec![lut];
+
+                let mut blocks = vec![are_all_msb_equal_to_zero];
+                self.server_key
+                    .apply_lookup_vector_packed_assign(&mut blocks, &luts);
+
+                blocks[0].clone()
+            }
+            (true, true) => {
+                // assert should have  been hit earlier
+                unreachable!("Empty input ciphertext")
+            }
+        }
+    }
+
+    fn unchecked_scalar_block_slice_compare_parallelized(
+        &self,
+        lhs_blocks: &[Ciphertext],
+        scalar_blocks: &[u8],
+    ) -> Vec<Ciphertext> {
+        assert_eq!(lhs_blocks.len(), scalar_blocks.len());
+
+        let shortint_key = &self.server_key.key.key.key;
+        let message_modulus = shortint_key.message_modulus.0;
+
+        let mut signs: Vec<_> = lhs_blocks
+            .chunks(2)
+            .zip(scalar_blocks.chunks(2))
+            .map(|(lhs_chunk, scalar_chunk)| {
+                let packed_scalar = scalar_chunk[0]
+                    + (scalar_chunk.get(1).copied().unwrap_or(0) * message_modulus as u8);
+                let mut packed_lhs = self.pack_block_chunk(lhs_chunk);
+
+                let delta = (1u64 << (u64::BITS as u64 - 1))
+                    / (packed_lhs.carry_modulus.0 * packed_lhs.message_modulus.0);
+                let plaintext = Plaintext((packed_scalar as u64) * delta);
+
+                lwe_ciphertext_plaintext_sub_assign(&mut packed_lhs.ct, plaintext);
+                packed_lhs
+            })
+            .collect();
+
+        self.server_key
+            .apply_same_lookup_vector_packed_assign(&mut signs, self.sign_lut);
+
+        for signs_block in signs.iter_mut() {
+            shortint_key.unchecked_scalar_add_assign(signs_block, 1);
+        }
+
+        signs
+    }
+
+    pub fn scalar_max<T, Scalar>(&self, lhs: &T, rhs: Scalar) -> T
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+    {
+        let mut tmp_lhs;
+        let lhs = if lhs.block_carries_are_empty() {
+            lhs
+        } else {
+            tmp_lhs = lhs.clone();
+            self.server_key.full_propagate(&mut tmp_lhs);
+            &tmp_lhs
+        };
+        self.unchecked_scalar_min_or_max(lhs, rhs, MinMaxSelector::Max)
+    }
+
+    pub fn scalar_min<T, Scalar>(&self, lhs: &T, rhs: Scalar) -> T
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+    {
+        let mut tmp_lhs;
+        let lhs = if lhs.block_carries_are_empty() {
+            lhs
+        } else {
+            tmp_lhs = lhs.clone();
+            self.server_key.full_propagate(&mut tmp_lhs);
+            &tmp_lhs
+        };
+        self.unchecked_scalar_min_or_max(lhs, rhs, MinMaxSelector::Min)
+    }
+
+    pub fn unchecked_scalar_min_or_max<T, Scalar>(
+        &self,
+        lhs: &T,
+        rhs: Scalar,
+        selector: MinMaxSelector,
+    ) -> T
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+    {
+        let return_lhs = match selector {
+            MinMaxSelector::Max => self.unchecked_scalar_gt(lhs, rhs),
+            MinMaxSelector::Min => self.unchecked_scalar_le(lhs, rhs),
+        };
+
+        let rhs = self
+            .server_key
+            .key
+            .key
+            .create_trivial_radix(rhs, lhs.blocks().len());
+
+        let do_clean_message = true;
+        self.server_key.unchecked_programmable_if_then_else(
+            &return_lhs.0,
+            lhs,
+            &rhs,
+            |x| x == 1,
+            do_clean_message,
+        )
+    }
+}
diff --git a/tfhe/src/integer/fpga/server_key/fpga.rs b/tfhe/src/integer/fpga/server_key/fpga.rs
new file mode 100644
index 000000000..7a0abc50f
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/fpga.rs
@@ -0,0 +1,143 @@
+use crate::core_crypto::fpga::keyswitch_bootstrap::KeyswitchBootstrapPacked;
+use crate::core_crypto::fpga::lookup_vector::LookupVector;
+use crate::high_level_api::Tag;
+use crate::keys::inner::IntegerServerKey;
+use crate::shortint::Ciphertext;
+use crate::BelfortServerKey;
+
+impl BelfortServerKey {
+    pub fn connect(&mut self) {
+        #[cfg(not(feature = "emulate_fpga"))]
+        {
+            use crate::core_crypto::fpga::utils::Connect;
+
+            let server_key = &self.key.key.key;
+
+            self.fpga_utils.connect(server_key);
+        }
+    }
+
+    pub fn connect_to(&mut self, fpga_indexes: Vec<usize>) {
+        #[cfg(not(feature = "emulate_fpga"))]
+        {
+            use crate::core_crypto::fpga::utils::Connect;
+
+            let server_key = &self.key.key.key;
+
+            self.fpga_utils.connect_to(server_key, fpga_indexes);
+        }
+    }
+
+    pub fn disconnect(&mut self) {
+        #[cfg(not(feature = "emulate_fpga"))]
+        self.fpga_utils.disconnect();
+    }
+
+    pub fn pbs_key(&self) -> &crate::integer::ServerKey {
+        &self.key.key
+    }
+
+    pub fn tag(&self) -> &Tag {
+        &self.tag
+    }
+
+    #[cfg(not(feature = "emulate_fpga"))]
+    fn apply_keyswitch_bootstrap_on_trivials(
+        &self,
+        cts: &mut Vec<Ciphertext>,
+        luts: &[LookupVector],
+    ) {
+        use rayon::iter::*;
+        use std::sync::Arc;
+
+        let arc_key: &Arc<IntegerServerKey> = &self.key;
+        let shortint_key = &arc_key.key.key;
+
+        cts.par_iter_mut()
+            .enumerate()
+            .filter(|(_, ct)| ct.is_trivial())
+            .for_each(|(index, ct)| {
+                let lut_vector: &LookupVector = &luts[index];
+                let lut_table = shortint_key.convert_lookup_vector_to_lookup_table(lut_vector);
+                shortint_key.trivial_pbs_assign(ct, &lut_table);
+            });
+    }
+
+    pub fn apply_lookup_vector_packed_assign(
+        &self,
+        cts: &mut Vec<Ciphertext>,
+        luts: &[LookupVector],
+    ) {
+        #[cfg(not(feature = "emulate_fpga"))]
+        {
+            self.apply_keyswitch_bootstrap_on_trivials(cts, luts);
+            self.fpga_utils.keyswitch_bootstrap_packed(cts, luts);
+        }
+
+        #[cfg(feature = "emulate_fpga")]
+        {
+            let shortint_key = &self.key.key.key;
+            shortint_key.apply_lookup_vector_packed_assign(cts, luts);
+        }
+    }
+
+    pub fn apply_same_lookup_vector_packed_assign(
+        &self,
+        ciphertexts: &mut Vec<Ciphertext>,
+        lut: LookupVector,
+    ) {
+        let luts: Vec<LookupVector> = vec![lut; ciphertexts.len()];
+
+        self.apply_lookup_vector_packed_assign(ciphertexts, &luts);
+    }
+
+    pub fn apply_lookup_vector_single_assign(
+        &self,
+        ciphertext: &mut Ciphertext,
+        lut: LookupVector,
+    ) {
+        // TODO: Can we get rid of clones here
+
+        let luts = vec![lut];
+        let mut cts = vec![ciphertext.clone()];
+
+        self.apply_lookup_vector_packed_assign(&mut cts, &luts);
+
+        ciphertext.clone_from(cts.first().unwrap());
+    }
+
+    pub fn apply_same_lookup_vector_mut_packed_assign(
+        &self,
+        ciphertexts: &mut Vec<&mut Ciphertext>,
+        lut: LookupVector,
+    ) {
+        let luts: Vec<LookupVector> = vec![lut; ciphertexts.len()];
+
+        self.apply_lookup_vector_mut_packed_assign(ciphertexts, &luts);
+    }
+
+    pub fn apply_lookup_vector_mut_packed_assign(
+        &self,
+        ciphertext: &mut Vec<&mut Ciphertext>,
+        luts: &[LookupVector],
+    ) {
+        let mut ct_vec: Vec<Ciphertext> = ciphertext
+            .iter_mut()
+            .map(|block| (*block).clone())
+            .collect();
+
+        #[cfg(feature = "fpga")]
+        self.apply_lookup_vector_packed_assign(&mut ct_vec, luts);
+
+        #[cfg(not(feature = "fpga"))]
+        {
+            let shortint_key = &self.key.key.key;
+            shortint_key.apply_lookup_vector_packed_assign(&mut ct_vec, luts);
+        }
+
+        ciphertext
+            .iter_mut()
+            .enumerate()
+            .for_each(|(i, block)| (*block).clone_from(&ct_vec[i]));
+    }
+}
diff --git a/tfhe/src/integer/fpga/server_key/luts.rs b/tfhe/src/integer/fpga/server_key/luts.rs
new file mode 100644
index 000000000..8aef50a88
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/luts.rs
@@ -0,0 +1,28 @@
+use crate::core_crypto::fpga::lookup_vector::LookupVector;
+use crate::BelfortServerKey;
+
+impl BelfortServerKey {
+    pub fn lut_message_extract(&self) -> LookupVector {
+        let shortint_key = &self.key.key.key;
+        let func = |x| (x % shortint_key.message_modulus.0);
+        shortint_key.generate_lookup_vector(&func)
+    }
+
+    pub fn lut_carry_extract(&self) -> LookupVector {
+        let shortint_key = &self.key.key.key;
+        let func = |x| (x / shortint_key.message_modulus.0);
+        shortint_key.generate_lookup_vector(&func)
+    }
+
+    pub fn lut_mul_2lsb(&self) -> LookupVector {
+        let shortint_key = &self.key.key.key;
+        let func = |x, y| (x * y) % shortint_key.message_modulus.0;
+        shortint_key.generate_lookup_vector_bivariate(&func)
+    }
+
+    pub fn lut_mul_2msb(&self) -> LookupVector {
+        let shortint_key = &self.key.key.key;
+        let func = |x, y| (x * y) / shortint_key.message_modulus.0;
+        shortint_key.generate_lookup_vector_bivariate(&func)
+    }
+}
diff --git a/tfhe/src/integer/fpga/server_key/mod.rs b/tfhe/src/integer/fpga/server_key/mod.rs
new file mode 100644
index 000000000..0f9c174a5
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/mod.rs
@@ -0,0 +1,483 @@
+mod comparator;
+mod fpga;
+mod luts;
+mod radix;
+
+use std::sync::Arc;
+
+use crate::core_crypto::commons::numeric::UnsignedInteger;
+use crate::core_crypto::fpga::lookup_vector::LookupVector;
+use crate::core_crypto::fpga::BelfortFpgaUtils;
+use crate::high_level_api::keys::inner::IntegerServerKey;
+use crate::high_level_api::keys::ServerKey;
+use crate::high_level_api::Tag;
+use crate::integer::IntegerRadixCiphertext;
+use crate::shortint::parameters::Degree;
+use crate::shortint::Ciphertext;
+
+use rayon::iter::*;
+
+#[derive(Clone)]
+pub struct BelfortServerKey {
+    pub key: Arc<IntegerServerKey>,
+    pub fpga_utils: BelfortFpgaUtils,
+    pub tag: Tag,
+}
+
+impl From<&ServerKey> for BelfortServerKey {
+    fn from(value: &ServerKey) -> Self {
+        let ServerKey { key, tag } = value.clone();
+        Self::default(key, tag)
+    }
+}
+
+impl From<&IntegerServerKey> for BelfortServerKey {
+    fn from(value: &IntegerServerKey) -> Self {
+        Self::default(Arc::new(value.clone()), Tag::default())
+    }
+}
+
+impl From<&crate::integer::ServerKey> for BelfortServerKey {
+    fn from(value: &crate::integer::ServerKey) -> Self {
+        let integer_server_key = IntegerServerKey {
+            key: value.clone(),
+            cpk_key_switching_key_material: None,
+            compression_key: None,
+            decompression_key: None,
+        };
+        Self::default(Arc::new(integer_server_key), Tag::default())
+    }
+}
+
+impl From<Arc<crate::integer::ServerKey>> for BelfortServerKey {
+    fn from(value: Arc<crate::integer::ServerKey>) -> Self {
+        let server_key = Arc::unwrap_or_clone(value);
+        Self::from(&server_key)
+    }
+}
+
+enum OutputCarry {
+    None = 0,
+    Generated = 1,
+    Propagated = 2,
+}
+
+impl BelfortServerKey {
+    pub fn default(key: Arc<IntegerServerKey>, tag: Tag) -> Self {
+        Self {
+            key,
+            tag,
+            fpga_utils: BelfortFpgaUtils::default(),
+        }
+    }
+
+    pub fn conditional_full_propagate_bivariate<'a, T>(&self, lhs: &'a mut T, rhs: &'a mut T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.conditional_full_propagate(lhs);
+        self.conditional_full_propagate(rhs);
+    }
+
+    /// Executes a full propagate if there are carries.
+    pub fn conditional_full_propagate<T>(&self, term: &mut T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        if !term.block_carries_are_empty() {
+            self.full_propagate(term);
+        }
+    }
+
+    pub fn full_propagate<T>(&self, ctxt: &mut T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.partial_propagate_blocks(ctxt.blocks_mut());
+    }
+
+    /// This function takes an input slice of shortint ciphertext (aka blocks)
+    /// for which at most one bit of carry is consumed in each block, and
+    /// it does the carry propagation in place.
+    ///
+    /// It returns the output carry of the last block
+    ///
+    /// Used in (among other) 'default' addition:
+    /// - first unchecked_add
+    /// - at this point at most on bit of carry is taken
+    /// - use this function to propagate them in parallel
+    pub(crate) fn propagate_single_carry_parallelized_low_latency(
+        &self,
+        blocks: &mut [Ciphertext],
+    ) {
+        let generates_or_propagates = self.generate_init_carry_array(blocks);
+
+        let input_carries = self.compute_carry_propagation(generates_or_propagates);
+
+        let shortint_key = &self.key.key.key;
+
+        blocks
+            .par_iter_mut()
+            .zip(input_carries.par_iter())
+            .for_each(|(block, input_carry)| {
+                shortint_key.unchecked_add_assign(block, input_carry);
+            });
+
+        let lut_message_extract = self.lut_message_extract();
+        let mut blocks_vec = blocks.to_vec();
+        self.apply_same_lookup_vector_packed_assign(&mut blocks_vec, lut_message_extract);
+
+        blocks
+            .par_iter_mut()
+            .zip(blocks_vec.par_iter())
+            .for_each(|(block, vec_block)| {
+                block.clone_from(vec_block);
+            });
+    }
+
+    fn generate_init_carry_array(&self, sum_blocks: &[Ciphertext]) -> Vec<Ciphertext> {
+        let shortint_key = &self.key.key.key;
+
+        let lut_does_block_generate_carry = {
+            let func = |x| {
+                if x >= shortint_key.message_modulus.0 {
+                    OutputCarry::Generated as u64
+                } else {
+                    OutputCarry::None as u64
+                }
+            };
+            shortint_key.generate_lookup_vector(&func)
+        };
+        let lut_does_block_generate_or_propagate = {
+            let func = |x| {
+                if x >= shortint_key.message_modulus.0 {
+                    OutputCarry::Generated as u64
+                } else if x == (shortint_key.message_modulus.0 - 1) {
+                    OutputCarry::Propagated as u64
+                } else {
+                    OutputCarry::None as u64
+                }
+            };
+            shortint_key.generate_lookup_vector(&func)
+        };
+
+        let mut luts: Vec<LookupVector> = Vec::with_capacity(sum_blocks.len());
+
+        sum_blocks
+            .par_iter()
+            .enumerate()
+            .map(|(i, _)| {
+                if i == 0 {
+                    lut_does_block_generate_carry
+                } else {
+                    lut_does_block_generate_or_propagate
+                }
+            })
+            .collect_into_vec(&mut luts);
+
+        let mut generates_or_propagates = sum_blocks.to_vec();
+
+        self.apply_lookup_vector_packed_assign(&mut generates_or_propagates, &luts);
+
+        generates_or_propagates
+    }
+
+    pub(crate) fn compute_carry_propagation(
+        &self,
+        generates_or_propagates: Vec<Ciphertext>,
+    ) -> Vec<Ciphertext> {
+        let size = generates_or_propagates.len();
+        let fpga_count = self.fpga_utils.fpga_indexes.len();
+
+        // Performance improvement starts from 64-bit numbers (=ciphertexts of size 32 for 2M2C)
+        // In case of multiple FPGA's there is no improvements
+        if size >= 32 && fpga_count == 1 {
+            self.compute_carry_propagation_parallelized_work_efficient(generates_or_propagates)
+        } else {
+            self.compute_carry_propagation_parallelized_low_latency(generates_or_propagates)
+        }
+    }
+
+    /// Backbone algorithm of parallel carry (only one bit) propagation
+    ///
+    /// Uses the Hillis and Steele prefix scan
+    ///
+    /// Requires the blocks to have at least 4 bits
+    pub(crate) fn compute_carry_propagation_parallelized_low_latency(
+        &self,
+        generates_or_propagates: Vec<Ciphertext>,
+    ) -> Vec<Ciphertext> {
+        if generates_or_propagates.is_empty() {
+            return vec![];
+        }
+
+        let num_blocks = generates_or_propagates.len();
+
+        let mut carries_out =
+            self.compute_prefix_sum_hillis_steele(generates_or_propagates, "carry_propagation_sum");
+
+        let mut last_block_out_carry = self.key.key.key.create_trivial(0u64);
+        std::mem::swap(&mut carries_out[num_blocks - 1], &mut last_block_out_carry);
+        last_block_out_carry.degree = Degree::new(1);
+
+        carries_out.rotate_right(1);
+        carries_out
+    }
+
+    /// Computes a prefix sum/scan in parallel using Hillis & Steel algorithm
+    pub(crate) fn compute_prefix_sum_hillis_steele(
+        &self,
+        mut blocks: Vec<Ciphertext>,
+        lut_name: &str,
+    ) -> Vec<Ciphertext> {
+        let shortint_key = &self.key.key.key;
+        debug_assert!(shortint_key.message_modulus.0 * shortint_key.carry_modulus.0 >= (1 << 4));
+
+        if blocks.is_empty() {
+            return vec![];
+        }
+
+        let num_blocks = blocks.len();
+        let num_steps = blocks.len().ceil_ilog2() as usize;
+
+        let mut space = 1;
+        let mut step_output = blocks.clone();
+
+        let lut_function: Box<dyn Fn(u64, u64) -> u64> = match lut_name {
+            "carry_propagation_sum" => Box::new(|msb: u64, lsb: u64| {
+                if msb == OutputCarry::Propagated as u64 {
+                    lsb
+                } else {
+                    msb
+                }
+            }),
+            "trailing_bits_sum" => Box::new(
+                |block_num_bit_count: u64, more_significant_block_bit_count: u64| {
+                    if more_significant_block_bit_count
+                        == (shortint_key.message_modulus.0.ilog2() as u64)
+                    {
+                        block_num_bit_count
+                    } else {
+                        0_u64
+                    }
+                },
+            ),
+            _ => panic!("unknown lut {lut_name}"),
+        };
+
+        let lut_vector_sum = shortint_key.generate_lookup_vector_bivariate(&lut_function);
+
+        for _ in 0..num_steps {
+            let mut prev_block_carries = Vec::with_capacity(num_blocks - space);
+            for block in blocks.iter().take(num_blocks - space) {
+                prev_block_carries.push(block.clone());
+            }
+
+            let mut step_output_vec = step_output[space..num_blocks].to_vec();
+            let mut prepared_blocks =
+                self.prepare_bivariate(&mut step_output_vec, &prev_block_carries);
+
+            self.apply_same_lookup_vector_packed_assign(&mut prepared_blocks, lut_vector_sum);
+
+            for (i, block) in prepared_blocks.into_iter().enumerate() {
+                step_output[space + i] = block;
+            }
+
+            for i in space..num_blocks {
+                blocks[i].clone_from(&step_output[i]);
+            }
+
+            space *= 2;
+        }
+
+        blocks
+    }
+
+    pub fn propagate_parallelized<T>(&self, ctxt: &mut T, index: usize) -> Ciphertext
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let luts = vec![self.lut_carry_extract(), self.lut_message_extract()];
+
+        let block = &ctxt.blocks()[index].clone();
+        let mut result = vec![block.clone(), block.clone()];
+        self.apply_lookup_vector_packed_assign(&mut result, &luts);
+
+        let (carry, message) = (result[0].clone(), result[1].clone());
+        ctxt.blocks_mut()[index] = message;
+
+        if index < ctxt.blocks().len() - 1 {
+            let shortint_key = &self.key.key.key;
+            shortint_key.unchecked_add_assign(&mut ctxt.blocks_mut()[index + 1], &carry);
+        }
+        carry
+    }
+
+    fn partial_propagate_blocks(&self, blocks: &mut [Ciphertext]) {
+        let shortint_key = &self.key.key.key;
+        let highest_degree = blocks
+            .iter()
+            .max_by(|block_a, block_b| block_a.degree.get().cmp(&block_b.degree.get()))
+            .map(|block| block.degree.get())
+            .unwrap();
+
+        if highest_degree > (shortint_key.message_modulus.0 - 1) * 2 {
+            let (mut message_blocks, carry_blocks) = self.extract_message_and_carry_blocks(blocks);
+
+            blocks.swap_with_slice(&mut message_blocks);
+            for (block, carry) in blocks[1..].iter_mut().zip(carry_blocks.iter()) {
+                shortint_key.unchecked_add_assign(block, carry);
+            }
+        }
+        self.propagate_single_carry_parallelized_low_latency(blocks);
+    }
+
+    pub(crate) fn extract_message_and_carry_blocks(
+        &self,
+        blocks: &[Ciphertext],
+    ) -> (Vec<Ciphertext>, Vec<Ciphertext>) {
+        let num_blocks = blocks.len();
+        let mut luts = Vec::with_capacity(2 * num_blocks);
+        luts.extend(std::iter::repeat(self.lut_message_extract()).take(num_blocks));
+        luts.extend(std::iter::repeat(self.lut_carry_extract()).take(num_blocks));
+
+        let mut prepared_blocks = Vec::with_capacity(2 * num_blocks);
+        prepared_blocks.extend(blocks.to_owned());
+        prepared_blocks.extend(blocks.to_owned());
+
+        self.apply_lookup_vector_packed_assign(&mut prepared_blocks, &luts);
+
+        let (messages, carries) = prepared_blocks.split_at(num_blocks);
+
+        (messages.to_vec(), carries.to_vec())
+    }
+
+    pub fn prepare_bivariate(
+        &self,
+        lhs_blocks: &mut [Ciphertext],
+        rhs_blocks: &[Ciphertext],
+    ) -> Vec<Ciphertext> {
+        let mut prepared_blocks = Vec::new();
+
+        lhs_blocks
+            .iter_mut()
+            .zip(rhs_blocks.iter())
+            .for_each(|(lhs_block, rhs_block)| {
+                let mut block_clone_sum = lhs_block.clone();
+                self.key
+                    .key
+                    .key
+                    .unchecked_apply_lookup_table_bivariate_assign_prep(
+                        &mut block_clone_sum,
+                        rhs_block,
+                    );
+                prepared_blocks.push(block_clone_sum);
+            });
+
+        prepared_blocks
+    }
+
+    pub(crate) fn compute_carry_propagation_parallelized_work_efficient(
+        &self,
+        mut carry_out: Vec<Ciphertext>,
+    ) -> Vec<Ciphertext> {
+        let shortint_key = &self.key.key.key;
+        debug_assert!(shortint_key.message_modulus.0 * shortint_key.carry_modulus.0 >= (1 << 3));
+
+        let num_blocks = carry_out.len();
+        let num_steps = num_blocks.ilog2();
+
+        let lut_vector_carry_propagation_sum = {
+            let func = |msb: u64, lsb: u64| {
+                if msb == OutputCarry::Propagated as u64 {
+                    lsb
+                } else {
+                    msb
+                }
+            };
+            shortint_key.generate_lookup_vector_bivariate(&func)
+        };
+
+        // Up-Sweep phase
+        for i in 0..num_steps {
+            let two_pow_i_plus_1 = 2_usize.checked_pow(i + 1).unwrap();
+            let two_pow_i = 2_usize.checked_pow(i).unwrap();
+
+            let mut current_blocks = vec![];
+            let mut previous_blocks = vec![];
+
+            carry_out
+                .chunks_exact_mut(two_pow_i_plus_1)
+                .for_each(|carry_out| {
+                    let (current_block, head) = carry_out.split_last_mut().unwrap();
+                    let previous_block = &head[two_pow_i - 1];
+
+                    current_blocks.push(current_block.clone());
+                    previous_blocks.push(previous_block.clone());
+                });
+
+            let mut prepared_blocks = self.prepare_bivariate(&mut current_blocks, &previous_blocks);
+            self.apply_same_lookup_vector_packed_assign(
+                &mut prepared_blocks,
+                lut_vector_carry_propagation_sum,
+            );
+
+            let mut prepared_block_iter = prepared_blocks.into_iter();
+            carry_out
+                .chunks_exact_mut(two_pow_i_plus_1)
+                .for_each(|carry_out_chunk| {
+                    let (last, _) = carry_out_chunk.split_last_mut().unwrap();
+                    *last = prepared_block_iter.next().unwrap();
+                });
+        }
+
+        // Down-Sweep phase
+        shortint_key.create_trivial_assign(&mut carry_out[num_blocks - 1], 0);
+
+        for i in (0..num_steps).rev() {
+            let two_pow_i_plus_1 = 2usize.checked_pow(i + 1).unwrap();
+            let two_pow_i = 2usize.checked_pow(i).unwrap();
+
+            let mut blocks1 = vec![];
+            let mut blocks2 = vec![];
+
+            (0..num_blocks).step_by(two_pow_i_plus_1).for_each(|k| {
+                blocks1.push(carry_out[k + two_pow_i - 1].clone());
+                blocks2.push(carry_out[k + two_pow_i_plus_1 - 1].clone());
+            });
+
+            let mut buffer = self.prepare_bivariate(&mut blocks1, &blocks2);
+            self.apply_same_lookup_vector_packed_assign(
+                &mut buffer,
+                lut_vector_carry_propagation_sum,
+            );
+
+            let mut drainer = buffer.drain(..);
+            for k in (0..num_blocks).step_by(two_pow_i_plus_1) {
+                let b = drainer.next().unwrap();
+                carry_out.swap(k + two_pow_i - 1, k + two_pow_i_plus_1 - 1);
+                carry_out[k + two_pow_i_plus_1 - 1] = b;
+            }
+            drop(drainer);
+            assert!(buffer.is_empty());
+        }
+
+        // The first step of the Down-Sweep phase sets the
+        // first block to 0, so no need to re-do it
+        carry_out
+    }
+
+    pub(crate) fn pack_blocks<T>(&self, ct_left: &T, ct_right: &T) -> Vec<Ciphertext>
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut result: Vec<Ciphertext> = ct_left.blocks().to_vec();
+        result
+            .iter_mut()
+            .zip(ct_right.blocks().iter())
+            .for_each(|(ct_left_i, ct_right_i)| {
+                self.key.key.pack_block_assign(ct_right_i, ct_left_i)
+            });
+        result
+    }
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/abs.rs b/tfhe/src/integer/fpga/server_key/radix/abs.rs
new file mode 100644
index 000000000..de29a0299
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/abs.rs
@@ -0,0 +1,34 @@
+use crate::integer::ciphertext::IntegerRadixCiphertext;
+use crate::integer::fpga::server_key::BelfortServerKey;
+use log::warn;
+
+impl BelfortServerKey {
+    pub fn unchecked_abs<T>(&self, ct: &T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        warn!("Non-optimized function call. Contact Belfort if you experience a slow run.");
+        self.key.key.unchecked_abs_parallelized(ct)
+    }
+
+    pub fn smart_abs<T>(&self, ct: &mut T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.conditional_full_propagate(ct);
+        self.unchecked_abs(ct)
+    }
+
+    pub fn abs<T>(&self, ct: &T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        if ct.block_carries_are_empty() {
+            self.unchecked_abs(ct)
+        } else {
+            let mut cloned = ct.clone();
+            self.full_propagate(&mut cloned);
+            self.unchecked_abs(&cloned)
+        }
+    }
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/add.rs b/tfhe/src/integer/fpga/server_key/radix/add.rs
new file mode 100644
index 000000000..a4db918e8
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/add.rs
@@ -0,0 +1,153 @@
+use crate::integer::ciphertext::IntegerRadixCiphertext;
+use crate::integer::fpga::server_key::BelfortServerKey;
+use crate::integer::server_key::CheckError;
+
+impl BelfortServerKey {
+    /// Computes homomorphically an addition between two ciphertexts encrypting integer values.
+    ///
+    /// This function, like all "default" operations (i.e. not smart, checked or unchecked), will
+    /// check that the input ciphertexts block carries are empty and clears them if it's not the
+    /// case and the operation requires it. It outputs a ciphertext whose block carries are always
+    /// empty.
+    ///
+    /// This means that when using only "default" operations, a given operation (like add for
+    /// example) has always the same performance characteristics from one call to another and
+    /// guarantees correctness by pre-emptively clearing carries of output ciphertexts.
+    pub fn add<T>(&self, ct1: &T, ct2: &T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut ct_res = ct1.clone();
+        self.add_assign(&mut ct_res, ct2);
+        ct_res
+    }
+
+    pub fn add_assign<T>(&self, ct1: &mut T, ct2: &T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut tmp_rhs;
+
+        let (lhs, rhs) = match (ct1.block_carries_are_empty(), ct2.block_carries_are_empty()) {
+            (true, true) => (ct1, ct2),
+            (true, false) => {
+                tmp_rhs = ct2.clone();
+                self.full_propagate(&mut tmp_rhs);
+                (ct1, &tmp_rhs)
+            }
+            (false, true) => {
+                self.full_propagate(ct1);
+                (ct1, ct2)
+            }
+            (false, false) => {
+                tmp_rhs = ct2.clone();
+                self.full_propagate(ct1);
+                self.full_propagate(&mut tmp_rhs);
+                (ct1, &tmp_rhs)
+            }
+        };
+
+        // TODO: if you go below 4 bits think about this
+        self.unchecked_add_assign_parallelized_low_latency(lhs, rhs);
+    }
+
+    pub fn unchecked_add<T>(&self, ct1: &T, ct2: &T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.key.key.unchecked_add(ct1, ct2)
+    }
+
+    pub fn unchecked_add_assign<T>(&self, ct1: &mut T, ct2: &T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.key.key.unchecked_add_assign(ct1, ct2);
+    }
+
+    pub fn checked_add<T>(&self, ct1: &T, ct2: &T) -> Result<T, CheckError>
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.key.key.is_add_possible(ct1, ct2)?;
+        Ok(self.key.key.unchecked_add(ct1, ct2))
+    }
+
+    pub fn smart_add<T>(&self, ct1: &mut T, ct2: &mut T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        if self.key.key.is_add_possible(ct1, ct2).is_err() {
+            self.full_propagate(ct1);
+            self.full_propagate(ct2);
+        }
+
+        self.key.key.is_add_possible(ct1, ct2).unwrap();
+        self.key.key.unchecked_add(ct1, ct2)
+    }
+
+    pub fn checked_add_assign<T>(&self, ct1: &mut T, ct2: &T) -> Result<(), CheckError>
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.key.key.is_add_possible(ct1, ct2)?;
+        self.unchecked_add_assign(ct1, ct2);
+        Ok(())
+    }
+
+    pub fn smart_add_assign<T>(&self, ct1: &mut T, ct2: &mut T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let integer_key = &self.key.key;
+        if integer_key.is_add_possible(ct1, ct2).is_err() {
+            self.full_propagate(ct1);
+            self.full_propagate(ct2);
+        }
+        integer_key.is_add_possible(ct1, ct2).unwrap();
+        self.unchecked_add_assign(ct1, ct2);
+    }
+
+    /// This add_assign two numbers
+    ///
+    /// It uses the Hillis and Steele algorithm to do
+    /// prefix sum / cumulative sum in parallel.
+    ///
+    /// It it not "work efficient" as in, it adds a lot
+    /// of work compared to the single threaded approach,
+    /// however it is highly parallelized and so is the fastest
+    /// assuming enough threads are available.
+    ///
+    /// At most num_block - 1 threads are used
+    ///
+    /// Returns the output carry that can be used to check for unsigned addition
+    /// overflow.
+    ///
+    /// # Requirements
+    ///
+    /// - The parameters have 4 bits in total
+    /// - Adding rhs to lhs must not consume more than one carry
+    ///
+    /// # Output
+    ///
+    /// - lhs will have its carries empty
+    pub(crate) fn unchecked_add_assign_parallelized_low_latency<T>(&self, lhs: &mut T, rhs: &T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let integer_key = &self.key.key;
+
+        let degree_after_add_does_not_go_beyond_first_carry = lhs
+            .blocks()
+            .iter()
+            .zip(rhs.blocks().iter())
+            .all(|(bl, br)| {
+                let degree_after_add = bl.degree.get() + br.degree.get();
+                degree_after_add < (integer_key.message_modulus().0 * 2)
+            });
+        assert!(degree_after_add_does_not_go_beyond_first_carry);
+
+        integer_key.unchecked_add_assign_parallelized(lhs, rhs);
+        self.propagate_single_carry_parallelized_low_latency(lhs.blocks_mut())
+    }
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/bit_extractor.rs b/tfhe/src/integer/fpga/server_key/radix/bit_extractor.rs
new file mode 100644
index 000000000..11381667b
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/bit_extractor.rs
@@ -0,0 +1,110 @@
+use crate::core_crypto::fpga::lookup_vector::LookupVector;
+use crate::integer::fpga::server_key::BelfortServerKey;
+use crate::shortint::Ciphertext;
+use itertools::iproduct;
+
+pub(crate) struct BitExtractor<'a> {
+    bit_extract_luts: Vec<LookupVector>,
+    bits_per_block: usize,
+    server_key: &'a BelfortServerKey,
+}
+
+impl<'a> BitExtractor<'a> {
+    pub(crate) fn msg_with_final_offset0(
+        server_key: &'a BelfortServerKey,
+        bits_per_block: usize,
+    ) -> Self {
+        let shortint_key = &server_key.key.key.key;
+
+        let mut bit_extract_luts: Vec<LookupVector> = Vec::new();
+
+        bit_extract_luts.push({
+            // Scalar Bitand 1
+            {
+                let func = |x| x & 1;
+                shortint_key.generate_lookup_vector(&func)
+            }
+        });
+        if bits_per_block == 2 {
+            bit_extract_luts.push({
+                // Message bit 1 extraction
+                {
+                    let func = |x| (x >> 1) & 1_u64;
+                    shortint_key.generate_lookup_vector(&func)
+                }
+            });
+        }
+
+        Self {
+            bit_extract_luts,
+            bits_per_block,
+            server_key,
+        }
+    }
+
+    /// Creates a bit extractor that will extract bits from an input ciphertext
+    /// into single blocks.
+    ///
+    /// The offset which is 2 gives the position where the extracted bit shall be placed
+    /// in the resulting block.
+    /// It may be used to align the bit with a certain position to avoid
+    /// shifting it later (and increasing noise)
+    pub(crate) fn msg_with_final_offset2(
+        server_key: &'a BelfortServerKey,
+        bits_per_block: usize,
+    ) -> Self {
+        let shortint_key = &server_key.key.key.key;
+
+        let mut bit_extract_luts: Vec<LookupVector> = Vec::new();
+
+        bit_extract_luts.push({
+            // Message bit 0 extraction with offset two
+            {
+                let func = |x| (x & 1) << 2;
+                shortint_key.generate_lookup_vector(&func)
+            }
+        });
+        if bits_per_block == 2 {
+            bit_extract_luts.push({
+                // Message bit 1 extraction with offset two
+                {
+                    let func = |x| ((x >> 1) & 1_u64) << 2;
+                    shortint_key.generate_lookup_vector(&func)
+                }
+            });
+        }
+
+        Self {
+            bit_extract_luts,
+            bits_per_block,
+            server_key,
+        }
+    }
+
+    pub(crate) fn extract_all_bits(&self, blocks: &[Ciphertext]) -> Vec<Ciphertext> {
+        let num_blocks: usize = blocks.len();
+        self.extract_n_bits(blocks, num_blocks * self.bits_per_block)
+    }
+
+    pub(crate) fn extract_n_bits(&self, blocks: &[Ciphertext], n: usize) -> Vec<Ciphertext> {
+        let num_blocks = blocks.len();
+        let (blocks_idxs, lut_idxs): (Vec<usize>, Vec<usize>) =
+            iproduct!(0..num_blocks, 0..self.bits_per_block)
+                .take(n)
+                .unzip();
+        let mut blocks = blocks_idxs
+            .iter()
+            .map(|block_idx| blocks[*block_idx].clone())
+            .collect::<Vec<_>>();
+
+        let luts = lut_idxs
+            .iter()
+            .map(|lut_idx| self.bit_extract_luts[*lut_idx])
+            .collect::<Vec<_>>();
+
+        self.server_key
+            .apply_lookup_vector_packed_assign(&mut blocks, &luts);
+
+        blocks
+    }
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/bitwise_op.rs b/tfhe/src/integer/fpga/server_key/radix/bitwise_op.rs
new file mode 100644
index 000000000..3f395dc4b
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/bitwise_op.rs
@@ -0,0 +1,536 @@
+use crate::core_crypto::prelude::lwe_ciphertext_opposite_assign;
+use crate::integer::ciphertext::IntegerRadixCiphertext;
+use crate::integer::fpga::server_key::BelfortServerKey;
+use crate::shortint::ciphertext::Degree;
+
+impl BelfortServerKey {
+    pub fn unchecked_bitand<T>(&self, ct_left: &T, ct_right: &T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut result = ct_left.clone();
+        self.unchecked_bitand_assign(&mut result, ct_right);
+        result
+    }
+
+    pub fn unchecked_bitand_assign<T>(&self, ct_left: &mut T, ct_right: &T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut result = self.pack_blocks(ct_left, ct_right);
+
+        let shortint_key = &self.key.key.key;
+        let lut_bitand = {
+            let func = |x, y| x & y;
+            shortint_key.generate_lookup_vector_bivariate(&func)
+        };
+
+        self.apply_same_lookup_vector_packed_assign(&mut result, lut_bitand);
+
+        for (i, block) in result.into_iter().enumerate() {
+            ct_left.blocks_mut()[i] = block;
+        }
+    }
+
+    /// Computes homomorphically a bitand between two ciphertexts encrypting integer values.
+    ///
+    /// # Warning
+    ///
+    /// - Multithreaded
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // Generate the client key and the server key:
+    /// let num_blocks = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, num_blocks);
+    ///
+    /// let msg1 = 14;
+    /// let msg2 = 97;
+    ///
+    /// let mut ct1 = cks.encrypt(msg1);
+    /// let mut ct2 = cks.encrypt(msg2);
+    ///
+    /// let ct_res = sks.smart_bitand(&mut ct1, &mut ct2);
+    ///
+    /// // Decrypt:
+    /// let dec_result: u64 = cks.decrypt(&ct_res);
+    /// assert_eq!(dec_result, msg1 & msg2);
+    /// ```
+    pub fn smart_bitand<T>(&self, ct_left: &mut T, ct_right: &mut T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.full_propagate_if_degree_too_large(ct_left, ct_right);
+        self.unchecked_bitand(ct_left, ct_right)
+    }
+
+    pub fn smart_bitand_assign<T>(&self, ct_left: &mut T, ct_right: &mut T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.full_propagate_if_degree_too_large(ct_left, ct_right);
+        self.key.key.unchecked_bitand_assign(ct_left, ct_right);
+    }
+
+    /// Computes homomorphically a bitand between two ciphertexts encrypting integer values.
+    ///
+    /// This function, like all "default" operations (i.e. not smart, checked or unchecked), will
+    /// check that the input ciphertexts block carries are empty and clears them if it's not the
+    /// case and the operation requires it. It outputs a ciphertext whose block carries are always
+    /// empty.
+    ///
+    /// This means that when using only "default" operations, a given operation (like add for
+    /// example) has always the same performance characteristics from one call to another and
+    /// guarantees correctness by pre-emptively clearing carries of output ciphertexts.
+    ///
+    /// # Warning
+    ///
+    /// - Multithreaded
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // Generate the client key and the server key:
+    /// let num_blocks = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, num_blocks);
+    ///
+    /// let msg1 = 14;
+    /// let msg2 = 97;
+    ///
+    /// let ct1 = cks.encrypt(msg1);
+    /// let ct2 = cks.encrypt(msg2);
+    ///
+    /// let ct_res = sks.bitand(&ct1, &ct2);
+    ///
+    /// // Decrypt:
+    /// let dec_result: u64 = cks.decrypt(&ct_res);
+    /// assert_eq!(dec_result, msg1 & msg2);
+    /// ```
+    pub fn bitand<T>(&self, ct_left: &T, ct_right: &T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut ct_res = ct_left.clone();
+        self.bitand_assign(&mut ct_res, ct_right);
+        ct_res
+    }
+
+    pub fn bitand_assign<T>(&self, ct_left: &mut T, ct_right: &T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut tmp_rhs;
+
+        let (lhs, rhs) = match (
+            ct_left.block_carries_are_empty(),
+            ct_right.block_carries_are_empty(),
+        ) {
+            (true, true) => (ct_left, ct_right),
+            (true, false) => {
+                tmp_rhs = ct_right.clone();
+                self.full_propagate(&mut tmp_rhs);
+                (ct_left, &tmp_rhs)
+            }
+            (false, true) => {
+                self.full_propagate(ct_left);
+                (ct_left, ct_right)
+            }
+            (false, false) => {
+                tmp_rhs = ct_right.clone();
+
+                self.full_propagate(ct_left);
+                self.full_propagate(&mut tmp_rhs);
+
+                (ct_left, &tmp_rhs)
+            }
+        };
+
+        self.unchecked_bitand_assign(lhs, rhs);
+    }
+
+    pub fn unchecked_bitor<T>(&self, ct_left: &T, ct_right: &T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut result = ct_left.clone();
+        self.unchecked_bitor_assign(&mut result, ct_right);
+        result
+    }
+
+    pub fn unchecked_bitor_assign<T>(&self, ct_left: &mut T, ct_right: &T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut result = self.pack_blocks(ct_left, ct_right);
+
+        let shortint_key = &self.key.key.key;
+        let lut_bitor = {
+            let func = |x, y| x | y;
+            shortint_key.generate_lookup_vector_bivariate(&func)
+        };
+
+        self.apply_same_lookup_vector_packed_assign(&mut result, lut_bitor);
+
+        for (i, block) in result.into_iter().enumerate() {
+            ct_left.blocks_mut()[i] = block;
+        }
+    }
+
+    /// Computes homomorphically a bitor between two ciphertexts encrypting integer values.
+    ///
+    /// # Warning
+    ///
+    /// - Multithreaded
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // Generate the client key and the server key:
+    /// let num_blocks = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, num_blocks);
+    ///
+    /// let msg1 = 14;
+    /// let msg2 = 97;
+    ///
+    /// let mut ct1 = cks.encrypt(msg1);
+    /// let mut ct2 = cks.encrypt(msg2);
+    ///
+    /// let ct_res = sks.smart_bitor(&mut ct1, &mut ct2);
+    ///
+    /// // Decrypt:
+    /// let dec_result: u64 = cks.decrypt(&ct_res);
+    /// assert_eq!(dec_result, msg1 | msg2);
+    /// ```
+    pub fn smart_bitor<T>(&self, ct_left: &mut T, ct_right: &mut T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.full_propagate_if_degree_too_large(ct_left, ct_right);
+        self.unchecked_bitor(ct_left, ct_right)
+    }
+
+    pub fn smart_bitor_assign<T>(&self, ct_left: &mut T, ct_right: &mut T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.full_propagate_if_degree_too_large(ct_left, ct_right);
+        self.unchecked_bitor_assign(ct_left, ct_right);
+    }
+
+    /// Computes homomorphically a bitor between two ciphertexts encrypting integer values.
+    ///
+    /// This function, like all "default" operations (i.e. not smart, checked or unchecked), will
+    /// check that the input ciphertexts block carries are empty and clears them if it's not the
+    /// case and the operation requires it. It outputs a ciphertext whose block carries are always
+    /// empty.
+    ///
+    /// This means that when using only "default" operations, a given operation (like add for
+    /// example) has always the same performance characteristics from one call to another and
+    /// guarantees correctness by pre-emptively clearing carries of output ciphertexts.
+    ///
+    /// # Warning
+    ///
+    /// - Multithreaded
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // Generate the client key and the server key:
+    /// let num_blocks = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, num_blocks);
+    ///
+    /// let msg1 = 14;
+    /// let msg2 = 97;
+    ///
+    /// let ct1 = cks.encrypt(msg1);
+    /// let ct2 = cks.encrypt(msg2);
+    ///
+    /// let ct_res = sks.bitor(&ct1, &ct2);
+    ///
+    /// // Decrypt:
+    /// let dec_result: u64 = cks.decrypt(&ct_res);
+    /// assert_eq!(dec_result, msg1 | msg2);
+    /// ```
+    pub fn bitor<T>(&self, ct_left: &T, ct_right: &T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut ct_res = ct_left.clone();
+        self.bitor_assign(&mut ct_res, ct_right);
+        ct_res
+    }
+
+    pub fn bitor_assign<T>(&self, ct_left: &mut T, ct_right: &T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut tmp_rhs;
+
+        let (lhs, rhs) = match (
+            ct_left.block_carries_are_empty(),
+            ct_right.block_carries_are_empty(),
+        ) {
+            (true, true) => (ct_left, ct_right),
+            (true, false) => {
+                tmp_rhs = ct_right.clone();
+                self.full_propagate(&mut tmp_rhs);
+                (ct_left, &tmp_rhs)
+            }
+            (false, true) => {
+                self.full_propagate(ct_left);
+                (ct_left, ct_right)
+            }
+            (false, false) => {
+                tmp_rhs = ct_right.clone();
+
+                self.full_propagate(ct_left);
+                self.full_propagate(&mut tmp_rhs);
+
+                (ct_left, &tmp_rhs)
+            }
+        };
+
+        self.unchecked_bitor_assign(lhs, rhs);
+    }
+
+    pub fn unchecked_bitxor<T>(&self, ct_left: &T, ct_right: &T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut result = ct_left.clone();
+        self.unchecked_bitxor_assign(&mut result, ct_right);
+        result
+    }
+
+    pub fn unchecked_bitxor_assign<T>(&self, ct_left: &mut T, ct_right: &T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut result = self.pack_blocks(ct_left, ct_right);
+
+        let shortint_key = &self.key.key.key;
+        let lut_bitxor = {
+            let func = |x, y| x ^ y;
+            shortint_key.generate_lookup_vector_bivariate(&func)
+        };
+
+        self.apply_same_lookup_vector_packed_assign(&mut result, lut_bitxor);
+
+        for (i, block) in result.into_iter().enumerate() {
+            ct_left.blocks_mut()[i] = block;
+        }
+    }
+
+    /// Computes homomorphically a bitxor between two ciphertexts encrypting integer values.
+    ///
+    /// # Warning
+    ///
+    /// - Multithreaded
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // Generate the client key and the server key:
+    /// let num_blocks = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, num_blocks);
+    ///
+    /// let msg1 = 14;
+    /// let msg2 = 97;
+    ///
+    /// let mut ct1 = cks.encrypt(msg1);
+    /// let mut ct2 = cks.encrypt(msg2);
+    ///
+    /// let ct_res = sks.smart_bitxor(&mut ct1, &mut ct2);
+    ///
+    /// // Decrypt:
+    /// let dec_result: u64 = cks.decrypt(&ct_res);
+    /// assert_eq!(dec_result, msg1 ^ msg2);
+    /// ```
+    pub fn smart_bitxor<T>(&self, ct_left: &mut T, ct_right: &mut T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.full_propagate_if_degree_too_large(ct_left, ct_right);
+        self.unchecked_bitxor(ct_left, ct_right)
+    }
+
+    pub fn smart_bitxor_assign<T>(&self, ct_left: &mut T, ct_right: &mut T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.full_propagate_if_degree_too_large(ct_left, ct_right);
+        self.unchecked_bitxor_assign(ct_left, ct_right);
+    }
+
+    /// Computes homomorphically a bitxor between two ciphertexts encrypting integer values.
+    ///
+    /// This function, like all "default" operations (i.e. not smart, checked or unchecked), will
+    /// check that the input ciphertexts block carries are empty and clears them if it's not the
+    /// case and the operation requires it. It outputs a ciphertext whose block carries are always
+    /// empty.
+    ///
+    /// This means that when using only "default" operations, a given operation (like add for
+    /// example) has always the same performance characteristics from one call to another and
+    /// guarantees correctness by pre-emptively clearing carries of output ciphertexts.
+    ///
+    /// # Warning
+    ///
+    /// - Multithreaded
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // Generate the client key and the server key:
+    /// let num_blocks = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, num_blocks);
+    ///
+    /// let msg1 = 14;
+    /// let msg2 = 97;
+    ///
+    /// let ct1 = cks.encrypt(msg1);
+    /// let ct2 = cks.encrypt(msg2);
+    ///
+    /// let ct_res = sks.bitxor(&ct1, &ct2);
+    ///
+    /// // Decrypt:
+    /// let dec_result: u64 = cks.decrypt(&ct_res);
+    /// assert_eq!(dec_result, msg1 ^ msg2);
+    /// ```
+    pub fn bitxor<T>(&self, ct_left: &T, ct_right: &T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut ct_res = ct_left.clone();
+        self.bitxor_assign(&mut ct_res, ct_right);
+        ct_res
+    }
+
+    pub fn bitxor_assign<T>(&self, ct_left: &mut T, ct_right: &T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut tmp_rhs;
+
+        let (lhs, rhs) = match (
+            ct_left.block_carries_are_empty(),
+            ct_right.block_carries_are_empty(),
+        ) {
+            (true, true) => (ct_left, ct_right),
+            (true, false) => {
+                tmp_rhs = ct_right.clone();
+                self.full_propagate(&mut tmp_rhs);
+                (ct_left, &tmp_rhs)
+            }
+            (false, true) => {
+                self.full_propagate(ct_left);
+                (ct_left, ct_right)
+            }
+            (false, false) => {
+                tmp_rhs = ct_right.clone();
+
+                self.full_propagate(ct_left);
+                self.full_propagate(&mut tmp_rhs);
+
+                (ct_left, &tmp_rhs)
+            }
+        };
+
+        self.unchecked_bitxor_assign(lhs, rhs);
+    }
+
+    /// Computes homomorphically a bitnot on a ciphertext encrypting integer values.
+    ///
+    /// This function, like all "default" operations (i.e. not smart, checked or unchecked), will
+    /// check that the input ciphertext block carries are empty and clears them if it's not the
+    /// case and the operation requires it. It outputs a ciphertext whose block carries are always
+    /// empty.
+    ///
+    /// This means that when using only "default" operations, a given operation (like add for
+    /// example) has always the same performance characteristics from one call to another and
+    /// guarantees correctness by pre-emptively clearing carries of output ciphertexts.
+    ///
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // Generate the client key and the server key:
+    /// let num_blocks = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, num_blocks);
+    ///
+    /// let msg = 14;
+    ///
+    /// let ct = cks.encrypt(msg);
+    ///
+    /// let ct_res = sks.bitnot(&ct);
+    ///
+    /// // Decrypt:
+    /// let dec_result: u64 = cks.decrypt(&ct_res);
+    /// assert_eq!(dec_result, (!msg) % (1 << 8));
+    /// ```
+    pub fn bitnot<T>(&self, ct: &T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut ct_res = ct.clone();
+        self.bitnot_assign(&mut ct_res);
+        ct_res
+    }
+
+    pub fn bitnot_assign<T>(&self, ct: &mut T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.conditional_full_propagate(ct);
+
+        ct.blocks_mut().iter_mut().for_each(|ct_block| {
+            assert!(ct_block.message_modulus.0.is_power_of_two());
+
+            // We do (-ciphertext) + (msg_mod -1) as it allows to avoid an allocation
+            lwe_ciphertext_opposite_assign(&mut ct_block.ct);
+            self.key
+                .key
+                .key
+                .unchecked_scalar_add_assign(ct_block, ct_block.message_modulus.0 as u8 - 1);
+            ct_block.degree = Degree::new(ct_block.message_modulus.0 - 1)
+        });
+    }
+
+    fn full_propagate_if_degree_too_large<T>(&self, ct_left: &mut T, ct_right: &mut T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let integer_key = &self.key.key;
+        if integer_key
+            .is_functional_bivariate_pbs_possible(ct_left, ct_right)
+            .is_err()
+        {
+            self.full_propagate(ct_left);
+            self.full_propagate(ct_right);
+        }
+        integer_key
+            .is_functional_bivariate_pbs_possible(ct_left, ct_right)
+            .unwrap();
+    }
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/cmux.rs b/tfhe/src/integer/fpga/server_key/radix/cmux.rs
new file mode 100644
index 000000000..b7a25ca0e
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/cmux.rs
@@ -0,0 +1,306 @@
+use crate::integer::ciphertext::boolean_value::BooleanBlock;
+use crate::integer::IntegerRadixCiphertext;
+use crate::shortint::Ciphertext;
+use crate::BelfortServerKey;
+use rayon::prelude::*;
+use std::sync::Arc;
+
+impl BelfortServerKey {
+    /// FHE "if then else" selection.
+    ///
+    /// Returns a new ciphertext that encrypts the same value
+    /// as either true_ct or false_ct depending on the value of condition:
+    ///
+    /// - If condition == 1, the returned ciphertext will encrypt the same value as true_ct.
+    /// - If condition == 0, the returned ciphertext will encrypt the same value as false_ct.
+    ///
+    /// To ensure correct results, condition must encrypt either 0 or 1
+    /// (e.g result from a comparison).
+    ///
+    /// Note that while the returned ciphertext encrypts the same value as
+    /// either true_ct or false_ct, it won't exactly be true_ct or false_ct.
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let size = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, size);
+    ///
+    /// let a = 128u8;
+    /// let b = 55u8;
+    ///
+    /// let ct_a = cks.encrypt(a);
+    /// let ct_b = cks.encrypt(b);
+    ///
+    /// let condition = sks.scalar_ge_parallelized(&ct_a, 66);
+    ///
+    /// let ct_res = sks.if_then_else_parallelized(&condition, &ct_a, &ct_b);
+    ///
+    /// // Decrypt:
+    /// let dec: u8 = cks.decrypt(&ct_res);
+    /// assert_eq!(if a >= 66 { a } else { b }, dec);
+    /// assert_ne!(ct_a, ct_res);
+    /// assert_ne!(ct_b, ct_res);
+    /// ```
+    pub fn if_then_else<T>(&self, condition: &BooleanBlock, true_ct: &T, false_ct: &T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut ct_clones = [None, None];
+        let mut ct_refs = [true_ct, false_ct];
+
+        ct_refs
+            .iter_mut()
+            .zip(ct_clones.iter_mut())
+            .for_each(|(ct_ref, ct_clone)| {
+                if !ct_ref.block_carries_are_empty() {
+                    let mut cloned = ct_ref.clone();
+                    self.full_propagate(&mut cloned);
+                    *ct_ref = ct_clone.insert(cloned);
+                }
+            });
+
+        let [true_ct, false_ct] = ct_refs;
+        self.unchecked_if_then_else(condition, true_ct, false_ct)
+    }
+
+    /// Encrypted CMUX.
+    ///
+    /// It is another name for [Self::if_then_else_parallelized]
+    pub fn cmux<T>(&self, condition: &BooleanBlock, true_ct: &T, false_ct: &T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.if_then_else(condition, true_ct, false_ct)
+    }
+
+    /// FHE "if then else" selection.
+    ///
+    /// Returns a new ciphertext that encrypts the same value
+    /// as either true_ct or false_ct depending on the value of condition:
+    ///
+    /// - If condition == 1, the returned ciphertext will encrypt the same value as true_ct.
+    /// - If condition == 0, the returned ciphertext will encrypt the same value as false_ct.
+    ///
+    /// To ensure correct results, condition must encrypt either 0 or 1
+    /// (e.g result from a comparison).
+    ///
+    /// Note that while the returned ciphertext encrypts the same value as
+    /// either true_ct or false_ct, it won't exactly be true_ct or false_ct.
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let size = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, size);
+    ///
+    /// let a = 128u8;
+    /// let b = 55u8;
+    ///
+    /// let mut ct_a = cks.encrypt(a);
+    /// let mut ct_b = cks.encrypt(b);
+    ///
+    /// let mut condition = sks.scalar_ge_parallelized(&ct_a, 66);
+    ///
+    /// let ct_res = sks.smart_if_then_else_parallelized(&mut condition, &mut ct_a, &mut ct_b);
+    ///
+    /// // Decrypt:
+    /// let dec: u8 = cks.decrypt(&ct_res);
+    /// assert_eq!(if a >= 66 { a } else { b }, dec);
+    /// assert_ne!(ct_a, ct_res);
+    /// assert_ne!(ct_b, ct_res);
+    /// ```
+    pub fn smart_if_then_else<T>(
+        &self,
+        condition: &mut BooleanBlock,
+        true_ct: &mut T,
+        false_ct: &mut T,
+    ) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        if !condition.0.carry_is_empty() {
+            let lut = self.lut_message_extract();
+            self.apply_lookup_vector_single_assign(&mut condition.0, lut);
+        }
+
+        let mut ct_refs = [true_ct, false_ct];
+
+        for ct_ref in ct_refs.iter_mut() {
+            self.conditional_full_propagate(*ct_ref);
+        }
+
+        let [true_ct, false_ct] = ct_refs;
+        self.unchecked_if_then_else(condition, true_ct, false_ct)
+    }
+
+    /// Encrypted CMUX.
+    ///
+    /// It is another name for [Self::smart_if_then_else_parallelized]
+    pub fn smart_cmux<T>(
+        &self,
+        condition: &mut BooleanBlock,
+        true_ct: &mut T,
+        false_ct: &mut T,
+    ) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.smart_if_then_else(condition, true_ct, false_ct)
+    }
+
+    pub fn unchecked_if_then_else<T>(
+        &self,
+        condition: &BooleanBlock,
+        true_ct: &T,
+        false_ct: &T,
+    ) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let condition_block = &condition.0;
+        let do_clean_message = true;
+        self.unchecked_programmable_if_then_else(
+            condition_block,
+            true_ct,
+            false_ct,
+            |x| x == 1,
+            do_clean_message,
+        )
+    }
+
+    pub fn unchecked_cmux<T>(&self, condition: &BooleanBlock, true_ct: &T, false_ct: &T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.unchecked_if_then_else(condition, true_ct, false_ct)
+    }
+
+    /// if do clean message is false, the resulting ciphertext won't be cleaned (message_extract)
+    /// meaning that yes, the resulting ciphertext's encrypted message is within 0..msg_msg
+    /// but its degree is the same as after adding to ciphertext
+    ///
+    /// TLDR: do_clean_message should be false only if you plan on doing your own PBS
+    /// soon after. (may need to force degree yourself not to trigger asserts)
+    // Note: do_clean_message is needed until degree is used for both
+    // message range and noise management.
+    pub(crate) fn unchecked_programmable_if_then_else<T, F>(
+        &self,
+        condition_block: &Ciphertext,
+        true_ct: &T,
+        false_ct: &T,
+        predicate_function: F,
+        do_clean_message: bool,
+    ) -> T
+    where
+        T: IntegerRadixCiphertext,
+        F: Fn(u64) -> bool + Send + Sync + Copy,
+    {
+        let mut true_ct = true_ct.clone();
+        let mut false_ct = false_ct.clone();
+        self.zero_out_if(
+            &mut true_ct,
+            &mut false_ct,
+            predicate_function,
+            condition_block,
+        );
+
+        let shortint_key = Arc::new(&self.key.key.key);
+        true_ct
+            .blocks_mut()
+            .par_iter_mut()
+            .zip(false_ct.blocks().par_iter())
+            .for_each(|(lhs_block, rhs_block)| {
+                shortint_key.unchecked_add_assign(lhs_block, rhs_block);
+            });
+
+        if do_clean_message {
+            let lut_message_extract = self.lut_message_extract();
+            let mut blocks = true_ct.blocks_mut().to_vec();
+            self.apply_same_lookup_vector_packed_assign(&mut blocks, lut_message_extract);
+
+            true_ct
+                .blocks_mut()
+                .par_iter_mut()
+                .zip(blocks.par_iter())
+                .for_each(|(block, vec_block)| {
+                    block.clone_from(vec_block);
+                });
+        }
+        true_ct
+    }
+
+    /// This function takes a ciphertext encrypting any integer value
+    /// and block encrypting a boolean value (0 or 1).
+    ///
+    /// The input integer ciphertext will have all its block zeroed if condition_block
+    /// encrypts 0, otherwise each block keeps its value.
+    pub(crate) fn zero_out_if<T, F>(
+        &self,
+        ct1: &mut T,
+        ct2: &mut T,
+        predicate_function: F,
+        condition_block: &Ciphertext,
+    ) where
+        T: IntegerRadixCiphertext,
+        F: Fn(u64) -> bool,
+    {
+        let shortint_key = &self.key.key.key;
+
+        let integer_key = &self.key.key;
+        assert!(condition_block.degree.get() < condition_block.message_modulus.0);
+
+        let inverted_predicate_function = |x| !predicate_function(x);
+
+        if condition_block.degree.get() == 0 {
+            if predicate_function(0u64) {
+                integer_key.create_trivial_zero_assign_radix(ct2);
+            }
+
+            if inverted_predicate_function(0u64) {
+                integer_key.create_trivial_zero_assign_radix(ct1);
+            }
+
+            return;
+        }
+        let num_blocks = ct1.blocks().len();
+
+        let predicate_lut = {
+            let func = |x, y| if y == 1 { 0 } else { x };
+            shortint_key.generate_lookup_vector_bivariate(&func)
+        };
+
+        let inverted_predicate_lut = {
+            let func = |x, y| if y == 1 { x } else { 0 };
+            shortint_key.generate_lookup_vector_bivariate(&func)
+        };
+
+        let mut luts = vec![inverted_predicate_lut; num_blocks];
+        luts.extend(vec![predicate_lut; num_blocks]);
+
+        let condition_vec = vec![condition_block.clone(); num_blocks];
+        let mut prepared_blocks = vec![];
+
+        let ct1_blocks = ct1.blocks_mut();
+        let ct2_blocks = ct2.blocks_mut();
+
+        prepared_blocks.extend(self.prepare_bivariate(&mut ct1_blocks.to_vec(), &condition_vec));
+        prepared_blocks.extend(self.prepare_bivariate(&mut ct2_blocks.to_vec(), &condition_vec));
+
+        self.apply_lookup_vector_packed_assign(&mut prepared_blocks, &luts);
+
+        let half_len = prepared_blocks.len() / 2;
+
+        for (i, block) in prepared_blocks.iter().take(half_len).enumerate() {
+            ct1_blocks[i].clone_from(block);
+        }
+
+        for (i, block) in prepared_blocks.iter().skip(half_len).enumerate() {
+            ct2_blocks[i].clone_from(block);
+        }
+    }
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/comparison.rs b/tfhe/src/integer/fpga/server_key/radix/comparison.rs
new file mode 100644
index 000000000..29ae8cdd7
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/comparison.rs
@@ -0,0 +1,261 @@
+use crate::integer::ciphertext::boolean_value::BooleanBlock;
+use crate::integer::ciphertext::IntegerRadixCiphertext;
+use crate::integer::fpga::server_key::comparator::Comparator;
+use crate::integer::fpga::server_key::BelfortServerKey;
+use crate::shortint::Ciphertext;
+
+impl BelfortServerKey {
+    pub fn unchecked_eq<T>(&self, lhs: &T, rhs: &T) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        assert_eq!(lhs.blocks().len(), rhs.blocks().len());
+
+        let mut result = self.pack_blocks(lhs, rhs);
+
+        let shortint_key = &self.key.key.key;
+
+        let lut_equal_to = {
+            let func = |x, y| u64::from(x == y);
+            shortint_key.generate_lookup_vector_bivariate(&func)
+        };
+
+        self.apply_same_lookup_vector_packed_assign(&mut result, lut_equal_to);
+
+        let is_equal_result: Ciphertext = self.are_all_comparisons_block_true(result);
+
+        BooleanBlock::new_unchecked(is_equal_result)
+    }
+
+    pub fn unchecked_ne<T>(&self, lhs: &T, rhs: &T) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        assert_eq!(lhs.blocks().len(), rhs.blocks().len());
+
+        let mut result = self.pack_blocks(lhs, rhs);
+
+        let shortint_key = &self.key.key.key;
+
+        let lut_not_equal_to = {
+            let func = |x, y| u64::from(x != y);
+            shortint_key.generate_lookup_vector_bivariate(&func)
+        };
+
+        self.apply_same_lookup_vector_packed_assign(&mut result, lut_not_equal_to);
+
+        let is_not_equal_result: Ciphertext = self.is_at_least_one_comparisons_block_true(result);
+
+        BooleanBlock::new_unchecked(is_not_equal_result)
+    }
+
+    pub fn unchecked_gt<T>(&self, lhs: &T, rhs: &T) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        Comparator::new(self).unchecked_gt(lhs, rhs)
+    }
+
+    pub fn unchecked_ge<T>(&self, lhs: &T, rhs: &T) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        Comparator::new(self).unchecked_ge(lhs, rhs)
+    }
+
+    pub fn unchecked_lt<T>(&self, lhs: &T, rhs: &T) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        Comparator::new(self).unchecked_lt(lhs, rhs)
+    }
+
+    pub fn unchecked_le<T>(&self, lhs: &T, rhs: &T) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        Comparator::new(self).unchecked_le(lhs, rhs)
+    }
+
+    pub fn unchecked_max<T>(&self, lhs: &T, rhs: &T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        Comparator::new(self).unchecked_max(lhs, rhs)
+    }
+
+    pub fn unchecked_min<T>(&self, lhs: &T, rhs: &T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        Comparator::new(self).unchecked_min(lhs, rhs)
+    }
+
+    pub fn smart_eq<T>(&self, lhs: &mut T, rhs: &mut T) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.conditional_full_propagate_bivariate(lhs, rhs);
+
+        self.unchecked_eq(lhs, rhs)
+    }
+
+    pub fn smart_ne<T>(&self, lhs: &mut T, rhs: &mut T) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.conditional_full_propagate_bivariate(lhs, rhs);
+
+        self.unchecked_ne(lhs, rhs)
+    }
+
+    pub fn smart_gt<T>(&self, lhs: &mut T, rhs: &mut T) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        Comparator::new(self).smart_gt(lhs, rhs)
+    }
+
+    pub fn smart_ge<T>(&self, lhs: &mut T, rhs: &mut T) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        Comparator::new(self).smart_ge(lhs, rhs)
+    }
+
+    pub fn smart_lt<T>(&self, lhs: &mut T, rhs: &mut T) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        Comparator::new(self).smart_lt(lhs, rhs)
+    }
+
+    pub fn smart_le<T>(&self, lhs: &mut T, rhs: &mut T) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        Comparator::new(self).smart_le(lhs, rhs)
+    }
+
+    pub fn smart_max<T>(&self, lhs: &mut T, rhs: &mut T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        Comparator::new(self).smart_max(lhs, rhs)
+    }
+
+    pub fn smart_min<T>(&self, lhs: &mut T, rhs: &mut T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        Comparator::new(self).smart_min(lhs, rhs)
+    }
+
+    pub fn eq<T>(&self, lhs: &T, rhs: &T) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut tmp_lhs;
+        let mut tmp_rhs;
+
+        let (lhs, rhs) = match (lhs.block_carries_are_empty(), rhs.block_carries_are_empty()) {
+            (true, true) => (lhs, rhs),
+            (true, false) => {
+                tmp_rhs = rhs.clone();
+                self.full_propagate(&mut tmp_rhs);
+                (lhs, &tmp_rhs)
+            }
+            (false, true) => {
+                tmp_lhs = lhs.clone();
+                self.full_propagate(&mut tmp_lhs);
+                (&tmp_lhs, rhs)
+            }
+            (false, false) => {
+                tmp_lhs = lhs.clone();
+                tmp_rhs = rhs.clone();
+
+                self.full_propagate(&mut tmp_lhs);
+                self.full_propagate(&mut tmp_rhs);
+
+                (&tmp_lhs, &tmp_rhs)
+            }
+        };
+
+        self.unchecked_eq(lhs, rhs)
+    }
+
+    pub fn ne<T>(&self, lhs: &T, rhs: &T) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut tmp_lhs;
+        let mut tmp_rhs;
+
+        let (lhs, rhs) = match (lhs.block_carries_are_empty(), rhs.block_carries_are_empty()) {
+            (true, true) => (lhs, rhs),
+            (true, false) => {
+                tmp_rhs = rhs.clone();
+                self.full_propagate(&mut tmp_rhs);
+                (lhs, &tmp_rhs)
+            }
+            (false, true) => {
+                tmp_lhs = lhs.clone();
+                self.full_propagate(&mut tmp_lhs);
+                (&tmp_lhs, rhs)
+            }
+            (false, false) => {
+                tmp_lhs = lhs.clone();
+                tmp_rhs = rhs.clone();
+
+                self.full_propagate(&mut tmp_lhs);
+                self.full_propagate(&mut tmp_rhs);
+
+                (&tmp_lhs, &tmp_rhs)
+            }
+        };
+
+        self.unchecked_ne(lhs, rhs)
+    }
+
+    pub fn gt<T>(&self, lhs: &T, rhs: &T) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        Comparator::new(self).gt(lhs, rhs)
+    }
+
+    pub fn ge<T>(&self, lhs: &T, rhs: &T) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        Comparator::new(self).ge(lhs, rhs)
+    }
+
+    pub fn lt<T>(&self, lhs: &T, rhs: &T) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        Comparator::new(self).lt(lhs, rhs)
+    }
+
+    pub fn le<T>(&self, lhs: &T, rhs: &T) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        Comparator::new(self).le(lhs, rhs)
+    }
+
+    pub fn max<T>(&self, lhs: &T, rhs: &T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        Comparator::new(self).max(lhs, rhs)
+    }
+
+    pub fn min<T>(&self, lhs: &T, rhs: &T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        Comparator::new(self).min(lhs, rhs)
+    }
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/count_zeros_ones.rs b/tfhe/src/integer/fpga/server_key/radix/count_zeros_ones.rs
new file mode 100644
index 000000000..b3ca9dcd4
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/count_zeros_ones.rs
@@ -0,0 +1,88 @@
+use crate::integer::fpga::server_key::BelfortServerKey;
+use crate::integer::server_key::radix_parallel::count_zeros_ones::BitCountKind;
+use crate::integer::{IntegerRadixCiphertext, RadixCiphertext};
+use log::warn;
+
+impl BelfortServerKey {
+    /// Returns the number of ones in the binary representation of `ct`
+    ///
+    /// * ct must not have any carries
+    /// * The returned result has enough blocks to encrypt 32bits (e.g. 1_1 parameters -> 32 blocks,
+    ///   3_3 parameters -> 11 blocks == 33 bits)
+    pub fn unchecked_count_ones<T>(&self, ct: &T) -> RadixCiphertext
+    where
+        T: IntegerRadixCiphertext,
+    {
+        warn!("Non-optimized function call. Contact Belfort if you experience a slow run.");
+        self.key
+            .key
+            .unchecked_count_bits_parallelized(ct, BitCountKind::One)
+    }
+
+    /// Returns the number of zeros in the binary representation of `ct`
+    ///
+    /// * ct must not have any carries
+    /// * The returned result has enough blocks to encrypt 32bits (e.g. 1_1 parameters -> 32 blocks,
+    ///   3_3 parameters -> 11 blocks == 33 bits)
+    pub fn unchecked_count_zeros<T>(&self, ct: &T) -> RadixCiphertext
+    where
+        T: IntegerRadixCiphertext,
+    {
+        warn!("Non-optimized function call. Contact Belfort if you experience a slow run.");
+        self.key
+            .key
+            .unchecked_count_bits_parallelized(ct, BitCountKind::Zero)
+    }
+
+    /// Returns the number of ones in the binary representation of `ct`
+    ///
+    /// * The returned result has enough blocks to encrypt 32bits (e.g. 1_1 parameters -> 32 blocks,
+    ///   3_3 parameters -> 11 blocks == 33 bits)
+    pub fn smart_count_ones<T>(&self, ct: &mut T) -> RadixCiphertext
+    where
+        T: IntegerRadixCiphertext,
+    {
+        warn!("Non-optimized function call. Contact Belfort if you experience a slow run.");
+        self.key
+            .key
+            .smart_count_bits_parallelized(ct, BitCountKind::One)
+    }
+
+    /// Returns the number of zeros in the binary representation of `ct`
+    ///
+    /// * The returned result has enough blocks to encrypt 32bits (e.g. 1_1 parameters -> 32 blocks,
+    ///   3_3 parameters -> 11 blocks == 33 bits)
+    pub fn smart_count_zeros<T>(&self, ct: &mut T) -> RadixCiphertext
+    where
+        T: IntegerRadixCiphertext,
+    {
+        warn!("Non-optimized function call. Contact Belfort if you experience a slow run.");
+        self.key
+            .key
+            .smart_count_bits_parallelized(ct, BitCountKind::Zero)
+    }
+
+    /// Returns the number of ones in the binary representation of `ct`
+    ///
+    /// * The returned result has enough blocks to encrypt 32bits (e.g. 1_1 parameters -> 32 blocks,
+    ///   3_3 parameters -> 11 blocks == 33 bits)
+    pub fn count_ones<T>(&self, ct: &T) -> RadixCiphertext
+    where
+        T: IntegerRadixCiphertext,
+    {
+        warn!("Non-optimized function call. Contact Belfort if you experience a slow run.");
+        self.key.key.count_bits_parallelized(ct, BitCountKind::One)
+    }
+
+    /// Returns the number of zeros in the binary representation of `ct`
+    ///
+    /// * The returned result has enough blocks to encrypt 32bits (e.g. 1_1 parameters -> 32 blocks,
+    ///   3_3 parameters -> 11 blocks == 33 bits)
+    pub fn count_zeros<T>(&self, ct: &T) -> RadixCiphertext
+    where
+        T: IntegerRadixCiphertext,
+    {
+        warn!("Non-optimized function call. Contact Belfort if you experience a slow run.");
+        self.key.key.count_bits_parallelized(ct, BitCountKind::Zero)
+    }
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/div_mod.rs b/tfhe/src/integer/fpga/server_key/radix/div_mod.rs
new file mode 100644
index 000000000..ca5a352a5
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/div_mod.rs
@@ -0,0 +1,715 @@
+use crate::core_crypto::fpga::lookup_vector::LookupVector;
+use crate::integer::ciphertext::{IntegerRadixCiphertext, RadixCiphertext};
+use crate::integer::server_key::comparator::ZeroComparisonType;
+use crate::integer::IntegerCiphertext;
+use crate::shortint::{Ciphertext, MessageModulus};
+use crate::BelfortServerKey;
+
+impl BelfortServerKey {
+    //======================================================================
+    //                Div Rem
+    //======================================================================
+    pub fn unchecked_div_rem<T>(&self, numerator: &T, divisor: &T) -> (T, T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let n = RadixCiphertext::from_blocks(numerator.blocks().to_vec());
+        let d = RadixCiphertext::from_blocks(divisor.blocks().to_vec());
+        let (q, r) = self.unsigned_unchecked_div_rem(&n, &d);
+        let q = T::from_blocks(q.into_blocks());
+        let r = T::from_blocks(r.into_blocks());
+        (q, r)
+    }
+
+    fn unsigned_unchecked_div_rem(
+        &self,
+        numerator: &RadixCiphertext,
+        divisor: &RadixCiphertext,
+    ) -> (RadixCiphertext, RadixCiphertext) {
+        // Pseudocode of the school-book / long-division algorithm:
+        //
+        //
+        // div(N/D):
+        // Q := 0                  -- Initialize quotient and remainder to zero
+        // R := 0
+        // for i := n âˆ’ 1 .. 0 do  -- Where n is number of bits in N
+        //   R := R << 1           -- Left-shift R by 1 bit
+        //   R(0) := N(i)          -- Set the least-significant bit of R equal to bit i of the
+        //                         -- numerator
+        //   if R â‰¥ D then
+        //     R := R âˆ’ D
+        //     Q(i) := 1
+        //   end
+        // end
+        let integer_key = &self.key.key;
+        let shortint_key = &integer_key.key;
+        let message_modulus = integer_key.message_modulus();
+        let carry_modulus = integer_key.carry_modulus();
+
+        let lut_message_extract = {
+            let func = |x| (x % shortint_key.message_modulus.0);
+            shortint_key.generate_lookup_vector(&func)
+        };
+
+        assert_eq!(
+            numerator.blocks.len(),
+            divisor.blocks.len(),
+            "numerator and divisor must have same number of blocks \
+            numerator: {} blocks, divisor: {} blocks",
+            numerator.blocks.len(),
+            divisor.blocks.len(),
+        );
+        assert!(
+            message_modulus.0.is_power_of_two(),
+            "The message modulus ({}) needs to be a power of two",
+            message_modulus.0
+        );
+        assert!(
+            numerator.block_carries_are_empty(),
+            "The numerator must have its carries empty"
+        );
+        assert!(
+            divisor.block_carries_are_empty(),
+            "The numerator must have its carries empty"
+        );
+
+        assert!(numerator
+            .blocks()
+            .iter()
+            .all(|block| block.message_modulus == message_modulus
+                && block.carry_modulus == carry_modulus));
+        assert!(divisor
+            .blocks()
+            .iter()
+            .all(|block| block.message_modulus == message_modulus
+                && block.carry_modulus == carry_modulus));
+
+        let num_blocks = numerator.blocks.len();
+        let num_bits_in_message = message_modulus.0.ilog2() as u64;
+        let total_bits = num_bits_in_message * num_blocks as u64;
+
+        let mut quotient: RadixCiphertext = integer_key.create_trivial_zero_radix(num_blocks);
+        let mut remainder1: RadixCiphertext = integer_key.create_trivial_zero_radix(num_blocks);
+        let mut remainder2: RadixCiphertext = integer_key.create_trivial_zero_radix(num_blocks);
+
+        let mut numerator_block_stack = numerator.blocks.clone();
+
+        let merge_overflow_flags_lut = self.generate_overflow_luts();
+
+        for i in (0..total_bits).rev() {
+            let block_of_bit = (i / num_bits_in_message) as usize;
+            let pos_in_block = (i % num_bits_in_message) as usize;
+
+            // msb_bit_set goes from [0 to total_bits - 1]
+            let msb_bit_set = (total_bits - 1 - i) as usize;
+
+            let last_non_trivial_block = msb_bit_set / (num_bits_in_message as usize);
+            // Index to the first block of the remainder that is fully trivial 0
+            // and all blocks after it are also trivial zeros
+            // This number is in range 1..=num_blocks - 1
+            let first_trivial_block = last_non_trivial_block + 1;
+
+            // All blocks starting from the first_trivial_block are known to be trivial
+            // So we can avoid work.
+            // Note that, these are always non-empty (i.e. there is always at least one non trivial
+            // block)
+            let mut interesting_remainder1 =
+                RadixCiphertext::from(remainder1.blocks[..=last_non_trivial_block].to_vec());
+            let mut interesting_remainder2 =
+                RadixCiphertext::from(remainder2.blocks[..=last_non_trivial_block].to_vec());
+            let mut interesting_divisor =
+                RadixCiphertext::from(divisor.blocks[..=last_non_trivial_block].to_vec());
+            let mut divisor_ms_blocks = RadixCiphertext::from(
+                divisor.blocks[((msb_bit_set + 1) / num_bits_in_message as usize)..].to_vec(),
+            );
+
+            let mut blocks = Vec::new();
+            let mut luts = Vec::new();
+
+            // We split the divisor at a block position, when in reality the split should be at a
+            // bit position meaning that potentially (depending on msb_bit_set) the
+            // split versions share some bits they should not. So we do one PBS on the
+            // last block of the interesting_divisor, and first block of divisor_ms_blocks
+            // to trim out bits which should not be there
+
+            if ((msb_bit_set + 1) % num_bits_in_message as usize) != 0 {
+                // The last block of the interesting part of the remainder
+                // can contain bits which we should not account for
+                // we have to zero them out
+                blocks.push(interesting_divisor.blocks.last_mut().unwrap());
+                let lut_scalar_bitand_one = {
+                    let func = |x| x & 1;
+                    shortint_key.generate_lookup_vector(&func)
+                };
+                luts.push(lut_scalar_bitand_one);
+            }
+
+            if !divisor_ms_blocks.blocks.is_empty()
+                && ((msb_bit_set + 1) % num_bits_in_message as usize) != 0
+            {
+                // As above, we need to zero out some bits, but here it's in the
+                // first block of most significant blocks of the divisor.
+                // The block has the same value as the last block of interesting_divisor.
+                // Here we will zero out the bits that the trim_last_interesting_divisor_bits
+                // above wanted to keep.
+                blocks.push(divisor_ms_blocks.blocks.first_mut().unwrap());
+                let lut_scalar_bitand_two = {
+                    let func = |x| x & 2;
+                    shortint_key.generate_lookup_vector(&func)
+                };
+                luts.push(lut_scalar_bitand_two);
+            }
+
+            self.apply_lookup_vector_mut_packed_assign(&mut blocks, &luts);
+
+            // This does
+            //  R := R << 1; R(0) := N(i)
+            //
+            // We could do that by left shifting R by one, then unchecked_add the correct numerator
+            // bit.
+            //
+            // However, to keep the remainder clean (noise wise), what we do is that we put the
+            // remainder block from which we need to extract the bit, as the LSB of the
+            // Remainder, so that left shifting will pull the bit we need.
+            let numerator_block = numerator_block_stack
+                .pop()
+                .expect("internal error: empty numerator block stack in div");
+            // prepend block and then shift
+            interesting_remainder1.blocks.insert(0, numerator_block);
+            self.unchecked_scalar_left_shift_assign(&mut interesting_remainder1, 1);
+
+            // Extract the block we inserted earlier, and see if it should be dropped
+            // or added back for processing
+            let numerator_block = interesting_remainder1.blocks.remove(0);
+            if pos_in_block != 0 {
+                // We have not yet extracted all the bits from this numerator
+                // so, we put it back on the front so that it gets taken next iteration
+                numerator_block_stack.push(numerator_block);
+            }
+
+            self.unchecked_scalar_left_shift_assign(&mut interesting_remainder2, 1);
+
+            // if interesting_remainder1 != 0 -> interesting_remainder2 == 0
+            // if interesting_remainder1 == 0 -> interesting_remainder2 != 0
+            // In practice interesting_remainder1 contains the numerator bit,
+            // but in that position, interesting_remainder2 always has a 0
+            let mut merged_interesting_remainder = interesting_remainder1;
+
+            self.unchecked_add_assign(&mut merged_interesting_remainder, &interesting_remainder2);
+
+            let (mut new_remainder, subtraction_overflowed) = self
+                .unchecked_unsigned_overflowing_sub(
+                    &merged_interesting_remainder,
+                    &interesting_divisor,
+                );
+
+            // Returns 1 if all divisor upper blocks = 0
+            let at_least_one_upper_block_is_non_zero = {
+                // Do a comparison (==) with 0 for trivial blocks
+                let trivial_blocks = &divisor_ms_blocks.blocks;
+                if trivial_blocks.is_empty() {
+                    shortint_key.create_trivial(0)
+                } else {
+                    // We could call unchecked_scalar_ne_parallelized
+                    // But we are in the special case where scalar == 0
+                    // So we can skip some stuff
+                    let tmp = self
+                        .compare_blocks_with_zero(trivial_blocks, ZeroComparisonType::Difference);
+                    self.is_at_least_one_comparisons_block_true(tmp)
+                }
+            };
+
+            // Creates a cleaned version (noise wise) of the merged remainder
+            // so that it can be safely used in bivariate PBSes
+            self.apply_same_lookup_vector_packed_assign(
+                &mut merged_interesting_remainder.blocks,
+                lut_message_extract,
+            );
+
+            let overflow_sum = integer_key.key.unchecked_add(
+                subtraction_overflowed.as_ref(),
+                &at_least_one_upper_block_is_non_zero,
+            );
+
+            // Here, we will do what zero_out_if does, but to stay within noise constraints,
+            // we do it by hand so that we apply the factor (shift) to the correct block
+            //conditionally_zero_out_merged_interesting_remainder
+            assert!(overflow_sum.degree.get() <= 2); // at_least_one_upper_block_is_non_zero maybe be a trivial 0
+            let factor = MessageModulus(overflow_sum.degree.get() + 1);
+
+            merged_interesting_remainder
+                .blocks_mut()
+                .iter_mut()
+                .for_each(|block| {
+                    shortint_key.unchecked_scalar_mul_assign(block, factor.0 as u8);
+                    shortint_key.unchecked_add_assign(block, &overflow_sum);
+                });
+
+            new_remainder.blocks_mut().iter_mut().for_each(|block| {
+                shortint_key.unchecked_scalar_mul_assign(block, factor.0 as u8);
+                shortint_key.unchecked_add_assign(block, &overflow_sum);
+            });
+
+            let mut did_not_overflow_flag = at_least_one_upper_block_is_non_zero.clone();
+            integer_key
+                .pack_block_assign(subtraction_overflowed.as_ref(), &mut did_not_overflow_flag);
+
+            let cutoff = merged_interesting_remainder.blocks.len();
+
+            let zero_out_if_overflow_did_not_happen_lut = {
+                const fn overflow_happened(overflow_sum: u64) -> bool {
+                    overflow_sum != 0
+                }
+                let func = |block: u64, overflow_sum| {
+                    if overflow_happened(overflow_sum) {
+                        block
+                    } else {
+                        0
+                    }
+                };
+                self.gen_lut_for_overflows(factor, func)
+            };
+            let zero_out_if_overflow_happened_lut = {
+                const fn overflow_happened(overflow_sum: u64) -> bool {
+                    overflow_sum != 0
+                }
+                let func = |block: u64, overflow_sum| {
+                    if overflow_happened(overflow_sum) {
+                        0
+                    } else {
+                        block
+                    }
+                };
+                self.gen_lut_for_overflows(factor, func)
+            };
+
+            let cleaned_merged_interesting_remainder_luts = merged_interesting_remainder
+                .blocks
+                .iter()
+                .map(|_| zero_out_if_overflow_did_not_happen_lut);
+
+            let new_remainder_luts = new_remainder
+                .blocks
+                .iter()
+                .map(|_| zero_out_if_overflow_happened_lut);
+
+            // Combine both vectors into a single vector
+            let mut combined_luts: Vec<_> = cleaned_merged_interesting_remainder_luts
+                .chain(new_remainder_luts)
+                .collect();
+
+            combined_luts.push(merge_overflow_flags_lut[pos_in_block]);
+
+            // Combine both vectors into a single vector
+            let mut combined_cts: Vec<_> = merged_interesting_remainder
+                .blocks
+                .into_iter()
+                .chain(new_remainder.blocks.into_iter())
+                .collect();
+
+            combined_cts.push(did_not_overflow_flag);
+
+            self.apply_lookup_vector_packed_assign(&mut combined_cts, &combined_luts);
+
+            let (cleaned_merged_interesting_remainder, new_remainder, did_not_overflow_flag) = {
+                (
+                    RadixCiphertext::from(combined_cts[0..cutoff].to_vec()),
+                    RadixCiphertext::from(combined_cts[cutoff..combined_cts.len() - 1].to_vec()),
+                    combined_cts.last().unwrap(),
+                )
+            };
+
+            shortint_key
+                .unchecked_add_assign(&mut quotient.blocks[block_of_bit], did_not_overflow_flag);
+
+            assert_eq!(
+                remainder1.blocks[..first_trivial_block].len(),
+                cleaned_merged_interesting_remainder.blocks.len()
+            );
+            assert_eq!(
+                remainder2.blocks[..first_trivial_block].len(),
+                new_remainder.blocks.len()
+            );
+
+            remainder1.blocks[..first_trivial_block]
+                .iter_mut()
+                .zip(cleaned_merged_interesting_remainder.blocks.iter())
+                .for_each(|(remainder_block, new_value)| {
+                    remainder_block.clone_from(new_value);
+                });
+            remainder2.blocks[..first_trivial_block]
+                .iter_mut()
+                .zip(new_remainder.blocks.iter())
+                .for_each(|(remainder_block, new_value)| {
+                    remainder_block.clone_from(new_value);
+                });
+        }
+
+        // Clean the quotient and remainder
+        // as even though they have no carries, they are not at nominal noise level
+        remainder1
+            .blocks_mut()
+            .iter_mut()
+            .zip(remainder2.blocks.iter())
+            .for_each(|(r1_block, r2_block)| {
+                shortint_key.unchecked_add_assign(r1_block, r2_block);
+            });
+
+        let mut remainder_and_quotient: Vec<Ciphertext> = remainder1
+            .blocks
+            .iter()
+            .chain(quotient.blocks.iter())
+            .cloned()
+            .collect();
+
+        self.apply_same_lookup_vector_packed_assign(
+            &mut remainder_and_quotient,
+            lut_message_extract,
+        );
+        let (remainder1_arr, quotient_arr) =
+            remainder_and_quotient.split_at(remainder1.blocks.len());
+
+        remainder1 = RadixCiphertext::from(remainder1_arr.to_vec());
+
+        quotient = RadixCiphertext::from(quotient_arr.to_vec());
+
+        (quotient, remainder1)
+    }
+
+    fn gen_lut_for_overflows(
+        &self,
+        factor: MessageModulus,
+        func: impl Fn(u64, u64) -> u64,
+    ) -> LookupVector {
+        let integer_key = &self.key.key;
+        let shortint_key = &integer_key.key;
+        let message_modulus = factor.0;
+        match message_modulus {
+            1..4 => {
+                shortint_key.generate_lookup_vector_bivariate_with_factor(&func, message_modulus)
+            }
+            _ => panic!("Unexpected factor value: {factor:?}"),
+        }
+    }
+
+    /// Computes homomorphically the quotient and remainder of the division between two ciphertexts
+    ///
+    /// # Notes
+    ///
+    /// When the divisor is 0:
+    ///
+    /// - For unsigned operands, the returned quotient will be the max value (i.e. all bits set to
+    ///   1) the remainder will have the value of the numerator.
+    ///
+    /// - For signed operands, remainder will have the same value as the numerator, and, if the
+    ///   numerator is < 0, quotient will be -1 else 1
+    ///
+    /// This behaviour should not be relied on.
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2;
+    ///
+    /// // Generate the client key and the server key:
+    /// let num_blocks = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2, num_blocks);
+    ///
+    /// let msg1 = 97;
+    /// let msg2 = 14;
+    ///
+    /// let ct1 = cks.encrypt(msg1);
+    /// let ct2 = cks.encrypt(msg2);
+    ///
+    /// // Compute homomorphically the quotient and remainder:
+    /// let (q_res, r_res) = sks.div_rem(&ct1, &ct2);
+    ///
+    /// // Decrypt:
+    /// let q: u64 = cks.decrypt(&q_res);
+    /// let r: u64 = cks.decrypt(&r_res);
+    /// assert_eq!(q, msg1 / msg2);
+    /// assert_eq!(r, msg1 % msg2);
+    /// ```
+    pub fn div_rem<T>(&self, numerator: &T, divisor: &T) -> (T, T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut tmp_numerator;
+        let mut tmp_divisor;
+
+        let (numerator, divisor) = match (
+            numerator.block_carries_are_empty(),
+            divisor.block_carries_are_empty(),
+        ) {
+            (true, true) => (numerator, divisor),
+            (true, false) => {
+                tmp_divisor = divisor.clone();
+                self.full_propagate(&mut tmp_divisor);
+                (numerator, &tmp_divisor)
+            }
+            (false, true) => {
+                tmp_numerator = numerator.clone();
+                self.full_propagate(&mut tmp_numerator);
+                (&tmp_numerator, divisor)
+            }
+            (false, false) => {
+                tmp_divisor = divisor.clone();
+                tmp_numerator = numerator.clone();
+                self.full_propagate(&mut tmp_numerator);
+                self.full_propagate(&mut tmp_divisor);
+                (&tmp_numerator, &tmp_divisor)
+            }
+        };
+
+        self.unchecked_div_rem(numerator, divisor)
+    }
+
+    pub fn smart_div_rem<T>(&self, numerator: &mut T, divisor: &mut T) -> (T, T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.conditional_full_propagate_bivariate(numerator, divisor);
+        self.unchecked_div_rem(numerator, divisor)
+    }
+
+    //======================================================================
+    //                Div
+    //======================================================================
+
+    pub fn unchecked_div_assign<T>(&self, numerator: &mut T, divisor: &T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let (q, _r) = self.unchecked_div_rem(numerator, divisor);
+        *numerator = q;
+    }
+
+    pub fn unchecked_div<T>(&self, numerator: &T, divisor: &T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let (q, _r) = self.unchecked_div_rem(numerator, divisor);
+        q
+    }
+
+    pub fn smart_div_assign<T>(&self, numerator: &mut T, divisor: &mut T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let (q, _r) = self.smart_div_rem(numerator, divisor);
+        *numerator = q;
+    }
+
+    pub fn smart_div<T>(&self, numerator: &mut T, divisor: &mut T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let (q, _r) = self.smart_div_rem(numerator, divisor);
+        q
+    }
+
+    pub fn div_assign<T>(&self, numerator: &mut T, divisor: &T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut tmp_divisor;
+
+        let (numerator, divisor) = match (
+            numerator.block_carries_are_empty(),
+            divisor.block_carries_are_empty(),
+        ) {
+            (true, true) => (numerator, divisor),
+            (true, false) => {
+                tmp_divisor = divisor.clone();
+                self.full_propagate(&mut tmp_divisor);
+                (numerator, &tmp_divisor)
+            }
+            (false, true) => {
+                self.full_propagate(numerator);
+                (numerator, divisor)
+            }
+            (false, false) => {
+                tmp_divisor = divisor.clone();
+
+                self.full_propagate(numerator);
+                self.full_propagate(&mut tmp_divisor);
+                (numerator, &tmp_divisor)
+            }
+        };
+
+        let (q, _r) = self.unchecked_div_rem(numerator, divisor);
+        *numerator = q;
+    }
+
+    /// Computes homomorphically the quotient of the division between two ciphertexts
+    ///
+    /// # Note
+    ///
+    /// If you need both the quotient and remainder use [Self::div_rem].
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2;
+    ///
+    /// // Generate the client key and the server key:
+    /// let num_blocks = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2, num_blocks);
+    ///
+    /// let msg1 = 97;
+    /// let msg2 = 14;
+    ///
+    /// let ct1 = cks.encrypt(msg1);
+    /// let ct2 = cks.encrypt(msg2);
+    ///
+    /// // Compute homomorphically a division:
+    /// let ct_res = sks.div(&ct1, &ct2);
+    ///
+    /// // Decrypt:
+    /// let dec_result: u64 = cks.decrypt(&ct_res);
+    /// assert_eq!(dec_result, msg1 / msg2);
+    /// ```
+    pub fn div<T>(&self, numerator: &T, divisor: &T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let (q, _r) = self.div_rem(numerator, divisor);
+        q
+    }
+
+    //======================================================================
+    //                Rem
+    //======================================================================
+
+    pub fn unchecked_rem_assign<T>(&self, numerator: &mut T, divisor: &T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let (_q, r) = self.unchecked_div_rem(numerator, divisor);
+        *numerator = r;
+    }
+
+    pub fn unchecked_rem<T>(&self, numerator: &T, divisor: &T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let (_q, r) = self.unchecked_div_rem(numerator, divisor);
+        r
+    }
+
+    pub fn smart_rem_assign<T>(&self, numerator: &mut T, divisor: &mut T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let (_q, r) = self.smart_div_rem(numerator, divisor);
+        *numerator = r;
+    }
+
+    pub fn smart_rem<T>(&self, numerator: &mut T, divisor: &mut T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let (_q, r) = self.smart_div_rem(numerator, divisor);
+        r
+    }
+
+    pub fn rem_assign<T>(&self, numerator: &mut T, divisor: &T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut tmp_divisor;
+
+        let (numerator, divisor) = match (
+            numerator.block_carries_are_empty(),
+            divisor.block_carries_are_empty(),
+        ) {
+            (true, true) => (numerator, divisor),
+            (true, false) => {
+                tmp_divisor = divisor.clone();
+                self.full_propagate(&mut tmp_divisor);
+                (numerator, &tmp_divisor)
+            }
+            (false, true) => {
+                self.full_propagate(numerator);
+                (numerator, divisor)
+            }
+            (false, false) => {
+                tmp_divisor = divisor.clone();
+
+                self.full_propagate(numerator);
+                self.full_propagate(&mut tmp_divisor);
+                (numerator, &tmp_divisor)
+            }
+        };
+
+        let (_q, r) = self.unchecked_div_rem(numerator, divisor);
+        *numerator = r;
+    }
+
+    /// Computes homomorphically the remainder (rest) of the division between two ciphertexts
+    ///
+    /// # Note
+    ///
+    /// If you need both the quotient and remainder use [Self::div_rem].
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2;
+    ///
+    /// // Generate the client key and the server key:
+    /// let num_blocks = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2, num_blocks);
+    ///
+    /// let msg1 = 97;
+    /// let msg2 = 14;
+    ///
+    /// let ct1 = cks.encrypt(msg1);
+    /// let ct2 = cks.encrypt(msg2);
+    ///
+    /// // Compute homomorphically the remainder:
+    /// let ct_res = sks.rem(&ct1, &ct2);
+    ///
+    /// // Decrypt:
+    /// let dec_result: u64 = cks.decrypt(&ct_res);
+    /// assert_eq!(dec_result, msg1 % msg2);
+    /// ```
+    pub fn rem<T>(&self, numerator: &T, divisor: &T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let (_q, r) = self.div_rem(numerator, divisor);
+        r
+    }
+
+    /// The overflow flag is computed by combining 2 separate values,
+    /// this vec will contain the lut that merges these two flags.
+    ///
+    /// Normally only one lut should be needed, and that lut would output a block
+    /// encrypting 0 or 1.
+    /// However, since the resulting block would then be left shifted and added to
+    /// another existing noisy block, we create many LUTs that shift the boolean value
+    /// to the correct position, to reduce noise growth
+    fn generate_overflow_luts(&self) -> Vec<LookupVector> {
+        let shortint_key = &self.key.key.key;
+
+        let lut_msg_bit0_overflow_flag = {
+            let func = |x: u64, y: u64| u64::from(x == 0 && y == 0);
+            shortint_key.generate_lookup_vector_bivariate(&func)
+        };
+        let lut_msg_bit1_overflow_flag = {
+            let func = |x: u64, y: u64| u64::from(x == 0 && y == 0) << 1;
+            shortint_key.generate_lookup_vector_bivariate(&func)
+        };
+
+        let mut luts = vec![lut_msg_bit0_overflow_flag];
+        if shortint_key.message_modulus.0 == 4 {
+            luts.push(lut_msg_bit1_overflow_flag);
+        }
+
+        luts
+    }
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/ilog2.rs b/tfhe/src/integer/fpga/server_key/radix/ilog2.rs
new file mode 100644
index 000000000..f8ef9159b
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/ilog2.rs
@@ -0,0 +1,432 @@
+use crate::core_crypto::fpga::lookup_vector::LookupVector;
+use crate::integer::server_key::radix_parallel::ilog2::{BitValue, Direction};
+use crate::integer::{
+    IntegerCiphertext, IntegerRadixCiphertext, RadixCiphertext, SignedRadixCiphertext,
+};
+use crate::shortint::Ciphertext;
+use crate::BelfortServerKey;
+
+impl BelfortServerKey {
+    fn count_consecutive_bits<T>(
+        &self,
+        ct: &T,
+        direction: Direction,
+        bit_value: BitValue,
+    ) -> RadixCiphertext
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let integer_key = &self.key.key;
+        if ct.blocks().is_empty() {
+            return integer_key.create_trivial_zero_radix(0);
+        }
+
+        let num_bits_in_message = integer_key.message_modulus().0.ilog2();
+        let num_blocks = ct.blocks().len();
+
+        let num_bits_in_ciphertext = num_bits_in_message
+            .checked_mul(num_blocks as u32)
+            .expect("Number of bits encrypted exceeds u32::MAX");
+
+        let leading_count_per_blocks =
+            self.prepare_count_of_consecutive_bits(ct.clone(), direction, bit_value);
+
+        // `num_bits_in_ciphertext` is the max value to represent
+        // its ilog2 + 1 gives how many bits are required to represent it.
+        let counter_num_blocks = (num_bits_in_ciphertext.ilog2() + 1).div_ceil(num_bits_in_message);
+
+        let cts = leading_count_per_blocks
+            .into_iter()
+            .map(|block| {
+                let mut ct: RadixCiphertext =
+                    integer_key.create_trivial_zero_radix(counter_num_blocks as usize);
+                ct.blocks[0] = block;
+                ct
+            })
+            .collect::<Vec<_>>();
+
+        self.unchecked_sum_ciphertexts_vec(cts)
+            .expect("internal error, empty ciphertext count")
+    }
+
+    fn prepare_count_of_consecutive_bits<T>(
+        &self,
+        ct: T,
+        direction: Direction,
+        bit_value: BitValue,
+    ) -> Vec<Ciphertext>
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let integer_key = &self.key.key;
+        let message_modulus = integer_key.message_modulus().0;
+        assert!(
+            integer_key.carry_modulus().0 >= message_modulus,
+            "A carry modulus as least as big as the message modulus is required"
+        );
+
+        let mut blocks = ct.into_blocks();
+
+        let lut = self.gen_lut_for_trailing_leading(direction, bit_value);
+
+        let luts = vec![lut; blocks.len()];
+
+        // Assign to each block its number of leading/trailing zeros/ones
+        // in the message space
+        self.apply_lookup_vector_packed_assign(&mut blocks, &luts);
+
+        if direction == Direction::Leading {
+            // Our blocks are from lsb to msb
+            // `leading` means starting from the msb, so we reverse block
+            // for the cum sum process done later
+            blocks.reverse();
+        }
+
+        // Trailing bits sum function ensures that each block keeps the number of leading
+        // zeros or becomes 0 if the preceding block contains a bit set to one
+        // (leading_zeros != num bits in message)
+        self.compute_prefix_sum_hillis_steele(blocks, "trailing_bits_sum")
+    }
+
+    fn gen_lut_for_trailing_leading(
+        &self,
+        direction: Direction,
+        bit_value: BitValue,
+    ) -> LookupVector {
+        let shortint_key = &self.key.key.key;
+        let message_modulus = shortint_key.message_modulus.0;
+
+        let func: Box<dyn Fn(u64) -> u64> = match (direction, bit_value) {
+            (Direction::Trailing, BitValue::One) => {
+                let func_trailing_bits_one = |x| {
+                    let x = x % message_modulus;
+                    let mut count = 0;
+                    for i in 0..message_modulus.ilog2() {
+                        if (x >> i) & 1 == BitValue::Zero as u64 {
+                            break;
+                        }
+                        count += 1;
+                    }
+                    count
+                };
+                Box::new(func_trailing_bits_one)
+            }
+            (Direction::Trailing, BitValue::Zero) => {
+                let func_trailing_bits_zero = |x| {
+                    let x = x % message_modulus;
+                    let mut count = 0;
+                    for i in 0..message_modulus.ilog2() {
+                        if (x >> i) & 1 == BitValue::One as u64 {
+                            break;
+                        }
+                        count += 1;
+                    }
+                    count
+                };
+                Box::new(func_trailing_bits_zero)
+            }
+            (Direction::Leading, BitValue::One) => {
+                let func_leading_bits_one = |x| {
+                    let x = x % message_modulus;
+                    let mut count = 0;
+                    for i in (0..message_modulus.ilog2()).rev() {
+                        if (x >> i) & 1 == BitValue::Zero as u64 {
+                            break;
+                        }
+                        count += 1;
+                    }
+                    count
+                };
+                Box::new(func_leading_bits_one)
+            }
+            (Direction::Leading, BitValue::Zero) => {
+                let func_leading_bits_zero = |x| {
+                    let x = x % message_modulus;
+                    let mut count = 0;
+                    for i in (0..message_modulus.ilog2()).rev() {
+                        if (x >> i) & 1 == BitValue::One as u64 {
+                            break;
+                        }
+                        count += 1;
+                    }
+                    count
+                };
+                Box::new(func_leading_bits_zero)
+            }
+        };
+        shortint_key.generate_lookup_vector(&|x| func(x))
+    }
+
+    //==============================================================================================
+    //  Unchecked
+    //==============================================================================================
+    pub fn unchecked_trailing_zeros<T>(&self, ct: &T) -> RadixCiphertext
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.count_consecutive_bits(ct, Direction::Trailing, BitValue::Zero)
+    }
+
+    pub fn unchecked_trailing_ones<T>(&self, ct: &T) -> RadixCiphertext
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.count_consecutive_bits(ct, Direction::Trailing, BitValue::One)
+    }
+
+    pub fn unchecked_leading_zeros<T>(&self, ct: &T) -> RadixCiphertext
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.count_consecutive_bits(ct, Direction::Leading, BitValue::Zero)
+    }
+
+    pub fn unchecked_leading_ones<T>(&self, ct: &T) -> RadixCiphertext
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.count_consecutive_bits(ct, Direction::Leading, BitValue::One)
+    }
+
+    /// Returns the base 2 logarithm of the number, rounded down.
+    ///
+    /// See [Self::ilog2_parallelized] for an example
+    ///
+    /// Expects ct to have clean carries
+    pub fn unchecked_ilog2<T>(&self, ct: &T) -> RadixCiphertext
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let integer_key = &self.key.key;
+        let shortint_key = &integer_key.key;
+
+        if ct.blocks().is_empty() {
+            return integer_key.create_trivial_zero_radix(ct.blocks().len());
+        }
+
+        let message_modulus = integer_key.message_modulus().0;
+        let num_bits_in_message = message_modulus.ilog2();
+        let original_num_blocks = ct.blocks().len();
+
+        let num_bits_in_ciphertext = num_bits_in_message
+            .checked_mul(original_num_blocks as u32)
+            .expect("Number of bits encrypted exceeds u32::MAX");
+
+        // `num_bits_in_ciphertext-1` is the max value we want to represent
+        // its ilog2 + 1 gives use how many bits we need to be able to represent it.
+        // We add `1` to this number as we are going to use signed numbers later
+        //
+        // The ilog2 of a number that is on n bits, is in range 1..=n-1
+        let counter_num_blocks =
+            ((num_bits_in_ciphertext - 1).ilog2() + 1 + 1).div_ceil(num_bits_in_message) as usize;
+
+        // x.ilog2() = (x.num_bit() - 1) - x.leading_zeros()
+        // - (x.num_bit() - 1) is trivially known
+        // - we can get leading zeros via a sum
+        //
+        // The sum includes a full propagation and the subtraction
+        // will add another full propagation which is costly.
+        //
+        // However, we can do better:
+        // let N = (x.num_bit() - 1)
+        // let L0 = x.leading_zeros()
+        // ```
+        // x.ilog2() = N - L0
+        // x.ilog2() = -(-(N - L0))
+        // x.ilog2() = -(-N + L0)
+        // ```
+        // N is a clear number, so getting -N is free.
+        // -N + L0 where L0 is actually `sum(L0[b0], .., L0[num_blocks-1])`
+        // can be done with `sum(-N, L0[b0], .., L0[num_blocks-1]) by switching to signed
+        // numbers.
+        //
+        // Also, to do -(-N + L0) aka -sum(-N, L0[b0], .., L0[num_blocks-1])
+        // we can make the sum return a non-fully propagated result,
+        // and extract message/carry blocks while negating them at the same time
+        // using the fact that in twos complement -X = bitnot(X) + 1
+        // so given a non propagated `C`, we can compute the fully propagated `PC`
+        // PC = bitnot(message(C)) + bitnot(blockshift(carry(C), 1)) + 2
+
+        let leading_zeros_per_blocks =
+            self.prepare_count_of_consecutive_bits(ct.clone(), Direction::Leading, BitValue::Zero);
+
+        let mut cts = leading_zeros_per_blocks
+            .into_iter()
+            .map(|block| {
+                let mut ct: SignedRadixCiphertext =
+                    integer_key.create_trivial_zero_radix(counter_num_blocks);
+                ct.blocks[0] = block;
+                ct
+            })
+            .collect::<Vec<_>>();
+        cts.push(
+            integer_key
+                .create_trivial_radix(-(num_bits_in_ciphertext as i32 - 1i32), counter_num_blocks),
+        );
+
+        let result = self
+            .unchecked_partial_sum_ciphertexts_vec(cts)
+            .expect("internal error, empty ciphertext count");
+
+        let lut_extract_bitnot_message = {
+            let func = |x| {
+                let m: u64 = x % shortint_key.message_modulus.0; // extract message
+                (!m) % shortint_key.message_modulus.0 // bitnot the message
+            };
+            shortint_key.generate_lookup_vector(&func)
+        };
+        let lut_extract_bitnot_carry = {
+            let func = |x| {
+                let c: u64 = x / shortint_key.message_modulus.0; // extract carry
+                (!c) % shortint_key.message_modulus.0 // bitnot the carry
+            };
+            shortint_key.generate_lookup_vector(&func)
+        };
+
+        let mut message_blocks = result.blocks().to_vec();
+        self.apply_same_lookup_vector_packed_assign(
+            &mut message_blocks,
+            lut_extract_bitnot_message,
+        );
+
+        let mut carry_blocks = result.blocks()[..counter_num_blocks - 1].to_vec();
+        self.apply_same_lookup_vector_packed_assign(&mut carry_blocks, lut_extract_bitnot_carry);
+
+        // Normally this would be 0, but we want the bitnot of 0, which is msg_mod-1
+        carry_blocks.insert(0, integer_key.key.create_trivial(message_modulus - 1));
+
+        let message = SignedRadixCiphertext::from(message_blocks);
+        let carry = SignedRadixCiphertext::from(carry_blocks);
+        let result = self
+            .sum_ciphertexts(
+                [
+                    message,
+                    carry,
+                    integer_key.create_trivial_radix(2u32, counter_num_blocks),
+                ]
+                .iter(),
+            )
+            .unwrap();
+
+        self.cast_to_unsigned(result, counter_num_blocks)
+    }
+
+    //==============================================================================================
+    //  Default
+    //==============================================================================================
+    pub fn trailing_zeros<T>(&self, ct: &T) -> RadixCiphertext
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut tmp;
+        let ct = if ct.block_carries_are_empty() {
+            ct
+        } else {
+            tmp = ct.clone();
+            self.full_propagate(&mut tmp);
+            &tmp
+        };
+        self.unchecked_trailing_zeros(ct)
+    }
+
+    pub fn trailing_ones<T>(&self, ct: &T) -> RadixCiphertext
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut tmp;
+        let ct = if ct.block_carries_are_empty() {
+            ct
+        } else {
+            tmp = ct.clone();
+            self.full_propagate(&mut tmp);
+            &tmp
+        };
+        self.unchecked_trailing_ones(ct)
+    }
+    pub fn leading_zeros<T>(&self, ct: &T) -> RadixCiphertext
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut tmp;
+        let ct = if ct.block_carries_are_empty() {
+            ct
+        } else {
+            tmp = ct.clone();
+            self.full_propagate(&mut tmp);
+            &tmp
+        };
+        self.unchecked_leading_zeros(ct)
+    }
+
+    pub fn leading_ones<T>(&self, ct: &T) -> RadixCiphertext
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut tmp;
+        let ct = if ct.block_carries_are_empty() {
+            ct
+        } else {
+            tmp = ct.clone();
+            self.full_propagate(&mut tmp);
+            &tmp
+        };
+        self.unchecked_leading_ones(ct)
+    }
+
+    /// Returns the base 2 logarithm of the number, rounded down.
+    pub fn ilog2<T>(&self, ct: &T) -> RadixCiphertext
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut tmp;
+        let ct = if ct.block_carries_are_empty() {
+            ct
+        } else {
+            tmp = ct.clone();
+            self.full_propagate(&mut tmp);
+            &tmp
+        };
+
+        self.unchecked_ilog2(ct)
+    }
+
+    //==============================================================================================
+    //  Smart
+    //==============================================================================================
+
+    /// See [Self::trailing_zeros]
+    pub fn smart_trailing_zeros<T>(&self, ct: &mut T) -> RadixCiphertext
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.conditional_full_propagate(ct);
+        self.unchecked_trailing_zeros(ct)
+    }
+
+    /// See [Self::trailing_ones]
+    pub fn smart_trailing_ones<T>(&self, ct: &mut T) -> RadixCiphertext
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.conditional_full_propagate(ct);
+        self.unchecked_trailing_ones(ct)
+    }
+
+    /// See [Self::leading_zeros]
+    pub fn smart_leading_zeros<T>(&self, ct: &mut T) -> RadixCiphertext
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.conditional_full_propagate(ct);
+        self.unchecked_leading_zeros(ct)
+    }
+
+    /// See [Self::leading_ones]
+    pub fn smart_leading_ones<T>(&self, ct: &mut T) -> RadixCiphertext
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.conditional_full_propagate(ct);
+        self.unchecked_leading_ones(ct)
+    }
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/mod.rs b/tfhe/src/integer/fpga/server_key/radix/mod.rs
new file mode 100644
index 000000000..bac78914b
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/mod.rs
@@ -0,0 +1,174 @@
+use crate::integer::{
+    IntegerCiphertext, IntegerRadixCiphertext, RadixCiphertext, SignedRadixCiphertext,
+};
+
+use super::BelfortServerKey;
+
+mod abs;
+mod add;
+mod bit_extractor;
+mod bitwise_op;
+mod cmux;
+mod comparison;
+mod count_zeros_ones;
+mod div_mod;
+mod ilog2;
+mod modulus_switch_compression;
+mod mul;
+mod neg;
+mod reverse_bits;
+mod rotate;
+mod scalar_add;
+mod scalar_bitwise_op;
+mod scalar_comparison;
+mod scalar_div_mod;
+mod scalar_mul;
+mod scalar_rotate;
+mod scalar_shift;
+mod scalar_sub;
+mod shift;
+mod slice;
+mod sub;
+mod sum;
+mod vector_comparisons;
+mod vector_find;
+
+#[cfg(test)]
+pub(crate) mod tests;
+
+impl BelfortServerKey {
+    /// Cast a RadixCiphertext or SignedRadixCiphertext to a RadixCiphertext
+    /// with a possibly different number of blocks
+    ///
+    /// # Example
+    ///
+    ///```rust
+    /// use tfhe::integer::{gen_keys_radix, IntegerCiphertext};
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// let num_blocks = 4;
+    ///
+    /// // Generate the client key and the server key:
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, num_blocks);
+    ///
+    /// let msg = -2i8;
+    ///
+    /// let ct1 = cks.encrypt_signed(msg);
+    /// assert_eq!(ct1.blocks().len(), 4);
+    ///
+    /// let ct_res = sks.cast_to_unsigned(ct1, 8);
+    /// assert_eq!(ct_res.blocks().len(), 8);
+    ///
+    /// // Decrypt
+    /// let res: u16 = cks.decrypt(&ct_res);
+    /// assert_eq!(msg as u16, res);
+    /// ```
+    pub fn cast_to_unsigned<T: IntegerRadixCiphertext>(
+        &self,
+        mut source: T,
+        target_num_blocks: usize,
+    ) -> RadixCiphertext {
+        if !source.block_carries_are_empty() {
+            self.full_propagate(&mut source);
+        }
+
+        let blocks = source.into_blocks();
+        let current_num_blocks = blocks.len();
+
+        let blocks = if T::IS_SIGNED {
+            // Casting from signed to unsigned
+            // We have to trim or sign extend first
+            if target_num_blocks > current_num_blocks {
+                let mut ct_as_signed_radix = SignedRadixCiphertext::from_blocks(blocks);
+
+                let num_blocks_to_add = target_num_blocks - current_num_blocks;
+                self.extend_radix_with_sign_msb_assign(&mut ct_as_signed_radix, num_blocks_to_add);
+                ct_as_signed_radix.blocks
+            } else {
+                let mut ct_as_unsigned_radix = crate::integer::RadixCiphertext::from_blocks(blocks);
+                let num_blocks_to_remove = current_num_blocks - target_num_blocks;
+                self.trim_radix_blocks_msb_assign(&mut ct_as_unsigned_radix, num_blocks_to_remove);
+                ct_as_unsigned_radix.blocks
+            }
+        } else {
+            // Casting from unsigned to unsigned, this is just about trimming/extending with zeros
+            let mut ct_as_unsigned_radix = crate::integer::RadixCiphertext::from_blocks(blocks);
+            if target_num_blocks > current_num_blocks {
+                let num_blocks_to_add = target_num_blocks - current_num_blocks;
+                self.key
+                    .key
+                    .extend_radix_with_trivial_zero_blocks_msb_assign(
+                        &mut ct_as_unsigned_radix,
+                        num_blocks_to_add,
+                    );
+            } else {
+                let num_blocks_to_remove = current_num_blocks - target_num_blocks;
+                self.trim_radix_blocks_msb_assign(&mut ct_as_unsigned_radix, num_blocks_to_remove);
+            };
+            ct_as_unsigned_radix.blocks
+        };
+
+        assert_eq!(
+            blocks.len(),
+            target_num_blocks,
+            "internal error, wrong number of blocks after casting"
+        );
+        crate::integer::RadixCiphertext::from(blocks)
+    }
+
+    /// Remove MSB blocks from an existing [`RadixCiphertext`]. This can be useful for
+    /// casting operations.
+    pub fn trim_radix_blocks_msb_assign(&self, ct: &mut RadixCiphertext, num_blocks: usize) {
+        let len = ct.blocks.len();
+        ct.blocks.truncate(len - num_blocks);
+        if !ct.block_carries_are_empty() {
+            self.full_propagate(ct);
+        }
+    }
+
+    /// Extends the most significant blocks using the sign bit.
+    /// Used to cast [SignedRadixCiphertext]
+    pub fn extend_radix_with_sign_msb_assign(
+        &self,
+        ct: &mut SignedRadixCiphertext,
+        num_blocks: usize,
+    ) {
+        self.conditional_full_propagate(ct);
+
+        let shortint_key = &self.key.key.key;
+
+        let last_block = ct
+            .blocks
+            .last()
+            .expect("Cannot sign extend an empty ciphertext");
+
+        let mut blocks = vec![last_block.clone()];
+
+        let lut_padding_block_creator = {
+            let func = |x| {
+                let message_modulus = shortint_key.message_modulus.0;
+                let x = x % message_modulus;
+                let num_bits_in_block = message_modulus.ilog2();
+                let x_sign_bit = x >> (num_bits_in_block - 1) & 1;
+                // padding is a message full of 1 if sign bit is one
+                // else padding is a zero message
+                (message_modulus - 1) * x_sign_bit
+            };
+            shortint_key.generate_lookup_vector(&func)
+        };
+        self.apply_lookup_vector_packed_assign(&mut blocks, &[lut_padding_block_creator]);
+
+        let new_len = num_blocks + ct.blocks.len();
+        ct.blocks.resize(new_len, blocks[0].clone());
+    }
+
+    pub(crate) fn get_additions_to_fill_carry(&self) -> usize {
+        let integer_key = &self.key.key;
+        let carry_modulus = integer_key.carry_modulus().0;
+        let message_modulus = integer_key.message_modulus().0;
+
+        let total_modulus = message_modulus * carry_modulus;
+        let message_max = message_modulus - 1;
+        ((total_modulus - 1) / message_max) as usize
+    }
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/modulus_switch_compression.rs b/tfhe/src/integer/fpga/server_key/radix/modulus_switch_compression.rs
new file mode 100644
index 000000000..ee61f20cc
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/modulus_switch_compression.rs
@@ -0,0 +1,59 @@
+use crate::integer::ciphertext::{
+    BaseRadixCiphertext, BaseSignedRadixCiphertext, CompressedModulusSwitchedRadixCiphertext,
+    CompressedModulusSwitchedSignedRadixCiphertext,
+};
+use crate::integer::{RadixCiphertext, SignedRadixCiphertext};
+use crate::BelfortServerKey;
+use log::warn;
+
+impl BelfortServerKey {
+    pub fn switch_modulus_and_compress(
+        &self,
+        ct: &RadixCiphertext,
+    ) -> CompressedModulusSwitchedRadixCiphertext {
+        warn!("Non-optimized function call. Contact Belfort if you experience a slow run.");
+        CompressedModulusSwitchedRadixCiphertext(
+            self.key
+                .key
+                .switch_modulus_and_compress_generic_parallelized(&ct.blocks),
+        )
+    }
+
+    pub fn decompress(
+        &self,
+        compressed_ct: &CompressedModulusSwitchedRadixCiphertext,
+    ) -> RadixCiphertext {
+        warn!("Non-optimized function call. Contact Belfort if you experience a slow run.");
+        BaseRadixCiphertext {
+            blocks: self
+                .key
+                .key
+                .decompress_generic_parallelized(&compressed_ct.0),
+        }
+    }
+
+    pub fn switch_modulus_and_compress_signed(
+        &self,
+        ct: &SignedRadixCiphertext,
+    ) -> CompressedModulusSwitchedSignedRadixCiphertext {
+        warn!("Non-optimized function call. Contact Belfort if you experience a slow run.");
+        CompressedModulusSwitchedSignedRadixCiphertext(
+            self.key
+                .key
+                .switch_modulus_and_compress_generic_parallelized(&ct.blocks),
+        )
+    }
+
+    pub fn decompress_signed(
+        &self,
+        compressed_ct: &CompressedModulusSwitchedSignedRadixCiphertext,
+    ) -> SignedRadixCiphertext {
+        warn!("Non-optimized function call. Contact Belfort if you experience a slow run.");
+        BaseSignedRadixCiphertext {
+            blocks: self
+                .key
+                .key
+                .decompress_generic_parallelized(&compressed_ct.0),
+        }
+    }
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/mul.rs b/tfhe/src/integer/fpga/server_key/radix/mul.rs
new file mode 100644
index 000000000..58c358352
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/mul.rs
@@ -0,0 +1,783 @@
+use log::warn;
+
+use crate::core_crypto::fpga::lookup_vector::LookupVector;
+use crate::integer::ciphertext::IntegerRadixCiphertext;
+use crate::integer::fpga::server_key::BelfortServerKey;
+use crate::integer::{BooleanBlock, RadixCiphertext};
+use crate::shortint::Ciphertext;
+
+impl BelfortServerKey {
+    /// Computes homomorphically a multiplication between a ciphertext encrypting an integer value
+    /// and another encrypting a shortint value.
+    ///
+    /// This function computes the operation without checking if it exceeds the capacity of the
+    /// ciphertext.
+    ///
+    /// The result is assigned to the `ct_left` ciphertext.
+    ///
+    /// # Warning
+    ///
+    /// - Multithreaded
+    ///
+    /// # Example
+    ///
+    ///```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // Generate the client key and the server key:
+    /// let num_blocks = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, num_blocks);
+    ///
+    /// let clear_1 = 170;
+    /// let clear_2 = 3;
+    ///
+    /// // Encrypt two messages
+    /// let mut ct_left = cks.encrypt(clear_1);
+    /// let ct_right = cks.encrypt_one_block(clear_2);
+    ///
+    /// // Compute homomorphically a multiplication
+    /// sks.unchecked_block_mul_assign(&mut ct_left, &ct_right, 0);
+    ///
+    /// // Decrypt
+    /// let res: u64 = cks.decrypt(&ct_left);
+    /// assert_eq!((clear_1 * clear_2) % 256, res);
+    /// ```
+    pub fn unchecked_block_mul_assign<T>(
+        &self,
+        ct_left: &mut T,
+        ct_right: &Ciphertext,
+        index: usize,
+    ) where
+        T: IntegerRadixCiphertext,
+    {
+        *ct_left = self.unchecked_block_mul(ct_left, ct_right, index);
+    }
+
+    /// Computes homomorphically a multiplication between a ciphertexts encrypting an integer
+    /// value and another encrypting a shortint value.
+    ///
+    /// This function computes the operation without checking if it exceeds the capacity of the
+    /// ciphertext.
+    ///
+    /// The result is returned as a new ciphertext.
+    ///
+    ///
+    /// # Example
+    ///
+    ///```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // Generate the client key and the server key:
+    /// let num_blocks = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, num_blocks);
+    ///
+    /// let clear_1 = 55;
+    /// let clear_2 = 3;
+    ///
+    /// // Encrypt two messages
+    /// let ct_left = cks.encrypt(clear_1);
+    /// let ct_right = cks.encrypt_one_block(clear_2);
+    ///
+    /// // Compute homomorphically a multiplication
+    /// let ct_res = sks.unchecked_block_mul(&ct_left, &ct_right, 0);
+    ///
+    /// // Decrypt
+    /// let res: u64 = cks.decrypt(&ct_res);
+    /// assert_eq!((clear_1 * clear_2) % 256, res);
+    /// ```
+    pub fn unchecked_block_mul<T>(&self, ct1: &T, ct2: &Ciphertext, index: usize) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let (result_lsb, result_msb) = self.unchecked_block_mul_lsb_msb(ct1, ct2, index);
+        self.unchecked_add(&result_lsb, &result_msb)
+    }
+
+    /// Computes homomorphically a multiplication between a ciphertext encrypting integer value
+    /// and another encrypting a shortint value.
+    ///
+    /// The result is returned as a new ciphertext.
+    ///
+    /// # Warning
+    ///
+    /// - Multithreaded
+    ///
+    /// # Example
+    ///
+    ///```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // Generate the client key and the server key:
+    /// let num_blocks = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, num_blocks);
+    ///
+    /// let clear_1 = 170;
+    /// let clear_2 = 3;
+    ///
+    /// // Encrypt two messages
+    /// let mut ctxt_1 = cks.encrypt(clear_1);
+    /// let mut ctxt_2 = cks.encrypt_one_block(clear_2);
+    ///
+    /// // Compute homomorphically a multiplication
+    /// let ct_res = sks.smart_block_mul(&mut ctxt_1, &mut ctxt_2, 0);
+    ///
+    /// // Decrypt
+    /// let res: u64 = cks.decrypt(&ct_res);
+    /// assert_eq!((clear_1 * clear_2) % 256, res);
+    /// ```
+    // by convention smart operations take mut refs to their inputs, even if they do not modify them
+    #[allow(clippy::needless_pass_by_ref_mut)]
+    pub fn smart_block_mul<T>(&self, ct1: &mut T, ct2: &mut Ciphertext, index: usize) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        // Makes sure we can do the multiplications
+        self.full_propagate(ct1);
+
+        let (mut result_lsb, mut result_msb) = self.unchecked_block_mul_lsb_msb(ct1, ct2, index);
+
+        self.smart_add(&mut result_lsb, &mut result_msb)
+    }
+
+    pub fn smart_block_mul_assign<T>(&self, ct1: &mut T, ct2: &mut Ciphertext, index: usize)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        *ct1 = self.smart_block_mul(ct1, ct2, index);
+    }
+
+    /// Computes homomorphically a multiplication between a ciphertext encrypting integer value
+    /// and another encrypting a shortint value.
+    ///
+    /// The result is returned as a new ciphertext.
+    ///
+    /// This function, like all "default" operations (i.e. not smart, checked or unchecked), will
+    /// check that the input ciphertexts block carries are empty and clears them if it's not the
+    /// case and the operation requires it. It outputs a ciphertext whose block carries are always
+    /// empty.
+    ///
+    /// This means that when using only "default" operations, a given operation (like add for
+    /// example) has always the same performance characteristics from one call to another and
+    /// guarantees correctness by pre-emptively clearing carries of output ciphertexts.
+    ///
+    /// # Warning
+    ///
+    /// - Multithreaded
+    ///
+    /// # Example
+    ///
+    ///```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // Generate the client key and the server key:
+    /// let num_blocks = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, num_blocks);
+    ///
+    /// let clear_1 = 170;
+    /// let clear_2 = 3;
+    ///
+    /// // Encrypt two messages
+    /// let ctxt_1 = cks.encrypt(clear_1);
+    /// let ctxt_2 = cks.encrypt_one_block(clear_2);
+    ///
+    /// // Compute homomorphically a multiplication
+    /// let ct_res = sks.block_mul(&ctxt_1, &ctxt_2, 0);
+    ///
+    /// // Decrypt
+    /// let res: u64 = cks.decrypt(&ct_res);
+    /// assert_eq!((clear_1 * clear_2) % 256, res);
+    /// ```
+    pub fn block_mul<T>(&self, ct1: &T, ct2: &Ciphertext, index: usize) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut ct_res = ct1.clone();
+        self.block_mul_assign(&mut ct_res, ct2, index);
+        ct_res
+    }
+
+    pub fn block_mul_assign<T>(&self, ct1: &mut T, ct2: &Ciphertext, index: usize)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut tmp_rhs: Ciphertext;
+        let shortint_key = &self.key.key.key;
+        let (lhs, rhs) = match (ct1.block_carries_are_empty(), ct2.carry_is_empty()) {
+            (true, true) => (ct1, ct2),
+            (true, false) => {
+                tmp_rhs = ct2.clone();
+                shortint_key.message_extract_assign(&mut tmp_rhs);
+                (ct1, &tmp_rhs)
+            }
+            (false, true) => {
+                self.full_propagate(ct1);
+                (ct1, ct2)
+            }
+            (false, false) => {
+                tmp_rhs = ct2.clone();
+                self.full_propagate(ct1);
+                shortint_key.message_extract_assign(&mut tmp_rhs);
+                (ct1, &tmp_rhs)
+            }
+        };
+        self.unchecked_block_mul_assign(lhs, rhs, index);
+        self.full_propagate(lhs);
+    }
+
+    /// Computes homomorphically a multiplication between two ciphertexts encrypting integer values.
+    ///
+    /// This function, like all "default" operations (i.e. not smart, checked or unchecked)
+    /// checks that the input ciphertexts block carries are empty and clears them if it's not the
+    /// case and the operation requires it. It outputs a ciphertext whose block carries are always
+    /// empty.
+    ///
+    /// This means that when using only "default" operations, a given operation (like add for
+    /// example) has always the same performance characteristics from one call to another and
+    /// guarantees correctness by pre-emptively clearing carries of output ciphertexts.
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // Generate the client key and the server key:
+    /// let num_blocks = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, num_blocks);
+    ///
+    /// let clear_1 = 170;
+    /// let clear_2 = 6;
+    ///
+    /// // Encrypt two messages
+    /// let ctxt_1 = cks.encrypt(clear_1);
+    /// let ctxt_2 = cks.encrypt(clear_2);
+    ///
+    /// // Compute homomorphically a multiplication
+    /// let ct_res = sks.mul(&ctxt_1, &ctxt_2);
+    /// // Decrypt
+    /// let res: u64 = cks.decrypt(&ct_res);
+    /// assert_eq!((clear_1 * clear_2) % 256, res);
+    /// ```
+    pub fn mul<T>(&self, lhs: &T, rhs: &T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut ct_res = lhs.clone();
+        self.mul_assign(&mut ct_res, rhs);
+        ct_res
+    }
+
+    pub fn mul_assign<T>(&self, lhs: &mut T, rhs: &T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut tmp_rhs;
+
+        let (lhs, rhs) = match (lhs.block_carries_are_empty(), rhs.block_carries_are_empty()) {
+            (true, true) => (lhs, rhs),
+            (true, false) => {
+                tmp_rhs = rhs.clone();
+                self.full_propagate(&mut tmp_rhs);
+                (lhs, &tmp_rhs)
+            }
+            (false, true) => {
+                self.full_propagate(lhs);
+                (lhs, rhs)
+            }
+            (false, false) => {
+                tmp_rhs = rhs.clone();
+                self.full_propagate(lhs);
+                self.full_propagate(&mut tmp_rhs);
+                (lhs, &tmp_rhs)
+            }
+        };
+
+        self.unchecked_mul_assign(lhs, rhs);
+    }
+
+    /// Smart_mul always checks whether there is a need for full_propagate() and
+    /// continues by performing the multiplication.
+    pub fn smart_mul<T>(&self, lhs: &mut T, rhs: &mut T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.conditional_full_propagate_bivariate(lhs, rhs);
+        self.unchecked_mul(lhs, rhs)
+    }
+
+    pub fn smart_mul_assign<T>(&self, lhs: &mut T, rhs: &mut T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.conditional_full_propagate_bivariate(lhs, rhs);
+        self.unchecked_mul_assign(lhs, rhs);
+    }
+
+    pub fn unchecked_unsigned_overflowing_mul(
+        &self,
+        lhs: &RadixCiphertext,
+        rhs: &RadixCiphertext,
+    ) -> (RadixCiphertext, BooleanBlock) {
+        warn!("Non-optimized function call. Contact Belfort if you experience a slow run.");
+        self.key
+            .key
+            .unchecked_unsigned_overflowing_mul_parallelized(lhs, rhs)
+    }
+
+    pub fn unchecked_unsigned_overflowing_mul_assign(
+        &self,
+        lhs: &mut RadixCiphertext,
+        rhs: &RadixCiphertext,
+    ) -> BooleanBlock {
+        let (result, overflowed) = self.unchecked_unsigned_overflowing_mul(lhs, rhs);
+        *lhs = result;
+        overflowed
+    }
+
+    /// Computes homomorphically a multiplication along with an overflow flag
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // Generate the client key and the server key:
+    /// let num_blocks = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, num_blocks);
+    ///
+    /// let clear_1 = 128u8;
+    /// let clear_2 = 5u8;
+    ///
+    /// // Encrypt two messages
+    /// let ctxt_1 = cks.encrypt(clear_1);
+    /// let ctxt_2 = cks.encrypt(clear_2);
+    ///
+    /// // Compute homomorphically a multiplication
+    /// let (ct_res, ct_overflowed) = sks.unsigned_overflowing_mul(&ctxt_1, &ctxt_2);
+    /// // Decrypt
+    /// let res: u8 = cks.decrypt(&ct_res);
+    /// let overflowed = cks.decrypt_bool(&ct_overflowed);
+    ///
+    /// let (expected_result, expected_overflowed) = clear_1.overflowing_mul(clear_2);
+    /// assert_eq!(res, expected_result);
+    /// assert_eq!(overflowed, expected_overflowed);
+    /// ```
+    pub fn unsigned_overflowing_mul(
+        &self,
+        ct1: &RadixCiphertext,
+        ct2: &RadixCiphertext,
+    ) -> (RadixCiphertext, BooleanBlock) {
+        let mut ct_res = ct1.clone();
+        let overflowed = self.unsigned_overflowing_mul_assign(&mut ct_res, ct2);
+        (ct_res, overflowed)
+    }
+
+    pub fn unsigned_overflowing_mul_assign(
+        &self,
+        ct1: &mut RadixCiphertext,
+        ct2: &RadixCiphertext,
+    ) -> BooleanBlock {
+        let mut tmp_rhs;
+
+        let (lhs, rhs) = match (ct1.block_carries_are_empty(), ct2.block_carries_are_empty()) {
+            (true, true) => (ct1, ct2),
+            (true, false) => {
+                tmp_rhs = ct2.clone();
+                self.full_propagate(&mut tmp_rhs);
+                (ct1, &tmp_rhs)
+            }
+            (false, true) => {
+                self.full_propagate(ct1);
+                (ct1, ct2)
+            }
+            (false, false) => {
+                tmp_rhs = ct2.clone();
+                self.full_propagate(ct1);
+                self.full_propagate(&mut tmp_rhs);
+                (ct1, &tmp_rhs)
+            }
+        };
+
+        self.unchecked_unsigned_overflowing_mul_assign(lhs, rhs)
+    }
+
+    /// Computes homomorphically a multiplication between two ciphertexts encrypting integer values.
+    ///
+    /// This function computes the operation without checking if it exceeds the capacity of the
+    /// ciphertext.
+    ///
+    /// The result is assigned to the `ct_left` ciphertext.
+    ///
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // Generate the client key and the server key:
+    /// let num_blocks = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, num_blocks);
+    ///
+    /// let clear_1 = 255;
+    /// let clear_2 = 143;
+    ///
+    /// // Encrypt two messages
+    /// let mut ctxt_1 = cks.encrypt(clear_1);
+    /// let ctxt_2 = cks.encrypt(clear_2);
+    ///
+    /// // Compute homomorphically a multiplication
+    /// let ct_res = sks.unchecked_mul(&mut ctxt_1, &ctxt_2);
+    ///
+    /// // Decrypt
+    /// let res: u64 = cks.decrypt(&ct_res);
+    /// assert_eq!((clear_1 * clear_2) % 256, res);
+    /// ```
+    pub fn unchecked_mul<T>(&self, lhs: &T, rhs: &T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut ct_res = lhs.clone();
+        self.unchecked_mul_assign(&mut ct_res, rhs);
+        ct_res
+    }
+
+    pub fn unchecked_mul_assign<T>(&self, lhs: &mut T, rhs: &T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let integer_key = &self.key.key;
+        if rhs.holds_boolean_value() {
+            integer_key.zero_out_if_condition_is_false(lhs, &rhs.blocks()[0]);
+            return;
+        }
+
+        if lhs.holds_boolean_value() {
+            let mut cloned_rhs = rhs.clone();
+            integer_key.zero_out_if_condition_is_false(&mut cloned_rhs, &lhs.blocks()[0]);
+            *lhs = cloned_rhs;
+            return;
+        }
+
+        self.compute_terms_for_mul_low(lhs, rhs);
+    }
+
+    /// This functions computes the terms resulting from multiplying each block
+    /// of rhs with lhs. When summed these terms will give the low part of the result.
+    /// i.e. in a (lhs: Nbit * rhs: Nbit) multiplication, summing the terms will give a N bit result
+    /// This function is written to exploit the available parallellism on fpga
+    fn compute_terms_for_mul_low<T>(&self, lhs: &mut T, rhs: &T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let integer_key = &self.key.key;
+        let shortint_key = &integer_key.key;
+        let message_modulus = integer_key.message_modulus().0;
+        let max_index = lhs.blocks().len() - 1;
+
+        let mut ciphertexts: Vec<Ciphertext> = vec![];
+        let mut luts: Vec<LookupVector> = vec![];
+        let mut block_indexes: Vec<usize> = vec![];
+
+        let lut_vector_mult_2lsb = self.lut_mul_2lsb();
+        let lut_vector_mult_2msb = self.lut_mul_2msb();
+
+        let multiplication_iter = rhs
+            .blocks()
+            .iter()
+            .enumerate()
+            .filter(|(_, block)| block.degree.get() != 0)
+            .flat_map(|(index_rhs, block_rhs)| {
+                // Further blocks will overflow as computation happens in modulo
+                lhs.blocks()[0..=max_index - index_rhs]
+                    .iter()
+                    .enumerate()
+                    .filter(|(_, block_lhs)| block_lhs.degree.get() != 0)
+                    .map(move |(index_lhs, bl_lhs)| {
+                        let mut block_lhs = bl_lhs.clone();
+                        // Combines the two blocks to serve as an input for LUT of multiplication
+                        shortint_key.unchecked_apply_lookup_table_bivariate_assign_prep(
+                            &mut block_lhs,
+                            block_rhs,
+                        );
+                        (block_lhs, lut_vector_mult_2lsb, index_rhs + index_lhs)
+                    })
+            });
+
+        // The modulus defines the number of bits of the message.
+        // If the modulus is smaller than 2, the carry won't overflow,
+        // since the message is either 0 or 1.
+        let multiplication_terms: Vec<_> = if message_modulus > 2 {
+            multiplication_iter
+                .chain(
+                    rhs.blocks()[..rhs.blocks().len() - 1]
+                        .iter()
+                        .enumerate()
+                        .filter(|(_, block)| block.degree.get() != 0)
+                        .flat_map(|(index_rhs, block_rhs)| {
+                            lhs.blocks()[0..(max_index - index_rhs)]
+                                .iter()
+                                .enumerate()
+                                .filter(|(_, block_lhs)| block_lhs.degree.get() != 0)
+                                .map(move |(index_lhs, bl_lhs)| {
+                                    let mut block_lhs = bl_lhs.clone();
+
+                                    shortint_key
+                                        .unchecked_apply_lookup_table_bivariate_assign_prep(
+                                            &mut block_lhs,
+                                            block_rhs,
+                                        );
+                                    (block_lhs, lut_vector_mult_2msb, index_rhs + index_lhs + 1)
+                                })
+                        }),
+                )
+                .collect()
+        } else {
+            multiplication_iter.collect()
+        };
+
+        for (ct, lut, index) in multiplication_terms {
+            ciphertexts.push(ct);
+            luts.push(lut);
+            block_indexes.push(index);
+        }
+
+        let mut to_add =
+            self.execute_short_int_multiplications(ciphertexts, &luts, block_indexes, max_index);
+
+        self.adder_tree_assign_batched(&mut to_add);
+
+        let result_blocks = self.flatten_result(to_add);
+
+        lhs.blocks_mut()
+            .iter_mut()
+            .enumerate()
+            .for_each(|(index, block)| {
+                block.clone_from(&result_blocks[index]);
+            });
+    }
+
+    fn adder_tree_assign_batched(&self, input_list: &mut [Vec<Ciphertext>]) {
+        let shortint_key = &self.key.key.key;
+
+        let max_additions_per_slot = self.get_additions_to_fill_carry();
+        let max_index = input_list.len() - 1;
+
+        let mut ready_index = 0; // index of the first column that still has work left
+        let mut current_index; // index of the slot where we now look for extra bootstraps
+        let pbs_slots_parallel = 32; // TODO: determine best value (32, 64 or 84) with script depending on FPGA parallelism
+
+        let mut ciphertext_stack =
+            Vec::<(Ciphertext, usize, LookupVector)>::with_capacity(pbs_slots_parallel);
+        let mut take_amount;
+
+        let lut_message_extract = self.lut_message_extract();
+        let lut_carry_extract = self.lut_carry_extract();
+
+        while ready_index <= max_index {
+            let mut pbs_slots_open = pbs_slots_parallel;
+            current_index = ready_index;
+
+            while current_index <= max_index && pbs_slots_open > 0 {
+                let input_column = &mut input_list[current_index];
+
+                let max_additions = if current_index == max_index {
+                    pbs_slots_open * max_additions_per_slot
+                } else {
+                    // If not at the highest index, every set of inputs results in two PBS: msg and
+                    // carry extract
+                    (pbs_slots_open / 2) * max_additions_per_slot
+                };
+
+                take_amount = input_column.len().min(max_additions);
+                let mut slots_filled = take_amount / max_additions_per_slot;
+
+                if current_index == ready_index {
+                    // The first unfinished column needs to be processed first.
+                    // Carries might be added for the following columns, which can result in extra
+                    // filled slots.
+                    let has_partial_slot = (take_amount % max_additions_per_slot) > 1;
+                    slots_filled += has_partial_slot as usize;
+
+                    if slots_filled == 0 {
+                        // All work is done for the current column
+                        ready_index += 1;
+                    } else {
+                        // Inside the first unfinished column - Full slots
+                        for _ in 0..slots_filled - 1 {
+                            let mut res = input_column.pop().unwrap();
+                            let mut second_res = input_column.pop().unwrap();
+                            shortint_key.unchecked_add_assign(&mut res, &second_res);
+                            for _ in 0..(max_additions_per_slot - 2) {
+                                shortint_key
+                                    .unchecked_add_assign(&mut res, &input_column.pop().unwrap());
+                            }
+                            res.clone_into(&mut second_res);
+                            ciphertext_stack.push((res, current_index, lut_message_extract));
+                            if current_index != max_index {
+                                ciphertext_stack.push((
+                                    second_res,
+                                    current_index + 1,
+                                    lut_carry_extract,
+                                ));
+                            }
+                            take_amount -= max_additions_per_slot;
+                        }
+
+                        // Partial slots
+                        let mut res = input_column.pop().unwrap();
+                        let mut second_res = input_column.pop().unwrap();
+                        shortint_key.unchecked_add_assign(&mut res, &second_res);
+                        for _ in 0..(take_amount.min(max_additions_per_slot) - 2) {
+                            shortint_key
+                                .unchecked_add_assign(&mut res, &input_column.pop().unwrap());
+                        }
+                        res.clone_into(&mut second_res);
+                        ciphertext_stack.push((res, current_index, lut_message_extract));
+                        if current_index != max_index {
+                            ciphertext_stack.push((
+                                second_res,
+                                current_index + 1,
+                                lut_carry_extract,
+                            ));
+                        }
+                    }
+                } else {
+                    // Only take full slots if previous columns could still carry over carries
+                    for _ in 0..slots_filled {
+                        let mut res = input_column.pop().unwrap();
+                        let mut second_res = input_column.pop().unwrap();
+                        shortint_key.unchecked_add_assign(&mut res, &second_res);
+                        for _ in 0..(max_additions_per_slot - 2) {
+                            shortint_key
+                                .unchecked_add_assign(&mut res, &input_column.pop().unwrap());
+                        }
+                        res.clone_into(&mut second_res);
+                        ciphertext_stack.push((res, current_index, lut_message_extract));
+                        if current_index != max_index {
+                            ciphertext_stack.push((
+                                second_res,
+                                current_index + 1,
+                                lut_carry_extract,
+                            ));
+                        }
+                    }
+                }
+
+                if current_index == max_index {
+                    pbs_slots_open -= slots_filled;
+                } else {
+                    // Every operation counts twice (msg and carry)
+                    pbs_slots_open -= 2 * slots_filled;
+                }
+                current_index += 1;
+            }
+
+            let mut luts: Vec<LookupVector> = Vec::with_capacity(ciphertext_stack.len());
+            let mut ciphertexts: Vec<Ciphertext> = ciphertext_stack
+                .iter()
+                .map(|(ct, _, lut)| {
+                    luts.push(*lut);
+                    (*ct).clone()
+                })
+                .collect();
+
+            if !ciphertext_stack.is_empty() {
+                self.apply_lookup_vector_packed_assign(&mut ciphertexts, &luts);
+            }
+
+            ciphertext_stack
+                .iter_mut()
+                .enumerate()
+                .for_each(|(index, ct)| ct.0.clone_from(&ciphertexts[index]));
+
+            for _ in 0..ciphertext_stack.len() {
+                let (ct, index, _) = ciphertext_stack.pop().unwrap();
+                input_list[index].push(ct);
+            }
+        }
+    }
+
+    fn unchecked_block_mul_lsb_msb<T>(&self, ct1: &T, ct2: &Ciphertext, index: usize) -> (T, T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let ct1 = self.blockshift(ct1, index);
+        let ct_len = ct1.blocks().len();
+        let shortint_key = &self.key.key.key;
+
+        let lut_vector_mul_2lsb = self.lut_mul_2lsb();
+        let lut_vector_mul_2msb = self.lut_mul_2msb();
+
+        let mut ciphertexts: Vec<Ciphertext> = vec![];
+        let mut luts: Vec<LookupVector> = vec![];
+        let mut block_indexes: Vec<usize> = vec![];
+
+        // Unchecked LSB multiply
+        ct1.blocks()
+            .iter()
+            .chain(ct1.blocks()[..ct_len - 1].iter())
+            .enumerate()
+            .filter(|(_, block)| block.degree.get() != 0)
+            .for_each(|(index, block)| {
+                let mut block = block.clone();
+                shortint_key.unchecked_apply_lookup_table_bivariate_assign_prep(&mut block, ct2);
+                let (lut, index) = if index < ct_len {
+                    (lut_vector_mul_2lsb, index)
+                } else {
+                    // Extra +1 to interleave first block of MSB,
+                    // because the first LSB block is always free of carries
+                    (lut_vector_mul_2msb, index + 1)
+                };
+
+                ciphertexts.push(block);
+                luts.push(lut);
+                block_indexes.push(index);
+            });
+
+        let max_index = 2 * ct_len - 1;
+        let to_add =
+            self.execute_short_int_multiplications(ciphertexts, &luts, block_indexes, max_index);
+
+        let mut result_lsb = self.flatten_result(to_add);
+
+        let result_msb = result_lsb.split_off(ct_len);
+        (T::from_blocks(result_lsb), T::from_blocks(result_msb))
+    }
+
+    fn execute_short_int_multiplications(
+        &self,
+        mut ciphertexts: Vec<Ciphertext>,
+        luts: &[LookupVector],
+        block_indexes: Vec<usize>,
+        max_index: usize,
+    ) -> Vec<Vec<Ciphertext>> {
+        let mut to_add: Vec<Vec<Ciphertext>> = vec![vec![]; max_index + 1];
+
+        self.apply_lookup_vector_packed_assign(&mut ciphertexts, luts);
+        for (ct, block_index) in ciphertexts.into_iter().zip(block_indexes) {
+            to_add[block_index].push(ct);
+        }
+
+        to_add
+    }
+
+    fn flatten_result(&self, result: Vec<Vec<Ciphertext>>) -> Vec<Ciphertext> {
+        let shortint_key = &self.key.key.key;
+        result
+            .into_iter()
+            .flat_map(|b| {
+                if b.is_empty() {
+                    vec![shortint_key.create_trivial(0)]
+                } else {
+                    b
+                }
+            })
+            .collect()
+    }
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/neg.rs b/tfhe/src/integer/fpga/server_key/radix/neg.rs
new file mode 100644
index 000000000..ab4cdf30a
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/neg.rs
@@ -0,0 +1,101 @@
+use crate::integer::ciphertext::IntegerRadixCiphertext;
+use crate::integer::fpga::server_key::BelfortServerKey;
+
+impl BelfortServerKey {
+    /// Homomorphically computes the opposite of a ciphertext encrypting an integer message.
+    ///
+    /// The result is returned as a new ciphertext.
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let size = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, size);
+    ///
+    /// let msg = 1u64;
+    /// let mut ctxt = cks.encrypt(msg);
+    ///
+    /// // Compute homomorphically a negation
+    /// let ct_res = sks.smart_neg_parallelized(&mut ctxt);
+    ///
+    /// // Decrypt
+    /// let dec: u64 = cks.decrypt(&ct_res);
+    /// assert_eq!(255, dec);
+    /// ```
+    pub fn smart_neg<T>(&self, ctxt: &mut T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let integer_key = &self.key.key;
+        if integer_key.is_neg_possible(ctxt).is_err() {
+            self.full_propagate(ctxt);
+        }
+        integer_key.is_neg_possible(ctxt).unwrap();
+        integer_key.unchecked_neg(ctxt)
+    }
+
+    /// Homomorphically computes the opposite of a ciphertext encrypting an integer message.
+    ///
+    /// The result is returned as a new ciphertext.
+    ///
+    /// This function, like all "default" operations (i.e. not smart, checked or unchecked), will
+    /// check that the input ciphertexts block carries are empty and clears them if it's not the
+    /// case and the operation requires it. It outputs a ciphertext whose block carries are always
+    /// empty.
+    ///
+    /// This means that when using only "default" operations, a given operation (like add for
+    /// example) has always the same performance characteristics from one call to another and
+    /// guarantees correctness by pre-emptively clearing carries of output ciphertexts.
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let size = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, size);
+    ///
+    /// let msg = 1u64;
+    ///
+    /// // Encrypt two messages:
+    /// let mut ctxt = cks.encrypt(msg);
+    ///
+    /// // Compute homomorphically a negation
+    /// let ct_res = sks.neg_parallelized(&mut ctxt);
+    ///
+    /// // Decrypt
+    /// let dec: u64 = cks.decrypt(&ct_res);
+    /// assert_eq!(255, dec);
+    /// ```
+    pub fn neg<T>(&self, ctxt: &T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let integer_key = &self.key.key;
+        let mut tmp_ctxt;
+
+        let ct = if ctxt.block_carries_are_empty() {
+            ctxt
+        } else {
+            tmp_ctxt = ctxt.clone();
+            self.full_propagate(&mut tmp_ctxt);
+            &tmp_ctxt
+        };
+
+        if integer_key.is_eligible_for_parallel_single_carry_propagation(ct.blocks().len()) {
+            let mut ct = integer_key.unchecked_neg(ct);
+            self.propagate_single_carry_parallelized_low_latency(ct.blocks_mut());
+            ct
+        } else {
+            let mut ct = integer_key.unchecked_neg(ct);
+            integer_key.full_propagate(&mut ct);
+            ct
+        }
+    }
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/reverse_bits.rs b/tfhe/src/integer/fpga/server_key/radix/reverse_bits.rs
new file mode 100644
index 000000000..72745bec5
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/reverse_bits.rs
@@ -0,0 +1,37 @@
+use crate::integer::ciphertext::IntegerRadixCiphertext;
+use crate::integer::fpga::server_key::BelfortServerKey;
+use log::warn;
+
+impl BelfortServerKey {
+    /// Reverse the bits of the integer
+    ///
+    /// # Example
+    ///
+    ///```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// let num_blocks = 4;
+    ///
+    /// // Generate the client key and the server key:
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, num_blocks);
+    ///
+    /// let msg = 0b10110100_u8;
+    ///
+    /// let ct = cks.encrypt(msg);
+    ///
+    /// // Compute homomorphically an addition:
+    /// let ct_res = sks.reverse_bits(&ct);
+    ///
+    /// // Decrypt:
+    /// let res: u8 = cks.decrypt(&ct_res);
+    /// assert_eq!(msg.reverse_bits(), res);
+    /// ```
+    pub fn reverse_bits<T>(&self, ct: &T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        warn!("Non-optimized function call. Contact Belfort if you experience a slow run.");
+        self.key.key.reverse_bits_parallelized(ct)
+    }
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/rotate.rs b/tfhe/src/integer/fpga/server_key/radix/rotate.rs
new file mode 100644
index 000000000..ad77b81bc
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/rotate.rs
@@ -0,0 +1,197 @@
+use super::shift::BarrelShifterOperation;
+use crate::integer::ciphertext::{IntegerRadixCiphertext, RadixCiphertext};
+use crate::integer::fpga::server_key::BelfortServerKey;
+
+impl BelfortServerKey {
+    //======================================================================
+    //                Rotate Right
+    //======================================================================
+
+    pub fn unchecked_rotate_right<T>(&self, ct: &T, n: &RadixCiphertext) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut result = ct.clone();
+        self.unchecked_rotate_right_assign(&mut result, n);
+        result
+    }
+
+    pub fn unchecked_rotate_right_assign<T>(&self, ct: &mut T, n: &RadixCiphertext)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.barrel_shifter(ct, n, BarrelShifterOperation::RightRotate);
+    }
+
+    pub fn smart_rotate_right_assign<T>(&self, ct: &mut T, n: &mut RadixCiphertext)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.conditional_full_propagate(ct);
+        self.conditional_full_propagate(n);
+
+        self.unchecked_rotate_right_assign(ct, n);
+    }
+
+    pub fn smart_rotate_right<T>(&self, ct: &mut T, rotate: &mut RadixCiphertext) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.conditional_full_propagate(ct);
+        self.conditional_full_propagate(rotate);
+
+        self.unchecked_rotate_right(ct, rotate)
+    }
+
+    /// Computes homomorphically a rotation of bits.
+    ///
+    /// Shifts the bits to the right by a specified amount,
+    /// `n`, wrapping the truncated bits to the beginning of the resulting integer.
+    ///
+    /// The result is returned as a new ciphertext.
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let size = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, size);
+    ///
+    /// let msg = 128u8;
+    /// let n = 2;
+    ///
+    /// let ct = cks.encrypt(msg as u64);
+    /// let n_ct = cks.encrypt(n as u64);
+    ///
+    /// let ct_res = sks.rotate_right(&ct, &n_ct);
+    ///
+    /// // Decrypt:
+    /// let dec: u64 = cks.decrypt(&ct_res);
+    /// assert_eq!(msg.rotate_right(n as u32) as u64, dec);
+    /// ```
+    pub fn rotate_right_assign<T>(&self, ct: &mut T, rotate: &RadixCiphertext)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.conditional_full_propagate(ct);
+        let mut propagated_rotate;
+
+        let rotate = if rotate.block_carries_are_empty() {
+            propagated_rotate = rotate.clone();
+            self.full_propagate(&mut propagated_rotate);
+            &propagated_rotate
+        } else {
+            rotate
+        };
+
+        self.unchecked_rotate_right_assign(ct, rotate);
+    }
+
+    pub fn rotate_right<T>(&self, ct: &T, rotate: &RadixCiphertext) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut ct_res = ct.clone();
+        self.rotate_right_assign(&mut ct_res, rotate);
+        ct_res
+    }
+
+    //======================================================================
+    //                Rotate Left
+    //======================================================================
+
+    pub fn unchecked_rotate_left<T>(&self, ct_left: &T, n: &RadixCiphertext) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut result = ct_left.clone();
+        self.unchecked_rotate_left_assign(&mut result, n);
+        result
+    }
+
+    pub fn unchecked_rotate_left_assign<T>(&self, ct: &mut T, n: &RadixCiphertext)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.barrel_shifter(ct, n, BarrelShifterOperation::LeftRotate);
+    }
+
+    pub fn smart_rotate_left_assign<T>(&self, ct: &mut T, n: &mut RadixCiphertext)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.conditional_full_propagate(ct);
+        self.conditional_full_propagate(n);
+
+        self.unchecked_rotate_left_assign(ct, n);
+    }
+
+    pub fn smart_rotate_left<T>(&self, ct: &mut T, rotate: &mut RadixCiphertext) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.conditional_full_propagate(ct);
+        self.conditional_full_propagate(rotate);
+
+        self.unchecked_rotate_left(ct, rotate)
+    }
+
+    pub fn rotate_left_assign<T>(&self, ct: &mut T, rotate: &RadixCiphertext)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.conditional_full_propagate(ct);
+
+        let mut propagated_rotate;
+        let rotate = if rotate.block_carries_are_empty() {
+            propagated_rotate = rotate.clone();
+            self.full_propagate(&mut propagated_rotate);
+            &propagated_rotate
+        } else {
+            rotate
+        };
+
+        self.unchecked_rotate_left_assign(ct, rotate);
+    }
+
+    /// Computes homomorphically a rotation of bits.
+    ///
+    /// Shifts the bits to the left by a specified amount,
+    /// `n`, wrapping the truncated bits to the end of the resulting integer.
+    ///
+    /// The result is returned as a new ciphertext.
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let size = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, size);
+    ///
+    /// let msg = 128u8;
+    /// let n = 2;
+    ///
+    /// let ct = cks.encrypt(msg as u64);
+    /// let n_ct = cks.encrypt(n as u64);
+    ///
+    /// let ct_res = sks.rotate_left(&ct, &n_ct);
+    ///
+    /// // Decrypt:
+    /// let dec: u64 = cks.decrypt(&ct_res);
+    /// assert_eq!(msg.rotate_left(n as u32) as u64, dec);
+    /// ```
+    pub fn rotate_left<T>(&self, ct: &T, rotate: &RadixCiphertext) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut ct_res = ct.clone();
+        self.rotate_left_assign(&mut ct_res, rotate);
+        ct_res
+    }
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/scalar_add.rs b/tfhe/src/integer/fpga/server_key/radix/scalar_add.rs
new file mode 100644
index 000000000..d6d3c196a
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/scalar_add.rs
@@ -0,0 +1,160 @@
+use crate::core_crypto::prelude::UnsignedNumeric;
+use crate::integer::block_decomposition::DecomposableInto;
+use crate::integer::ciphertext::IntegerRadixCiphertext;
+use crate::integer::fpga::server_key::BelfortServerKey;
+use crate::integer::{BooleanBlock, RadixCiphertext};
+use log::warn;
+
+impl BelfortServerKey {
+    pub fn overflowing_scalar_add_assign<T, Scalar>(
+        &self,
+        lhs: &mut T,
+        scalar: Scalar,
+    ) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u8>,
+    {
+        warn!("Non-optimized function call. Contact Belfort if you experience a slow run.");
+        self.key
+            .key
+            .overflowing_scalar_add_assign_parallelized(lhs, scalar)
+    }
+
+    pub fn overflowing_scalar_add<T, Scalar>(&self, lhs: &T, scalar: Scalar) -> (T, BooleanBlock)
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u8>,
+    {
+        let mut result = lhs.clone();
+        let overflowed = self.overflowing_scalar_add_assign(&mut result, scalar);
+        (result, overflowed)
+    }
+
+    pub fn unsigned_overflowing_scalar_add_assign<Scalar>(
+        &self,
+        lhs: &mut RadixCiphertext,
+        scalar: Scalar,
+    ) -> BooleanBlock
+    where
+        Scalar: UnsignedNumeric + DecomposableInto<u8>,
+    {
+        self.overflowing_scalar_add_assign(lhs, scalar)
+    }
+
+    pub fn unsigned_overflowing_scalar_add<Scalar>(
+        &self,
+        lhs: &RadixCiphertext,
+        scalar: Scalar,
+    ) -> (RadixCiphertext, BooleanBlock)
+    where
+        Scalar: UnsignedNumeric + DecomposableInto<u8>,
+    {
+        self.overflowing_scalar_add(lhs, scalar)
+    }
+    /// Computes homomorphically the addition of ciphertext with a scalar.
+    ///
+    /// The result is returned in a new ciphertext.
+    ///
+    /// This function, like all "default" operations (i.e. not smart, checked or unchecked), will
+    /// check that the input ciphertexts block carries are empty and clears them if it's not the
+    /// case and the operation requires it. It outputs a ciphertext whose block carries are always
+    /// empty.
+    ///
+    /// This means that when using only "default" operations, a given operation (like add for
+    /// example) has always the same performance characteristics from one call to another and
+    /// guarantees correctness by pre-emptively clearing carries of output ciphertexts.
+    pub fn scalar_add<T, Scalar>(&self, ct: &T, scalar: Scalar) -> T
+    where
+        Scalar: DecomposableInto<u8>,
+        T: IntegerRadixCiphertext,
+    {
+        let mut ct_res = ct.clone();
+        self.scalar_add_assign(&mut ct_res, scalar);
+        ct_res
+    }
+
+    /// Computes homomorphically the addition of ciphertext with a scalar.
+    ///
+    /// The result is assigned to the `ct_left` ciphertext.
+    ///
+    /// This function, like all "default" operations (i.e. not smart, checked or unchecked), will
+    /// check that the input ciphertexts block carries are empty and clears them if it's not the
+    /// case and the operation requires it. It outputs a ciphertext whose block carries are always
+    /// empty.
+    ///
+    /// This means that when using only "default" operations, a given operation (like add for
+    /// example) has always the same performance characteristics from one call to another and
+    /// guarantees correctness by pre-emptively clearing carries of output ciphertexts.
+    pub fn scalar_add_assign<T, Scalar>(&self, ct: &mut T, scalar: Scalar)
+    where
+        Scalar: DecomposableInto<u8>,
+        T: IntegerRadixCiphertext,
+    {
+        self.conditional_full_propagate(ct);
+
+        let integer_key = &self.key.key;
+        if integer_key.is_eligible_for_parallel_single_carry_propagation(ct.blocks().len()) {
+            self.unchecked_scalar_add_assign(ct, scalar);
+            self.propagate_single_carry_parallelized_low_latency(ct.blocks_mut());
+        } else {
+            self.unchecked_scalar_add_assign(ct, scalar);
+            self.full_propagate(ct);
+        }
+    }
+
+    pub fn unchecked_scalar_add<T, Scalar>(&self, ct: &mut T, scalar: Scalar) -> T
+    where
+        Scalar: DecomposableInto<u8>,
+        T: IntegerRadixCiphertext,
+    {
+        self.key.key.unchecked_scalar_add(ct, scalar)
+    }
+
+    /// Computes homomorphically an addition between a scalar and a ciphertext.
+    ///
+    /// This function computes the operation without checking if it exceeds the capacity of the
+    /// ciphertext.
+    ///
+    /// The result is assigned to the `ct_left` ciphertext.
+    pub fn unchecked_scalar_add_assign<T, C>(&self, ct: &mut C, scalar: T)
+    where
+        T: DecomposableInto<u8>,
+        C: IntegerRadixCiphertext,
+    {
+        self.key.key.unchecked_scalar_add_assign(ct, scalar);
+    }
+
+    /// Computes homomorphically the addition of ciphertext with a scalar.
+    ///
+    /// The result is returned in a new ciphertext.
+    pub fn smart_scalar_add<T, Scalar>(&self, ct: &mut T, scalar: Scalar) -> T
+    where
+        Scalar: DecomposableInto<u8>,
+        T: IntegerRadixCiphertext,
+    {
+        let integer_key = &self.key.key;
+
+        if integer_key.is_scalar_add_possible(ct, scalar).is_err() {
+            self.full_propagate(ct);
+        }
+        integer_key.is_scalar_add_possible(ct, scalar).unwrap();
+        integer_key.unchecked_scalar_add(ct, scalar)
+    }
+
+    /// Computes homomorphically the addition of ciphertext with a scalar.
+    ///
+    /// The result is assigned to the `ct_left` ciphertext.
+    pub fn smart_scalar_add_assign<T, Scalar>(&self, ct: &mut T, scalar: Scalar)
+    where
+        Scalar: DecomposableInto<u8>,
+        T: IntegerRadixCiphertext,
+    {
+        let integer_key = &self.key.key;
+        if integer_key.is_scalar_add_possible(ct, scalar).is_err() {
+            self.full_propagate(ct);
+        }
+        integer_key.is_scalar_add_possible(ct, scalar).unwrap();
+        integer_key.unchecked_scalar_add_assign(ct, scalar);
+    }
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/scalar_bitwise_op.rs b/tfhe/src/integer/fpga/server_key/radix/scalar_bitwise_op.rs
new file mode 100644
index 000000000..c40512fda
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/scalar_bitwise_op.rs
@@ -0,0 +1,437 @@
+use crate::integer::block_decomposition::{BlockDecomposer, DecomposableInto};
+use crate::integer::ciphertext::{IntegerRadixCiphertext, RadixCiphertext};
+use crate::shortint::ciphertext::Degree;
+use crate::BelfortServerKey;
+
+impl BelfortServerKey {
+    pub fn unchecked_scalar_bitand<T, Scalar>(&self, lhs: &T, rhs: Scalar) -> T
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u8>,
+    {
+        let mut result = lhs.clone();
+        self.unchecked_scalar_bitand_assign(&mut result, rhs);
+        result
+    }
+
+    pub fn unchecked_scalar_bitand_assign<T, Scalar>(&self, lhs: &mut T, rhs: Scalar)
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u8>,
+    {
+        let integer_key = &self.key.key;
+        let shortint_key = &integer_key.key;
+
+        let message_modulus = integer_key.message_modulus().0;
+        assert!(message_modulus.is_power_of_two());
+
+        let clear_blocks = BlockDecomposer::with_early_stop_at_zero(rhs, message_modulus.ilog2())
+            .iter_as::<u8>()
+            .collect::<Vec<_>>();
+
+        let mut luts = Vec::new();
+        let mut blocks_vec = Vec::new();
+        let mut new_degrees = Vec::new();
+
+        lhs.blocks_mut()
+            .iter_mut()
+            .zip(clear_blocks.iter().copied())
+            .for_each(|(lhs_block, clear_block)| {
+                let new_degree = lhs_block
+                    .degree
+                    .after_bitand(Degree::new(clear_block as u64));
+
+                new_degrees.push(new_degree);
+
+                let lut_scalar_bit_and = if clear_block < 4 {
+                    shortint_key.generate_lookup_vector(&|x| x & (clear_block as u64))
+                } else {
+                    panic!("Unexpected clear_block value: {clear_block}")
+                };
+
+                blocks_vec.push(lhs_block);
+                luts.push(lut_scalar_bit_and)
+            });
+
+        self.apply_lookup_vector_mut_packed_assign(&mut blocks_vec, &luts);
+
+        Self::update_degrees(lhs, new_degrees);
+
+        let num_clear_blocks = clear_blocks.len();
+        if num_clear_blocks < lhs.blocks().len() {
+            // Blocks beyond clear_blocks.len() should be 'bitanded'
+            // with '0', however, no matter the block value the result will be 0
+            for block in &mut lhs.blocks_mut()[num_clear_blocks..] {
+                shortint_key.create_trivial_assign(block, 0);
+            }
+        }
+    }
+
+    pub fn smart_scalar_bitand<T, Scalar>(&self, lhs: &mut T, rhs: Scalar) -> T
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u8>,
+    {
+        self.conditional_full_propagate(lhs);
+        let mut result = lhs.clone();
+        self.unchecked_scalar_bitand_assign(&mut result, rhs);
+        result
+    }
+
+    pub fn smart_scalar_bitand_assign<T, Scalar>(&self, lhs: &mut T, rhs: Scalar)
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u8>,
+    {
+        self.conditional_full_propagate(lhs);
+        self.unchecked_scalar_bitand_assign(lhs, rhs);
+    }
+
+    /// Computes homomorphically a bitand between a ciphertexts and a clear value
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // Generate the client key and the server key:
+    /// let num_blocks = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, num_blocks);
+    ///
+    /// let msg1 = 14u8;
+    /// let msg2 = 97u8;
+    ///
+    /// let ct1 = cks.encrypt(msg1);
+    ///
+    /// let ct_res = sks.scalar_bitand(&ct1, msg2);
+    ///
+    /// // Decrypt:
+    /// let dec_result: u8 = cks.decrypt(&ct_res);
+    /// assert_eq!(dec_result, msg1 & msg2);
+    /// ```
+    pub fn scalar_bitand<T, Scalar>(&self, lhs: &T, rhs: Scalar) -> T
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u8>,
+    {
+        let mut result = lhs.clone();
+        self.scalar_bitand_assign(&mut result, rhs);
+        result
+    }
+
+    /// Computes homomorphically a bitand between a ciphertexts and a clear value
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // Generate the client key and the server key:
+    /// let num_blocks = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, num_blocks);
+    ///
+    /// let msg1 = 123u8;
+    /// let msg2 = 34u8;
+    ///
+    /// let mut ct1 = cks.encrypt(msg1);
+    ///
+    /// sks.scalar_bitand_assign(&mut ct1, msg2);
+    ///
+    /// // Decrypt:
+    /// let dec_result: u8 = cks.decrypt(&ct1);
+    /// assert_eq!(dec_result, msg1 & msg2);
+    /// ```
+    pub fn scalar_bitand_assign<T, Scalar>(&self, lhs: &mut T, rhs: Scalar)
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u8>,
+    {
+        self.conditional_full_propagate(lhs);
+        self.unchecked_scalar_bitand_assign(lhs, rhs);
+    }
+
+    pub fn unchecked_scalar_bitor<T, Scalar>(&self, lhs: &T, rhs: Scalar) -> T
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u8>,
+    {
+        let mut result = lhs.clone();
+        self.unchecked_scalar_bitor_assign(&mut result, rhs);
+        result
+    }
+
+    pub fn unchecked_scalar_bitor_assign<T, Scalar>(&self, lhs: &mut T, rhs: Scalar)
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u8>,
+    {
+        let shortint_key = &self.key.key.key;
+        let message_modulus = shortint_key.message_modulus.0;
+        assert!(message_modulus.is_power_of_two());
+
+        let clear_blocks =
+            BlockDecomposer::with_early_stop_at_zero(rhs, message_modulus.ilog2()).iter_as::<u8>();
+
+        let mut luts = Vec::new();
+        let mut blocks_vec = Vec::new();
+        let mut new_degrees = Vec::new();
+
+        lhs.blocks_mut()
+            .iter_mut()
+            .zip(clear_blocks)
+            .for_each(|(lhs_block, clear_block)| {
+                let clear_block = clear_block as u64;
+                let new_degree = lhs_block.degree.after_bitor(Degree::new(clear_block));
+                new_degrees.push(new_degree);
+
+                let lut_scalar_bit_or = if clear_block < 4 {
+                    shortint_key.generate_lookup_vector(&|x| x | clear_block)
+                } else {
+                    panic!("Unexpected clear_block value: {clear_block}")
+                };
+
+                blocks_vec.push(lhs_block);
+                luts.push(lut_scalar_bit_or)
+            });
+
+        self.apply_lookup_vector_mut_packed_assign(&mut blocks_vec, &luts);
+
+        Self::update_degrees(lhs, new_degrees);
+
+        // Blocks beyond clear_blocks.len() should be 'ored'
+        // with '0', which means they keep their value
+    }
+
+    pub fn smart_scalar_bitor<T, Scalar>(&self, lhs: &mut T, rhs: Scalar) -> T
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u8>,
+    {
+        self.conditional_full_propagate(lhs);
+        let mut result = lhs.clone();
+        self.unchecked_scalar_bitor_assign(&mut result, rhs);
+        result
+    }
+
+    pub fn smart_scalar_bitor_assign<T, Scalar>(&self, lhs: &mut T, rhs: Scalar)
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u8>,
+    {
+        self.conditional_full_propagate(lhs);
+        self.unchecked_scalar_bitor_assign(lhs, rhs);
+    }
+
+    /// Computes homomorphically a bitor between a ciphertexts and a clear value
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // Generate the client key and the server key:
+    /// let num_blocks = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, num_blocks);
+    ///
+    /// let msg1 = 14u8;
+    /// let msg2 = 97u8;
+    ///
+    /// let ct1 = cks.encrypt(msg1);
+    ///
+    /// let ct_res = sks.scalar_bitor(&ct1, msg2);
+    ///
+    /// // Decrypt:
+    /// let dec_result: u8 = cks.decrypt(&ct_res);
+    /// assert_eq!(dec_result, msg1 | msg2);
+    /// ```
+    pub fn scalar_bitor<T, Scalar>(&self, lhs: &T, rhs: Scalar) -> T
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u8>,
+    {
+        let mut result = lhs.clone();
+        self.scalar_bitor_assign(&mut result, rhs);
+        result
+    }
+
+    /// Computes homomorphically a bitor between a ciphertexts and a clear value
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // Generate the client key and the server key:
+    /// let num_blocks = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, num_blocks);
+    ///
+    /// let msg1 = 123u8;
+    /// let msg2 = 34u8;
+    ///
+    /// let mut ct1 = cks.encrypt(msg1);
+    ///
+    /// sks.scalar_bitor_assign(&mut ct1, msg2);
+    ///
+    /// // Decrypt:
+    /// let dec_result: u8 = cks.decrypt(&ct1);
+    /// assert_eq!(dec_result, msg1 | msg2);
+    /// ```
+    pub fn scalar_bitor_assign<T, Scalar>(&self, lhs: &mut T, rhs: Scalar)
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u8>,
+    {
+        self.conditional_full_propagate(lhs);
+        self.unchecked_scalar_bitor_assign(lhs, rhs);
+    }
+
+    pub fn unchecked_scalar_bitxor<T, Scalar>(&self, lhs: &T, rhs: Scalar) -> T
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u8>,
+    {
+        let mut result = lhs.clone();
+        self.unchecked_scalar_bitxor_assign(&mut result, rhs);
+        result
+    }
+
+    pub fn unchecked_scalar_bitxor_assign<T, Scalar>(&self, lhs: &mut T, rhs: Scalar)
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u8>,
+    {
+        let shortint_key = &self.key.key.key;
+        let message_modulus = shortint_key.message_modulus.0;
+        assert!(message_modulus.is_power_of_two());
+
+        let clear_blocks =
+            BlockDecomposer::with_early_stop_at_zero(rhs, message_modulus.ilog2()).iter_as::<u8>();
+
+        let mut luts = Vec::new();
+        let mut blocks_vec = Vec::new();
+        let mut new_degrees = Vec::new();
+
+        lhs.blocks_mut()
+            .iter_mut()
+            .zip(clear_blocks)
+            .for_each(|(lhs_block, clear_block)| {
+                let clear_block = clear_block as u64;
+                let new_degree = lhs_block.degree.after_bitxor(Degree::new(clear_block));
+                new_degrees.push(new_degree);
+
+                let lut_scalar_bit_xor = if clear_block < 4 {
+                    shortint_key.generate_lookup_vector(&|x| x ^ clear_block)
+                } else {
+                    panic!("Unexpected clear_block value: {clear_block}")
+                };
+
+                blocks_vec.push(lhs_block);
+                luts.push(lut_scalar_bit_xor)
+            });
+
+        self.apply_lookup_vector_mut_packed_assign(&mut blocks_vec, &luts);
+
+        Self::update_degrees(lhs, new_degrees);
+
+        // Blocks beyond clear_blocks.len() should be 'xored'
+        // with '0', which means they keep their value
+    }
+
+    pub fn smart_scalar_bitxor<T, Scalar>(&self, lhs: &mut T, rhs: Scalar) -> T
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u8>,
+    {
+        self.conditional_full_propagate(lhs);
+        let mut result = lhs.clone();
+        self.unchecked_scalar_bitxor_assign(&mut result, rhs);
+        result
+    }
+
+    pub fn smart_scalar_bitxor_assign<T, Scalar>(&self, lhs: &mut RadixCiphertext, rhs: Scalar)
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u8>,
+    {
+        self.conditional_full_propagate(lhs);
+        self.unchecked_scalar_bitxor_assign(lhs, rhs);
+    }
+
+    /// Computes homomorphically a bitxor between a ciphertexts and a clear value
+    ///
+    /// # Examples
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // Generate the client key and the server key:
+    /// let num_blocks = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, num_blocks);
+    ///
+    /// let msg1 = 14u8;
+    /// let msg2 = 97u8;
+    ///
+    /// let ct1 = cks.encrypt(msg1);
+    ///
+    /// let ct_res = sks.scalar_bitxor(&ct1, msg2);
+    ///
+    /// // Decrypt:
+    /// let dec_result: u8 = cks.decrypt(&ct_res);
+    /// assert_eq!(dec_result, msg1 ^ msg2);
+    /// ```
+    pub fn scalar_bitxor<T, Scalar>(&self, lhs: &T, rhs: Scalar) -> T
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u8>,
+    {
+        let mut result = lhs.clone();
+        self.scalar_bitxor_assign(&mut result, rhs);
+        result
+    }
+
+    /// Computes homomorphically a bitxor between a ciphertexts and a clear value
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // Generate the client key and the server key:
+    /// let num_blocks = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, num_blocks);
+    ///
+    /// let msg1 = 123u8;
+    /// let msg2 = 34u8;
+    ///
+    /// let mut ct1 = cks.encrypt(msg1);
+    ///
+    /// sks.scalar_bitxor_assign(&mut ct1, msg2);
+    ///
+    /// // Decrypt:
+    /// let dec_result: u8 = cks.decrypt(&ct1);
+    /// assert_eq!(dec_result, msg1 ^ msg2);
+    /// ```
+    pub fn scalar_bitxor_assign<T, Scalar>(&self, lhs: &mut T, rhs: Scalar)
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u8>,
+    {
+        self.conditional_full_propagate(lhs);
+        self.unchecked_scalar_bitxor_assign(lhs, rhs);
+    }
+
+    fn update_degrees<T: IntegerRadixCiphertext>(lhs: &mut T, new_degrees: Vec<Degree>) {
+        lhs.blocks_mut()
+            .iter_mut()
+            .zip(new_degrees)
+            .for_each(|(lhs_block, new_degree)| {
+                lhs_block.degree = new_degree;
+            });
+    }
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/scalar_comparison.rs b/tfhe/src/integer/fpga/server_key/radix/scalar_comparison.rs
new file mode 100644
index 000000000..29f2ffd99
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/scalar_comparison.rs
@@ -0,0 +1,659 @@
+use crate::core_crypto::fpga::lookup_vector::LookupVector;
+use crate::integer::block_decomposition::{BlockDecomposer, DecomposableInto};
+use crate::integer::fpga::server_key::comparator::Comparator;
+use crate::integer::fpga::server_key::BelfortServerKey;
+use crate::integer::server_key::comparator::*;
+use crate::integer::{BooleanBlock, IntegerRadixCiphertext};
+use crate::shortint::ciphertext::Degree;
+use crate::shortint::Ciphertext;
+
+#[derive(Clone, Copy, PartialEq)]
+enum EqualitySelector {
+    Eq,
+    Ne,
+}
+
+impl BelfortServerKey {
+    /// This takes a Vec of shortint blocks, where each block is
+    /// either 0 or 1.
+    ///
+    /// It returns a shortint block encrypting 1 if all input blocks are 1
+    /// otherwise the block encrypts 0
+    ///
+    /// if the vec is empty, a trivial 1 is returned
+    pub(crate) fn are_all_comparisons_block_true(
+        &self,
+        mut block_comparisons: Vec<Ciphertext>,
+    ) -> Ciphertext {
+        let shortint_key = &self.key.key.key;
+
+        if block_comparisons.is_empty() {
+            return shortint_key.create_trivial(1);
+        }
+
+        let max_sum_size = self.key.key.max_sum_size(Degree::new(1));
+
+        while block_comparisons.len() > 1 {
+            // Since all blocks encrypt either 0 or 1, we can sum max_value of them
+            // as in the worst case we will be adding `max_value` ones
+            let sums_and_luts = block_comparisons.chunks(max_sum_size).map(|blocks| {
+                let mut sum = blocks[0].clone();
+                for other_block in &blocks[1..] {
+                    shortint_key.unchecked_add_assign(&mut sum, other_block);
+                }
+
+                let lut_is_equal_to = {
+                    let len_block = blocks.len() as u64;
+                    let func = if len_block < 16 {
+                        |x| u64::from((x & 15_u64) == len_block)
+                    } else {
+                        panic!("Unexpected blocks.len() value: {}", blocks.len())
+                    };
+                    shortint_key.generate_lookup_vector(&func)
+                };
+                (sum, lut_is_equal_to)
+            });
+
+            let (mut sums, luts): (Vec<Ciphertext>, Vec<LookupVector>) = sums_and_luts.unzip();
+
+            self.apply_lookup_vector_packed_assign(&mut sums, &luts);
+
+            block_comparisons.clear();
+            block_comparisons.extend(sums);
+        }
+
+        block_comparisons
+            .into_iter()
+            .next()
+            .expect("one block was expected")
+    }
+
+    /// This takes a Vec of shortint blocks, where each block is
+    /// either 0 or 1.
+    ///
+    /// It returns a shortint block encrypting 1 if at least input blocks is 1
+    /// otherwise the block encrypts 0 (all blocks encrypts 0)
+    ///
+    /// if the vec is empty, a trivial 1 is returned
+    pub(crate) fn is_at_least_one_comparisons_block_true(
+        &self,
+        mut block_comparisons: Vec<Ciphertext>,
+    ) -> Ciphertext {
+        let shortint_key = &self.key.key.key;
+
+        let max_sum_size = self.key.key.max_sum_size(Degree::new(1));
+
+        while block_comparisons.len() > 1 {
+            block_comparisons = block_comparisons
+                .chunks(max_sum_size)
+                .map(|blocks| {
+                    let mut sum = blocks[0].clone();
+                    for other_block in &blocks[1..] {
+                        shortint_key.unchecked_add_assign(&mut sum, other_block);
+                    }
+                    sum
+                })
+                .collect();
+
+            let lut_is_non_zero = {
+                let func = |x| u64::from(x != 0);
+                shortint_key.generate_lookup_vector(&func)
+            };
+
+            self.apply_same_lookup_vector_packed_assign(&mut block_comparisons, lut_is_non_zero);
+        }
+
+        block_comparisons
+            .into_iter()
+            .next()
+            .expect("one block was expected")
+    }
+
+    pub(crate) fn are_all_blocks_zero(&self, ciphertexts: &[Ciphertext]) -> Ciphertext {
+        let block_comparisons =
+            self.compare_blocks_with_zero(ciphertexts, ZeroComparisonType::Equality);
+        self.are_all_comparisons_block_true(block_comparisons)
+    }
+
+    /// This takes an input slice of blocks.
+    ///
+    /// Each block can encrypt any value as long as its < message_modulus.
+    ///
+    /// It will compare blocks with 0, for either equality or difference.
+    ///
+    /// This returns a Vec of block, where each block encrypts 1 or 0
+    /// depending on if all blocks matched with the comparison type with 0.
+    ///
+    /// E.g. For ZeroComparisonType::Equality, if all input blocks are zero
+    /// than all returned block will encrypt 1
+    ///
+    /// The returned Vec will have less block than the number of input blocks.
+    /// The returned blocks potentially needs to be 'reduced' to one block
+    /// with e.g. are_all_comparisons_block_true.
+    ///
+    /// This function exists because sometimes it is faster to concatenate
+    /// multiple vec of 'boolean' shortint block before reducing them with
+    /// are_all_comparisons_block_true
+    pub(crate) fn compare_blocks_with_zero(
+        &self,
+        lhs: &[Ciphertext],
+        comparison_type: ZeroComparisonType,
+    ) -> Vec<Ciphertext> {
+        if lhs.is_empty() {
+            return vec![];
+        }
+
+        debug_assert!(lhs.iter().all(Ciphertext::carry_is_empty));
+
+        let shortint_key = &self.key.key.key;
+
+        // The idea is that we will sum chunks of blocks until carries are full
+        // then we compare the sum with 0.
+        //
+        // If all blocks were 0, the sum will be zero
+        // If at least one bock was not zero, the sum won't be zero
+        let num_elements_to_fill_carry = self.get_additions_to_fill_carry();
+        let lut_is_mod_equal_to_zero = {
+            if matches!(comparison_type, ZeroComparisonType::Equality) {
+                let func_is_mod_equal_to_zero = |x| {
+                    u64::from(
+                        x % (shortint_key.message_modulus.0 * shortint_key.carry_modulus.0) == 0,
+                    )
+                };
+                shortint_key.generate_lookup_vector(&func_is_mod_equal_to_zero)
+            } else {
+                let func_is_mod_not_equal_to_zero = |x| {
+                    u64::from(
+                        x % (shortint_key.message_modulus.0 * shortint_key.carry_modulus.0) != 0,
+                    )
+                };
+                shortint_key.generate_lookup_vector(&func_is_mod_not_equal_to_zero)
+            }
+        };
+
+        let mut result = lhs
+            .chunks(num_elements_to_fill_carry)
+            .map(|chunk| {
+                let mut sum = chunk[0].clone();
+                for other_block in &chunk[1..] {
+                    shortint_key.unchecked_add_assign(&mut sum, other_block);
+                }
+                sum
+            })
+            .collect::<Vec<_>>();
+
+        self.apply_same_lookup_vector_packed_assign(&mut result, lut_is_mod_equal_to_zero);
+
+        result
+    }
+
+    /// Given a slice of scalar values, and a total_modulus
+    /// where  each scalar value is < total_modulus
+    ///
+    /// This will return a vector of size `total_modulus`,
+    /// where for each index, the vec contains either
+    /// - `None` if fhe scalar was not present in the slice,
+    /// - or `Some` lookuptable that allows to compare a shortint block to the scalar value at this
+    ///   index
+    ///
+    ///
+    ///  E.g.
+    ///  - input slice: [0, 2],
+    ///  - total_modulus: 4, returns -> [Some(LUT(|x| x == 0)), None, Some(LUT(|x| x == 2), None]
+    fn create_scalar_comparison_luts(
+        &self,
+        scalar_blocks: &[u8],
+        comparison_type: EqualitySelector,
+    ) -> Vec<LookupVector> {
+        let shortint_key = &self.key.key.key;
+
+        // One lut per scalar block
+        // And only generate a lut for scalar block
+        // actually present
+        let mut scalar_comp_luts = Vec::new();
+
+        for scalar_block in scalar_blocks.iter().copied() {
+            match comparison_type {
+                EqualitySelector::Eq => {
+                    let lut_is_equal_to = {
+                        let func = if scalar_block < 16 {
+                            |x| u64::from((x & 15_u64) == scalar_block as u64)
+                        } else {
+                            panic!("Unexpected scalar_block value: {scalar_block}")
+                        };
+                        shortint_key.generate_lookup_vector(&func)
+                    };
+
+                    scalar_comp_luts.push(lut_is_equal_to);
+                }
+                EqualitySelector::Ne => {
+                    let lut_is_not_equal_to = {
+                        let func = if scalar_block < 16 {
+                            |x| u64::from((x & 15_u64) != scalar_block as u64)
+                        } else {
+                            panic!("Unexpected scalar_block value: {scalar_block}")
+                        };
+                        shortint_key.generate_lookup_vector(&func)
+                    };
+
+                    scalar_comp_luts.push(lut_is_not_equal_to);
+                }
+            }
+        }
+        scalar_comp_luts
+    }
+
+    /// Compares for equality a ciphertexts and a clear value
+    ///
+    /// Returns a ciphertext containing 1 if lhs == rhs, otherwise 0
+    ///
+    /// Requires carry bits to be empty
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// let size = 4;
+    ///
+    /// // Generate the client key and the server key:
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, size);
+    ///
+    /// let msg1 = 14u64;
+    /// let msg2 = 97u64;
+    ///
+    /// let ct1 = cks.encrypt(msg1);
+    ///
+    /// let ct_res = sks.unchecked_scalar_eq(&ct1, msg2);
+    ///
+    /// // Decrypt:
+    /// let dec_result = cks.decrypt_bool(&ct_res);
+    /// assert_eq!(dec_result, msg1 == msg2);
+    /// ```
+    pub fn unchecked_scalar_eq<T, Scalar>(&self, lhs: &T, rhs: Scalar) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+    {
+        debug_assert!(lhs.block_carries_are_empty());
+        let integer_key = &self.key.key;
+
+        if T::IS_SIGNED {
+            match integer_key.is_scalar_out_of_bounds(lhs, rhs) {
+                std::cmp::Ordering::Greater | std::cmp::Ordering::Less => {
+                    // Scalar is not within bounds so it cannot be equal
+                    return integer_key.create_trivial_boolean_block(false);
+                }
+                std::cmp::Ordering::Equal => {
+                    let trivial = integer_key.create_trivial_radix(rhs, lhs.blocks().len());
+                    return self.unchecked_eq(lhs, &trivial);
+                }
+            }
+        }
+
+        // Starting From here, we know lhs (T) is an unsigned ciphertext
+        if rhs < Scalar::ZERO {
+            return integer_key.create_trivial_boolean_block(false);
+        }
+
+        let message_modulus = integer_key.message_modulus().0;
+        let carry_modulus = integer_key.carry_modulus().0;
+        let total_modulus = message_modulus * carry_modulus;
+        let max_value = total_modulus - 1;
+
+        assert!(carry_modulus >= message_modulus);
+        u8::try_from(max_value).unwrap();
+
+        let num_blocks = lhs.blocks().len();
+        let num_blocks_halved = (num_blocks / 2) + (num_blocks % 2);
+
+        let mut scalar_blocks =
+            BlockDecomposer::with_early_stop_at_zero(rhs, total_modulus.ilog2())
+                .iter_as::<u64>()
+                .map(|x| x as u8)
+                .collect::<Vec<_>>();
+
+        // If we have more scalar blocks than lhs.blocks
+        // and that any of these additional blocks is != 0
+        // then lhs != rhs
+        let is_scalar_obviously_bigger = scalar_blocks
+            .get(num_blocks_halved..) // We may have less scalar blocks
+            .is_some_and(|sub_slice| sub_slice.iter().any(|&scalar_block| scalar_block != 0));
+        if is_scalar_obviously_bigger {
+            return integer_key.create_trivial_boolean_block(false);
+        }
+
+        // If we are sill here, that means scalar_blocks above
+        // num_blocks_halved are 0s, we can remove them
+        // as we will handle them separately.
+        // (truncate can be called even if scalar_blocks.len() < num_blocks_halved);
+        scalar_blocks.truncate(num_blocks_halved);
+
+        let scalar_comp_luts =
+            self.create_scalar_comparison_luts(&scalar_blocks, EqualitySelector::Eq);
+
+        // scalar_blocks.len() is known to be <= to num_blocks_halved
+        // but num_blocks_halved takes into account the non-even num_blocks case
+        let split_index = num_blocks.min(scalar_blocks.len() * 2);
+        let (least_significant_blocks, most_significant_blocks) =
+            lhs.blocks().split_at(split_index);
+
+        let (mut cmp_1, mut cmp_2) = {
+            let mut packed_blocks: Vec<Ciphertext> = least_significant_blocks
+                .chunks(2)
+                .map(|two_blocks| integer_key.pack_block_chunk(two_blocks))
+                .collect();
+
+            self.apply_lookup_vector_packed_assign(&mut packed_blocks, &scalar_comp_luts);
+
+            (
+                packed_blocks,
+                self.compare_blocks_with_zero(
+                    most_significant_blocks,
+                    ZeroComparisonType::Equality,
+                ),
+            )
+        };
+        cmp_1.append(&mut cmp_2);
+        let is_equal_result = self.are_all_comparisons_block_true(cmp_1);
+        BooleanBlock::new_unchecked(is_equal_result)
+    }
+
+    pub fn unchecked_scalar_ne<T, Scalar>(&self, lhs: &T, rhs: Scalar) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+    {
+        debug_assert!(lhs.block_carries_are_empty());
+        let integer_key = &self.key.key;
+
+        if T::IS_SIGNED {
+            match integer_key.is_scalar_out_of_bounds(lhs, rhs) {
+                std::cmp::Ordering::Greater | std::cmp::Ordering::Less => {
+                    // Scalar is not within bounds so its not equal
+                    return integer_key.create_trivial_boolean_block(true);
+                }
+                std::cmp::Ordering::Equal => {
+                    let trivial = integer_key.create_trivial_radix(rhs, lhs.blocks().len());
+                    return self.unchecked_ne(lhs, &trivial);
+                }
+            }
+        }
+
+        if rhs < Scalar::ZERO {
+            return integer_key.create_trivial_boolean_block(true);
+        }
+
+        let message_modulus = integer_key.message_modulus().0;
+        let carry_modulus = integer_key.carry_modulus().0;
+        let total_modulus = message_modulus * carry_modulus;
+        let max_value = total_modulus - 1;
+
+        assert!(carry_modulus >= message_modulus);
+        u8::try_from(max_value).unwrap();
+
+        let num_blocks = lhs.blocks().len();
+        let num_blocks_halved = (num_blocks / 2) + (num_blocks % 2);
+
+        let mut scalar_blocks =
+            BlockDecomposer::with_early_stop_at_zero(rhs, total_modulus.ilog2())
+                .iter_as::<u64>()
+                .map(|x| x as u8)
+                .collect::<Vec<_>>();
+
+        // If we have more scalar blocks than lhs.blocks
+        // and that any of these block additional blocks is != 0
+        // then lhs != rhs
+        let is_scalar_obviously_bigger = scalar_blocks
+            .get(num_blocks_halved..) // We may have less scalar blocks
+            .is_some_and(|sub_slice| sub_slice.iter().any(|&scalar_block| scalar_block != 0));
+        if is_scalar_obviously_bigger {
+            return integer_key.create_trivial_boolean_block(true);
+        }
+        // If we are sill here, that means scalar_blocks above
+        // num_blocks_halved are 0s, we can remove them
+        // as we will handle them separately.
+        // (truncate can be called even if scalar_blocks.len() < num_blocks_halved);
+        scalar_blocks.truncate(num_blocks_halved);
+
+        let scalar_comp_luts =
+            self.create_scalar_comparison_luts(&scalar_blocks, EqualitySelector::Ne);
+
+        // scalar_blocks.len() is known to be <= to num_blocks_halved
+        // but num_blocks_halved takes into account the non-even num_blocks case
+        let split_index = num_blocks.min(scalar_blocks.len() * 2);
+        let (least_significant_blocks, most_significant_blocks) =
+            lhs.blocks().split_at(split_index);
+
+        let (mut cmp_1, mut cmp_2) = {
+            let mut packed_blocks: Vec<Ciphertext> = least_significant_blocks
+                .chunks(2)
+                .map(|two_blocks| integer_key.pack_block_chunk(two_blocks))
+                .collect();
+
+            self.apply_lookup_vector_packed_assign(&mut packed_blocks, &scalar_comp_luts);
+
+            (
+                packed_blocks,
+                self.compare_blocks_with_zero(
+                    most_significant_blocks,
+                    ZeroComparisonType::Difference,
+                ),
+            )
+        };
+        cmp_1.append(&mut cmp_2);
+        let is_equal_result = self.is_at_least_one_comparisons_block_true(cmp_1);
+        BooleanBlock::new_unchecked(is_equal_result)
+    }
+
+    pub fn smart_scalar_eq<T, Scalar>(&self, lhs: &mut T, rhs: Scalar) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+    {
+        self.conditional_full_propagate(lhs);
+        self.unchecked_scalar_eq(lhs, rhs)
+    }
+
+    pub fn scalar_eq<T, Scalar>(&self, lhs: &T, rhs: Scalar) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+    {
+        let mut tmp_lhs;
+        let lhs = if lhs.block_carries_are_empty() {
+            lhs
+        } else {
+            tmp_lhs = lhs.clone();
+            self.full_propagate(&mut tmp_lhs);
+            &tmp_lhs
+        };
+        self.unchecked_scalar_eq(lhs, rhs)
+    }
+
+    pub fn smart_scalar_ne<T, Scalar>(&self, lhs: &mut T, rhs: Scalar) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+    {
+        self.conditional_full_propagate(lhs);
+        self.unchecked_scalar_ne(lhs, rhs)
+    }
+
+    pub fn scalar_ne<T, Scalar>(&self, lhs: &T, rhs: Scalar) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+    {
+        let mut tmp_lhs;
+        let lhs = if lhs.block_carries_are_empty() {
+            lhs
+        } else {
+            tmp_lhs = lhs.clone();
+            self.full_propagate(&mut tmp_lhs);
+            &tmp_lhs
+        };
+        self.unchecked_scalar_ne(lhs, rhs)
+    }
+
+    /// Computes homomorphically if lhs > rhs
+    pub fn scalar_gt<T, Scalar>(&self, lhs: &T, rhs: Scalar) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+    {
+        let mut ct_res = lhs.clone();
+        self.smart_scalar_gt(&mut ct_res, rhs)
+    }
+
+    pub fn smart_scalar_gt<T, Scalar>(&self, lhs: &mut T, rhs: Scalar) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+    {
+        self.conditional_full_propagate(lhs);
+        Comparator::new(self).scalar_gt(lhs, rhs)
+    }
+
+    pub fn unchecked_scalar_gt<T, Scalar>(&self, lhs: &T, rhs: Scalar) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+    {
+        Comparator::new(self).unchecked_scalar_gt(lhs, rhs)
+    }
+
+    /// Computes homomorphically if lhs >= rhs
+    pub fn scalar_ge<T, Scalar>(&self, lhs: &T, rhs: Scalar) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+    {
+        let mut ct_res = lhs.clone();
+        self.smart_scalar_ge(&mut ct_res, rhs)
+    }
+
+    pub fn smart_scalar_ge<T, Scalar>(&self, lhs: &mut T, rhs: Scalar) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+    {
+        self.conditional_full_propagate(lhs);
+        Comparator::new(self).scalar_ge(lhs, rhs)
+    }
+
+    pub fn unchecked_scalar_ge<T, Scalar>(&self, lhs: &T, rhs: Scalar) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+    {
+        Comparator::new(self).unchecked_scalar_ge(lhs, rhs)
+    }
+
+    pub fn scalar_lt<T, Scalar>(&self, lhs: &T, rhs: Scalar) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+    {
+        let mut ct_res = lhs.clone();
+        self.smart_scalar_lt(&mut ct_res, rhs)
+    }
+
+    pub fn smart_scalar_lt<T, Scalar>(&self, lhs: &mut T, rhs: Scalar) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+    {
+        self.conditional_full_propagate(lhs);
+        Comparator::new(self).scalar_lt(lhs, rhs)
+    }
+
+    pub fn unchecked_scalar_lt<T, Scalar>(&self, lhs: &T, rhs: Scalar) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+    {
+        Comparator::new(self).unchecked_scalar_lt(lhs, rhs)
+    }
+
+    /// Compute homomorphically lhs <= rhs
+    pub fn scalar_le<T, Scalar>(&self, lhs: &T, rhs: Scalar) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+    {
+        let mut ct_res = lhs.clone();
+        self.smart_scalar_le(&mut ct_res, rhs)
+    }
+
+    pub fn smart_scalar_le<T, Scalar>(&self, lhs: &mut T, rhs: Scalar) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+    {
+        self.conditional_full_propagate(lhs);
+        Comparator::new(self).scalar_le(lhs, rhs)
+    }
+
+    pub fn unchecked_scalar_le<T, Scalar>(&self, lhs: &T, rhs: Scalar) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+    {
+        Comparator::new(self).unchecked_scalar_le(lhs, rhs)
+    }
+
+    /// Computes homomorphically the maximum between a ciphertext and a scalar value
+    pub fn scalar_max<T, Scalar>(&self, lhs: &T, rhs: Scalar) -> T
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+    {
+        let mut ct_res = lhs.clone();
+        self.smart_scalar_max(&mut ct_res, rhs)
+    }
+
+    pub fn smart_scalar_max<T, Scalar>(&self, lhs: &mut T, rhs: Scalar) -> T
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+    {
+        self.conditional_full_propagate(lhs);
+        Comparator::new(self).scalar_max(lhs, rhs)
+    }
+
+    pub fn unchecked_scalar_max<T, Scalar>(&self, lhs: &T, rhs: Scalar) -> T
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+    {
+        Comparator::new(self).unchecked_scalar_min_or_max(lhs, rhs, MinMaxSelector::Max)
+    }
+
+    pub fn scalar_min<T, Scalar>(&self, lhs: &T, rhs: Scalar) -> T
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+    {
+        let mut ct_res = lhs.clone();
+        self.smart_scalar_min(&mut ct_res, rhs)
+    }
+
+    pub fn smart_scalar_min<T, Scalar>(&self, lhs: &mut T, rhs: Scalar) -> T
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+    {
+        self.conditional_full_propagate(lhs);
+        Comparator::new(self).scalar_min(lhs, rhs)
+    }
+
+    pub fn unchecked_scalar_min<T, Scalar>(&self, lhs: &T, rhs: Scalar) -> T
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+    {
+        Comparator::new(self).unchecked_scalar_min_or_max(lhs, rhs, MinMaxSelector::Min)
+    }
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/scalar_div_mod.rs b/tfhe/src/integer/fpga/server_key/radix/scalar_div_mod.rs
new file mode 100644
index 000000000..60103fd5d
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/scalar_div_mod.rs
@@ -0,0 +1,392 @@
+use crate::integer::block_decomposition::DecomposableInto;
+use crate::integer::ciphertext::{RadixCiphertext, SignedRadixCiphertext};
+use crate::integer::fpga::server_key::BelfortServerKey;
+use crate::integer::server_key::radix_parallel::scalar_div_mod::SignedReciprocable;
+use crate::integer::server_key::{MiniUnsignedInteger, Reciprocable, ScalarMultiplier};
+use log::warn;
+
+impl BelfortServerKey {
+    pub fn scalar_div<T>(&self, numerator: &RadixCiphertext, divisor: T) -> RadixCiphertext
+    where
+        T: Reciprocable + DecomposableInto<u8>,
+    {
+        let mut result = numerator.clone();
+        self.scalar_div_assign(&mut result, divisor);
+        result
+    }
+
+    pub fn scalar_div_assign<T>(&self, numerator: &mut RadixCiphertext, divisor: T)
+    where
+        T: Reciprocable + DecomposableInto<u8>,
+    {
+        self.conditional_full_propagate(numerator);
+        *numerator = self.unchecked_scalar_div(numerator, divisor);
+    }
+
+    pub fn scalar_rem<T>(&self, numerator: &RadixCiphertext, divisor: T) -> RadixCiphertext
+    where
+        T: Reciprocable + ScalarMultiplier + DecomposableInto<u8>,
+    {
+        let mut result = numerator.clone();
+        self.scalar_rem_assign(&mut result, divisor);
+        result
+    }
+
+    pub fn scalar_rem_assign<T>(&self, numerator: &mut RadixCiphertext, divisor: T)
+    where
+        T: Reciprocable + ScalarMultiplier + DecomposableInto<u8>,
+    {
+        warn!("Non-optimized function call. Contact Belfort if you experience a slow run.");
+        self.conditional_full_propagate(numerator);
+        *numerator = self
+            .key
+            .key
+            .unchecked_scalar_rem_parallelized(numerator, divisor);
+    }
+
+    pub fn unchecked_scalar_div<T>(
+        &self,
+        numerator: &RadixCiphertext,
+        divisor: T,
+    ) -> RadixCiphertext
+    where
+        T: Reciprocable,
+    {
+        warn!("Non-optimized function call. Contact Belfort if you experience a slow run.");
+        self.key
+            .key
+            .unchecked_scalar_div_parallelized(numerator, divisor)
+    }
+
+    /// # Note
+    /// This division rounds (truncates) the quotient towards zero
+    pub fn unchecked_signed_scalar_div<T>(
+        &self,
+        numerator: &SignedRadixCiphertext,
+        divisor: T,
+    ) -> SignedRadixCiphertext
+    where
+        T: SignedReciprocable,
+        <<T as SignedReciprocable>::Unsigned as Reciprocable>::DoublePrecision: Send,
+    {
+        warn!("Non-optimized function call. Contact Belfort if you experience a slow run.");
+        self.key
+            .key
+            .unchecked_signed_scalar_div_parallelized(numerator, divisor)
+    }
+
+    /// # Note
+    ///
+    /// - This division rounds (truncates) the quotient towards 0
+    pub fn unchecked_signed_scalar_div_rem<T>(
+        &self,
+        numerator: &SignedRadixCiphertext,
+        divisor: T,
+    ) -> (SignedRadixCiphertext, SignedRadixCiphertext)
+    where
+        T: SignedReciprocable + ScalarMultiplier,
+        <<T as SignedReciprocable>::Unsigned as Reciprocable>::DoublePrecision: Send,
+    {
+        let quotient = self.unchecked_signed_scalar_div(numerator, divisor);
+
+        // remainder = numerator - (quotient * divisor)
+        let tmp = self.unchecked_scalar_mul(&quotient, divisor);
+        let remainder = self.sub(numerator, &tmp);
+
+        (quotient, remainder)
+    }
+
+    /// # Note
+    ///
+    /// - This division rounds (truncates) the quotient towards 0
+    /// - If you need both the quotient and remainder use
+    ///   [Self::unchecked_signed_scalar_div_rem_parallelized] instead.
+    pub fn unchecked_signed_scalar_rem<T>(
+        &self,
+        numerator: &SignedRadixCiphertext,
+        divisor: T,
+    ) -> SignedRadixCiphertext
+    where
+        T: SignedReciprocable + ScalarMultiplier,
+        <<T as SignedReciprocable>::Unsigned as Reciprocable>::DoublePrecision: Send,
+    {
+        let (_, remainder) = self.unchecked_signed_scalar_div_rem(numerator, divisor);
+
+        remainder
+    }
+
+    /// Computes and returns the quotient and remainder of the division between
+    /// a signed ciphertext and a signed clear value.
+    ///
+    /// # Note
+    ///
+    /// - This division rounds (truncates) the quotient towards 0
+    pub fn signed_scalar_div_rem<T>(
+        &self,
+        numerator: &SignedRadixCiphertext,
+        divisor: T,
+    ) -> (SignedRadixCiphertext, SignedRadixCiphertext)
+    where
+        T: SignedReciprocable + ScalarMultiplier,
+        <<T as SignedReciprocable>::Unsigned as Reciprocable>::DoublePrecision: Send,
+    {
+        if numerator.block_carries_are_empty() {
+            self.unchecked_signed_scalar_div_rem(numerator, divisor)
+        } else {
+            let mut tmp = numerator.clone();
+            self.full_propagate(&mut tmp);
+            self.unchecked_signed_scalar_div_rem(&tmp, divisor)
+        }
+    }
+
+    /// Computes the quotient of the division between
+    /// a signed ciphertext and a signed clear value and assigns the
+    /// result to the input ciphertext.
+    ///
+    /// # Note
+    ///
+    /// - This division rounds (truncates) the quotient towards 0
+    pub fn signed_scalar_div_assign<T>(&self, numerator: &mut SignedRadixCiphertext, divisor: T)
+    where
+        T: SignedReciprocable,
+        <<T as SignedReciprocable>::Unsigned as Reciprocable>::DoublePrecision: Send,
+    {
+        self.conditional_full_propagate(numerator);
+
+        *numerator = self.unchecked_signed_scalar_div(numerator, divisor);
+    }
+
+    /// Computes and returns the quotient of the division between
+    /// a signed ciphertext and a signed clear value.
+    ///
+    /// # Note
+    ///
+    /// - This division rounds (truncates) the quotient towards 0
+    /// - If you need both the quotient and remainder use [Self::signed_scalar_div_rem] instead.
+    pub fn signed_scalar_div<T>(
+        &self,
+        numerator: &SignedRadixCiphertext,
+        divisor: T,
+    ) -> SignedRadixCiphertext
+    where
+        T: SignedReciprocable,
+        <<T as SignedReciprocable>::Unsigned as Reciprocable>::DoublePrecision: Send,
+    {
+        let mut result = numerator.clone();
+        self.signed_scalar_div_assign(&mut result, divisor);
+        result
+    }
+
+    /// Computes and returns the remainder of the division between
+    /// a signed ciphertext and a signed clear value.
+    ///
+    /// # Note
+    ///
+    /// - If you need both the quotient and remainder use [Self::signed_scalar_div_rem] instead.
+    pub fn signed_scalar_rem<T>(
+        &self,
+        numerator: &SignedRadixCiphertext,
+        divisor: T,
+    ) -> SignedRadixCiphertext
+    where
+        T: SignedReciprocable + ScalarMultiplier,
+        <<T as SignedReciprocable>::Unsigned as Reciprocable>::DoublePrecision: Send,
+    {
+        let mut result = numerator.clone();
+        self.signed_scalar_rem_assign(&mut result, divisor);
+        result
+    }
+
+    /// Computes the remainder of the division between
+    /// a signed ciphertext and a signed clear value and assigns the
+    /// result to the input ciphertext.
+    pub fn signed_scalar_rem_assign<T>(&self, numerator: &mut SignedRadixCiphertext, divisor: T)
+    where
+        T: SignedReciprocable + ScalarMultiplier,
+        <<T as SignedReciprocable>::Unsigned as Reciprocable>::DoublePrecision: Send,
+    {
+        self.conditional_full_propagate(numerator);
+
+        let remainder = self.unchecked_signed_scalar_rem(numerator, divisor);
+        *numerator = remainder;
+    }
+
+    /// # Note
+    /// This division rounds the quotient towards minus infinity
+    pub fn unchecked_signed_scalar_div_floor<T>(
+        &self,
+        numerator: &SignedRadixCiphertext,
+        divisor: T,
+    ) -> SignedRadixCiphertext
+    where
+        T: SignedReciprocable,
+        <<T as SignedReciprocable>::Unsigned as Reciprocable>::DoublePrecision: Send,
+    {
+        warn!("Non-optimized function call. Contact Belfort if you experience a slow run.");
+
+        self.key
+            .key
+            .unchecked_signed_scalar_div_floor_parallelized(numerator, divisor)
+    }
+
+    /// # Note
+    /// This division rounds the quotient towards minus infinity
+    pub fn unchecked_signed_scalar_div_rem_floor<T>(
+        &self,
+        numerator: &SignedRadixCiphertext,
+        divisor: T,
+    ) -> (SignedRadixCiphertext, SignedRadixCiphertext)
+    where
+        T: SignedReciprocable + ScalarMultiplier,
+        <<T as SignedReciprocable>::Unsigned as Reciprocable>::DoublePrecision: Send,
+    {
+        let quotient = self.unchecked_signed_scalar_div_floor(numerator, divisor);
+
+        // remainder = numerator - (quotient * divisor)
+        let tmp = self.unchecked_scalar_mul(&quotient, divisor);
+        let remainder = self.sub(numerator, &tmp);
+
+        (quotient, remainder)
+    }
+
+    pub fn unchecked_scalar_div_rem<T>(
+        &self,
+        numerator: &RadixCiphertext,
+        divisor: T,
+    ) -> (RadixCiphertext, RadixCiphertext)
+    where
+        T: Reciprocable + ScalarMultiplier + DecomposableInto<u8>,
+    {
+        let quotient = self.unchecked_scalar_div(numerator, divisor);
+        let remainder = if MiniUnsignedInteger::is_power_of_two(divisor) {
+            // unchecked_scalar_div would have panicked if divisor was zero
+            self.scalar_bitand(numerator, divisor - T::ONE)
+        } else {
+            // remainder = numerator - (quotient * divisor)
+            let tmp = self.unchecked_scalar_mul(&quotient, divisor);
+            self.sub(numerator, &tmp)
+        };
+
+        (quotient, remainder)
+    }
+
+    pub fn unchecked_scalar_rem<T>(
+        &self,
+        numerator: &RadixCiphertext,
+        divisor: T,
+    ) -> RadixCiphertext
+    where
+        T: Reciprocable + ScalarMultiplier + DecomposableInto<u8>,
+    {
+        if MiniUnsignedInteger::is_power_of_two(divisor) {
+            // The remainder is simply the bits that would get 'shifted out'
+            return self.scalar_bitand(numerator, divisor - T::ONE);
+        }
+
+        let (_quotient, remainder) = self.unchecked_scalar_div_rem(numerator, divisor);
+        remainder
+    }
+
+    pub fn smart_scalar_div_assign<T>(&self, numerator: &mut RadixCiphertext, divisor: T)
+    where
+        T: Reciprocable + DecomposableInto<u8>,
+    {
+        self.conditional_full_propagate(numerator);
+
+        *numerator = self.unchecked_scalar_div(numerator, divisor);
+    }
+
+    pub fn smart_scalar_rem_assign<T>(&self, numerator: &mut RadixCiphertext, divisor: T)
+    where
+        T: Reciprocable + ScalarMultiplier + DecomposableInto<u8>,
+    {
+        self.conditional_full_propagate(numerator);
+
+        *numerator = self.unchecked_scalar_rem(numerator, divisor);
+    }
+
+    pub fn smart_scalar_div<T>(
+        &self,
+        numerator: &mut RadixCiphertext,
+        divisor: T,
+    ) -> RadixCiphertext
+    where
+        T: Reciprocable + DecomposableInto<u8>,
+    {
+        self.conditional_full_propagate(numerator);
+
+        self.unchecked_scalar_div(numerator, divisor)
+    }
+
+    pub fn smart_scalar_rem<T>(
+        &self,
+        numerator: &mut RadixCiphertext,
+        divisor: T,
+    ) -> RadixCiphertext
+    where
+        T: Reciprocable + ScalarMultiplier + DecomposableInto<u8>,
+    {
+        self.conditional_full_propagate(numerator);
+
+        self.unchecked_scalar_rem(numerator, divisor)
+    }
+
+    pub fn smart_scalar_div_rem<T>(
+        &self,
+        numerator: &mut RadixCiphertext,
+        divisor: T,
+    ) -> (RadixCiphertext, RadixCiphertext)
+    where
+        T: Reciprocable + ScalarMultiplier + DecomposableInto<u8>,
+    {
+        self.conditional_full_propagate(numerator);
+
+        self.unchecked_scalar_div_rem(numerator, divisor)
+    }
+
+    /// Computes homomorphically the euclidean the division of a ciphertext by a scalar.
+    ///
+    /// # Panics
+    ///
+    /// Panics if scalar is zero.
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let size = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2, size);
+    ///
+    /// let msg = 230u8;
+    /// let scalar = 12u8;
+    ///
+    /// let ct = cks.encrypt(msg);
+    ///
+    /// // Compute homomorphically a scalar division:
+    /// let (q, r) = sks.scalar_div_rem(&ct, scalar);
+    ///
+    /// let decrypted_quotient: u8 = cks.decrypt(&q);
+    /// let decrypted_remainder: u8 = cks.decrypt(&r);
+    /// assert_eq!(msg / scalar, decrypted_quotient);
+    /// assert_eq!(msg % scalar, decrypted_remainder);
+    /// ```
+    pub fn scalar_div_rem<T>(
+        &self,
+        numerator: &RadixCiphertext,
+        divisor: T,
+    ) -> (RadixCiphertext, RadixCiphertext)
+    where
+        T: Reciprocable + ScalarMultiplier + DecomposableInto<u8>,
+    {
+        if numerator.block_carries_are_empty() {
+            self.unchecked_scalar_div_rem(numerator, divisor)
+        } else {
+            let mut cloned_numerator = numerator.clone();
+            self.full_propagate(&mut cloned_numerator);
+            self.unchecked_scalar_div_rem(&cloned_numerator, divisor)
+        }
+    }
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/scalar_mul.rs b/tfhe/src/integer/fpga/server_key/radix/scalar_mul.rs
new file mode 100644
index 000000000..6731af14e
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/scalar_mul.rs
@@ -0,0 +1,213 @@
+use crate::integer::block_decomposition::{BlockDecomposer, DecomposableInto};
+use crate::integer::ciphertext::IntegerRadixCiphertext;
+use crate::integer::server_key::ScalarMultiplier;
+use crate::BelfortServerKey;
+
+impl BelfortServerKey {
+    pub fn unchecked_scalar_mul<T, Scalar>(&self, ct: &T, scalar: Scalar) -> T
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: ScalarMultiplier + DecomposableInto<u8>,
+    {
+        let mut ct_res = ct.clone();
+        self.unchecked_scalar_mul_assign(&mut ct_res, scalar);
+        ct_res
+    }
+
+    pub fn unchecked_scalar_mul_assign<T, Scalar>(&self, lhs: &mut T, scalar: Scalar)
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: ScalarMultiplier + DecomposableInto<u8>,
+    {
+        let integer_key = &self.key.key;
+        let shortint_key = &integer_key.key;
+
+        if scalar == Scalar::ZERO || lhs.blocks().is_empty() {
+            for block in lhs.blocks_mut() {
+                shortint_key.create_trivial_assign(block, 0);
+            }
+            return;
+        }
+
+        if scalar == Scalar::ONE {
+            return;
+        }
+
+        if scalar.is_power_of_two() {
+            // Shifting cost one bivariate PBS so its always faster
+            // than multiplying
+            self.unchecked_scalar_left_shift_assign(lhs, scalar.ilog2() as u64);
+            return;
+        }
+
+        let num_blocks = lhs.blocks().len();
+        let msg_bits = shortint_key.message_modulus.0.ilog2() as usize;
+
+        let scalar_bits = BlockDecomposer::with_early_stop_at_zero(scalar, 1)
+            .iter_as::<u8>()
+            .collect::<Vec<_>>();
+
+        // We don't want to compute shifts if we are not going to use the
+        // resulting value
+        let mut has_at_least_one_set = vec![false; msg_bits];
+        for (i, bit) in scalar_bits.iter().copied().enumerate() {
+            if bit == 1 {
+                has_at_least_one_set[i % msg_bits] = true;
+            }
+        }
+
+        // Contains all shifted values of lhs for shift in range (0..msg_bits)
+        // The idea is that with these we can create all other shift that are in
+        // range (0..total_bits) for free (block rotation)
+        let preshifted_lhs = (0..msg_bits)
+            .map(|shift_amount| {
+                if has_at_least_one_set[shift_amount] {
+                    self.unchecked_scalar_left_shift(lhs, shift_amount)
+                } else {
+                    integer_key.create_trivial_zero_radix(num_blocks)
+                }
+            })
+            .collect::<Vec<_>>();
+
+        let num_ciphertext_bits = msg_bits * num_blocks;
+        let all_shifted_lhs = scalar_bits
+            .iter()
+            .enumerate()
+            .take(num_ciphertext_bits) // shift beyond that are technically resulting in 0s
+            .filter(|(_, &rhs_bit)| rhs_bit == 1)
+            .map(|(i, _)| integer_key.blockshift(&preshifted_lhs[i % msg_bits], i / msg_bits))
+            .collect::<Vec<_>>();
+
+        if let Some(result) = self.unchecked_sum_ciphertexts_vec(all_shifted_lhs) {
+            *lhs = result;
+        } else {
+            integer_key.create_trivial_zero_assign_radix(lhs);
+        }
+    }
+
+    /// Computes homomorphically a multiplication between a scalar and a ciphertext.
+    ///
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let modulus = 1 << 8;
+    /// let size = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, size);
+    ///
+    /// let msg = 230;
+    /// let scalar = 376;
+    ///
+    /// let mut ct = cks.encrypt(msg);
+    ///
+    /// // Compute homomorphically a scalar multiplication:
+    /// let ct_res = sks.smart_scalar_mul(&mut ct, scalar);
+    ///
+    /// // Decrypt:
+    /// let clear: u64 = cks.decrypt(&ct_res);
+    /// assert_eq!(msg * scalar % modulus, clear);
+    /// ```
+    pub fn smart_scalar_mul<T, Scalar>(&self, lhs: &mut T, scalar: Scalar) -> T
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: ScalarMultiplier + DecomposableInto<u8>,
+    {
+        self.conditional_full_propagate(lhs);
+        self.unchecked_scalar_mul(lhs, scalar)
+    }
+
+    pub fn smart_scalar_mul_assign<T, Scalar>(&self, lhs: &mut T, scalar: Scalar)
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: ScalarMultiplier + DecomposableInto<u8>,
+    {
+        self.conditional_full_propagate(lhs);
+        self.unchecked_scalar_mul_assign(lhs, scalar);
+    }
+
+    /// Computes homomorphically a multiplication between a scalar and a ciphertext.
+    ///
+    /// This function, like all "default" operations (i.e. not smart, checked or unchecked), will
+    /// check that the input ciphertexts block carries are empty and clears them if it's not the
+    /// case and the operation requires it. It outputs a ciphertext whose block carries are always
+    /// empty.
+    ///
+    /// This means that when using only "default" operations, a given operation (like add for
+    /// example) has always the same performance characteristics from one call to another and
+    /// guarantees correctness by pre-emptively clearing carries of output ciphertexts.
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let modulus = 1 << 8;
+    /// let size = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, size);
+    ///
+    /// let msg = 230;
+    /// let scalar = 376;
+    ///
+    /// let mut ct = cks.encrypt(msg);
+    ///
+    /// // Compute homomorphically a scalar multiplication:
+    /// let ct_res = sks.scalar_mul(&mut ct, scalar);
+    ///
+    /// // Decrypt:
+    /// let clear: u64 = cks.decrypt(&ct_res);
+    /// assert_eq!(msg * scalar % modulus, clear);
+    /// ```
+    pub fn scalar_mul<T, Scalar>(&self, ct: &T, scalar: Scalar) -> T
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: ScalarMultiplier + DecomposableInto<u8>,
+    {
+        let mut ct_res = ct.clone();
+        self.scalar_mul_assign(&mut ct_res, scalar);
+        ct_res
+    }
+
+    pub fn scalar_mul_assign<T, Scalar>(&self, lhs: &mut T, scalar: Scalar)
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: ScalarMultiplier + DecomposableInto<u8>,
+    {
+        self.conditional_full_propagate(lhs);
+        self.unchecked_scalar_mul_assign(lhs, scalar);
+    }
+
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let size = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, size);
+    ///
+    /// let msg = 1u64;
+    /// let power = 2;
+    ///
+    /// let ct = cks.encrypt(msg);
+    ///
+    /// // Compute homomorphically a scalar multiplication:
+    /// let ct_res = sks.blockshift(&ct, power);
+    ///
+    /// // Decrypt:
+    /// let clear: u64 = cks.decrypt(&ct_res);
+    /// assert_eq!(16, clear);
+    /// ```
+    pub fn blockshift<T>(&self, ctxt: &T, shift: usize) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.key.key.blockshift(ctxt, shift)
+    }
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/scalar_rotate.rs b/tfhe/src/integer/fpga/server_key/radix/scalar_rotate.rs
new file mode 100644
index 000000000..39fce74c6
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/scalar_rotate.rs
@@ -0,0 +1,660 @@
+use crate::core_crypto::prelude::CastFrom;
+use crate::integer::ciphertext::IntegerRadixCiphertext;
+use crate::BelfortServerKey;
+
+impl BelfortServerKey {
+    //======================================================================
+    //                Rotate Right
+    //======================================================================
+
+    /// Computes homomorphically a rotation of bits.
+    ///
+    /// Shifts the bits to the right by a specified amount,
+    /// `n`, wrapping the truncated bits to the beginning of the resulting integer.
+    ///
+    /// If necessary the carries of the input will be cleaned beforehand,
+    /// but its value won't change, the result is returned in a new ciphertext
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let size = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, size);
+    ///
+    /// let msg = 128u8;
+    /// let n = 2;
+    ///
+    /// let mut ct = cks.encrypt(msg as u64);
+    ///
+    /// let ct_res = sks.smart_scalar_rotate_right(&mut ct, n);
+    ///
+    /// // Decrypt:
+    /// let dec: u64 = cks.decrypt(&ct_res);
+    /// assert_eq!(msg.rotate_right(n as u32) as u64, dec);
+    /// ```
+    pub fn smart_scalar_rotate_right<T, Scalar>(&self, ct: &mut T, n: Scalar) -> T
+    where
+        T: IntegerRadixCiphertext,
+        u64: CastFrom<Scalar>,
+    {
+        self.conditional_full_propagate(ct);
+        self.unchecked_scalar_rotate_right(ct, n)
+    }
+
+    /// Computes homomorphically a rotation of bits.
+    ///
+    /// Shifts the bits to the right by a specified amount,
+    /// `n`, wrapping the truncated bits to the beginning of the resulting integer.
+    ///
+    /// The result is assigned to the input ciphertext
+    ///
+    /// If necessary carries will be cleaned beforehand
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let size = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, size);
+    ///
+    /// let msg = 128u8;
+    /// let n = 2;
+    ///
+    /// let mut ct = cks.encrypt(msg as u64);
+    ///
+    /// sks.smart_scalar_rotate_right_assign(&mut ct, n);
+    ///
+    /// // Decrypt:
+    /// let dec: u64 = cks.decrypt(&ct);
+    /// assert_eq!(msg.rotate_right(n as u32) as u64, dec);
+    /// ```
+    pub fn smart_scalar_rotate_right_assign<T, Scalar>(&self, ct: &mut T, n: Scalar)
+    where
+        T: IntegerRadixCiphertext,
+        u64: CastFrom<Scalar>,
+    {
+        self.conditional_full_propagate(ct);
+        self.unchecked_scalar_rotate_right_assign(ct, n);
+    }
+
+    /// Computes homomorphically a rotation of bits.
+    ///
+    /// Shifts the bits to the right by a specified amount,
+    /// `n`, wrapping the truncated bits to the beginning of the resulting integer.
+    ///
+    /// The result is returned as a new ciphertext.
+    ///
+    /// # Requirements
+    ///
+    /// - The blocks parameter's carry space have at least one more bit than message space
+    /// - The input ciphertext carry buffer is empty / clean
+    ///
+    /// # Output
+    ///
+    /// - The output's carries will be clean
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let size = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, size);
+    ///
+    /// let msg = 128u8;
+    /// let n = 2;
+    ///
+    /// let ct = cks.encrypt(msg as u64);
+    ///
+    /// let ct_res = sks.scalar_rotate_right(&ct, n);
+    ///
+    /// // Decrypt:
+    /// let dec: u64 = cks.decrypt(&ct_res);
+    /// assert_eq!(msg.rotate_right(n as u32) as u64, dec);
+    /// ```
+    pub fn scalar_rotate_right<T, Scalar>(&self, ct_right: &T, n: Scalar) -> T
+    where
+        T: IntegerRadixCiphertext,
+        u64: CastFrom<Scalar>,
+    {
+        let mut result = ct_right.clone();
+        self.scalar_rotate_right_assign(&mut result, n);
+        result
+    }
+
+    /// Computes homomorphically a rotation of bits.
+    ///
+    /// Shifts the bits to the right by a specified amount,
+    /// `n`, wrapping the truncated bits to the beginning of the resulting integer.
+    ///
+    /// The result is assigned to the input ciphertext
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let size = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, size);
+    ///
+    /// let msg = 128u8;
+    /// let n = 2;
+    ///
+    /// let mut ct = cks.encrypt(msg as u64);
+    ///
+    /// sks.scalar_rotate_right_assign(&mut ct, n);
+    ///
+    /// // Decrypt:
+    /// let dec: u64 = cks.decrypt(&ct);
+    /// assert_eq!(msg.rotate_right(n as u32) as u64, dec);
+    /// ```
+    pub fn scalar_rotate_right_assign<T, Scalar>(&self, ct: &mut T, n: Scalar)
+    where
+        T: IntegerRadixCiphertext,
+        u64: CastFrom<Scalar>,
+    {
+        self.conditional_full_propagate(ct);
+        self.unchecked_scalar_rotate_right_assign(ct, n);
+    }
+
+    /// Computes homomorphically a rotation of bits.
+    ///
+    /// Shifts the bits to the right by a specified amount,
+    /// `n`, wrapping the truncated bits to the beginning of the resulting integer.
+    ///
+    /// The result is returned as a new ciphertext.
+    ///
+    /// # Requirements
+    ///
+    /// - The blocks parameter's carry space have at least one more bit than message space
+    /// - The input ciphertext carry buffer is empty / clean
+    ///
+    /// # Output
+    ///
+    /// - The output's carries will be clean
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let size = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, size);
+    ///
+    /// let msg = 128u8;
+    /// let n = 2;
+    ///
+    /// let ct = cks.encrypt(msg as u64);
+    ///
+    /// let ct_res = sks.unchecked_scalar_rotate_right(&ct, n);
+    ///
+    /// // Decrypt:
+    /// let dec: u64 = cks.decrypt(&ct_res);
+    /// assert_eq!(msg.rotate_right(n as u32) as u64, dec);
+    /// ```
+    pub fn unchecked_scalar_rotate_right<T, Scalar>(&self, ct: &T, n: Scalar) -> T
+    where
+        T: IntegerRadixCiphertext,
+        u64: CastFrom<Scalar>,
+    {
+        let mut result = ct.clone();
+        self.unchecked_scalar_rotate_right_assign(&mut result, n);
+        result
+    }
+
+    /// Computes homomorphically a rotation of bits.
+    ///
+    /// Shifts the bits to the right by a specified amount,
+    /// `n`, wrapping the truncated bits to the beginning of the resulting integer.
+    ///
+    /// The result is assigned to the input ciphertext
+    ///
+    /// # Requirements
+    ///
+    /// - The blocks parameter's carry space have at least one more bit than message space
+    /// - The input ciphertext carry buffer is empty / clean
+    ///
+    /// # Output
+    ///
+    /// - The output's carries will be clean
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let size = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, size);
+    ///
+    /// let msg = 128u8;
+    /// let n = 2;
+    ///
+    /// let mut ct = cks.encrypt(msg as u64);
+    ///
+    /// sks.unchecked_scalar_rotate_right_assign(&mut ct, n);
+    ///
+    /// // Decrypt:
+    /// let dec: u64 = cks.decrypt(&ct);
+    /// assert_eq!(msg.rotate_right(n as u32) as u64, dec);
+    /// ```
+    pub fn unchecked_scalar_rotate_right_assign<T, Scalar>(&self, ct: &mut T, n: Scalar)
+    where
+        T: IntegerRadixCiphertext,
+        u64: CastFrom<Scalar>,
+    {
+        // We know by how much we want to
+        // rotate since `n` is a clear value.
+        //
+        // Implement rotating in two step
+        // 1) rotate blocks
+        // 2) shift within each block and `propagate' the next one
+        let integer_key = &self.key.key;
+        let shortint_key = &integer_key.key;
+
+        debug_assert!(ct.block_carries_are_empty());
+        debug_assert!(integer_key.carry_modulus().0 >= integer_key.message_modulus().0 / 2);
+
+        let num_bits_in_message = integer_key.message_modulus().0.ilog2() as u64;
+        let num_blocks = ct.blocks().len();
+        let total_num_bits = num_bits_in_message * num_blocks as u64;
+
+        let n = u64::cast_from(n) % total_num_bits;
+        if n == 0 {
+            return;
+        }
+
+        let rotations = (n / num_bits_in_message) as usize;
+
+        // rotate left as the blocks are from LSB to MSB
+        ct.blocks_mut().rotate_left(rotations);
+
+        let shift_within_block = n % num_bits_in_message;
+        if shift_within_block == 0 {
+            return;
+        }
+
+        let mut new_blocks = (0..num_blocks)
+            .map(|index| {
+                // rotate_right means moving bits from MSB to LSB
+                // Since our blocks are from LSB to MSB, bits move from
+                // block `index + 1` to `index`
+                let bit_receiver_index = index;
+                let bit_giver_index = (index + 1) % num_blocks;
+
+                let mut bit_receiver_block = ct.blocks()[bit_receiver_index].clone();
+                let bit_giver_block = ct.blocks()[bit_giver_index].clone();
+
+                integer_key.pack_block_assign(&bit_giver_block, &mut bit_receiver_block);
+
+                bit_receiver_block
+            })
+            .collect::<Vec<_>>();
+
+        let lut_shift_and_propagate_swb1 = {
+            let func = |current_block, mut next_block| {
+                // left shift so as not to lose
+                // bits when shifting right afterwards
+                let message_modulus = shortint_key.message_modulus.0;
+                let num_bits_in_block = message_modulus.ilog2() as u64;
+                let shift_within_block = 1;
+
+                next_block <<= num_bits_in_block;
+                next_block >>= shift_within_block;
+
+                // The way of getting carry / message is reversed compared
+                // to the usual way but its normal:
+                // The message is in the upper bits, the carry in lower bits
+                let message_of_current_block = current_block >> shift_within_block;
+                let carry_of_previous_block = next_block % message_modulus;
+
+                message_of_current_block + carry_of_previous_block
+            };
+            shortint_key.generate_lookup_vector_bivariate(&func)
+        };
+
+        self.apply_same_lookup_vector_packed_assign(&mut new_blocks, lut_shift_and_propagate_swb1);
+        ct.blocks_mut().swap_with_slice(&mut new_blocks);
+
+        debug_assert!(ct.block_carries_are_empty());
+    }
+
+    //======================================================================
+    //                Rotate Left
+    //======================================================================
+
+    /// Computes homomorphically a rotation of bits.
+    ///
+    /// Shifts the bits to the left by a specified amount,
+    /// `n`, wrapping the truncated bits to the end of the resulting integer.
+    ///
+    /// If necessary the carries of the input will be cleaned beforehand,
+    /// but its value won't change, the result is returned in a new ciphertext
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let size = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, size);
+    ///
+    /// let msg = 128u8;
+    /// let n = 2u32;
+    ///
+    /// let mut ct = cks.encrypt(msg as u64);
+    ///
+    /// let ct_res = sks.smart_scalar_rotate_left(&mut ct, n);
+    ///
+    /// // Decrypt:
+    /// let dec: u64 = cks.decrypt(&ct_res);
+    /// assert_eq!(msg.rotate_left(n as u32) as u64, dec);
+    /// ```
+    pub fn smart_scalar_rotate_left<T, Scalar>(&self, ct: &mut T, n: Scalar) -> T
+    where
+        T: IntegerRadixCiphertext,
+        u64: CastFrom<Scalar>,
+    {
+        self.conditional_full_propagate(ct);
+        self.unchecked_scalar_rotate_left(ct, n)
+    }
+
+    /// Computes homomorphically a rotation of bits.
+    ///
+    /// Shifts the bits to the left by a specified amount,
+    /// `n`, wrapping the truncated bits to the end of the resulting integer.
+    ///
+    /// The result is assigned to the input ciphertext
+    ///
+    /// If necessary carries will be cleaned beforehand
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let size = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, size);
+    ///
+    /// let msg = 128u8;
+    /// let n = 2u32;
+    ///
+    /// let mut ct = cks.encrypt(msg as u64);
+    ///
+    /// sks.smart_scalar_rotate_left_assign(&mut ct, n);
+    ///
+    /// // Decrypt:
+    /// let dec: u64 = cks.decrypt(&ct);
+    /// assert_eq!(msg.rotate_left(n as u32) as u64, dec);
+    /// ```
+    pub fn smart_scalar_rotate_left_assign<T, Scalar>(&self, ct: &mut T, n: Scalar)
+    where
+        T: IntegerRadixCiphertext,
+        u64: CastFrom<Scalar>,
+    {
+        self.conditional_full_propagate(ct);
+        self.unchecked_scalar_rotate_left_assign(ct, n);
+    }
+
+    /// Computes homomorphically a rotation of bits.
+    ///
+    /// Shifts the bits to the left by a specified amount,
+    /// `n`, wrapping the truncated bits to the end of the resulting integer.
+    ///
+    /// The result is returned as a new ciphertext.
+    ///
+    /// # Requirements
+    ///
+    /// - The blocks parameter's carry space have at least one more bit than message space
+    /// - The input ciphertext carry buffer is empty / clean
+    ///
+    /// # Output
+    ///
+    /// - The output's carries will be clean
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let size = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, size);
+    ///
+    /// let msg = 128u8;
+    /// let n = 2u32;
+    ///
+    /// let ct = cks.encrypt(msg as u64);
+    ///
+    /// let ct_res = sks.scalar_rotate_left(&ct, n);
+    ///
+    /// // Decrypt:
+    /// let dec: u64 = cks.decrypt(&ct_res);
+    /// assert_eq!(msg.rotate_left(n as u32) as u64, dec);
+    /// ```
+    pub fn scalar_rotate_left<T, Scalar>(&self, ct_left: &T, n: Scalar) -> T
+    where
+        T: IntegerRadixCiphertext,
+        u64: CastFrom<Scalar>,
+    {
+        let mut result = ct_left.clone();
+        self.scalar_rotate_left_assign(&mut result, n);
+        result
+    }
+
+    /// Computes homomorphically a rotation of bits.
+    ///
+    /// Shifts the bits to the left by a specified amount,
+    /// `n`, wrapping the truncated bits to the end of the resulting integer.
+    ///
+    /// The result is assigned to the input ciphertext
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let size = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, size);
+    ///
+    /// let msg = 128u8;
+    /// let n = 2u32;
+    ///
+    /// let mut ct = cks.encrypt(msg as u64);
+    ///
+    /// sks.scalar_rotate_left_assign(&mut ct, n);
+    ///
+    /// // Decrypt:
+    /// let dec: u64 = cks.decrypt(&ct);
+    /// assert_eq!(msg.rotate_left(n as u32) as u64, dec);
+    /// ```
+    pub fn scalar_rotate_left_assign<T, Scalar>(&self, ct: &mut T, n: Scalar)
+    where
+        T: IntegerRadixCiphertext,
+        u64: CastFrom<Scalar>,
+    {
+        self.conditional_full_propagate(ct);
+        self.unchecked_scalar_rotate_left_assign(ct, n);
+    }
+
+    /// Computes homomorphically a rotation of bits.
+    ///
+    /// Shifts the bits to the left by a specified amount,
+    /// `n`, wrapping the truncated bits to the end of the resulting integer.
+    ///
+    /// The result is returned as a new ciphertext.
+    ///
+    /// # Requirements
+    ///
+    /// - The blocks parameter's carry space have at least one more bit than message space
+    /// - The input ciphertext carry buffer is empty / clean
+    ///
+    /// # Output
+    ///
+    /// - The output's carries will be clean
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let size = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, size);
+    ///
+    /// let msg = 128u8;
+    /// let n = 2u32;
+    ///
+    /// let ct = cks.encrypt(msg as u64);
+    ///
+    /// let ct_res = sks.unchecked_scalar_rotate_left(&ct, n);
+    ///
+    /// // Decrypt:
+    /// let dec: u64 = cks.decrypt(&ct_res);
+    /// assert_eq!(msg.rotate_left(n as u32) as u64, dec);
+    /// ```
+    pub fn unchecked_scalar_rotate_left<T, Scalar>(&self, ct: &T, n: Scalar) -> T
+    where
+        T: IntegerRadixCiphertext,
+        u64: CastFrom<Scalar>,
+    {
+        let mut result = ct.clone();
+        self.unchecked_scalar_rotate_left_assign(&mut result, n);
+        result
+    }
+
+    /// Computes homomorphically a rotation of bits.
+    ///
+    /// Shifts the bits to the left by a specified amount,
+    /// `n`, wrapping the truncated bits to the end of the resulting integer.
+    ///
+    /// The result is assigned to the input ciphertext
+    ///
+    /// # Requirements
+    ///
+    /// - The blocks parameter's carry space have at least one more bit than message space
+    /// - The input ciphertext carry buffer is empty / clean
+    ///
+    /// # Output
+    ///
+    /// - The output's carries will be clean
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let size = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, size);
+    ///
+    /// let msg = 128u8;
+    /// let n = 2u32;
+    ///
+    /// let mut ct = cks.encrypt(msg as u64);
+    ///
+    /// sks.unchecked_scalar_rotate_left_assign(&mut ct, n);
+    ///
+    /// // Decrypt:
+    /// let dec: u64 = cks.decrypt(&ct);
+    /// assert_eq!(msg.rotate_left(n as u32) as u64, dec);
+    /// ```
+    pub fn unchecked_scalar_rotate_left_assign<T, Scalar>(&self, ct: &mut T, n: Scalar)
+    where
+        T: IntegerRadixCiphertext,
+        u64: CastFrom<Scalar>,
+    {
+        // We know by how much we will rotate since `n` is a clear value.
+        //
+        // Implement rotating in two steps
+        // 1) rotate blocks
+        // 2) shift within each block and 'propagate' to the next one
+        let integer_key = &self.key.key;
+        let shortint_key = &integer_key.key;
+
+        debug_assert!(ct.block_carries_are_empty());
+        debug_assert!(integer_key.carry_modulus().0 >= integer_key.message_modulus().0 / 2);
+
+        let num_bits_in_message = integer_key.message_modulus().0.ilog2() as u64;
+        let num_blocks = ct.blocks().len();
+        let total_num_bits = num_bits_in_message * num_blocks as u64;
+
+        let n = u64::cast_from(n) % total_num_bits;
+        if n == 0 {
+            return;
+        }
+
+        let rotations = (n / num_bits_in_message) as usize;
+        let shift_within_block = n % num_bits_in_message;
+
+        // rotate right as the blocks are from LSB to MSB
+        ct.blocks_mut().rotate_right(rotations);
+
+        if shift_within_block == 0 {
+            return;
+        }
+
+        let mut new_blocks = (0..num_blocks)
+            .map(|index| {
+                // Since our blocks are from LSB to MSB, bits move from
+                // block `index - 1` to `index`
+                let bit_receiver_index = index;
+                let bit_giver_index = if index == 0 {
+                    num_blocks - 1
+                } else {
+                    index - 1
+                };
+
+                let bit_receiver_block = ct.blocks()[bit_receiver_index].clone();
+                let mut bit_giver_block = ct.blocks()[bit_giver_index].clone();
+
+                integer_key.pack_block_assign(&bit_receiver_block, &mut bit_giver_block);
+
+                bit_giver_block
+            })
+            .collect::<Vec<_>>();
+
+        let lut_create_blocks_swb1 = {
+            let func = |previous_block, current_block| {
+                let message_modulus = shortint_key.message_modulus.0;
+                let shift_within_block = 1;
+
+                let current_block = current_block << shift_within_block;
+                let previous_block = previous_block << shift_within_block;
+
+                let message_of_current_block = current_block % message_modulus;
+                let carry_of_previous_block = previous_block / message_modulus;
+                message_of_current_block + carry_of_previous_block
+            };
+            shortint_key.generate_lookup_vector_bivariate(&func)
+        };
+        self.apply_same_lookup_vector_packed_assign(&mut new_blocks, lut_create_blocks_swb1);
+
+        ct.blocks_mut().swap_with_slice(&mut new_blocks[0..]);
+
+        debug_assert!(ct.block_carries_are_empty());
+    }
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/scalar_shift.rs b/tfhe/src/integer/fpga/server_key/radix/scalar_shift.rs
new file mode 100644
index 000000000..26fea0864
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/scalar_shift.rs
@@ -0,0 +1,750 @@
+use crate::core_crypto::commons::utils::izip;
+use crate::core_crypto::fpga::lookup_vector::LookupVector;
+use crate::core_crypto::prelude::CastFrom;
+use crate::integer::ciphertext::IntegerRadixCiphertext;
+use crate::shortint::ciphertext::Degree;
+use crate::shortint::Ciphertext;
+use crate::BelfortServerKey;
+
+impl BelfortServerKey {
+    //======================================================================
+    //                Shift Right
+    //======================================================================
+
+    /// Computes homomorphically a right shift.
+    ///
+    /// The result is returned as a new ciphertext.
+    ///
+    /// # Requirements
+    ///
+    /// - The blocks parameter's carry space have at least one more bit than message space
+    /// - The input ciphertext carry buffer is empty / clean
+    ///
+    /// # Output
+    ///
+    /// - The output's carries will be clean
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let size = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, size);
+    ///
+    /// let msg = 128;
+    /// let shift = 2;
+    ///
+    /// let ct = cks.encrypt(msg);
+    ///
+    /// // Compute homomorphically a right shift:
+    /// let ct_res = sks.unchecked_scalar_right_shift(&ct, shift);
+    ///
+    /// // Decrypt:
+    /// let dec: u64 = cks.decrypt(&ct_res);
+    /// assert_eq!(msg >> shift, dec);
+    /// ```
+    pub fn unchecked_scalar_right_shift<T, Scalar>(&self, ct: &T, shift: Scalar) -> T
+    where
+        T: IntegerRadixCiphertext,
+        u64: CastFrom<Scalar>,
+    {
+        let mut result = ct.clone();
+        self.unchecked_scalar_right_shift_assign(&mut result, shift);
+        result
+    }
+
+    /// Computes homomorphically a right shift.
+    ///
+    /// # Requirements
+    ///
+    /// - The blocks parameter's carry space have at at least (message_bits - 1)
+    /// - The input ciphertext carry buffer is empty / clean
+    ///
+    /// # Output
+    ///
+    /// - The carry of the output blocks will be empty / clean
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let size = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, size);
+    ///
+    /// let msg = 18;
+    /// let shift = 4;
+    ///
+    /// let mut ct = cks.encrypt(msg);
+    ///
+    /// // Compute homomorphically a right shift:
+    /// sks.unchecked_scalar_right_shift_assign(&mut ct, shift);
+    ///
+    /// // Decrypt:
+    /// let dec: u64 = cks.decrypt(&ct);
+    /// assert_eq!(msg >> shift, dec);
+    /// ```
+    pub fn unchecked_scalar_right_shift_assign<T, Scalar>(&self, ct: &mut T, shift: Scalar)
+    where
+        T: IntegerRadixCiphertext,
+        u64: CastFrom<Scalar>,
+    {
+        if T::IS_SIGNED {
+            self.unchecked_scalar_right_shift_arithmetic_assign(ct, shift);
+        } else {
+            self.unchecked_scalar_right_shift_logical_assign(ct, shift);
+        }
+
+        debug_assert!(ct.block_carries_are_empty());
+    }
+
+    pub fn unchecked_scalar_right_shift_arithmetic<T, Scalar>(&self, ct: &T, shift: Scalar) -> T
+    where
+        T: IntegerRadixCiphertext,
+        u64: CastFrom<Scalar>,
+    {
+        let mut result = ct.clone();
+        self.unchecked_scalar_right_shift_arithmetic_assign(&mut result, shift);
+        result
+    }
+
+    pub fn unchecked_scalar_right_shift_arithmetic_assign<T, Scalar>(
+        &self,
+        ct: &mut T,
+        shift: Scalar,
+    ) where
+        T: IntegerRadixCiphertext,
+        u64: CastFrom<Scalar>,
+    {
+        // The general idea is that we know by how much we shift
+        // since `shift` is a clear value.
+        //
+        // So we can implement shifting in two steps
+        // 1) shift blocks (implemented by using rotate + replace with trivial ciphertext block
+        //    which 'wrapped around`
+        // 2) shift within each block and 'propagate' block to the next one
+        //
+        debug_assert!(ct.block_carries_are_empty());
+        let integer_key = &self.key.key;
+        let shortint_key = &integer_key.key;
+
+        let carry_modulus = shortint_key.message_modulus.0;
+        let message_modulus = shortint_key.carry_modulus.0;
+        debug_assert!(carry_modulus >= message_modulus / 2);
+
+        let num_bits_in_block = message_modulus.ilog2() as u64;
+        let num_blocks = ct.blocks().len();
+        let total_num_bits = num_bits_in_block * num_blocks as u64;
+
+        let shift = u64::cast_from(shift) % total_num_bits;
+        if shift == 0 {
+            return;
+        }
+
+        let rotations = ((shift / num_bits_in_block) as usize).min(num_blocks);
+        let shift_within_block = shift % num_bits_in_block;
+
+        // rotate left as the blocks are from LSB to MSB
+        ct.blocks_mut().rotate_left(rotations);
+
+        if num_bits_in_block == 1 {
+            // if there is only 1 bit in the msg part, it means shift_within block is 0
+            // thus only rotations are required.
+
+            // We still need to pad with the value of the sign bit.
+            // And here since a block only has 1 bit of message
+            // we can optimize things by not doing the pbs to extract this sign bit
+            let sign_bit = ct.blocks()[num_blocks - rotations - 1].clone();
+            for block in &mut ct.blocks_mut()[num_blocks - rotations..] {
+                block.clone_from(&sign_bit);
+            }
+            return;
+        }
+
+        // In the arithmetic shift case we pad with the value of the sign bit.
+        //
+        // This requires a different shifting lut than in the logical shift case
+        // and another PBS to create the padding block.
+        let (last_shifted_block, padding_block) = {
+            let last_block = &ct.blocks()[num_blocks - rotations - 1];
+
+            let lut_last_block = if shift_within_block < 2 {
+                let func_last_block_sw = |x| {
+                    let num_bits_in_block = message_modulus.ilog2() as u64;
+
+                    let x = x % message_modulus;
+                    let x_sign_bit = x >> (num_bits_in_block - 1) & 1;
+                    let shifted = x >> shift_within_block;
+
+                    let mut padding = (message_modulus - 1) * x_sign_bit;
+
+                    padding <<= num_bits_in_block - shift_within_block;
+                    padding %= message_modulus;
+
+                    shifted | padding
+                };
+                shortint_key.generate_lookup_vector(&func_last_block_sw)
+            } else {
+                panic!("Unexpected shift value: {shift_within_block:?}")
+            };
+
+            let lut_pad_block_creator = {
+                let func = |x| {
+                    let num_bits_in_block = message_modulus.ilog2() as u64;
+
+                    let x = x % message_modulus;
+                    let x_sign_bit = x >> (num_bits_in_block - 1) & 1;
+
+                    (message_modulus - 1) * x_sign_bit
+                };
+                shortint_key.generate_lookup_vector(&func)
+            };
+
+            let luts: Vec<LookupVector> = vec![lut_last_block, lut_pad_block_creator];
+            let mut ct_vec: Vec<Ciphertext> = vec![last_block.clone(), last_block.clone()];
+
+            self.apply_lookup_vector_packed_assign(&mut ct_vec, &luts);
+
+            (ct_vec[0].clone(), ct_vec[1].clone())
+        };
+
+        let partial_blocks = self.unchecked_scalar_right_shift_inner_blocks(
+            &ct.blocks()[..num_blocks - rotations],
+            shift_within_block,
+        );
+
+        ct.blocks_mut()[num_blocks - rotations - 1] = last_shifted_block;
+
+        // We started with num_blocks, discarded 'rotations' blocks
+        // and did the last one separately
+        let blocks_to_replace = &mut ct.blocks_mut()[..num_blocks - rotations - 1];
+        assert_eq!(partial_blocks.len(), blocks_to_replace.len());
+        for (block, shifted_block) in izip!(blocks_to_replace, partial_blocks) {
+            *block = shifted_block;
+        }
+
+        // Replace blocks 'pulled' from the left with the correct padding block
+        for trivial_block in &mut ct.blocks_mut()[num_blocks - rotations..] {
+            trivial_block.clone_from(&padding_block);
+        }
+
+        debug_assert!(ct.block_carries_are_empty());
+    }
+
+    pub fn unchecked_scalar_right_shift_logical_assign<T, Scalar>(&self, ct: &mut T, shift: Scalar)
+    where
+        T: IntegerRadixCiphertext,
+        u64: CastFrom<Scalar>,
+    {
+        // The general idea, is that we know by how much to shift
+        // since `shift` is a clear value.
+        //
+        // So we can implement shifting in two steps
+        // 1) shift blocks (implemented by using rotate + replace with trivial ciphertext block
+        //    which 'wrapped around`
+        // 2) shift within each block and 'propagate' block to the next one
+
+        debug_assert!(ct.block_carries_are_empty());
+        let shortint_key = &self.key.key.key;
+        let carry_modulus = shortint_key.carry_modulus.0;
+        let message_modulus = shortint_key.message_modulus.0;
+        debug_assert!(carry_modulus >= message_modulus);
+
+        let num_bits_in_block = message_modulus.ilog2() as u64;
+        let num_blocks = ct.blocks().len();
+        let total_num_bits = num_bits_in_block * num_blocks as u64;
+
+        let shift = u64::cast_from(shift) % total_num_bits;
+        if shift == 0 {
+            return;
+        }
+
+        let rotations = ((shift / num_bits_in_block) as usize).min(num_blocks);
+        let shift_within_block = shift % num_bits_in_block;
+
+        // rotate left as the blocks are from LSB to MSB
+        ct.blocks_mut().rotate_left(rotations);
+        for block in &mut ct.blocks_mut()[num_blocks - rotations..] {
+            shortint_key.create_trivial_assign(block, 0);
+        }
+
+        if shift_within_block == 0 || rotations == num_blocks {
+            // Logical shift means pulling 0s, so we are done now
+            return;
+        }
+
+        let partial_blocks = self.unchecked_scalar_right_shift_inner_blocks(
+            &ct.blocks()[..num_blocks - rotations],
+            shift_within_block,
+        );
+        let last_shifted_block: Ciphertext = {
+            // The right-most block is done separately as it does not
+            // need to recuperate the shifted bits from its right neighbour.
+            let mut block = ct.blocks()[num_blocks - rotations - 1].clone();
+
+            // Apply mutation to the cloned block
+            if shift_within_block == 1 {
+                let degree = block.degree;
+                let lut_right_shift_1 = {
+                    let func = |x| x >> 1;
+                    shortint_key.generate_lookup_vector(&func)
+                };
+                self.apply_lookup_vector_single_assign(&mut block, lut_right_shift_1);
+                block.degree = Degree::new(degree.get() >> 1);
+            }
+            block
+        };
+
+        ct.blocks_mut()[num_blocks - rotations - 1] = last_shifted_block;
+        // We started with num_blocks, discarded 'rotations' blocks
+        // and did the last one separately
+        let blocks_to_replace = &mut ct.blocks_mut()[..num_blocks - rotations - 1];
+        assert_eq!(partial_blocks.len(), blocks_to_replace.len());
+        for (block, shifted_block) in izip!(blocks_to_replace, partial_blocks) {
+            *block = shifted_block;
+        }
+
+        debug_assert!(ct.block_carries_are_empty());
+    }
+
+    /// This is in internal function to share logic between
+    /// logical right shift and arithmetic right shift.
+    ///
+    /// This functions takes a slice of blocks in little endian order
+    /// and computes right shifting of bits where each blocks pulls bits
+    /// from its right-neighbour.
+    ///
+    /// This means the returned Vec has size `inner_blocks.len() - 1`,
+    /// the block at index `inner_blocks.len() - 1` needs to be handled
+    /// by the caller (arithmetic vs logical right shift).
+    fn unchecked_scalar_right_shift_inner_blocks(
+        &self,
+        inner_blocks: &[Ciphertext],
+        shift_within_block: u64,
+    ) -> Vec<Ciphertext> {
+        let integer_key = &self.key.key;
+        let shortint_key = &integer_key.key;
+
+        let message_modulus = integer_key.message_modulus().0;
+        let num_bits_in_block = message_modulus.ilog2() as u64;
+
+        assert!(shift_within_block < num_bits_in_block);
+        assert!(!inner_blocks.is_empty());
+
+        // Since we require that carries are empty,
+        // we can use the bivariate pbs to shift and propagate in parallel at the same time
+        // instead of first shifting then propagating
+        let lut = if shift_within_block < 2 {
+            let func_shift_and_propagate = |current_block, mut next_block, shift_within_block| {
+                let num_bits_in_block = message_modulus.ilog2() as u64;
+
+                next_block <<= num_bits_in_block;
+                next_block >>= shift_within_block;
+
+                let message_of_current_block = current_block >> shift_within_block;
+                let carry_of_previous_block = next_block % message_modulus;
+
+                message_of_current_block + carry_of_previous_block
+            };
+
+            let func_with_fixed_shift = |current_block, next_block| {
+                func_shift_and_propagate(current_block, next_block, shift_within_block)
+            };
+
+            shortint_key.generate_lookup_vector_bivariate(&func_with_fixed_shift)
+        } else {
+            panic!("Unexpected shift value: {shift_within_block:?}")
+        };
+
+        let mut inner_blocks_vec = inner_blocks
+            .windows(2)
+            .map(|blocks| {
+                // We are right-shifting,
+                // so we get the bits from the next block in the vec
+                let (mut current_block, next_block) = (blocks[0].clone(), blocks[1].clone());
+                integer_key.pack_block_assign(&next_block, &mut current_block);
+
+                current_block
+            })
+            .collect::<Vec<_>>();
+
+        self.apply_same_lookup_vector_packed_assign(&mut inner_blocks_vec, lut);
+
+        inner_blocks_vec
+    }
+
+    /// Computes homomorphically a right shift.
+    ///
+    /// The result is returned as a new ciphertext.
+    ///
+    /// This function, like all "default" operations (i.e. not smart, checked or unchecked), will
+    /// check that the input ciphertexts block carries are empty and clears them if it's not the
+    /// case and the operation requires it. It outputs a ciphertext whose block carries are always
+    /// empty.
+    ///
+    /// This means that when using only "default" operations, a given operation (like add for
+    /// example) has always the same performance characteristics from one call to another and
+    /// guarantees correctness by pre-emptively clearing carries of output ciphertexts.
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let size = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, size);
+    ///
+    /// let msg = 128;
+    /// let shift = 2;
+    ///
+    /// let ct = cks.encrypt(msg);
+    ///
+    /// // Compute homomorphically a right shift:
+    /// let ct_res = sks.scalar_right_shift(&ct, shift);
+    ///
+    /// // Decrypt:
+    /// let dec: u64 = cks.decrypt(&ct_res);
+    /// assert_eq!(msg >> shift, dec);
+    /// ```
+    pub fn scalar_right_shift<T, Scalar>(&self, ct: &T, shift: Scalar) -> T
+    where
+        T: IntegerRadixCiphertext,
+        u64: CastFrom<Scalar>,
+    {
+        let mut result = ct.clone();
+        self.scalar_right_shift_assign(&mut result, shift);
+        result
+    }
+
+    /// Computes homomorphically a right shift.
+    ///
+    /// The result is returned as a new ciphertext.
+    ///
+    /// This function, like all "default" operations (i.e. not smart, checked or unchecked), will
+    /// check that the input ciphertexts block carries are empty and clears them if it's not the
+    /// case and the operation requires it. It outputs a ciphertext whose block carries are always
+    /// empty.
+    ///
+    /// This means that when using only "default" operations, a given operation (like add for
+    /// example) has always the same performance characteristics from one call to another and
+    /// guarantees correctness by pre-emptively clearing carries of output ciphertexts.
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let size = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, size);
+    ///
+    /// let msg = 18;
+    /// let shift = 4;
+    ///
+    /// let mut ct = cks.encrypt(msg);
+    ///
+    /// // Compute homomorphically a right shift:
+    /// sks.scalar_right_shift_assign(&mut ct, shift);
+    ///
+    /// // Decrypt:
+    /// let dec: u64 = cks.decrypt(&ct);
+    /// assert_eq!(msg >> shift, dec);
+    /// ```
+    pub fn scalar_right_shift_assign<T, Scalar>(&self, ct: &mut T, shift: Scalar)
+    where
+        T: IntegerRadixCiphertext,
+        u64: CastFrom<Scalar>,
+    {
+        self.conditional_full_propagate(ct);
+        self.unchecked_scalar_right_shift_assign(ct, shift);
+    }
+
+    //======================================================================
+    //                Shift Left
+    //======================================================================
+
+    /// Computes homomorphically a left shift by a scalar.
+    ///
+    /// The result is returned as a new ciphertext.
+    ///
+    /// # Requirements
+    ///
+    /// - The blocks parameter's carry space have at least one more bit than message space
+    /// - The input ciphertext carry buffer is empty / clean
+    ///
+    /// # Output
+    ///
+    /// - The output ciphertext carry buffers will be clean / empty
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let size = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, size);
+    ///
+    /// let msg = 21;
+    /// let shift = 2;
+    ///
+    /// let ct1 = cks.encrypt(msg);
+    ///
+    /// // Compute homomorphically a left shift:
+    /// let ct_res = sks.unchecked_scalar_left_shift(&ct1, shift);
+    ///
+    /// // Decrypt:
+    /// let dec: u64 = cks.decrypt(&ct_res);
+    /// assert_eq!(msg << shift, dec);
+    /// ```
+    pub fn unchecked_scalar_left_shift<T, Scalar>(&self, ct_left: &T, shift: Scalar) -> T
+    where
+        T: IntegerRadixCiphertext,
+        u64: CastFrom<Scalar>,
+    {
+        let mut result = ct_left.clone();
+        self.unchecked_scalar_left_shift_assign(&mut result, shift);
+        result
+    }
+
+    /// Computes homomorphically a left shift by a scalar.
+    ///
+    /// The result is assigned in the input ciphertext
+    ///
+    /// # Requirements
+    ///
+    /// - The blocks parameter's carry space have at least (message_bits - 1)
+    /// - The input ciphertext carry buffer is empty / clean
+    ///
+    /// # Output
+    ///
+    /// - The ct carry buffers will be clean / empty afterwards
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let size = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, size);
+    ///
+    /// let msg = 13;
+    /// let shift = 2;
+    ///
+    /// let mut ct = cks.encrypt(msg);
+    ///
+    /// // Compute homomorphically a left shift:
+    /// sks.unchecked_scalar_left_shift_assign(&mut ct, shift);
+    ///
+    /// // Decrypt:
+    /// let dec: u64 = cks.decrypt(&ct);
+    /// assert_eq!(msg << shift, dec);
+    /// ```
+    pub fn unchecked_scalar_left_shift_assign<T, Scalar>(&self, ct: &mut T, shift: Scalar)
+    where
+        T: IntegerRadixCiphertext,
+        u64: CastFrom<Scalar>,
+    {
+        // The general idea, is that we know by how much we want to shift
+        // since `shift` is a clear value.
+        //
+        // So we can use that to implement shifting in two step
+        // 1) shift blocks (implemented by using rotate + replace with trivial ciphertext block
+        //    which 'wrapped around`
+        // 2) shift within each block in propagate block to the next one
+
+        debug_assert!(ct.block_carries_are_empty());
+        let integer_key = &self.key.key;
+        let shortint_key = &integer_key.key;
+
+        let carry_modulus = shortint_key.carry_modulus.0;
+        let message_modulus = shortint_key.message_modulus.0;
+        debug_assert!(carry_modulus >= message_modulus / 2);
+
+        let num_bits_in_block = message_modulus.ilog2() as u64;
+        let total_num_bits = num_bits_in_block * ct.blocks().len() as u64;
+
+        let shift = u64::cast_from(shift) % total_num_bits;
+        if shift == 0 {
+            return;
+        }
+
+        let rotations = ((shift / num_bits_in_block) as usize).min(ct.blocks().len());
+        let shift_within_block = shift % num_bits_in_block;
+
+        // rotate right as the blocks are from LSB to MSB
+        ct.blocks_mut().rotate_right(rotations);
+        // Every block below 'rotations' should be discarded
+        for block in &mut ct.blocks_mut()[..rotations] {
+            shortint_key.create_trivial_assign(block, 0);
+        }
+
+        if shift_within_block == 0 || rotations == ct.blocks().len() {
+            return;
+        }
+
+        //
+
+        // Since we require that carries are empty,
+        // we can use the bivariate bps to shift and propagate in parallel at the same time
+        // instead of first shifting then propagating
+        //
+        // The first block is done separately as it does not
+        // need to recuperate the shifted bits from its previous block,
+        // and also that way is does not need a special case for when rotations == 0
+
+        let mut partial_blocks = ct.blocks()[rotations..]
+            .windows(2)
+            .map(|blocks| {
+                // We are right-shifting,
+                // so we get the bits from the next block in the vec
+                let (mut previous_block, current_block) = (blocks[0].clone(), blocks[1].clone());
+                integer_key.pack_block_assign(&current_block, &mut previous_block);
+
+                previous_block
+            })
+            .collect::<Vec<_>>();
+
+        let block = ct.blocks()[rotations].clone();
+        partial_blocks.push(block);
+
+        let lut_create_blocks_swb1 = {
+            let func = |previous_block, current_block| {
+                let shift_within_block = 1;
+
+                let current_block = current_block << shift_within_block;
+                let previous_block = previous_block << shift_within_block;
+
+                let message_of_current_block = current_block % message_modulus;
+                let carry_of_previous_block = previous_block / message_modulus;
+                message_of_current_block + carry_of_previous_block
+            };
+            shortint_key.generate_lookup_vector_bivariate(&func)
+        };
+
+        let lut_shift1_mod = {
+            let func = |x| {
+                let modulus = message_modulus;
+                (x << 1) % modulus
+            };
+            shortint_key.generate_lookup_vector(&func)
+        };
+
+        let mut luts = vec![lut_create_blocks_swb1; partial_blocks.len() - 1];
+        luts.push(lut_shift1_mod);
+
+        self.apply_lookup_vector_packed_assign(&mut partial_blocks, &luts);
+
+        let block = partial_blocks.pop().unwrap();
+
+        // We started with num_blocks, discarded 'rotations' blocks
+        // and did the last one separately
+        ct.blocks_mut()[rotations] = block;
+        let blocks_to_replace = &mut ct.blocks_mut()[rotations + 1..];
+        assert_eq!(partial_blocks.len(), blocks_to_replace.len());
+        for (block, shifted_block) in izip!(blocks_to_replace, partial_blocks) {
+            *block = shifted_block;
+        }
+        debug_assert!(ct.block_carries_are_empty());
+    }
+
+    /// Computes homomorphically a left shift by a scalar.
+    ///
+    /// The result is returned as a new ciphertext.
+    ///
+    /// This function, like all "default" operations (i.e. not smart, checked or unchecked), will
+    /// check that the input ciphertexts block carries are empty and clears them if it's not the
+    /// case and the operation requires it. It outputs a ciphertext whose block carries are always
+    /// empty.
+    ///
+    /// This means that when using only "default" operations, a given operation (like add for
+    /// example) has always the same performance characteristics from one call to another and
+    /// guarantees correctness by pre-emptively clearing carries of output ciphertexts.
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let size = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, size);
+    ///
+    /// let msg = 21;
+    /// let shift = 2;
+    ///
+    /// let ct1 = cks.encrypt(msg);
+    ///
+    /// // Compute homomorphically a left shift:
+    /// let ct_res = sks.scalar_left_shift(&ct1, shift);
+    ///
+    /// // Decrypt:
+    /// let dec: u64 = cks.decrypt(&ct_res);
+    /// assert_eq!(msg << shift, dec);
+    /// ```
+    pub fn scalar_left_shift<T, Scalar>(&self, ct_left: &T, shift: Scalar) -> T
+    where
+        T: IntegerRadixCiphertext,
+        u64: CastFrom<Scalar>,
+    {
+        let mut result = ct_left.clone();
+        self.scalar_left_shift_assign(&mut result, shift);
+        result
+    }
+
+    /// Computes homomorphically a left shift by a scalar.
+    ///
+    /// The result is assigned in the input ciphertext
+    ///
+    /// This function, like all "default" operations (i.e. not smart, checked or unchecked), will
+    /// check that the input ciphertexts block carries are empty and clears them if it's not the
+    /// case and the operation requires it. It outputs a ciphertext whose block carries are always
+    /// empty.
+    ///
+    /// This means that when using only "default" operations, a given operation (like add for
+    /// example) has always the same performance characteristics from one call to another and
+    /// guarantees correctness by pre-emptively clearing carries of output ciphertexts.
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let size = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, size);
+    ///
+    /// let msg = 13;
+    /// let shift = 2;
+    ///
+    /// let mut ct = cks.encrypt(msg);
+    ///
+    /// // Compute homomorphically a right shift:
+    /// sks.scalar_left_shift_assign(&mut ct, shift);
+    ///
+    /// // Decrypt:
+    /// let dec: u64 = cks.decrypt(&ct);
+    /// assert_eq!(msg << shift, dec);
+    /// ```
+    pub fn scalar_left_shift_assign<T, Scalar>(&self, ct: &mut T, shift: Scalar)
+    where
+        T: IntegerRadixCiphertext,
+        u64: CastFrom<Scalar>,
+    {
+        self.conditional_full_propagate(ct);
+        self.unchecked_scalar_left_shift_assign(ct, shift);
+    }
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/scalar_sub.rs b/tfhe/src/integer/fpga/server_key/radix/scalar_sub.rs
new file mode 100644
index 000000000..ea16fb0c3
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/scalar_sub.rs
@@ -0,0 +1,124 @@
+use crate::core_crypto::prelude::{SignedNumeric, UnsignedNumeric};
+use crate::integer::block_decomposition::DecomposableInto;
+use crate::integer::ciphertext::IntegerRadixCiphertext;
+use crate::integer::fpga::server_key::BelfortServerKey;
+use crate::integer::server_key::TwosComplementNegation;
+use crate::integer::{BooleanBlock, RadixCiphertext, SignedRadixCiphertext};
+use log::warn;
+
+impl BelfortServerKey {
+    /// Computes homomorphically a subtraction of a ciphertext by a scalar.
+    ///
+    /// This function, like all "default" operations (i.e. not smart, checked or unchecked), will
+    /// check that the input ciphertexts block carries are empty and clears them if it's not the
+    /// case and the operation requires it. It outputs a ciphertext whose block carries are always
+    /// empty.
+    ///
+    /// This means that when using only "default" operations, a given operation (like add for
+    /// example) has always the same performance characteristics from one call to another and
+    /// guarantees correctness by pre-emptively clearing carries of output ciphertexts.
+    pub fn scalar_sub<T, Scalar>(&self, ct: &T, scalar: Scalar) -> T
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: TwosComplementNegation + DecomposableInto<u8>,
+    {
+        let mut ct_res = ct.clone();
+        self.scalar_sub_assign(&mut ct_res, scalar);
+        ct_res
+    }
+
+    pub fn scalar_sub_assign<T, Scalar>(&self, ct: &mut T, scalar: Scalar)
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: TwosComplementNegation + DecomposableInto<u8>,
+    {
+        self.conditional_full_propagate(ct);
+        let integer_key = &self.key.key;
+
+        integer_key.unchecked_scalar_sub_assign(ct, scalar);
+
+        if integer_key.is_eligible_for_parallel_single_carry_propagation(ct.blocks().len()) {
+            self.propagate_single_carry_parallelized_low_latency(ct.blocks_mut());
+        } else {
+            self.full_propagate(ct);
+        }
+    }
+    pub fn unchecked_scalar_sub<T, Scalar>(&self, ct: &mut T, scalar: Scalar) -> T
+    where
+        Scalar: TwosComplementNegation + DecomposableInto<u8>,
+        T: IntegerRadixCiphertext,
+    {
+        self.key.key.unchecked_scalar_sub(ct, scalar)
+    }
+
+    /// Computes homomorphically a subtraction of a ciphertext by a scalar.
+    pub fn smart_scalar_sub<T, Scalar>(&self, ct: &mut T, scalar: Scalar) -> T
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: TwosComplementNegation + DecomposableInto<u8>,
+    {
+        let integer_key = &self.key.key;
+
+        if integer_key.is_scalar_sub_possible(ct, scalar).is_err() {
+            self.full_propagate(ct);
+        }
+        integer_key.is_scalar_sub_possible(ct, scalar).unwrap();
+        integer_key.unchecked_scalar_sub(ct, scalar)
+    }
+
+    pub fn smart_scalar_sub_assign<T, Scalar>(&self, ct: &mut T, scalar: Scalar)
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: TwosComplementNegation + DecomposableInto<u8>,
+    {
+        let integer_key = &self.key.key;
+        if integer_key.is_scalar_sub_possible(ct, scalar).is_err() {
+            self.full_propagate(ct);
+        }
+        integer_key.is_scalar_sub_possible(ct, scalar).unwrap();
+        integer_key.unchecked_scalar_sub_assign(ct, scalar);
+    }
+
+    pub fn unsigned_overflowing_scalar_sub<T>(
+        &self,
+        lhs: &RadixCiphertext,
+        scalar: T,
+    ) -> (RadixCiphertext, BooleanBlock)
+    where
+        T: UnsignedNumeric + DecomposableInto<u8> + std::ops::Not<Output = T>,
+    {
+        let mut result = lhs.clone();
+        let overflow = self.unsigned_overflowing_scalar_sub_assign(&mut result, scalar);
+        (result, overflow)
+    }
+
+    pub fn unsigned_overflowing_scalar_sub_assign<T>(
+        &self,
+        lhs: &mut RadixCiphertext,
+        scalar: T,
+    ) -> BooleanBlock
+    where
+        T: UnsignedNumeric + DecomposableInto<u8> + std::ops::Not<Output = T>,
+    {
+        warn!("Non-optimized function call. Contact Belfort if you experience a slow run.");
+
+        self.key
+            .key
+            .unsigned_overflowing_scalar_sub_assign_parallelized(lhs, scalar)
+    }
+
+    pub fn signed_overflowing_scalar_sub_assig<Scalar>(
+        &self,
+        lhs: &mut SignedRadixCiphertext,
+        scalar: Scalar,
+    ) -> BooleanBlock
+    where
+        Scalar: SignedNumeric + DecomposableInto<u8> + std::ops::Not<Output = Scalar>,
+    {
+        warn!("Non-optimized function call. Contact Belfort if you experience a slow run.");
+
+        self.key
+            .key
+            .signed_overflowing_scalar_sub_assign_parallelized(lhs, scalar)
+    }
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/shift.rs b/tfhe/src/integer/fpga/server_key/radix/shift.rs
new file mode 100644
index 000000000..57349aea9
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/shift.rs
@@ -0,0 +1,398 @@
+use crate::integer::ciphertext::{IntegerRadixCiphertext, RadixCiphertext};
+use crate::integer::fpga::server_key::radix::bit_extractor::BitExtractor;
+use crate::integer::fpga::server_key::BelfortServerKey;
+use crate::shortint::Ciphertext;
+
+#[derive(Clone, Copy)]
+pub(super) enum BarrelShifterOperation {
+    LeftRotate,
+    LeftShift,
+    RightShift,
+    RightRotate,
+}
+
+impl BelfortServerKey {
+    //======================================================================
+    //                Shift Right
+    //======================================================================
+
+    pub fn unchecked_right_shift<T>(&self, ct_left: &T, shift: &RadixCiphertext) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut result = ct_left.clone();
+        self.unchecked_right_shift_assign(&mut result, shift);
+        result
+    }
+
+    pub fn unchecked_right_shift_assign<T>(&self, ct: &mut T, shift: &RadixCiphertext)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.barrel_shifter(ct, shift, BarrelShifterOperation::RightShift);
+    }
+
+    pub fn smart_right_shift_assign<T>(&self, ct: &mut T, shift: &mut RadixCiphertext)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.conditional_full_propagate(ct);
+        self.conditional_full_propagate(shift);
+
+        self.unchecked_right_shift_assign(ct, shift);
+    }
+
+    pub fn smart_right_shift<T>(&self, ct: &mut T, shift: &mut RadixCiphertext) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.conditional_full_propagate(ct);
+        self.conditional_full_propagate(shift);
+
+        self.unchecked_right_shift(ct, shift)
+    }
+
+    pub fn right_shift_assign<T>(&self, ct: &mut T, shift: &RadixCiphertext)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.conditional_full_propagate(ct);
+        let mut propagated_shift;
+
+        let shift = if shift.block_carries_are_empty() {
+            propagated_shift = shift.clone();
+            self.full_propagate(&mut propagated_shift);
+            &propagated_shift
+        } else {
+            shift
+        };
+
+        self.unchecked_right_shift_assign(ct, shift);
+    }
+
+    /// Computes homomorphically a right shift by an encrypted amount
+    ///
+    /// The result is returned as a new ciphertext.
+    ///
+    /// This function, like all "default" operations (i.e. not smart, checked or unchecked), will
+    /// check that the input ciphertexts block carries are empty and clears them if it's not the
+    /// case and the operation requires it. It outputs a ciphertext whose block carries are always
+    /// empty.
+    ///
+    /// This means that when using only "default" operations, a given operation (like add for
+    /// example) has always the same performance characteristics from one call to another and
+    /// guarantees correctness by pre-emptively clearing carries of output ciphertexts.
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let size = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, size);
+    ///
+    /// let msg = 128;
+    /// let shift = 2;
+    ///
+    /// let ct = cks.encrypt(msg);
+    /// let shift_ct = cks.encrypt(shift as u64);
+    ///
+    /// // Compute homomorphically a right shift:
+    /// let ct_res = sks.right_shift(&ct, &shift_ct);
+    ///
+    /// // Decrypt:
+    /// let dec: u64 = cks.decrypt(&ct_res);
+    /// assert_eq!(msg >> shift, dec);
+    /// ```
+    pub fn right_shift<T>(&self, ct: &T, shift: &RadixCiphertext) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut ct_res = ct.clone();
+        self.right_shift_assign(&mut ct_res, shift);
+        ct_res
+    }
+
+    //======================================================================
+    //                Shift Left
+    //======================================================================
+
+    /// left shift by and encrypted amount
+    ///
+    /// This requires:
+    /// - ct to have clean carries
+    /// - shift to have clean carries
+    /// - the number of bits in the block to be >= 3
+    pub fn unchecked_left_shift<T>(&self, ct_left: &T, shift: &RadixCiphertext) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut result = ct_left.clone();
+        self.unchecked_left_shift_assign(&mut result, shift);
+        result
+    }
+
+    /// left shift by and encrypted amount
+    ///
+    /// This requires:
+    /// - ct to have clean carries
+    /// - shift to have clean carries
+    /// - the number of bits in the block to be >= 3
+    pub fn unchecked_left_shift_assign<T>(&self, ct: &mut T, shift: &RadixCiphertext)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.barrel_shifter(ct, shift, BarrelShifterOperation::LeftShift);
+    }
+
+    pub fn smart_left_shift_assign<T>(&self, ct: &mut T, shift: &mut RadixCiphertext)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.conditional_full_propagate(ct);
+        self.conditional_full_propagate(shift);
+        self.unchecked_left_shift_assign(ct, shift);
+    }
+
+    pub fn smart_left_shift<T>(&self, ct: &mut T, shift: &mut RadixCiphertext) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.conditional_full_propagate(ct);
+        self.conditional_full_propagate(shift);
+        self.unchecked_left_shift(ct, shift)
+    }
+
+    pub fn left_shift_assign<T>(&self, ct: &mut T, shift: &RadixCiphertext)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.conditional_full_propagate(ct);
+        let mut propagated_shift;
+
+        let shift = if shift.block_carries_are_empty() {
+            propagated_shift = shift.clone();
+            self.full_propagate(&mut propagated_shift);
+            &propagated_shift
+        } else {
+            shift
+        };
+
+        self.unchecked_left_shift_assign(ct, shift);
+    }
+
+    /// Computes homomorphically a left shift by an encrypted amount.
+    ///
+    /// The result is returned as a new ciphertext.
+    ///
+    /// This function, like all "default" operations (i.e. not smart, checked or unchecked), will
+    /// check that the input ciphertexts block carries are empty and clears them if it's not the
+    /// case and the operation requires it. It outputs a ciphertext whose block carries are always
+    /// empty.
+    ///
+    /// This means that when using only "default" operations, a given operation (like add for
+    /// example) has always the same performance characteristics from one call to another and
+    /// guarantees correctness by pre-emptively clearing carries of output ciphertexts.
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let size = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, size);
+    ///
+    /// let msg = 21;
+    /// let shift = 2;
+    ///
+    /// let ct1 = cks.encrypt(msg);
+    /// let ct2 = cks.encrypt(shift as u64);
+    ///
+    /// // Compute homomorphically a left shift:
+    /// let ct_res = sks.left_shift(&ct1, &ct2);
+    ///
+    /// // Decrypt:
+    /// let dec: u64 = cks.decrypt(&ct_res);
+    /// assert_eq!(msg << shift, dec);
+    /// ```
+    pub fn left_shift<T>(&self, ct: &T, shift: &RadixCiphertext) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut ct_res = ct.clone();
+        self.left_shift_assign(&mut ct_res, shift);
+        ct_res
+    }
+
+    /// This implements a "barrel shifter".
+    ///
+    /// This construct is what is used in hardware to
+    /// implement left/right shift/rotate
+    ///
+    /// This requires:
+    /// - ct to have clean carries
+    /// - shift to have clean carries
+    /// - the number of bits in the block to be >= 3
+    ///
+    /// Similarly to rust `wrapping_shl/shr` functions
+    /// it removes any high-order bits of `shift`
+    /// that would cause the shift to exceed the bitwidth of the type.
+    ///
+    /// **However**, when the total number of bits represented by the
+    /// radix ciphertext is not a power of two (eg a ciphertext with 12 bits)
+    /// then, it removes bits that are higher than the closest higher power of two.
+    /// So for a 12 bits radix ciphertext, its closest higher power of two is 16,
+    /// thus, any bit that are higher than log2(16) will be removed
+    ///
+    /// `ct` will be assigned the result, and it will be in a fresh state
+    pub(super) fn barrel_shifter<T>(
+        &self,
+        ct: &mut T,
+        shift: &RadixCiphertext,
+        operation: BarrelShifterOperation,
+    ) where
+        T: IntegerRadixCiphertext,
+    {
+        if ct.blocks().is_empty() || shift.blocks.is_empty() {
+            return;
+        }
+
+        let num_blocks = ct.blocks().len();
+        let shortint_key = &self.key.key.key;
+        let message_bits_per_block = shortint_key.message_modulus.0.ilog2() as u64;
+        let carry_bits_per_block = shortint_key.carry_modulus.0.ilog2() as u64;
+        let total_nb_bits = message_bits_per_block * num_blocks as u64; // How many bits are in the shift
+
+        assert!(
+            (message_bits_per_block + carry_bits_per_block) >= 3,
+            "Blocks must have at least 3 bits"
+        );
+
+        let all_message_bits = {
+            let bit_extractor =
+                BitExtractor::msg_with_final_offset0(self, message_bits_per_block as usize);
+            bit_extractor.extract_all_bits(ct.blocks())
+        };
+
+        let shift_bits: Vec<Ciphertext> = {
+            let mut max_num_bits_that_tell_shift = total_nb_bits.ilog2() as u64;
+            // If the total_nb_bits is not a power of two,
+            // then the behaviour of shifting won't be the same.
+            // If shift >= total_nb_bits compared to when total_nb_bits
+            // is a power of two, we require more max num of bits in `shift_bits`
+            if !total_nb_bits.is_power_of_two() {
+                max_num_bits_that_tell_shift += 1;
+            };
+            // Extracts bits and put them in the bit index 2 (=> bit number 3)
+            // so that it is already aligned to the correct position of the cmux input
+            // and we reduce noise growth
+            let bit_extractor =
+                BitExtractor::msg_with_final_offset2(self, message_bits_per_block as usize);
+            bit_extractor.extract_n_bits(&shift.blocks, max_num_bits_that_tell_shift as usize)
+        };
+
+        let is_right_shift = matches!(operation, BarrelShifterOperation::RightShift);
+        let padding_bit = if T::IS_SIGNED && is_right_shift {
+            // Do an "arithmetic shift" by padding with the sign bit
+            all_message_bits.last().unwrap().clone()
+        } else {
+            shortint_key.create_trivial(0)
+        };
+
+        let mut input_bits_a = all_message_bits;
+        // Buffer used to hold inputs for a bitwise cmux gate, simulated using a PBS
+        let mut mux_inputs = input_bits_a.clone();
+
+        for (d, shift_bit) in shift_bits.iter().enumerate() {
+            let mut input_bits_b = input_bits_a.clone();
+
+            match operation {
+                BarrelShifterOperation::LeftShift => {
+                    input_bits_b.rotate_right(1 << d);
+                    input_bits_b[..1 << d].fill(padding_bit.clone());
+                }
+                BarrelShifterOperation::RightShift => {
+                    input_bits_b.rotate_left(1 << d);
+                    input_bits_b[total_nb_bits as usize - (1 << d)..].fill(padding_bit.clone());
+                }
+                BarrelShifterOperation::LeftRotate => {
+                    input_bits_b.rotate_right(1 << d);
+                }
+                BarrelShifterOperation::RightRotate => {
+                    input_bits_b.rotate_left(1 << d);
+                }
+            }
+
+            input_bits_a
+                .iter_mut()
+                .zip(mux_inputs.iter_mut())
+                .enumerate()
+                .for_each(|(i, (a, mux_gate_input))| {
+                    let b = &input_bits_b[i];
+
+                    // pack bits into one block so that we have
+                    // control_bit|b|a
+                    shortint_key.create_trivial_assign(mux_gate_input, 0);
+                    shortint_key.unchecked_add_assign(mux_gate_input, b);
+                    shortint_key.unchecked_scalar_mul_assign(mux_gate_input, 2);
+                    shortint_key.unchecked_add_assign(mux_gate_input, a);
+                    // The shift bit is already properly aligned/positioned
+                    shortint_key.unchecked_add_assign(mux_gate_input, shift_bit);
+                });
+
+            let lut_mux = {
+                let func = |x| {
+                    let x = x & 7;
+                    let control_bit = x >> 2;
+                    let previous_bit = (x & 2) >> 1;
+                    let current_bit = x & 1;
+
+                    if control_bit == 1_u64 {
+                        previous_bit
+                    } else {
+                        current_bit
+                    }
+                };
+                shortint_key.generate_lookup_vector(&func)
+            };
+
+            // We have control_bit|b|a
+            self.apply_same_lookup_vector_packed_assign(&mut mux_inputs, lut_mux);
+
+            input_bits_a.clone_from_slice(&mux_inputs);
+        }
+
+        // rename for clarity
+        let mut output_bits = input_bits_a;
+        assert!(output_bits.len() == message_bits_per_block as usize * num_blocks);
+
+        // We have to reconstruct blocks from the individual bits
+        let mut output_ct: Vec<&mut Ciphertext> = Vec::with_capacity(num_blocks);
+        output_bits
+            .as_mut_slice()
+            .chunks_exact_mut(message_bits_per_block as usize)
+            .for_each(|grouped_bits| {
+                let (head, last) = grouped_bits.split_at_mut(message_bits_per_block as usize - 1);
+                for bit in head.iter().rev() {
+                    shortint_key.unchecked_scalar_mul_assign(&mut last[0], 2);
+                    shortint_key.unchecked_add_assign(&mut last[0], bit);
+                }
+                output_ct.push(&mut last[0]);
+            });
+
+        // Clean the noise
+        let lut_message_extract = self.lut_message_extract();
+        self.apply_same_lookup_vector_mut_packed_assign(&mut output_ct, lut_message_extract);
+
+        output_ct
+            .into_iter()
+            .zip(ct.blocks_mut())
+            .for_each(|(output, block)| {
+                std::mem::swap(block, output);
+            });
+    }
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/slice.rs b/tfhe/src/integer/fpga/server_key/radix/slice.rs
new file mode 100644
index 000000000..4f1a9e1b6
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/slice.rs
@@ -0,0 +1,278 @@
+use log::warn;
+use std::ops::RangeBounds;
+
+use crate::error::InvalidRangeError;
+use crate::integer::fpga::server_key::BelfortServerKey;
+use crate::integer::RadixCiphertext;
+use crate::prelude::{CastFrom, CastInto};
+
+impl BelfortServerKey {
+    /// Extract a slice of bits from a ciphertext.
+    ///
+    /// The result is returned as a new ciphertext. This function is more efficient
+    /// if the range starts on a block boundary.
+    ///
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let num_blocks = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, num_blocks);
+    ///
+    /// let msg: u64 = 225;
+    /// let start_bit = 3;
+    /// let end_bit = 6;
+    ///
+    /// // Encrypt the message:
+    /// let ct = cks.encrypt(msg);
+    ///
+    /// let ct_res = sks
+    ///     .unchecked_scalar_bitslice(&ct, start_bit..end_bit)
+    ///     .unwrap();
+    ///
+    /// // Decrypt:
+    /// let clear = cks.decrypt(&ct_res);
+    /// assert_eq!((msg % (1 << end_bit)) >> start_bit, clear);
+    /// ```
+    pub fn unchecked_scalar_bitslice<B, R>(
+        &self,
+        ctxt: &RadixCiphertext,
+        range: R,
+    ) -> Result<RadixCiphertext, InvalidRangeError>
+    where
+        R: RangeBounds<B>,
+        B: CastFrom<usize> + CastInto<usize> + Copy,
+    {
+        warn!("Non-optimized function call. Contact Belfort if you experience a slow run.");
+        self.key
+            .key
+            .unchecked_scalar_bitslice_parallelized(ctxt, range)
+    }
+
+    /// Extract a slice of bits from a ciphertext.
+    ///
+    /// The result is assigned to the input ciphertext. This function is more efficient
+    /// if the range starts on a block boundary.
+    ///
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let num_blocks = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, num_blocks);
+    ///
+    /// let msg: u64 = 225;
+    /// let start_bit = 3;
+    /// let end_bit = 6;
+    ///
+    /// // Encrypt the message:
+    /// let mut ct = cks.encrypt(msg);
+    ///
+    /// sks.unchecked_scalar_bitslice_assign(&mut ct, start_bit..end_bit)
+    ///     .unwrap();
+    ///
+    /// // Decrypt:
+    /// let clear = cks.decrypt(&ct);
+    /// assert_eq!((msg % (1 << end_bit)) >> start_bit, clear);
+    /// ```
+    pub fn unchecked_scalar_bitslice_assign<B, R>(
+        &self,
+        ctxt: &mut RadixCiphertext,
+        range: R,
+    ) -> Result<(), InvalidRangeError>
+    where
+        R: RangeBounds<B>,
+        B: CastFrom<usize> + CastInto<usize> + Copy,
+    {
+        *ctxt = self.unchecked_scalar_bitslice(ctxt, range)?;
+        Ok(())
+    }
+
+    /// Extract a slice of bits from a ciphertext.
+    ///
+    /// The result is returned as a new ciphertext. This function is more efficient
+    /// if the range starts on a block boundary.
+    ///
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let num_blocks = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, num_blocks);
+    ///
+    /// let msg: u64 = 225;
+    /// let start_bit = 3;
+    /// let end_bit = 6;
+    ///
+    /// // Encrypt the message:
+    /// let ct = cks.encrypt(msg);
+    ///
+    /// let ct_res = sks.scalar_bitslice(&ct, start_bit..end_bit).unwrap();
+    ///
+    /// // Decrypt:
+    /// let clear = cks.decrypt(&ct_res);
+    /// assert_eq!((msg % (1 << end_bit)) >> start_bit, clear);
+    /// ```
+    pub fn scalar_bitslice<B, R>(
+        &self,
+        ctxt: &RadixCiphertext,
+        range: R,
+    ) -> Result<RadixCiphertext, InvalidRangeError>
+    where
+        R: RangeBounds<B>,
+        B: CastFrom<usize> + CastInto<usize> + Copy,
+    {
+        if ctxt.block_carries_are_empty() {
+            self.unchecked_scalar_bitslice(ctxt, range)
+        } else {
+            let mut ctxt = ctxt.clone();
+            self.full_propagate(&mut ctxt);
+            self.unchecked_scalar_bitslice(&ctxt, range)
+        }
+    }
+
+    /// Extract a slice of bits from a ciphertext.
+    ///
+    /// The result is assigned to the input ciphertext. This function is more efficient
+    /// if the range starts on a block boundary.
+    ///
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let num_blocks = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, num_blocks);
+    ///
+    /// let msg: u64 = 225;
+    /// let start_bit = 3;
+    /// let end_bit = 6;
+    ///
+    /// // Encrypt the message:
+    /// let mut ct = cks.encrypt(msg);
+    ///
+    /// sks.scalar_bitslice_assign(&mut ct, start_bit..end_bit)
+    ///     .unwrap();
+    ///
+    /// // Decrypt:
+    /// let clear = cks.decrypt(&ct);
+    /// assert_eq!((msg % (1 << end_bit)) >> start_bit, clear);
+    /// ```
+    pub fn scalar_bitslice_assign<B, R>(
+        &self,
+        ctxt: &mut RadixCiphertext,
+        range: R,
+    ) -> Result<(), InvalidRangeError>
+    where
+        R: RangeBounds<B>,
+        B: CastFrom<usize> + CastInto<usize> + Copy,
+    {
+        self.conditional_full_propagate(ctxt);
+
+        self.unchecked_scalar_bitslice_assign(ctxt, range)
+    }
+
+    /// Extract a slice of bits from a ciphertext.
+    ///
+    /// The result is returned as a new ciphertext. This function is more efficient
+    /// if the range starts on a block boundary.
+    ///
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let num_blocks = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, num_blocks);
+    ///
+    /// let msg: u64 = 225;
+    /// let start_bit = 3;
+    /// let end_bit = 6;
+    ///
+    /// // Encrypt the message:
+    /// let mut ct = cks.encrypt(msg);
+    ///
+    /// let ct_res = sks
+    ///     .smart_scalar_bitslice(&mut ct, start_bit..end_bit)
+    ///     .unwrap();
+    ///
+    /// // Decrypt:
+    /// let clear = cks.decrypt(&ct_res);
+    /// assert_eq!((msg % (1 << end_bit)) >> start_bit, clear);
+    /// ```
+    pub fn smart_scalar_bitslice<B, R>(
+        &self,
+        ctxt: &mut RadixCiphertext,
+        range: R,
+    ) -> Result<RadixCiphertext, InvalidRangeError>
+    where
+        R: RangeBounds<B>,
+        B: CastFrom<usize> + CastInto<usize> + Copy,
+    {
+        self.conditional_full_propagate(ctxt);
+
+        self.unchecked_scalar_bitslice(ctxt, range)
+    }
+
+    /// Extract a slice of bits from a ciphertext.
+    ///
+    /// The result is assigned to the input ciphertext. This function is more efficient
+    /// if the range starts on a block boundary.
+    ///
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let num_blocks = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, num_blocks);
+    ///
+    /// let msg: u64 = 225;
+    /// let start_bit = 3;
+    /// let end_bit = 6;
+    ///
+    /// // Encrypt the message:
+    /// let mut ct = cks.encrypt(msg);
+    ///
+    /// sks.smart_scalar_bitslice_assign(&mut ct, start_bit..end_bit)
+    ///     .unwrap();
+    ///
+    /// // Decrypt:
+    /// let clear = cks.decrypt(&ct);
+    /// assert_eq!((msg % (1 << end_bit)) >> start_bit, clear);
+    /// ```
+    pub fn smart_scalar_bitslice_assign<B, R>(
+        &self,
+        ctxt: &mut RadixCiphertext,
+        range: R,
+    ) -> Result<(), InvalidRangeError>
+    where
+        R: RangeBounds<B>,
+        B: CastFrom<usize> + CastInto<usize> + Copy,
+    {
+        self.conditional_full_propagate(ctxt);
+
+        self.unchecked_scalar_bitslice_assign(ctxt, range)
+    }
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/sub.rs b/tfhe/src/integer/fpga/server_key/radix/sub.rs
new file mode 100644
index 000000000..60e2b2c78
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/sub.rs
@@ -0,0 +1,313 @@
+use crate::core_crypto::fpga::lookup_vector::LookupVector;
+use crate::integer::ciphertext::IntegerRadixCiphertext;
+use crate::integer::fpga::server_key::{BelfortServerKey, OutputCarry};
+use crate::integer::server_key::CheckError;
+use crate::integer::{BooleanBlock, RadixCiphertext};
+use crate::shortint::ciphertext::Degree;
+use crate::shortint::Ciphertext;
+use rayon::prelude::*;
+use std::cmp::Ordering;
+
+impl BelfortServerKey {
+    /// Computes homomorphically the subtraction between ct_left and ct_right.
+    ///
+    /// This function, like all "default" operations (i.e. not smart, checked or unchecked), will
+    /// check that the input ciphertexts block carries are empty and clears them if it's not the
+    /// case and the operation requires it. It outputs a ciphertext whose block carries are always
+    /// empty.
+    ///
+    /// This means that when using only "default" operations, a given operation (like add for
+    /// example) has always the same performance characteristics from one call to another and
+    /// guarantees correctness by pre-emptively clearing carries of output ciphertexts.
+    pub fn sub<T>(&self, ct1: &T, ct2: &T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut ct_res = ct1.clone();
+        self.sub_assign(&mut ct_res, ct2);
+        ct_res
+    }
+
+    pub fn sub_assign<T>(&self, ct1: &mut T, ct2: &T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut tmp_rhs;
+        let (lhs, rhs) = match (ct1.block_carries_are_empty(), ct2.block_carries_are_empty()) {
+            (true, true) => (ct1, ct2),
+            (true, false) => {
+                tmp_rhs = ct2.clone();
+                self.full_propagate(&mut tmp_rhs);
+                (ct1, &tmp_rhs)
+            }
+            (false, true) => {
+                self.full_propagate(ct1);
+                (ct1, ct2)
+            }
+            (false, false) => {
+                tmp_rhs = ct2.clone();
+                self.full_propagate(ct1);
+                self.full_propagate(&mut tmp_rhs);
+                (ct1, &tmp_rhs)
+            }
+        };
+
+        // if you change params checkout Zama's code for this function
+        let neg = self.key.key.unchecked_neg(rhs);
+        self.unchecked_add_assign_parallelized_low_latency(lhs, &neg);
+    }
+    pub fn unchecked_sub<T>(&self, ct1: &T, ct2: &T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.key.key.unchecked_sub(ct1, ct2)
+    }
+
+    pub fn unchecked_sub_assign<T>(&self, ct1: &mut T, ct2: &T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.key.key.unchecked_sub_assign(ct1, ct2);
+    }
+
+    pub fn checked_sub<T>(&self, ct1: &T, ct2: &T) -> Result<T, CheckError>
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.key.key.is_sub_possible(ct1, ct2)?;
+        Ok(self.unchecked_sub(ct1, ct2))
+    }
+
+    pub fn checked_sub_assign<T>(&self, ct_left: &mut T, ct_right: &T) -> Result<(), CheckError>
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.key.key.is_sub_possible(ct_left, ct_right)?;
+        self.unchecked_sub_assign(ct_left, ct_right);
+        Ok(())
+    }
+
+    /// Computes homomorphically the subtraction between ct_left and ct_right.
+    pub fn smart_sub<T>(&self, ct1: &mut T, ct2: &mut T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let integer_key = &self.key.key;
+
+        if integer_key.is_neg_possible(ct2).is_err() {
+            self.full_propagate(ct2);
+        }
+
+        if integer_key.is_sub_possible(ct1, ct2).is_err() {
+            self.full_propagate(ct1);
+            self.full_propagate(ct2);
+        }
+
+        integer_key.is_sub_possible(ct1, ct2).unwrap();
+
+        let mut result = ct1.clone();
+        self.unchecked_sub_assign(&mut result, ct2);
+
+        result
+    }
+
+    /// Computes homomorphically the subtraction between ct_left and ct_right.
+    pub fn smart_sub_assign<T>(&self, ct1: &mut T, ct2: &mut T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let integer_key = &self.key.key;
+
+        if integer_key.is_neg_possible(ct2).is_err() {
+            self.full_propagate(ct2);
+        }
+
+        if integer_key.is_sub_possible(ct1, ct2).is_err() {
+            self.full_propagate(ct1);
+            self.full_propagate(ct2);
+        }
+
+        integer_key.is_sub_possible(ct1, ct2).unwrap();
+
+        self.unchecked_sub_assign(ct1, ct2);
+    }
+
+    /// Computes the subtraction and returns an indicator of overflow
+    pub fn unsigned_overflowing_sub(
+        &self,
+        ctxt_left: &RadixCiphertext,
+        ctxt_right: &RadixCiphertext,
+    ) -> (RadixCiphertext, BooleanBlock) {
+        let mut tmp_lhs;
+        let mut tmp_rhs;
+
+        let (lhs, rhs) = match (
+            ctxt_left.block_carries_are_empty(),
+            ctxt_right.block_carries_are_empty(),
+        ) {
+            (true, true) => (ctxt_left, ctxt_right),
+            (true, false) => {
+                tmp_rhs = ctxt_right.clone();
+                self.full_propagate(&mut tmp_rhs);
+                (ctxt_left, &tmp_rhs)
+            }
+            (false, true) => {
+                tmp_lhs = ctxt_left.clone();
+                self.full_propagate(&mut tmp_lhs);
+                (&tmp_lhs, ctxt_right)
+            }
+            (false, false) => {
+                tmp_lhs = ctxt_left.clone();
+                tmp_rhs = ctxt_right.clone();
+                self.full_propagate(&mut tmp_lhs);
+                self.full_propagate(&mut tmp_rhs);
+                (&tmp_lhs, &tmp_rhs)
+            }
+        };
+
+        let (mut res, overflow) = self.unchecked_unsigned_overflowing_sub(lhs, rhs);
+
+        self.full_propagate(&mut res);
+
+        (res, overflow)
+    }
+
+    pub fn unchecked_unsigned_overflowing_sub(
+        &self,
+        lhs: &RadixCiphertext,
+        rhs: &RadixCiphertext,
+    ) -> (RadixCiphertext, BooleanBlock) {
+        // Here we have to use manual unchecked_sub on shortint blocks
+        // rather than calling integer's unchecked_sub as we need each subtraction
+        // to be independent from other blocks. And we don't want to do subtraction by
+        // adding negation
+        assert_eq!(
+            lhs.blocks.len(),
+            rhs.blocks.len(),
+            "Left hand side must must have a number of blocks equal \
+            to the number of blocks of the right hand side: lhs {} blocks, rhs {} blocks",
+            lhs.blocks.len(),
+            rhs.blocks.len()
+        );
+
+        let ct = lhs
+            .blocks
+            .iter()
+            .zip(rhs.blocks.iter())
+            .map(|(lhs_block, rhs_block)| self.key.key.key.unchecked_sub(lhs_block, rhs_block))
+            .collect::<Vec<_>>();
+
+        let mut ct = RadixCiphertext::from(ct);
+        let overflowed = self.unsigned_overflowing_propagate_subtraction_borrow(&mut ct);
+        (ct, overflowed)
+    }
+
+    /// This function takes a ciphertext resulting from a subtraction of 2 clean ciphertexts
+    pub(in crate::integer) fn unsigned_overflowing_propagate_subtraction_borrow(
+        &self,
+        ct: &mut RadixCiphertext,
+    ) -> BooleanBlock {
+        let generates_or_propagates = self.generate_init_borrow_array(ct);
+        let (input_borrows, mut output_borrow) =
+            self.compute_borrow_propagation_parallelized_low_latency(generates_or_propagates);
+
+        let shortint_key = &self.key.key.key;
+        ct.blocks
+            .par_iter_mut()
+            .zip(input_borrows.par_iter())
+            .for_each(|(block, input_borrow)| {
+                // Do a true lwe subtraction, as unchecked_sub will adds a correcting term
+                // to avoid overflow (and trashing padding bit). Here we know each
+                // block in the ciphertext is >= 1, and that input borrow is either 0 or 1
+                // so no overflow possible.
+                crate::core_crypto::algorithms::lwe_ciphertext_sub_assign(
+                    &mut block.ct,
+                    &input_borrow.ct,
+                );
+                block.set_noise_level(
+                    block.noise_level() + input_borrow.noise_level(),
+                    shortint_key.max_noise_level,
+                );
+            });
+
+        let lut_message_extract = self.lut_message_extract();
+        let mut blocks = ct.blocks.clone();
+        self.apply_same_lookup_vector_packed_assign(&mut blocks, lut_message_extract);
+
+        ct.blocks
+            .par_iter_mut()
+            .zip(blocks.par_iter())
+            .for_each(|(block, vec_block)| {
+                block.clone_from(vec_block);
+            });
+
+        assert!(ct.block_carries_are_empty());
+        // we know here that the result is a boolean value
+        // however the lut used has a degree of 2.
+
+        output_borrow.degree = Degree::new(1);
+
+        BooleanBlock::new_unchecked(output_borrow)
+    }
+
+    pub(super) fn generate_init_borrow_array(&self, sum_ct: &RadixCiphertext) -> Vec<Ciphertext> {
+        let shortint_key = &self.key.key.key;
+
+        let lut_does_block_generate_borrow = {
+            let func = |x| {
+                if x < shortint_key.message_modulus.0 {
+                    OutputCarry::Generated as u64
+                } else {
+                    OutputCarry::None as u64
+                }
+            };
+            shortint_key.generate_lookup_vector(&func)
+        };
+        let lut_does_block_generate_or_propagate_borrow = {
+            let func = |x: u64| match x.cmp(&{ shortint_key.message_modulus.0 }) {
+                Ordering::Less => OutputCarry::Generated as u64,
+                Ordering::Equal => OutputCarry::Propagated as u64,
+                Ordering::Greater => OutputCarry::None as u64,
+            };
+            shortint_key.generate_lookup_vector(&func)
+        };
+
+        let mut luts: Vec<LookupVector> = Vec::with_capacity(sum_ct.blocks.len());
+
+        sum_ct
+            .blocks
+            .par_iter()
+            .enumerate()
+            .map(|(i, _)| {
+                if i == 0 {
+                    lut_does_block_generate_borrow
+                } else {
+                    lut_does_block_generate_or_propagate_borrow
+                }
+            })
+            .collect_into_vec(&mut luts);
+
+        let mut generates_or_propagates = sum_ct.blocks.clone();
+
+        self.apply_lookup_vector_packed_assign(&mut generates_or_propagates, &luts);
+
+        generates_or_propagates
+    }
+
+    pub(crate) fn compute_borrow_propagation_parallelized_low_latency(
+        &self,
+        generates_or_propagates: Vec<Ciphertext>,
+    ) -> (Vec<Ciphertext>, Ciphertext) {
+        let num_blocks = generates_or_propagates.len();
+        let mut borrows_out =
+            self.compute_prefix_sum_hillis_steele(generates_or_propagates, "carry_propagation_sum");
+
+        let shortint_key = &self.key.key.key;
+        let mut last_block_out_borrow = shortint_key.create_trivial(0);
+        std::mem::swap(&mut borrows_out[num_blocks - 1], &mut last_block_out_borrow);
+
+        borrows_out.rotate_right(1);
+        shortint_key.create_trivial_assign(&mut borrows_out[0], 0);
+        (borrows_out, last_block_out_borrow)
+    }
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/sum.rs b/tfhe/src/integer/fpga/server_key/radix/sum.rs
new file mode 100644
index 000000000..c8787bbd1
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/sum.rs
@@ -0,0 +1,315 @@
+use crate::integer::ciphertext::IntegerRadixCiphertext;
+use crate::integer::fpga::server_key::BelfortServerKey;
+
+use crate::integer::{BooleanBlock, RadixCiphertext};
+use crate::shortint::Ciphertext;
+
+use log::warn;
+impl BelfortServerKey {
+    /// Computes the sum of the ciphertexts in parallel.
+    ///
+    /// Returns a result that has non propagated carries
+    pub(crate) fn unchecked_partial_sum_ciphertexts_vec<T>(&self, terms: Vec<T>) -> Option<T>
+    where
+        T: IntegerRadixCiphertext,
+    {
+        Self::validate_input(&terms);
+
+        // Handle edge cases
+        match terms.len() {
+            0 => return None,
+            1 => return terms.into_iter().next(),
+            2 => return Some(self.add(&terms[0], &terms[1])),
+            _ => {}
+        }
+
+        let integer_key = &self.key.key;
+        let shortint_key = &integer_key.key;
+
+        let additions_to_fill_carry = self.get_additions_to_fill_carry();
+        let num_blocks = terms[0].blocks().len();
+
+        // Re-organize radix terms into columns of blocks
+        let mut columns = vec![vec![]; num_blocks];
+        for term in terms {
+            for (i, block) in term.into_blocks().into_iter().enumerate() {
+                if block.degree.get() != 0 {
+                    columns[i].push(block);
+                }
+            }
+        }
+
+        if columns.iter().all(Vec::is_empty) {
+            return Some(integer_key.create_trivial_radix(0, num_blocks));
+        }
+
+        // Buffer in which we will store resulting columns after an iteration
+        let mut colum_output_buffer = vec![Vec::new(); num_blocks];
+
+        let at_least_one_column_has_enough_elements =
+            |columns: &[Vec<Ciphertext>]| columns.iter().any(|c| c.len() > additions_to_fill_carry);
+
+        while at_least_one_column_has_enough_elements(&columns) {
+            let mut cts_to_extract_msg: Vec<Vec<Ciphertext>> = Vec::new();
+            for column in &columns {
+                let temp = column
+                    .chunks_exact(additions_to_fill_carry)
+                    .map(|chunk| {
+                        let mut result = chunk[0].clone();
+                        for c in &chunk[1..] {
+                            shortint_key.unchecked_add_assign(&mut result, c);
+                        }
+                        result
+                    })
+                    .collect();
+                cts_to_extract_msg.push(temp);
+            }
+
+            let sizes = cts_to_extract_msg
+                .iter()
+                .map(|v| v.len())
+                .collect::<Vec<usize>>();
+
+            let flattened_blocks: Vec<Ciphertext> =
+                cts_to_extract_msg.into_iter().flatten().collect();
+
+            let (cts_to_extract_msg, cts_to_extract_carry) =
+                self.extract_message_and_carry_blocks(&flattened_blocks);
+
+            let mut result_msg = Vec::new();
+            let mut result_carry = Vec::new();
+            let mut start = 0;
+
+            for size in &sizes {
+                let end = start + size;
+                result_msg.push(cts_to_extract_msg[start..end].to_vec());
+                result_carry.push(cts_to_extract_carry[start..end].to_vec());
+                start = end;
+            }
+
+            let mut columns_buffer = columns
+                .drain(..)
+                .zip(colum_output_buffer.iter_mut())
+                .enumerate()
+                .map(|(column_index, (mut column, out_buf))| {
+                    if column.len() < additions_to_fill_carry {
+                        return column;
+                    }
+
+                    let mut temp: Vec<(Ciphertext, Option<Ciphertext>)> = column
+                        .chunks_exact(additions_to_fill_carry)
+                        .enumerate()
+                        .map(|(idx, _)| {
+                            if column_index < num_blocks - 1 {
+                                (
+                                    result_msg[column_index][idx].clone(),
+                                    Some(result_carry[column_index][idx].clone()),
+                                )
+                            } else {
+                                (result_msg[column_index][idx].clone(), None)
+                            }
+                        })
+                        .collect();
+
+                    out_buf.clear();
+                    out_buf.append(&mut temp);
+
+                    let num_elem_in_rest = column.len() % additions_to_fill_carry;
+                    column.rotate_right(num_elem_in_rest);
+                    column.truncate(num_elem_in_rest);
+                    column
+                })
+                .collect();
+
+            std::mem::swap(&mut columns, &mut columns_buffer);
+
+            // Move resulting message and carry blocks where they belong
+            for (i, column_output) in colum_output_buffer.iter_mut().enumerate() {
+                for (msg, maybe_carry) in column_output.drain(..) {
+                    columns[i].push(msg);
+
+                    if let (Some(carry), true) = (maybe_carry, (i + 1) < columns.len()) {
+                        columns[i + 1].push(carry);
+                    }
+                }
+            }
+        }
+
+        // Reconstruct a radix from the columns
+        let blocks = columns
+            .into_iter()
+            .map(|mut column| {
+                if column.is_empty() {
+                    shortint_key.create_trivial(0)
+                } else {
+                    let (first_block, other_blocks) =
+                        column.as_mut_slice().split_first_mut().unwrap();
+                    for other in other_blocks {
+                        shortint_key.unchecked_add_assign(first_block, other);
+                    }
+                    column.swap_remove(0)
+                }
+            })
+            .collect::<Vec<_>>();
+        assert_eq!(blocks.len(), num_blocks);
+
+        Some(T::from_blocks(blocks))
+    }
+
+    fn validate_input<T: IntegerRadixCiphertext>(terms: &[T]) {
+        if terms.len() > 1 {
+            let num_blocks = terms[0].blocks().len();
+            assert!(
+                terms[1..].iter().all(|ct| ct.blocks().len() == num_blocks),
+                "Not all ciphertexts have the same number of blocks"
+            );
+            assert!(
+                terms
+                    .iter()
+                    .all(IntegerRadixCiphertext::block_carries_are_empty),
+                "All ciphertexts must have empty carries"
+            );
+        }
+    }
+
+    /// Computes the sum of the ciphertexts in parallel.
+    ///
+    /// - Returns None if ciphertexts is empty
+    ///
+    /// - Expects all ciphertexts to have empty carries
+    /// - Expects all ciphertexts to have the same size
+    pub fn unchecked_sum_ciphertexts_vec<T>(&self, ciphertexts: Vec<T>) -> Option<T>
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut result = self.unchecked_partial_sum_ciphertexts_vec(ciphertexts)?;
+
+        self.conditional_full_propagate(&mut result);
+        assert!(result.block_carries_are_empty());
+
+        Some(result)
+    }
+
+    /// See [Self::unchecked_sum_ciphertexts_vec]
+    pub fn unchecked_sum_ciphertexts<'a, T, C>(&self, ciphertexts: C) -> Option<T>
+    where
+        C: IntoIterator<Item = &'a T>,
+        T: IntegerRadixCiphertext + 'a,
+    {
+        let ciphertexts = ciphertexts.into_iter().map(Clone::clone).collect();
+        self.unchecked_sum_ciphertexts_vec(ciphertexts)
+    }
+
+    /// Computes the sum of the ciphertexts.
+    ///
+    /// - Returns None if ciphertexts is empty
+    ///
+    /// See [Self::unchecked_sum_ciphertexts] for constraints
+    pub fn sum_ciphertexts<'a, T, C>(&self, ciphertexts: C) -> Option<T>
+    where
+        C: IntoIterator<Item = &'a T>,
+        T: IntegerRadixCiphertext + 'a,
+    {
+        let mut ciphertexts = ciphertexts
+            .into_iter()
+            .map(Clone::clone)
+            .collect::<Vec<T>>();
+
+        for ct in ciphertexts.iter_mut() {
+            self.conditional_full_propagate(&mut *ct);
+        }
+
+        self.unchecked_sum_ciphertexts_vec(ciphertexts)
+    }
+
+    // Computes the sum of the ciphertexts.
+    ///
+    /// - Returns None if ciphertexts is empty
+    ///
+    /// See [Self::unchecked_sum_ciphertexts] for constraints
+    pub fn smart_sum_ciphertexts<T, C>(&self, mut ciphertexts: C) -> Option<T>
+    where
+        C: AsMut<[T]> + AsRef<[T]>,
+        T: IntegerRadixCiphertext,
+    {
+        ciphertexts.as_mut().iter_mut().for_each(|ct| {
+            self.conditional_full_propagate(&mut *ct);
+        });
+
+        self.unchecked_sum_ciphertexts(ciphertexts.as_ref())
+    }
+    /// - Expects all ciphertexts to have empty carries
+    /// - Expects all ciphertexts to have the same size
+    pub fn unchecked_unsigned_overflowing_sum_ciphertexts_vec(
+        &self,
+        ciphertexts: Vec<RadixCiphertext>,
+    ) -> Option<(RadixCiphertext, BooleanBlock)> {
+        warn!("Non-optimized function call. Contact Belfort if you experience a slow run.");
+        self.key
+            .key
+            .unchecked_unsigned_overflowing_sum_ciphertexts_vec_parallelized(ciphertexts)
+    }
+
+    /// Computes the sum of the unsigned ciphertexts.
+    /// Returns a boolean indicating if the sum overflowed, that is,
+    /// the result did not fit in a ciphertext.
+    ///
+    /// See [Self::unchecked_sum_ciphertexts_vec_parallelized]
+    pub fn unchecked_unsigned_overflowing_sum_ciphertexts<'a, C>(
+        &self,
+        ciphertexts: C,
+    ) -> Option<(RadixCiphertext, BooleanBlock)>
+    where
+        C: IntoIterator<Item = &'a RadixCiphertext>,
+    {
+        let ciphertexts = ciphertexts.into_iter().map(Clone::clone).collect();
+        self.unchecked_unsigned_overflowing_sum_ciphertexts_vec(ciphertexts)
+    }
+
+    /// Computes the sum of the unsigned ciphertexts.
+    /// Returns a boolean indicating if the sum overflowed, that is,
+    /// the result did not fit in a ciphertext.
+    ///
+    /// - Returns None if ciphertexts is empty
+    ///
+    /// See [Self::unchecked_sum_ciphertexts] for constraints
+    pub fn unsigned_overflowing_sum_ciphertexts<'a, C>(
+        &self,
+        ciphertexts: C,
+    ) -> Option<(RadixCiphertext, BooleanBlock)>
+    where
+        C: IntoIterator<Item = &'a RadixCiphertext>,
+    {
+        let mut ciphertexts = ciphertexts
+            .into_iter()
+            .map(Clone::clone)
+            .collect::<Vec<_>>();
+        ciphertexts
+            .iter_mut()
+            .filter(|ct| ct.block_carries_are_empty())
+            .for_each(|ct| self.conditional_full_propagate(ct));
+
+        self.unchecked_unsigned_overflowing_sum_ciphertexts_vec(ciphertexts)
+    }
+
+    /// Computes the sum of the unsigned ciphertexts.
+    /// Returns a boolean indicating if the sum overflowed, that is,
+    /// the result did not fit in a ciphertext.
+    ///
+    /// - Returns None if ciphertexts is empty
+    ///
+    /// See [Self::unchecked_sum_ciphertexts] for constraints
+    pub fn smart_unsigned_overflowing_sum_ciphertexts<C>(
+        &self,
+        mut ciphertexts: C,
+    ) -> Option<(RadixCiphertext, BooleanBlock)>
+    where
+        C: AsMut<[RadixCiphertext]> + AsRef<[RadixCiphertext]>,
+    {
+        ciphertexts.as_mut().iter_mut().for_each(|ct| {
+            self.conditional_full_propagate(ct);
+        });
+
+        self.unchecked_unsigned_overflowing_sum_ciphertexts(ciphertexts.as_ref())
+    }
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/tests/mod.rs b/tfhe/src/integer/fpga/server_key/radix/tests/mod.rs
new file mode 100644
index 000000000..fdfe1dc3d
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/tests/mod.rs
@@ -0,0 +1,141 @@
+use std::sync::Arc;
+
+use crate::integer::server_key::radix_parallel::tests_cases_unsigned::FunctionExecutor;
+use crate::integer::server_key::radix_parallel::tests_unsigned::NotTuple;
+use crate::integer::{RadixClientKey, ServerKey};
+use crate::BelfortServerKey;
+
+pub(crate) mod test_add;
+pub(crate) mod test_bitwise_op;
+pub(crate) mod test_comparison;
+pub(crate) mod test_div_mod;
+pub(crate) mod test_ilog2;
+pub(crate) mod test_mul;
+pub(crate) mod test_neg;
+pub(crate) mod test_propagate;
+pub(crate) mod test_rotate;
+pub(crate) mod test_scalar_add;
+pub(crate) mod test_scalar_bitwise_op;
+pub(crate) mod test_scalar_comparison;
+pub(crate) mod test_scalar_div_mod;
+pub(crate) mod test_scalar_mul;
+pub(crate) mod test_scalar_rotate;
+pub(crate) mod test_scalar_shift;
+pub(crate) mod test_scalar_sub;
+pub(crate) mod test_shift;
+pub(crate) mod test_sub;
+pub(crate) mod test_sum;
+
+macro_rules! _timed_execution {
+    ($code:expr) => {{
+        use std::time::Instant;
+        let time_start = Instant::now();
+        let result = $code;
+        let execution_time = time_start.elapsed();
+        println!("     Executed in {:?}", execution_time);
+        result
+    }};
+}
+macro_rules! create_test_default_params {
+    (
+        $name:ident
+    ) => {
+        $crate::integer::tests::create_parameterized_test!($name {
+            coverage => {
+                COVERAGE_PARAM_MESSAGE_2_CARRY_2_KS_PBS,
+            },
+            no_coverage => {
+                PARAM_MESSAGE_2_CARRY_2_KS_PBS,
+            }
+        });
+    };
+}
+pub(crate) use create_test_default_params;
+
+/// The function executor for FPGA server key,
+/// which forwards call to a BelfortServerKey method
+pub(crate) struct FpgaFunctionExecutor<F> {
+    /// The server key is set later, when the test cast calls setup
+    pub(crate) fks: Option<BelfortServerKey>,
+    /// The server key function which will be called
+    pub(crate) func: F,
+}
+
+impl<F> FpgaFunctionExecutor<F> {
+    pub(crate) fn new(func: F) -> Self {
+        Self { fks: None, func }
+    }
+
+    pub(crate) fn setup(&mut self, server_key: Arc<ServerKey>) {
+        self.disconnect();
+        self.fks = Some(BelfortServerKey::from(server_key));
+        let fpga_key = self.fks.as_mut().unwrap();
+        fpga_key.connect();
+    }
+
+    pub(crate) fn setup_single_fpga(&mut self, server_key: Arc<ServerKey>) {
+        self.disconnect();
+        self.fks = Some(BelfortServerKey::from(server_key));
+        let fpga_key = self.fks.as_mut().unwrap();
+        fpga_key.connect_to(vec![0]);
+    }
+
+    fn disconnect(&mut self) {
+        if let Some(fpga_key) = self.fks.as_mut() {
+            fpga_key.disconnect();
+        }
+    }
+}
+
+// Ensures fpga key is disconnected when it goes out of memory
+impl<F> Drop for FpgaFunctionExecutor<F> {
+    fn drop(&mut self) {
+        self.disconnect();
+    }
+}
+
+/// For unary operations
+impl<'a, F, I1, O> FunctionExecutor<I1, O> for FpgaFunctionExecutor<F>
+where
+    F: Fn(&BelfortServerKey, I1) -> O,
+    I1: NotTuple,
+{
+    fn setup(&mut self, _cks: &RadixClientKey, server_key: Arc<ServerKey>) {
+        self.setup(server_key);
+    }
+
+    fn execute(&mut self, input: I1) -> O {
+        let fks = self.fks.as_ref().expect("setup was not properly called");
+        (self.func)(fks, input)
+    }
+}
+
+/// For binary operations
+impl<F, I1, I2, O> FunctionExecutor<(I1, I2), O> for FpgaFunctionExecutor<F>
+where
+    F: Fn(&BelfortServerKey, I1, I2) -> O,
+{
+    fn setup(&mut self, _cks: &RadixClientKey, server_key: Arc<ServerKey>) {
+        self.setup(server_key);
+    }
+
+    fn execute(&mut self, input: (I1, I2)) -> O {
+        let fks = self.fks.as_ref().expect("setup was not properly called");
+        (self.func)(fks, input.0, input.1)
+    }
+}
+
+/// For ternary operations
+impl<F, I1, I2, I3, O> FunctionExecutor<(I1, I2, I3), O> for FpgaFunctionExecutor<F>
+where
+    F: Fn(&BelfortServerKey, I1, I2, I3) -> O,
+{
+    fn setup(&mut self, _cks: &RadixClientKey, server_key: Arc<ServerKey>) {
+        self.setup(server_key);
+    }
+
+    fn execute(&mut self, input: (I1, I2, I3)) -> O {
+        let fks = self.fks.as_ref().expect("setup was not properly called");
+        (self.func)(fks, input.0, input.1, input.2)
+    }
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/tests/test_add.rs b/tfhe/src/integer/fpga/server_key/radix/tests/test_add.rs
new file mode 100644
index 000000000..43ea97807
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/tests/test_add.rs
@@ -0,0 +1,34 @@
+use crate::integer::fpga::server_key::radix::tests::{
+    create_test_default_params, FpgaFunctionExecutor,
+};
+
+use crate::integer::fpga::BelfortServerKey;
+use crate::integer::server_key::radix_parallel::tests_unsigned::test_add::*;
+use crate::shortint::parameters::*;
+
+////////////////////////////////////////////////////////////////////////////////
+// The tests
+//
+// We do not inlcude all functions in `add.rs`, but exclude;
+//  - `pub(crate)` funcs, as they are helper functions
+//  - `_assign()` funcs, as normal versions already use them
+//  - `_unchecked()` funcs; they are actually the sw version, so tested there
+
+create_test_default_params!(integer_smart_add);
+create_test_default_params!(integer_default_add);
+
+fn integer_smart_add<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::smart_add);
+    smart_add_test(param, executor);
+}
+
+fn integer_default_add<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::add);
+    default_add_test(param, executor);
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/tests/test_bitwise_op.rs b/tfhe/src/integer/fpga/server_key/radix/tests/test_bitwise_op.rs
new file mode 100644
index 000000000..a7ea33c39
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/tests/test_bitwise_op.rs
@@ -0,0 +1,104 @@
+use crate::integer::fpga::server_key::radix::tests::{
+    create_test_default_params, FpgaFunctionExecutor,
+};
+use crate::integer::server_key::radix_parallel::tests_cases_unsigned::{
+    default_bitand_test, default_bitnot_test, default_bitor_test, default_bitxor_test,
+    smart_bitand_test, smart_bitor_test, smart_bitxor_test, unchecked_bitand_test,
+    unchecked_bitor_test, unchecked_bitxor_test,
+};
+
+use crate::integer::fpga::BelfortServerKey;
+#[cfg(tarpaulin)]
+use crate::shortint::parameters::coverage_parameters::*;
+use crate::shortint::parameters::*;
+
+create_test_default_params!(integer_smart_bitand);
+create_test_default_params!(integer_smart_bitor);
+create_test_default_params!(integer_smart_bitxor);
+create_test_default_params!(integer_default_bitand);
+create_test_default_params!(integer_default_bitxor);
+create_test_default_params!(integer_default_bitor);
+create_test_default_params!(integer_default_bitnot);
+create_test_default_params!(integer_unchecked_bitand);
+create_test_default_params!(integer_unchecked_bitxor);
+create_test_default_params!(integer_unchecked_bitor);
+
+fn integer_smart_bitand<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::smart_bitand);
+    smart_bitand_test(param, executor);
+}
+
+fn integer_smart_bitor<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::smart_bitor);
+    smart_bitor_test(param, executor);
+}
+
+fn integer_smart_bitxor<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::smart_bitxor);
+    smart_bitxor_test(param, executor);
+}
+
+fn integer_default_bitand<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::bitand);
+    default_bitand_test(param, executor);
+}
+
+fn integer_default_bitor<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::bitor);
+    default_bitor_test(param, executor);
+}
+
+fn integer_default_bitxor<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::bitxor);
+    default_bitxor_test(param, executor);
+}
+
+fn integer_default_bitnot<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::bitnot);
+    default_bitnot_test(param, executor);
+}
+
+fn integer_unchecked_bitand<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::unchecked_bitand);
+    unchecked_bitand_test(param, executor);
+}
+
+fn integer_unchecked_bitor<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::unchecked_bitor);
+    unchecked_bitor_test(param, executor);
+}
+
+fn integer_unchecked_bitxor<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::unchecked_bitxor);
+    unchecked_bitxor_test(param, executor);
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/tests/test_comparison.rs b/tfhe/src/integer/fpga/server_key/radix/tests/test_comparison.rs
new file mode 100644
index 000000000..87a7e7d3b
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/tests/test_comparison.rs
@@ -0,0 +1,114 @@
+use crate::integer::fpga::server_key::radix::tests::{
+    create_test_default_params, FpgaFunctionExecutor,
+};
+use crate::integer::server_key::radix_parallel::tests_unsigned::test_comparison::{
+    test_default_function, test_default_minmax, test_smart_function, test_smart_minmax,
+    test_unchecked_function, test_unchecked_minmax,
+};
+use crate::integer::U256;
+
+use crate::integer::fpga::BelfortServerKey;
+use crate::shortint::parameters::*;
+
+create_test_default_params!(integer_unchecked_min_u256);
+create_test_default_params!(integer_unchecked_max_u256);
+create_test_default_params!(integer_smart_min_u256);
+create_test_default_params!(integer_smart_max_u256);
+create_test_default_params!(integer_min_u256);
+create_test_default_params!(integer_max_u256);
+
+fn integer_unchecked_min_u256(params: impl Into<PBSParameters>) {
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::unchecked_min);
+    test_unchecked_minmax(params, 2, executor, std::cmp::min::<U256>);
+}
+
+fn integer_unchecked_max_u256(params: impl Into<PBSParameters>) {
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::unchecked_max);
+    test_unchecked_minmax(params, 2, executor, std::cmp::max::<U256>);
+}
+
+fn integer_smart_min_u256(params: impl Into<PBSParameters>) {
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::smart_min);
+    test_smart_minmax(params, 2, executor, std::cmp::min::<U256>);
+}
+
+fn integer_smart_max_u256(params: impl Into<PBSParameters>) {
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::smart_max);
+    test_smart_minmax(params, 2, executor, std::cmp::max::<U256>);
+}
+
+fn integer_min_u256(params: impl Into<PBSParameters>) {
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::min);
+    test_default_minmax(params, 2, executor, std::cmp::min::<U256>);
+}
+
+fn integer_max_u256(params: impl Into<PBSParameters>) {
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::max);
+    test_default_minmax(params, 2, executor, std::cmp::max::<U256>);
+}
+
+/// This macro generates the tests for a given comparison fn
+///
+/// All our comparison function have 3 variants:
+/// - unchecked_$comparison_name
+/// - smart_$comparison_name
+/// - default $comparison_name
+///
+/// So, for example, for the `gt` comparison fn, this macro will generate the tests for
+/// the 3 variants described above
+macro_rules! define_comparison_test_functions {
+    ($comparison_name:ident, $clear_type:ty) => {
+        ::paste::paste!{
+            fn [<integer_unchecked_ $comparison_name _ $clear_type:lower>]<P>(param: P) where P: Into<PBSParameters>{
+                let num_tests = 1;
+                let executor = FpgaFunctionExecutor::new(&BelfortServerKey::[<unchecked_ $comparison_name>]);
+                test_unchecked_function(
+                    param,
+                    num_tests,
+                    executor,
+                    |lhs, rhs| $clear_type::from(<$clear_type>::$comparison_name(&lhs, &rhs)),
+                )
+            }
+
+            fn [<integer_smart_ $comparison_name _ $clear_type:lower>]<P>(param: P) where P: Into<PBSParameters> {
+                let num_tests = 1;
+                let executor = FpgaFunctionExecutor::new(&BelfortServerKey::[<smart_ $comparison_name>]);
+                test_smart_function(
+                    param,
+                    num_tests,
+                    executor,
+                    |lhs, rhs| $clear_type::from(<$clear_type>::$comparison_name(&lhs, &rhs)),
+                )
+            }
+
+            fn [<integer_default_ $comparison_name _ $clear_type:lower>]<P>(param: P) where P: Into<PBSParameters> {
+                let num_tests = 1;
+                let executor = FpgaFunctionExecutor::new(&BelfortServerKey::[<$comparison_name>]);
+                test_default_function(
+                    param,
+                    num_tests,
+                    executor,
+                    |lhs, rhs| $clear_type::from(<$clear_type>::$comparison_name(&lhs, &rhs)),
+                )
+            }
+
+            create_test_default_params!([<integer_unchecked_ $comparison_name _ $clear_type:lower>]);
+            create_test_default_params!([<integer_smart_ $comparison_name _ $clear_type:lower>]);
+            create_test_default_params!([<integer_default_ $comparison_name _ $clear_type:lower>]);
+        }
+    };
+}
+
+define_comparison_test_functions!(eq, U256);
+define_comparison_test_functions!(ne, U256);
+define_comparison_test_functions!(lt, U256);
+define_comparison_test_functions!(le, U256);
+define_comparison_test_functions!(gt, U256);
+define_comparison_test_functions!(ge, U256);
+
+define_comparison_test_functions!(eq, u8);
+define_comparison_test_functions!(ne, u8);
+define_comparison_test_functions!(lt, u8);
+define_comparison_test_functions!(le, u8);
+define_comparison_test_functions!(gt, u8);
+define_comparison_test_functions!(ge, u8);
diff --git a/tfhe/src/integer/fpga/server_key/radix/tests/test_div_mod.rs b/tfhe/src/integer/fpga/server_key/radix/tests/test_div_mod.rs
new file mode 100644
index 000000000..628ae53bc
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/tests/test_div_mod.rs
@@ -0,0 +1,62 @@
+use crate::integer::fpga::server_key::radix::tests::{
+    create_test_default_params, FpgaFunctionExecutor,
+};
+
+use crate::integer::fpga::BelfortServerKey;
+use crate::integer::server_key::radix_parallel::tests_unsigned::test_div_mod::*;
+use crate::shortint::parameters::*;
+
+create_test_default_params!(integer_smart_div_rem);
+create_test_default_params!(integer_smart_div);
+create_test_default_params!(integer_smart_rem);
+create_test_default_params!(integer_default_div_rem);
+create_test_default_params!(integer_default_div);
+create_test_default_params!(integer_default_rem);
+
+fn integer_smart_div_rem<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::smart_div_rem);
+    smart_div_rem_test(param, executor);
+}
+
+fn integer_smart_div<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::smart_div);
+    smart_div_test(param, executor);
+}
+
+fn integer_smart_rem<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::smart_rem);
+    smart_rem_test(param, executor);
+}
+
+fn integer_default_div_rem<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::div_rem);
+    default_div_rem_test(param, executor);
+}
+
+fn integer_default_div<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::div);
+    default_div_test(param, executor);
+}
+
+fn integer_default_rem<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::rem);
+    default_rem_test(param, executor);
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/tests/test_ilog2.rs b/tfhe/src/integer/fpga/server_key/radix/tests/test_ilog2.rs
new file mode 100644
index 000000000..fe66f05a1
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/tests/test_ilog2.rs
@@ -0,0 +1,56 @@
+use crate::integer::fpga::server_key::radix::tests::{
+    create_test_default_params, FpgaFunctionExecutor,
+};
+use crate::integer::server_key::radix_parallel::tests_unsigned::test_ilog2::{
+    default_ilog2_test, default_leading_ones_test, default_leading_zeros_test,
+    default_trailing_ones_test, default_trailing_zeros_test,
+};
+
+use crate::integer::fpga::BelfortServerKey;
+use crate::shortint::parameters::*;
+
+create_test_default_params!(integer_default_trailing_zeros);
+create_test_default_params!(integer_default_trailing_ones);
+create_test_default_params!(integer_default_leading_zeros);
+create_test_default_params!(integer_default_leading_ones);
+create_test_default_params!(integer_default_ilog2);
+
+fn integer_default_trailing_zeros<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::trailing_zeros);
+    default_trailing_zeros_test(param, executor);
+}
+
+fn integer_default_trailing_ones<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::trailing_ones);
+    default_trailing_ones_test(param, executor);
+}
+
+fn integer_default_leading_zeros<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::leading_zeros);
+    default_leading_zeros_test(param, executor);
+}
+
+fn integer_default_leading_ones<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::leading_ones);
+    default_leading_ones_test(param, executor);
+}
+
+fn integer_default_ilog2<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::ilog2);
+    default_ilog2_test(param, executor);
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/tests/test_mul.rs b/tfhe/src/integer/fpga/server_key/radix/tests/test_mul.rs
new file mode 100644
index 000000000..40cc23097
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/tests/test_mul.rs
@@ -0,0 +1,147 @@
+use std::sync::Arc;
+
+use rand::Rng;
+
+use crate::integer::ciphertext::BaseRadixCiphertext;
+use crate::integer::fpga::server_key::radix::tests::{
+    create_test_default_params, FpgaFunctionExecutor,
+};
+use crate::integer::fpga::BelfortServerKey;
+use crate::integer::keycache::KEY_CACHE;
+use crate::integer::server_key::radix_parallel::tests_cases_unsigned::{
+    default_default_block_mul_test, default_mul_test, smart_block_mul_test, smart_mul_test,
+    unchecked_block_mul_test, unchecked_mul_corner_cases_test, unchecked_mul_test,
+};
+use crate::integer::server_key::radix_parallel::tests_unsigned::{
+    nb_tests_smaller_for_params, NB_CTXT,
+};
+use crate::integer::{IntegerKeyKind, RadixCiphertext, RadixClientKey};
+use crate::shortint::parameters::*;
+use crate::shortint::Ciphertext;
+
+use super::FunctionExecutor;
+
+create_test_default_params!(integer_default_mul);
+create_test_default_params!(integer_unchecked_mul);
+create_test_default_params!(integer_unchecked_mul_corner_cases);
+create_test_default_params!(integer_unchecked_block_mul);
+create_test_default_params!(integer_smart_block_mul);
+create_test_default_params!(integer_default_block_mul);
+create_test_default_params!(integer_smart_mul);
+create_test_default_params!(integer_trivial_mul);
+
+fn integer_default_mul<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::mul);
+    default_mul_test(param, executor);
+}
+
+fn integer_unchecked_mul<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::unchecked_mul);
+    unchecked_mul_test(param, executor);
+}
+
+fn integer_unchecked_mul_corner_cases<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::unchecked_mul);
+    unchecked_mul_corner_cases_test(param, executor);
+}
+
+fn integer_smart_mul<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::smart_mul);
+    smart_mul_test(param, executor);
+}
+
+fn integer_unchecked_block_mul<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::unchecked_block_mul);
+    unchecked_block_mul_test(param, executor);
+}
+
+fn integer_smart_block_mul<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::smart_block_mul);
+    smart_block_mul_test(param, executor);
+}
+
+fn integer_default_block_mul<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::block_mul);
+    default_default_block_mul_test(param, executor);
+}
+
+fn integer_trivial_mul<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::mul);
+    trivial_encryption_mul_test(param, executor);
+}
+
+fn trivial_encryption_mul_test<P, T>(param: P, mut executor: T)
+where
+    P: Into<PBSParameters>,
+    T: for<'a> FunctionExecutor<(&'a RadixCiphertext, &'a RadixCiphertext), RadixCiphertext>,
+{
+    let param = param.into();
+    let (cks, mut sks) = KEY_CACHE.get_from_params(param, IntegerKeyKind::Radix);
+    let cks = RadixClientKey::from((cks, NB_CTXT));
+
+    sks.set_deterministic_pbs_execution(true);
+    let sks = Arc::new(sks);
+
+    let mut rng = rand::thread_rng();
+
+    // message_modulus^vec_length
+    let modulus = cks.parameters().message_modulus().0.pow(NB_CTXT as u32) as u64;
+
+    executor.setup(&cks, sks.clone());
+
+    {
+        // test x * x
+        // where x is a trivial encryption of an integer with some of its bits set to 0
+        let clear = 16u8;
+        let num_blocks = 8;
+
+        let ctxt: BaseRadixCiphertext<Ciphertext> = sks.create_trivial_radix(clear, num_blocks);
+        let ctxt_clone = ctxt.clone();
+
+        let res = executor.execute((&ctxt, &ctxt_clone));
+        let dec: u16 = cks.decrypt(&res);
+        assert_eq!(dec, clear as u16 * clear as u16);
+    }
+
+    let nb_tests_smaller = nb_tests_smaller_for_params(param);
+    for _ in 0..nb_tests_smaller {
+        let clear1 = rng.gen::<u64>() % modulus;
+        let clear2 = rng.gen::<u64>() % modulus;
+
+        let ctxt_1: BaseRadixCiphertext<Ciphertext> = sks.create_trivial_radix(clear1, NB_CTXT);
+        let ctxt_2: BaseRadixCiphertext<Ciphertext> = sks.create_trivial_radix(clear2, NB_CTXT);
+
+        let mut res = ctxt_1.clone();
+
+        res = executor.execute((&res, &ctxt_2));
+        assert!(res.block_carries_are_empty());
+        let dec: u64 = cks.decrypt(&res);
+
+        let clear = (clear1 * clear2) % modulus;
+        assert_eq!(clear, dec);
+    }
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/tests/test_neg.rs b/tfhe/src/integer/fpga/server_key/radix/tests/test_neg.rs
new file mode 100644
index 000000000..68257bb91
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/tests/test_neg.rs
@@ -0,0 +1,28 @@
+use crate::integer::fpga::server_key::radix::tests::{
+    create_test_default_params, FpgaFunctionExecutor,
+};
+use crate::integer::fpga::BelfortServerKey;
+use crate::integer::server_key::radix_parallel::tests_unsigned::test_neg::*;
+
+#[cfg(tarpaulin)]
+use crate::shortint::parameters::coverage_parameters::*;
+use crate::shortint::parameters::*;
+
+create_test_default_params!(integer_smart_neg);
+create_test_default_params!(integer_default_neg);
+
+fn integer_smart_neg<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::smart_neg);
+    smart_neg_test(param, executor);
+}
+
+fn integer_default_neg<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::neg);
+    default_neg_test(param, executor);
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/tests/test_propagate.rs b/tfhe/src/integer/fpga/server_key/radix/tests/test_propagate.rs
new file mode 100644
index 000000000..408b2e193
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/tests/test_propagate.rs
@@ -0,0 +1,69 @@
+use crate::integer::fpga::server_key::radix::tests::{
+    create_test_default_params, FpgaFunctionExecutor,
+};
+use crate::integer::fpga::BelfortServerKey;
+
+use crate::integer::keycache::KEY_CACHE;
+use crate::integer::server_key::radix_parallel::tests_cases_unsigned::{
+    full_propagate_test, FunctionExecutor,
+};
+use crate::integer::{IntegerCiphertext, IntegerKeyKind, RadixCiphertext, RadixClientKey};
+use rand::Rng;
+use std::sync::Arc;
+use std::u128;
+
+use crate::shortint::parameters::*;
+
+create_test_default_params!(integer_full_propagate);
+create_test_default_params!(integer_single_fpga_propagate);
+
+fn integer_full_propagate<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::full_propagate);
+    full_propagate_test(param, executor);
+}
+
+fn integer_single_fpga_propagate<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::full_propagate);
+    single_fpga_propagate_with_first_block_clean_test(param, executor);
+}
+
+fn single_fpga_propagate_with_first_block_clean_test<P, F>(
+    param: P,
+    mut executor: FpgaFunctionExecutor<F>,
+) where
+    P: Into<PBSParameters>,
+    F: Fn(&BelfortServerKey, &mut RadixCiphertext) -> (),
+{
+    let (cks, sks) = KEY_CACHE.get_from_params(param, IntegerKeyKind::Radix);
+    let sks = Arc::new(sks);
+
+    let nb_ctxt =
+        (128f64 / (cks.parameters().message_modulus().0 as f64).log2().ceil()).ceil() as usize;
+
+    let cks: RadixClientKey = RadixClientKey::from((cks, nb_ctxt));
+
+    executor.setup_single_fpga(sks.clone());
+
+    let mut rng = rand::thread_rng();
+
+    let clear = rng.gen::<u128>();
+    // Ensure first block doesn't have carries
+    let clear_2 = rng.gen::<u128>() << 2;
+
+    let mut ct = cks.encrypt(clear);
+    let ct_2 = cks.encrypt(clear_2);
+
+    ct = sks.unchecked_add(&ct, &ct_2);
+    ct.blocks_mut()[0].degree = Degree::new(0);
+
+    executor.execute(&mut ct);
+    let clear_res = clear.wrapping_add(clear_2);
+    let dec_res = cks.decrypt::<u128>(&ct);
+    assert!(clear_res == dec_res, "Calculated results are the same!");
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/tests/test_rotate.rs b/tfhe/src/integer/fpga/server_key/radix/tests/test_rotate.rs
new file mode 100644
index 000000000..3713436f8
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/tests/test_rotate.rs
@@ -0,0 +1,47 @@
+use crate::integer::fpga::server_key::radix::tests::{
+    create_test_default_params, FpgaFunctionExecutor,
+};
+use crate::integer::server_key::radix_parallel::tests_cases_unsigned::{
+    default_rotate_left_test, default_rotate_right_test, unchecked_rotate_left_test,
+    unchecked_rotate_right_test,
+};
+
+use crate::integer::fpga::BelfortServerKey;
+use crate::shortint::parameters::*;
+
+create_test_default_params!(integer_unchecked_rotate_right);
+create_test_default_params!(integer_rotate_right);
+create_test_default_params!(integer_unchecked_rotate_left);
+create_test_default_params!(integer_rotate_left);
+
+fn integer_unchecked_rotate_right<P>(param: P)
+where
+    P: Into<PBSParameters> + Copy,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::unchecked_rotate_right);
+    unchecked_rotate_right_test(param, executor);
+}
+
+fn integer_rotate_right<P>(param: P)
+where
+    P: Into<PBSParameters> + Copy,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::rotate_right);
+    default_rotate_right_test(param, executor);
+}
+
+fn integer_unchecked_rotate_left<P>(param: P)
+where
+    P: Into<PBSParameters> + Copy,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::unchecked_rotate_left);
+    unchecked_rotate_left_test(param, executor);
+}
+
+fn integer_rotate_left<P>(param: P)
+where
+    P: Into<PBSParameters> + Copy,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::rotate_left);
+    default_rotate_left_test(param, executor);
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/tests/test_scalar_add.rs b/tfhe/src/integer/fpga/server_key/radix/tests/test_scalar_add.rs
new file mode 100644
index 000000000..d9dfc1151
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/tests/test_scalar_add.rs
@@ -0,0 +1,38 @@
+use crate::integer::fpga::server_key::radix::tests::{
+    create_test_default_params, FpgaFunctionExecutor,
+};
+use crate::integer::fpga::BelfortServerKey;
+
+use crate::integer::server_key::radix_parallel::tests_cases_unsigned::{
+    default_scalar_add_test, smart_scalar_add_test,
+};
+use crate::shortint::parameters::*;
+
+create_test_default_params!(integer_smart_scalar_add);
+create_test_default_params!(integer_default_scalar_add);
+// TODO: enable test when Belfort support is there
+// create_test_default_params!(integer_default_overflowing_scalar_add);
+
+fn integer_smart_scalar_add<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::smart_scalar_add);
+    smart_scalar_add_test(param, executor);
+}
+
+fn integer_default_scalar_add<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::scalar_add);
+    default_scalar_add_test(param, executor);
+}
+
+// fn integer_default_overflowing_scalar_add<P>(param: P)
+// where
+//     P: Into<PBSParameters>,
+// {
+//     let executor = FpgaFunctionExecutor::new(&BelfortServerKey::unsigned_overflowing_scalar_add);
+//     default_overflowing_scalar_add_test(param, executor);
+// }
diff --git a/tfhe/src/integer/fpga/server_key/radix/tests/test_scalar_bitwise_op.rs b/tfhe/src/integer/fpga/server_key/radix/tests/test_scalar_bitwise_op.rs
new file mode 100644
index 000000000..95a67555f
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/tests/test_scalar_bitwise_op.rs
@@ -0,0 +1,37 @@
+use crate::integer::fpga::server_key::radix::tests::{
+    create_test_default_params, FpgaFunctionExecutor,
+};
+use crate::integer::fpga::BelfortServerKey;
+
+use crate::integer::server_key::radix_parallel::tests_cases_unsigned::{
+    default_scalar_bitand_test, default_scalar_bitor_test, default_scalar_bitxor_test,
+};
+use crate::shortint::parameters::*;
+
+create_test_default_params!(integer_default_scalar_bitand);
+create_test_default_params!(integer_default_scalar_bitor);
+create_test_default_params!(integer_default_scalar_bitxor);
+
+fn integer_default_scalar_bitand<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::scalar_bitand);
+    default_scalar_bitand_test(param, executor);
+}
+
+fn integer_default_scalar_bitor<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::scalar_bitor);
+    default_scalar_bitor_test(param, executor);
+}
+
+fn integer_default_scalar_bitxor<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::scalar_bitxor);
+    default_scalar_bitxor_test(param, executor);
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/tests/test_scalar_comparison.rs b/tfhe/src/integer/fpga/server_key/radix/tests/test_scalar_comparison.rs
new file mode 100644
index 000000000..a9d94e8c2
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/tests/test_scalar_comparison.rs
@@ -0,0 +1,108 @@
+use crate::integer::fpga::server_key::radix::tests::{
+    create_test_default_params, FpgaFunctionExecutor,
+};
+use crate::integer::server_key::radix_parallel::tests_unsigned::test_scalar_comparison::{
+    test_default_scalar_function, test_default_scalar_minmax, test_smart_scalar_function,
+    test_smart_scalar_minmax, test_unchecked_scalar_function, test_unchecked_scalar_minmax,
+};
+use crate::integer::U256;
+
+use crate::integer::fpga::BelfortServerKey;
+use crate::shortint::parameters::*;
+use crate::shortint::ClassicPBSParameters;
+
+create_test_default_params!(integer_unchecked_scalar_min_u256);
+create_test_default_params!(integer_unchecked_scalar_max_u256);
+create_test_default_params!(integer_smart_scalar_min_u256);
+create_test_default_params!(integer_smart_scalar_max_u256);
+create_test_default_params!(integer_scalar_min_u256);
+create_test_default_params!(integer_scalar_max_u256);
+
+fn integer_unchecked_scalar_min_u256(params: ClassicPBSParameters) {
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::unchecked_scalar_min);
+    test_unchecked_scalar_minmax(params, 2, executor, std::cmp::min::<U256>);
+}
+
+fn integer_unchecked_scalar_max_u256(params: ClassicPBSParameters) {
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::unchecked_scalar_max);
+    test_unchecked_scalar_minmax(params, 2, executor, std::cmp::max::<U256>);
+}
+
+fn integer_smart_scalar_min_u256(params: ClassicPBSParameters) {
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::smart_scalar_min);
+    test_smart_scalar_minmax(params, 2, executor, std::cmp::min::<U256>);
+}
+
+fn integer_smart_scalar_max_u256(params: ClassicPBSParameters) {
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::smart_scalar_max);
+    test_smart_scalar_minmax(params, 2, executor, std::cmp::max::<U256>);
+}
+
+fn integer_scalar_min_u256(params: ClassicPBSParameters) {
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::scalar_min);
+    test_default_scalar_minmax(params, 2, executor, std::cmp::min::<U256>);
+}
+
+fn integer_scalar_max_u256(params: ClassicPBSParameters) {
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::scalar_max);
+    test_default_scalar_minmax(params, 2, executor, std::cmp::max::<U256>);
+}
+
+/// This macro generates the tests for a given scalar comparison fn
+///
+/// All our scalar comparison function have 3 variants:
+/// - unchecked_scalar_$comparison_name
+/// - smart_scalar_$comparison_name
+/// - scalar_$comparison_name
+///
+/// So, for example, for the `gt` comparison fn,
+/// this macro will generate the tests for the 3 variants described above
+macro_rules! define_scalar_comparison_test_functions {
+    ($comparison_name:ident, $clear_type:ty) => {
+        ::paste::paste!{
+            fn [<integer_unchecked_scalar_ $comparison_name _ $clear_type:lower>]<P>(param: P) where P: Into<PBSParameters>{
+                let num_tests = 1;
+                let executor = FpgaFunctionExecutor::new(&BelfortServerKey::[<unchecked_scalar_ $comparison_name>]);
+                test_unchecked_scalar_function(
+                    param,
+                    num_tests,
+                    executor,
+                    |lhs, rhs| $clear_type::from(<$clear_type>::$comparison_name(&lhs, &rhs)),
+                )
+            }
+
+            fn [<integer_smart_scalar_ $comparison_name _ $clear_type:lower>]<P>(param: P) where P: Into<PBSParameters>{
+                let num_tests = 1;
+                let executor = FpgaFunctionExecutor::new(&BelfortServerKey::[<smart_scalar_ $comparison_name>]);
+                test_smart_scalar_function(
+                    param,
+                    num_tests,
+                    executor,
+                    |lhs, rhs| $clear_type::from(<$clear_type>::$comparison_name(&lhs, &rhs)),
+                )
+            }
+
+            fn [<integer_default_scalar_ $comparison_name _ $clear_type:lower>]<P>(param: P) where P: Into<PBSParameters>{
+                let num_tests = 1;
+                let executor = FpgaFunctionExecutor::new(&BelfortServerKey::[<scalar_ $comparison_name>]);
+                test_default_scalar_function(
+                    param,
+                    num_tests,
+                    executor,
+                    |lhs, rhs| $clear_type::from(<$clear_type>::$comparison_name(&lhs, &rhs)),
+                )
+            }
+
+            create_test_default_params!([<integer_unchecked_scalar_ $comparison_name _ $clear_type:lower>]);
+            create_test_default_params!([<integer_smart_scalar_ $comparison_name _ $clear_type:lower>]);
+            create_test_default_params!([<integer_default_scalar_ $comparison_name _ $clear_type:lower>]);
+        }
+    };
+}
+
+define_scalar_comparison_test_functions!(eq, U256);
+define_scalar_comparison_test_functions!(ne, U256);
+define_scalar_comparison_test_functions!(lt, U256);
+define_scalar_comparison_test_functions!(le, U256);
+define_scalar_comparison_test_functions!(gt, U256);
+define_scalar_comparison_test_functions!(ge, U256);
diff --git a/tfhe/src/integer/fpga/server_key/radix/tests/test_scalar_div_mod.rs b/tfhe/src/integer/fpga/server_key/radix/tests/test_scalar_div_mod.rs
new file mode 100644
index 000000000..f3c993f34
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/tests/test_scalar_div_mod.rs
@@ -0,0 +1,17 @@
+use crate::integer::fpga::server_key::radix::tests::{
+    create_test_default_params, FpgaFunctionExecutor,
+};
+use crate::integer::server_key::radix_parallel::tests_unsigned::test_scalar_div_mod::default_scalar_div_rem_test;
+
+use crate::integer::fpga::BelfortServerKey;
+use crate::shortint::parameters::*;
+
+create_test_default_params!(integer_default_scalar_div_rem);
+
+fn integer_default_scalar_div_rem<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::scalar_div_rem);
+    default_scalar_div_rem_test(param, executor);
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/tests/test_scalar_mul.rs b/tfhe/src/integer/fpga/server_key/radix/tests/test_scalar_mul.rs
new file mode 100644
index 000000000..c325a54fb
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/tests/test_scalar_mul.rs
@@ -0,0 +1,56 @@
+use crate::integer::fpga::server_key::radix::tests::{
+    create_test_default_params, FpgaFunctionExecutor,
+};
+use crate::integer::server_key::radix_parallel::tests_cases_unsigned::{
+    default_scalar_mul_test, default_scalar_mul_u128_fix_non_reg_test, smart_scalar_mul_test,
+    smart_scalar_mul_u128_fix_non_reg_test, unchecked_scalar_mul_corner_cases_test,
+};
+
+use crate::integer::fpga::BelfortServerKey;
+use crate::shortint::parameters::*;
+
+create_test_default_params!(integer_unchecked_scalar_mul_corner_cases);
+create_test_default_params!(integer_smart_scalar_mul);
+create_test_default_params!(integer_smart_scalar_mul_u128_fix_non_reg_test);
+create_test_default_params!(integer_default_scalar_mul_u128_fix_non_reg_test);
+create_test_default_params!(integer_default_scalar_mul);
+
+fn integer_unchecked_scalar_mul_corner_cases<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::scalar_mul);
+    unchecked_scalar_mul_corner_cases_test(param, executor);
+}
+
+fn integer_smart_scalar_mul<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::smart_scalar_mul);
+    smart_scalar_mul_test(param, executor);
+}
+
+fn integer_smart_scalar_mul_u128_fix_non_reg_test<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::smart_scalar_mul);
+    smart_scalar_mul_u128_fix_non_reg_test(param, executor);
+}
+
+fn integer_default_scalar_mul_u128_fix_non_reg_test<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::scalar_mul);
+    default_scalar_mul_u128_fix_non_reg_test(param, executor);
+}
+
+fn integer_default_scalar_mul<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::scalar_mul);
+    default_scalar_mul_test(param, executor);
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/tests/test_scalar_rotate.rs b/tfhe/src/integer/fpga/server_key/radix/tests/test_scalar_rotate.rs
new file mode 100644
index 000000000..1536911a4
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/tests/test_scalar_rotate.rs
@@ -0,0 +1,47 @@
+use crate::integer::fpga::server_key::radix::tests::{
+    create_test_default_params, FpgaFunctionExecutor,
+};
+use crate::integer::server_key::radix_parallel::tests_unsigned::test_scalar_rotate::{
+    default_scalar_rotate_left_test, default_scalar_rotate_right_test,
+    unchecked_scalar_rotate_left_test, unchecked_scalar_rotate_right_test,
+};
+
+use crate::integer::fpga::BelfortServerKey;
+use crate::shortint::parameters::*;
+
+create_test_default_params!(integer_unchecked_scalar_rotate_left);
+create_test_default_params!(integer_default_scalar_rotate_left);
+create_test_default_params!(integer_unchecked_scalar_rotate_right);
+create_test_default_params!(integer_default_scalar_rotate_right);
+
+fn integer_default_scalar_rotate_left<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::scalar_rotate_left);
+    default_scalar_rotate_left_test(param, executor);
+}
+
+fn integer_unchecked_scalar_rotate_left<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::unchecked_scalar_rotate_left);
+    unchecked_scalar_rotate_left_test(param, executor);
+}
+
+fn integer_default_scalar_rotate_right<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::scalar_rotate_right);
+    default_scalar_rotate_right_test(param, executor);
+}
+
+fn integer_unchecked_scalar_rotate_right<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::unchecked_scalar_rotate_right);
+    unchecked_scalar_rotate_right_test(param, executor);
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/tests/test_scalar_shift.rs b/tfhe/src/integer/fpga/server_key/radix/tests/test_scalar_shift.rs
new file mode 100644
index 000000000..c6bb7dac5
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/tests/test_scalar_shift.rs
@@ -0,0 +1,47 @@
+use crate::integer::fpga::server_key::radix::tests::{
+    create_test_default_params, FpgaFunctionExecutor,
+};
+
+use crate::integer::fpga::BelfortServerKey;
+use crate::integer::server_key::radix_parallel::tests_cases_unsigned::{
+    default_scalar_left_shift_test, default_scalar_right_shift_test,
+    unchecked_scalar_left_shift_test, unchecked_scalar_right_shift_test,
+};
+use crate::shortint::parameters::*;
+
+create_test_default_params!(integer_unchecked_scalar_right_shift);
+create_test_default_params!(integer_unchecked_scalar_left_shift);
+create_test_default_params!(integer_scalar_right_shift);
+create_test_default_params!(integer_scalar_left_shift);
+
+fn integer_unchecked_scalar_right_shift<P>(param: P)
+where
+    P: Into<PBSParameters> + Copy,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::unchecked_scalar_right_shift);
+    unchecked_scalar_right_shift_test(param, executor);
+}
+
+fn integer_scalar_right_shift<P>(param: P)
+where
+    P: Into<PBSParameters> + Copy,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::scalar_right_shift);
+    default_scalar_right_shift_test(param, executor);
+}
+
+fn integer_unchecked_scalar_left_shift<P>(param: P)
+where
+    P: Into<PBSParameters> + Copy,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::unchecked_scalar_left_shift);
+    unchecked_scalar_left_shift_test(param, executor);
+}
+
+fn integer_scalar_left_shift<P>(param: P)
+where
+    P: Into<PBSParameters> + Copy,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::scalar_left_shift);
+    default_scalar_left_shift_test(param, executor);
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/tests/test_scalar_sub.rs b/tfhe/src/integer/fpga/server_key/radix/tests/test_scalar_sub.rs
new file mode 100644
index 000000000..70417f394
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/tests/test_scalar_sub.rs
@@ -0,0 +1,37 @@
+use crate::integer::fpga::server_key::radix::tests::{
+    create_test_default_params, FpgaFunctionExecutor,
+};
+
+use crate::integer::fpga::BelfortServerKey;
+use crate::integer::server_key::radix_parallel::tests_cases_unsigned::{
+    default_overflowing_scalar_sub_test, default_scalar_sub_test, smart_scalar_sub_test,
+};
+use crate::shortint::parameters::*;
+
+create_test_default_params!(integer_smart_scalar_sub);
+create_test_default_params!(integer_default_scalar_sub);
+create_test_default_params!(integer_default_overflowing_scalar_sub);
+
+fn integer_smart_scalar_sub<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::smart_scalar_sub);
+    smart_scalar_sub_test(param, executor);
+}
+
+fn integer_default_scalar_sub<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::scalar_sub);
+    default_scalar_sub_test(param, executor);
+}
+
+fn integer_default_overflowing_scalar_sub<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::unsigned_overflowing_scalar_sub);
+    default_overflowing_scalar_sub_test(param, executor);
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/tests/test_shift.rs b/tfhe/src/integer/fpga/server_key/radix/tests/test_shift.rs
new file mode 100644
index 000000000..22e339b96
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/tests/test_shift.rs
@@ -0,0 +1,47 @@
+use crate::integer::fpga::server_key::radix::tests::{
+    create_test_default_params, FpgaFunctionExecutor,
+};
+
+use crate::integer::fpga::BelfortServerKey;
+use crate::integer::server_key::radix_parallel::tests_cases_unsigned::{
+    default_left_shift_test, default_right_shift_test, unchecked_left_shift_test,
+    unchecked_right_shift_test,
+};
+use crate::shortint::parameters::*;
+
+create_test_default_params!(integer_unchecked_right_shift);
+create_test_default_params!(integer_right_shift);
+create_test_default_params!(integer_unchecked_left_shift);
+create_test_default_params!(integer_left_shift);
+
+fn integer_unchecked_right_shift<P>(param: P)
+where
+    P: Into<PBSParameters> + Copy,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::unchecked_right_shift);
+    unchecked_right_shift_test(param, executor);
+}
+
+fn integer_right_shift<P>(param: P)
+where
+    P: Into<PBSParameters> + Copy,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::right_shift);
+    default_right_shift_test(param, executor);
+}
+
+fn integer_unchecked_left_shift<P>(param: P)
+where
+    P: Into<PBSParameters> + Copy,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::unchecked_left_shift);
+    unchecked_left_shift_test(param, executor);
+}
+
+fn integer_left_shift<P>(param: P)
+where
+    P: Into<PBSParameters> + Copy,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::left_shift);
+    default_left_shift_test(param, executor);
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/tests/test_sub.rs b/tfhe/src/integer/fpga/server_key/radix/tests/test_sub.rs
new file mode 100644
index 000000000..44455fe25
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/tests/test_sub.rs
@@ -0,0 +1,46 @@
+use crate::integer::fpga::server_key::radix::tests::{
+    create_test_default_params, FpgaFunctionExecutor,
+};
+
+use crate::integer::fpga::BelfortServerKey;
+use crate::integer::server_key::radix_parallel::tests_unsigned::test_sub::*;
+use crate::shortint::parameters::*;
+
+////////////////////////////////////////////////////////////////////////////////
+// The tests
+//
+// We do not inlcude all functions in `sub.rs`, but exclude;
+//  - `pub(crate)` funcs, as they are helper functions
+//  - `_assign()` funcs, as normal versions already use them
+//  - `_unchecked()` funcs; they are actually the sw version, so tested there
+
+create_test_default_params!(integer_smart_sub);
+create_test_default_params!(integer_default_sub);
+create_test_default_params!(integer_default_overflowing_sub);
+
+////////////////////////////////////////////////////////////////////////////////
+// Helper functions associating tests with executors
+
+fn integer_smart_sub<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::smart_sub);
+    smart_sub_test(param, executor);
+}
+
+fn integer_default_sub<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::sub);
+    default_sub_test(param, executor);
+}
+
+fn integer_default_overflowing_sub<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::unsigned_overflowing_sub);
+    default_overflowing_sub_test(param, executor);
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/tests/test_sum.rs b/tfhe/src/integer/fpga/server_key/radix/tests/test_sum.rs
new file mode 100644
index 000000000..d445ad927
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/tests/test_sum.rs
@@ -0,0 +1,56 @@
+use crate::integer::fpga::server_key::radix::tests::{
+    create_test_default_params, FpgaFunctionExecutor,
+};
+
+use crate::integer::fpga::BelfortServerKey;
+use crate::integer::server_key::radix_parallel::tests_unsigned::test_sum::{
+    default_sum_ciphertexts_vec_test, integer_default_unsigned_overflowing_sum_ciphertexts_test,
+    integer_smart_sum_ciphertexts_slice_test,
+};
+use crate::integer::{BooleanBlock, RadixCiphertext};
+use crate::shortint::parameters::*;
+
+create_test_default_params!(integer_smart_sum_ciphertexts_slice);
+create_test_default_params!(integer_default_unsigned_overflowing_sum_ciphertexts_vec);
+create_test_default_params!(integer_default_sum_ciphertexts_vec);
+
+fn integer_default_unsigned_overflowing_sum_ciphertexts_vec<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let overflowing_sum_vec = |sks: &BelfortServerKey,
+                               ctxt: &Vec<RadixCiphertext>|
+     -> Option<(RadixCiphertext, BooleanBlock)> {
+        sks.unsigned_overflowing_sum_ciphertexts(ctxt)
+    };
+    let executor = FpgaFunctionExecutor::new(overflowing_sum_vec);
+    integer_default_unsigned_overflowing_sum_ciphertexts_test(param, executor);
+}
+
+fn integer_smart_sum_ciphertexts_slice<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    // Without this the compiler seems lost, and outputs errors about
+    // 'one type is more general than the other' probably because the
+    // `sum_ciphertexts_parallelized` is generic over the input collection
+    let smart_sum_vec = |sks: &BelfortServerKey,
+                         ctxt: &mut Vec<RadixCiphertext>|
+     -> Option<RadixCiphertext> { sks.smart_sum_ciphertexts(ctxt) };
+    let executor = FpgaFunctionExecutor::new(smart_sum_vec);
+    integer_smart_sum_ciphertexts_slice_test(param, executor);
+}
+
+fn integer_default_sum_ciphertexts_vec<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    // Without this the compiler seems lost, and outputs errors about
+    // 'one type is more general than the other' probably because the
+    // `sum_ciphertexts_parallelized` is generic over the input collection
+    let sum_vec = |sks: &BelfortServerKey,
+                   ctxt: &Vec<RadixCiphertext>|
+     -> Option<RadixCiphertext> { sks.sum_ciphertexts(ctxt) };
+    let executor = FpgaFunctionExecutor::new(sum_vec);
+    default_sum_ciphertexts_vec_test(param, executor);
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/vector_comparisons.rs b/tfhe/src/integer/fpga/server_key/radix/vector_comparisons.rs
new file mode 100644
index 000000000..081a1af40
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/vector_comparisons.rs
@@ -0,0 +1,103 @@
+use crate::integer::fpga::server_key::BelfortServerKey;
+use crate::integer::{BooleanBlock, IntegerRadixCiphertext};
+use log::warn;
+impl BelfortServerKey {
+    /// Compares two slices containing ciphertexts and returns an encryption of `true` if all
+    /// pairs are equal, otherwise, returns an encryption of `false`.
+    ///
+    /// - If slices do not have the same length, false is returned
+    /// - If at least one  pair (`lhs[i]`, `rhs[i]`) do not have the same number of blocks, false is
+    ///   returned
+    pub fn unchecked_all_eq_slices<T>(&self, lhs: &[T], rhs: &[T]) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        warn!("Non-optimized function call. Contact Belfort if you experience a slow run.");
+        self.key.key.unchecked_all_eq_slices_parallelized(lhs, rhs)
+    }
+
+    /// Compares two slices containing ciphertexts and returns an encryption of `true` if all
+    /// pairs are equal, otherwise, returns an encryption of `false`.
+    ///
+    /// - If slices do not have the same length, false is returned
+    /// - If at least one  pair (`lhs[i]`, `rhs[i]`) do not have the same number of blocks, false is
+    ///   returned
+    pub fn smart_all_eq_slices<T>(&self, lhs: &mut [T], rhs: &mut [T]) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        lhs.iter_mut()
+            .chain(rhs.iter_mut())
+            .for_each(|ct| self.conditional_full_propagate(ct));
+        self.unchecked_all_eq_slices(lhs, rhs)
+    }
+
+    /// Compares two slices containing ciphertexts and returns an encryption of `true` if all
+    /// pairs are equal, otherwise, returns an encryption of `false`.
+    ///
+    /// - If slices do not have the same length, false is returned
+    /// - If at least one  pair (`lhs[i]`, `rhs[i]`) do not have the same number of blocks, false is
+    ///   returned
+    pub fn all_eq_slices<T>(&self, lhs: &[T], rhs: &[T]) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut lhs_clone;
+        let mut rhs_clone;
+        let lhs = if lhs.iter().any(|ct| !ct.block_carries_are_empty()) {
+            lhs_clone = lhs.to_vec();
+            lhs_clone
+                .iter_mut()
+                .for_each(|ct| self.conditional_full_propagate(ct));
+            &lhs_clone
+        } else {
+            lhs
+        };
+
+        let rhs = if rhs.iter().any(|ct| !ct.block_carries_are_empty()) {
+            rhs_clone = rhs.to_vec();
+            rhs_clone
+                .iter_mut()
+                .for_each(|ct| self.conditional_full_propagate(ct));
+            &rhs_clone
+        } else {
+            rhs
+        };
+
+        self.unchecked_all_eq_slices(lhs, rhs)
+    }
+
+    /// Returns a boolean ciphertext encrypting `true` if `lhs` contains `rhs`, `false` otherwise
+    pub fn unchecked_contains_sub_slice<T>(&self, lhs: &[T], rhs: &[T]) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        warn!("Non-optimized function call. Contact Belfort if you experience a slow run.");
+        self.key
+            .key
+            .unchecked_contains_sub_slice_parallelized(lhs, rhs)
+    }
+
+    /// Returns a boolean ciphertext encrypting `true` if `lhs` contains `rhs`, `false` otherwise
+    pub fn smart_contains_sub_slice<T>(&self, lhs: &mut [T], rhs: &mut [T]) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        lhs.iter_mut().chain(rhs.iter_mut()).for_each(|radix| {
+            self.conditional_full_propagate(radix);
+        });
+
+        self.unchecked_contains_sub_slice(lhs, rhs)
+    }
+
+    /// Returns a boolean ciphertext encrypting `true` if `lhs` contains `rhs`, `false` otherwise
+    pub fn contains_sub_slice<T>(&self, lhs: &[T], rhs: &[T]) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        warn!("Non-optimized function call. Contact Belfort if you experience a slow run.");
+        self.key
+            .key
+            .unchecked_contains_sub_slice_parallelized(lhs, rhs)
+    }
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/vector_find.rs b/tfhe/src/integer/fpga/server_key/radix/vector_find.rs
new file mode 100644
index 000000000..aa6d3d51a
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/vector_find.rs
@@ -0,0 +1,720 @@
+use crate::core_crypto::prelude::UnsignedInteger;
+use crate::integer::fpga::server_key::BelfortServerKey;
+
+use crate::integer::block_decomposition::DecomposableInto;
+use crate::integer::server_key::radix_parallel::MatchValues;
+use crate::integer::{BooleanBlock, IntegerRadixCiphertext, RadixCiphertext};
+use crate::prelude::CastInto;
+use log::warn;
+use std::hash::Hash;
+
+impl BelfortServerKey {
+    /// `match` an input value to an output value
+    ///
+    /// - Input values are not required to span all possible values that `ct` could hold.
+    ///
+    /// - The output radix has a number of blocks that depends on the maximum possible output value
+    ///   from the `MatchValues`
+    ///
+    /// Returns a boolean block that encrypts `true` if the input `ct`
+    /// matched one of the possible inputs
+    pub fn unchecked_match_value<Clear>(
+        &self,
+        ct: &RadixCiphertext,
+        matches: &MatchValues<Clear>,
+    ) -> (RadixCiphertext, BooleanBlock)
+    where
+        Clear: UnsignedInteger + DecomposableInto<u64> + CastInto<usize>,
+    {
+        warn!("Non-optimized function call. Contact Belfort if you experience a slow run.");
+        self.key.key.unchecked_match_value_parallelized(ct, matches)
+    }
+
+    /// `match` an input value to an output value
+    ///
+    /// - Input values are not required to span all possible values that `ct` could hold.
+    ///
+    /// - The output radix has a number of blocks that depends on the maximum possible output value
+    ///   from the `MatchValues`
+    ///
+    /// Returns a boolean block that encrypts `true` if the input `ct`
+    /// matched one of the possible inputs
+    pub fn smart_match_value<Clear>(
+        &self,
+        ct: &mut RadixCiphertext,
+        matches: &MatchValues<Clear>,
+    ) -> (RadixCiphertext, BooleanBlock)
+    where
+        Clear: UnsignedInteger + DecomposableInto<u64> + CastInto<usize>,
+    {
+        self.conditional_full_propagate(ct);
+        self.unchecked_match_value(ct, matches)
+    }
+
+    /// `match` an input value to an output value
+    ///
+    /// - Input values are not required to span all possible values that `ct` could hold.
+    ///
+    /// - The output radix has a number of blocks that depends on the maximum possible output value
+    ///   from the `MatchValues`
+    ///
+    /// Returns a boolean block that encrypts `true` if the input `ct`
+    /// matched one of the possible inputs
+    pub fn match_value<Clear>(
+        &self,
+        ct: &RadixCiphertext,
+        matches: &MatchValues<Clear>,
+    ) -> (RadixCiphertext, BooleanBlock)
+    where
+        Clear: UnsignedInteger + DecomposableInto<u64> + CastInto<usize>,
+    {
+        if ct.block_carries_are_empty() {
+            self.unchecked_match_value(ct, matches)
+        } else {
+            let mut clone = ct.clone();
+            self.full_propagate(&mut clone);
+            self.unchecked_match_value(&clone, matches)
+        }
+    }
+
+    /// `match` an input value to an output value
+    ///
+    /// - Input values are not required to span all possible values that `ct` could hold.
+    ///
+    /// - The output radix has a number of blocks that depends on the maximum possible output value
+    ///   from the `MatchValues`
+    ///
+    ///
+    /// If none of the input matched the `ct` then, `ct` will encrypt the
+    /// value given to `or_value`
+    pub fn unchecked_match_value_or<Clear>(
+        &self,
+        ct: &RadixCiphertext,
+        matches: &MatchValues<Clear>,
+        or_value: Clear,
+    ) -> RadixCiphertext
+    where
+        Clear: UnsignedInteger + DecomposableInto<u64> + CastInto<usize>,
+    {
+        self.key
+            .key
+            .unchecked_match_value_or_parallelized(ct, matches, or_value)
+    }
+
+    /// `map` an input value to an output value
+    ///
+    /// - Input values are not required to span all possible values that `ct` could hold.
+    ///
+    /// - The output radix has a number of blocks that depends on the maximum possible output value
+    ///   from the `MatchValues`
+    ///
+    /// If none of the input matched the `ct` then, `ct` will encrypt the
+    /// value given to `or_value`
+    pub fn smart_match_value_or<Clear>(
+        &self,
+        ct: &mut RadixCiphertext,
+        matches: &MatchValues<Clear>,
+        or_value: Clear,
+    ) -> RadixCiphertext
+    where
+        Clear: UnsignedInteger + DecomposableInto<u64> + CastInto<usize>,
+    {
+        self.conditional_full_propagate(ct);
+        self.unchecked_match_value_or(ct, matches, or_value)
+    }
+
+    /// `match` an input value to an output value
+    ///
+    /// - Input values are not required to span all possible values that `ct` could hold.
+    ///
+    /// - The output radix has a number of blocks that depends on the maximum possible output value
+    ///   from the `MatchValues`
+    ///
+    /// If none of the input matched the `ct` then, `ct` will encrypt the
+    /// value given to `or_value`
+    pub fn match_value_or<Clear>(
+        &self,
+        ct: &RadixCiphertext,
+        matches: &MatchValues<Clear>,
+        or_value: Clear,
+    ) -> RadixCiphertext
+    where
+        Clear: UnsignedInteger + DecomposableInto<u64> + CastInto<usize>,
+    {
+        if ct.block_carries_are_empty() {
+            self.unchecked_match_value_or(ct, matches, or_value)
+        } else {
+            let mut clone = ct.clone();
+            self.full_propagate(&mut clone);
+            self.unchecked_match_value_or(&clone, matches, or_value)
+        }
+    }
+
+    /// Returns an encrypted `true` if the encrypted `value` is found in the encrypted slice
+    pub fn unchecked_contains<T>(&self, cts: &[T], value: &T) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        warn!("Non-optimized function call. Contact Belfort if you experience a slow run.");
+        self.key.key.unchecked_contains_parallelized(cts, value)
+    }
+
+    /// Returns an encrypted `true` if the encrypted `value` is found in the encrypted slice
+    pub fn smart_contains<T>(&self, cts: &mut [T], value: &mut T) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        warn!("Non-optimized function call. Contact Belfort if you experience a slow run.");
+        self.key.key.smart_contains_parallelized(cts, value)
+    }
+
+    /// Returns an encrypted `true` if the encrypted `value` is found in the encrypted slice
+    pub fn contains<T>(&self, cts: &[T], value: &T) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut tmp_cts;
+        let mut tmp_value;
+
+        let cts = if cts.iter().any(|ct| !ct.block_carries_are_empty()) {
+            tmp_cts = cts.to_vec();
+            tmp_cts
+                .iter_mut()
+                .for_each(|ct| self.conditional_full_propagate(ct));
+            &tmp_cts
+        } else {
+            cts
+        };
+
+        let value = if value.block_carries_are_empty() {
+            value
+        } else {
+            tmp_value = value.clone();
+            self.full_propagate(&mut tmp_value);
+            &tmp_value
+        };
+
+        self.unchecked_contains(cts, value)
+    }
+
+    /// Returns an encrypted `true` if the clear `value` is found in the encrypted slice
+    pub fn unchecked_contains_clear<T, Clear>(&self, cts: &[T], clear: Clear) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+        Clear: DecomposableInto<u64>,
+    {
+        self.key
+            .key
+            .unchecked_contains_clear_parallelized(cts, clear)
+    }
+
+    /// Returns an encrypted `true` if the clear `value` is found in the encrypted slice
+    pub fn smart_contains_clear<T, Clear>(&self, cts: &mut [T], clear: Clear) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+        Clear: DecomposableInto<u64>,
+    {
+        let mut tmp_cts;
+
+        let cts = if cts.iter().any(|ct| !ct.block_carries_are_empty()) {
+            tmp_cts = cts.to_vec();
+            tmp_cts
+                .iter_mut()
+                .filter(|ct| !ct.block_carries_are_empty())
+                .for_each(|ct| self.full_propagate(ct));
+            tmp_cts.as_slice()
+        } else {
+            cts
+        };
+
+        self.unchecked_contains_clear(cts, clear)
+    }
+
+    /// Returns an encrypted `true` if the clear `value` is found in the encrypted slice
+    pub fn contains_clear<T, Clear>(&self, cts: &[T], clear: Clear) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+        Clear: DecomposableInto<u64>,
+    {
+        warn!("Non-optimized function call. Contact Belfort if you experience a slow run.");
+        self.key.key.contains_clear_parallelized(cts, clear)
+    }
+
+    /// Returns an encrypted `true` if the encrypted `value` is found in the clear slice
+    pub fn unchecked_is_in_clears<T, Clear>(&self, ct: &T, clears: &[Clear]) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+        Clear: DecomposableInto<u64> + CastInto<usize>,
+    {
+        warn!("Non-optimized function call. Contact Belfort if you experience a slow run.");
+        self.key.key.unchecked_is_in_clears_parallelized(ct, clears)
+    }
+
+    /// Returns an encrypted `true` if the encrypted `value` is found in the clear slice
+    pub fn smart_is_in_clears<T, Clear>(&self, ct: &mut T, clears: &[Clear]) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+        Clear: DecomposableInto<u64> + CastInto<usize>,
+    {
+        self.conditional_full_propagate(ct);
+        self.unchecked_is_in_clears(ct, clears)
+    }
+
+    /// Returns an encrypted `true` if the encrypted `value` is found in the clear slice
+    pub fn is_in_clears<T, Clear>(&self, ct: &T, clears: &[Clear]) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+        Clear: DecomposableInto<u64> + CastInto<usize>,
+    {
+        let mut tmp_ct;
+        let ct = if ct.block_carries_are_empty() {
+            ct
+        } else {
+            tmp_ct = ct.clone();
+            self.full_propagate(&mut tmp_ct);
+            &tmp_ct
+        };
+        self.unchecked_is_in_clears(ct, clears)
+    }
+
+    /// Returns the encrypted index of the encrypted `value` in the clear slice
+    /// also returns an encrypted boolean that is `true` if the encrypted value was found.
+    ///
+    /// # Notes
+    ///
+    /// - clear values in the slice must be unique (otherwise use
+    ///   [Self::unchecked_first_index_in_clears])
+    /// - If the encrypted value is not in the clear slice, the returned index is 0
+    pub fn unchecked_index_in_clears<T, Clear>(
+        &self,
+        ct: &T,
+        clears: &[Clear],
+    ) -> (RadixCiphertext, BooleanBlock)
+    where
+        T: IntegerRadixCiphertext,
+        Clear: DecomposableInto<u64> + CastInto<usize>,
+    {
+        self.key
+            .key
+            .unchecked_index_in_clears_parallelized(ct, clears)
+    }
+
+    /// Returns the encrypted index of the encrypted `value` in the clear slice
+    /// also returns an encrypted boolean that is `true` if the encrypted value was found.
+    ///
+    /// # Notes
+    ///
+    /// - clear values in the slice must be unique (otherwise use
+    ///   [Self::smart_first_index_in_clears])
+    /// - If the encrypted value is not in the clear slice, the returned index is 0
+    pub fn smart_index_in_clears<T, Clear>(
+        &self,
+        ct: &mut T,
+        clears: &[Clear],
+    ) -> (RadixCiphertext, BooleanBlock)
+    where
+        T: IntegerRadixCiphertext,
+        Clear: DecomposableInto<u64> + CastInto<usize>,
+    {
+        self.conditional_full_propagate(ct);
+        self.unchecked_index_in_clears(ct, clears)
+    }
+
+    /// Returns the encrypted index of the encrypted `value` in the clear slice
+    /// also returns an encrypted boolean that is `true` if the encrypted value was found.
+    ///
+    /// # Notes
+    ///
+    /// - clear values in the slice must be unique (otherwise use [Self::index_in_clears])
+    /// - If the encrypted value is not in the clear slice, the returned index is 0
+    pub fn index_in_clears<T, Clear>(
+        &self,
+        ct: &T,
+        clears: &[Clear],
+    ) -> (RadixCiphertext, BooleanBlock)
+    where
+        T: IntegerRadixCiphertext,
+        Clear: DecomposableInto<u64> + CastInto<usize>,
+    {
+        let mut tmp_ct;
+        let ct = if ct.block_carries_are_empty() {
+            ct
+        } else {
+            tmp_ct = ct.clone();
+            self.full_propagate(&mut tmp_ct);
+            &tmp_ct
+        };
+
+        self.unchecked_index_in_clears(ct, clears)
+    }
+
+    /// Returns the encrypted index of the _first_ occurrence of encrypted `value` in the clear
+    /// slice also, it returns an encrypted boolean that is `true` if the encrypted value was
+    /// found.
+    ///
+    /// # Notes
+    ///
+    /// - If the encrypted value is not in the clear slice, the returned index is 0
+    pub fn unchecked_first_index_in_clears<T, Clear>(
+        &self,
+        ct: &T,
+        clears: &[Clear],
+    ) -> (RadixCiphertext, BooleanBlock)
+    where
+        T: IntegerRadixCiphertext,
+        Clear: DecomposableInto<u64> + CastInto<usize> + Hash,
+    {
+        self.key
+            .key
+            .unchecked_first_index_in_clears_parallelized(ct, clears)
+    }
+
+    /// Returns the encrypted index of the _first_ occurrence of encrypted `value` in the clear
+    /// slice also, it returns an encrypted boolean that is `true` if the encrypted value was
+    /// found.
+    ///
+    /// # Notes
+    ///
+    /// - If the encrypted value is not in the clear slice, the returned index is 0
+    pub fn smart_first_index_in_clears_parallelized<T, Clear>(
+        &self,
+        ct: &mut T,
+        clears: &[Clear],
+    ) -> (RadixCiphertext, BooleanBlock)
+    where
+        T: IntegerRadixCiphertext,
+        Clear: DecomposableInto<u64> + CastInto<usize> + Hash,
+    {
+        self.conditional_full_propagate(ct);
+
+        self.unchecked_first_index_in_clears(ct, clears)
+    }
+
+    /// Returns the encrypted index of the _first_ occurrence of encrypted `value` in the clear
+    /// slice also, it returns an encrypted boolean that is `true` if the encrypted value was
+    /// found.
+    ///
+    /// # Notes
+    ///
+    /// - If the encrypted value is not in the clear slice, the returned index is 0
+    pub fn first_index_in_clears<T, Clear>(
+        &self,
+        ct: &T,
+        clears: &[Clear],
+    ) -> (RadixCiphertext, BooleanBlock)
+    where
+        T: IntegerRadixCiphertext,
+        Clear: DecomposableInto<u64> + CastInto<usize> + Hash,
+    {
+        let mut tmp_ct;
+        let ct = if ct.block_carries_are_empty() {
+            ct
+        } else {
+            tmp_ct = ct.clone();
+            self.full_propagate(&mut tmp_ct);
+            &tmp_ct
+        };
+
+        self.unchecked_first_index_in_clears(ct, clears)
+    }
+
+    /// Returns the encrypted index of the of encrypted `value` in the ciphertext slice
+    /// also, it returns an encrypted boolean that is `true` if the encrypted value was found.
+    ///
+    /// # Notes
+    ///
+    /// - clear values in the slice must be unique (otherwise use [Self::unchecked_first_index_of])
+    /// - If the encrypted value is not in the encrypted slice, the returned index is 0
+    pub fn unchecked_index_of<T>(&self, cts: &[T], value: &T) -> (RadixCiphertext, BooleanBlock)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        warn!("Non-optimized function call. Contact Belfort if you experience a slow run.");
+        self.key.key.unchecked_index_of_parallelized(cts, value)
+    }
+
+    /// Returns the encrypted index of the of encrypted `value` in the ciphertext slice
+    /// also, it returns an encrypted boolean that is `true` if the encrypted value was found.
+    ///
+    /// # Notes
+    ///
+    /// - clear values in the slice must be unique (otherwise use [Self::smart_first_index_of])
+    /// - If the encrypted value is not in the encrypted slice, the returned index is 0
+    pub fn smart_index_of<T>(&self, cts: &mut [T], value: &mut T) -> (RadixCiphertext, BooleanBlock)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.conditional_full_propagate(value);
+
+        cts.iter_mut()
+            .for_each(|ct| self.conditional_full_propagate(ct));
+
+        self.unchecked_index_of(cts, value)
+    }
+
+    /// Returns the encrypted index of the of encrypted `value` in the ciphertext slice
+    /// also, it returns an encrypted boolean that is `true` if the encrypted value was found.
+    ///
+    /// # Notes
+    ///
+    /// - clear values in the slice must be unique (otherwise use [Self::first_index_of])
+    /// - If the encrypted value is not in the encrypted slice, the returned index is 0
+    pub fn index_of<T>(&self, cts: &[T], value: &T) -> (RadixCiphertext, BooleanBlock)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut tmp_cts;
+        let mut tmp_value;
+
+        let cts = if cts.iter().any(|ct| !ct.block_carries_are_empty()) {
+            tmp_cts = cts.to_vec();
+            tmp_cts
+                .iter_mut()
+                .filter(|ct| !ct.block_carries_are_empty())
+                .for_each(|ct| self.full_propagate(ct));
+            &tmp_cts
+        } else {
+            cts
+        };
+
+        let value = if value.block_carries_are_empty() {
+            value
+        } else {
+            tmp_value = value.clone();
+            self.full_propagate(&mut tmp_value);
+            &tmp_value
+        };
+
+        self.unchecked_index_of(cts, value)
+    }
+
+    /// Returns the encrypted index of the of clear `value` in the ciphertext slice
+    /// also, it returns an encrypted boolean that is `true` if the encrypted value was found.
+    ///
+    /// # Notes
+    ///
+    /// - clear values in the slice must be unique (otherwise use
+    ///   [Self::unchecked_first_index_of_clear])
+    /// - If the clear value is not in the encrypted slice, the returned index is 0
+    pub fn unchecked_index_of_clear<T, Clear>(
+        &self,
+        cts: &[T],
+        clear: Clear,
+    ) -> (RadixCiphertext, BooleanBlock)
+    where
+        T: IntegerRadixCiphertext,
+        Clear: DecomposableInto<u64> + CastInto<usize>,
+    {
+        self.key
+            .key
+            .unchecked_index_of_clear_parallelized(cts, clear)
+    }
+
+    /// Returns the encrypted index of the of clear `value` in the ciphertext slice
+    /// also, it returns an encrypted boolean that is `true` if the encrypted value was found.
+    ///
+    /// # Notes
+    ///
+    /// - clear values in the slice must be unique (otherwise use
+    ///   [Self::smart_first_index_of_clear_parallelized])
+    /// - If the clear value is not in the encrypted slice, the returned index is 0
+    pub fn smart_index_of_clear<T, Clear>(
+        &self,
+        cts: &mut [T],
+        clear: Clear,
+    ) -> (RadixCiphertext, BooleanBlock)
+    where
+        T: IntegerRadixCiphertext,
+        Clear: DecomposableInto<u64> + CastInto<usize>,
+    {
+        cts.iter_mut()
+            .for_each(|ct| self.conditional_full_propagate(ct));
+
+        self.unchecked_index_of_clear(cts, clear)
+    }
+
+    /// Returns the encrypted index of the of clear `value` in the ciphertext slice
+    /// also, it returns an encrypted boolean that is `true` if the encrypted value was found.
+    ///
+    /// # Notes
+    ///
+    /// - clear values in the slice must be unique (otherwise use
+    ///   [Self::first_index_of_clear_parallelized])
+    /// - If the clear value is not in the encrypted slice, the returned index is 0
+    pub fn index_of_clear_parallelized<T, Clear>(
+        &self,
+        cts: &[T],
+        clear: Clear,
+    ) -> (RadixCiphertext, BooleanBlock)
+    where
+        T: IntegerRadixCiphertext,
+        Clear: DecomposableInto<u64> + CastInto<usize>,
+    {
+        let mut tmp_cts;
+
+        let cts = if cts.iter().any(|ct| !ct.block_carries_are_empty()) {
+            tmp_cts = cts.to_vec();
+            tmp_cts
+                .iter_mut()
+                .for_each(|ct| self.conditional_full_propagate(ct));
+            tmp_cts.as_slice()
+        } else {
+            cts
+        };
+
+        self.unchecked_index_of_clear(cts, clear)
+    }
+
+    /// Returns the encrypted index of the _first_ occurrence of clear `value` in the ciphertext
+    /// slice also, it returns an encrypted boolean that is `true` if the encrypted value was
+    /// found.
+    ///
+    /// # Notes
+    ///
+    /// - If the clear value is not in the clear slice, the returned index is 0
+    pub fn unchecked_first_index_of_clear<T, Clear>(
+        &self,
+        cts: &[T],
+        clear: Clear,
+    ) -> (RadixCiphertext, BooleanBlock)
+    where
+        T: IntegerRadixCiphertext,
+        Clear: DecomposableInto<u64> + CastInto<usize>,
+    {
+        self.key
+            .key
+            .unchecked_first_index_of_clear_parallelized(cts, clear)
+    }
+
+    /// Returns the encrypted index of the _first_ occurrence of clear `value` in the ciphertext
+    /// slice also, it returns an encrypted boolean that is `true` if the encrypted value was
+    /// found.
+    ///
+    /// # Notes
+    ///
+    /// - If the clear value is not in the clear slice, the returned index is 0
+    pub fn smart_first_index_of_clear<T, Clear>(
+        &self,
+        cts: &mut [T],
+        clear: Clear,
+    ) -> (RadixCiphertext, BooleanBlock)
+    where
+        T: IntegerRadixCiphertext,
+        Clear: DecomposableInto<u64> + CastInto<usize>,
+    {
+        cts.iter_mut()
+            .filter(|ct| !ct.block_carries_are_empty())
+            .for_each(|ct| self.conditional_full_propagate(ct));
+
+        self.unchecked_first_index_of_clear(cts, clear)
+    }
+
+    /// Returns the encrypted index of the _first_ occurrence of clear `value` in the ciphertext
+    /// slice also, it returns an encrypted boolean that is `true` if the encrypted value was
+    /// found.
+    ///
+    /// # Notes
+    ///
+    /// - If the clear value is not in the clear slice, the returned index is 0
+    pub fn first_index_of_clear<T, Clear>(
+        &self,
+        cts: &[T],
+        clear: Clear,
+    ) -> (RadixCiphertext, BooleanBlock)
+    where
+        T: IntegerRadixCiphertext,
+        Clear: DecomposableInto<u64> + CastInto<usize>,
+    {
+        let mut tmp_cts;
+
+        let cts = if cts.iter().any(|ct| !ct.block_carries_are_empty()) {
+            tmp_cts = cts.to_vec();
+            tmp_cts
+                .iter_mut()
+                .for_each(|ct| self.conditional_full_propagate(ct));
+            tmp_cts.as_slice()
+        } else {
+            cts
+        };
+
+        self.unchecked_first_index_of_clear(cts, clear)
+    }
+
+    /// Returns the encrypted index of the _first_ occurrence of encrypted `value` in the ciphertext
+    /// slice also, it returns an encrypted boolean that is `true` if the encrypted value was
+    /// found.
+    ///
+    /// # Notes
+    ///
+    /// - If the encrypted value is not in the clear slice, the returned index is 0
+    pub fn unchecked_first_index_of<T>(
+        &self,
+        cts: &[T],
+        value: &T,
+    ) -> (RadixCiphertext, BooleanBlock)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.key
+            .key
+            .unchecked_first_index_of_parallelized(cts, value)
+    }
+
+    /// Returns the encrypted index of the _first_ occurrence of encrypted `value` in the ciphertext
+    /// slice also, it returns an encrypted boolean that is `true` if the encrypted value was
+    /// found.
+    ///
+    /// # Notes
+    ///
+    /// - If the encrypted value is not in the clear slice, the returned index is 0
+    pub fn smart_first_index_of_parallelized<T>(
+        &self,
+        cts: &mut [T],
+        value: &mut T,
+    ) -> (RadixCiphertext, BooleanBlock)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.conditional_full_propagate(value);
+
+        cts.iter_mut()
+            .for_each(|ct| self.conditional_full_propagate(ct));
+
+        self.unchecked_first_index_of(cts, value)
+    }
+
+    /// Returns the encrypted index of the _first_ occurrence of encrypted `value` in the ciphertext
+    /// slice also, it returns an encrypted boolean that is `true` if the encrypted value was
+    /// found.
+    ///
+    /// # Notes
+    ///
+    /// - If the encrypted value is not in the clear slice, the returned index is 0
+    pub fn first_index_of<T>(&self, cts: &[T], value: &T) -> (RadixCiphertext, BooleanBlock)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut tmp_cts;
+        let mut tmp_value;
+
+        let cts = if cts.iter().any(|ct| !ct.block_carries_are_empty()) {
+            tmp_cts = cts.to_vec();
+            tmp_cts
+                .iter_mut()
+                .for_each(|ct| self.conditional_full_propagate(ct));
+            &tmp_cts
+        } else {
+            cts
+        };
+
+        let value = if value.block_carries_are_empty() {
+            value
+        } else {
+            tmp_value = value.clone();
+            self.conditional_full_propagate(&mut tmp_value);
+            &tmp_value
+        };
+
+        self.unchecked_first_index_of(cts, value)
+    }
+}
diff --git a/tfhe/src/integer/mod.rs b/tfhe/src/integer/mod.rs
index 9fcd4cd57..0d2bd9347 100755
--- a/tfhe/src/integer/mod.rs
+++ b/tfhe/src/integer/mod.rs
@@ -66,12 +66,13 @@ pub mod parameters;
 pub mod prelude;
 pub mod public_key;
 pub mod server_key;
-#[cfg(feature = "experimental")]
-pub mod wopbs;
 
 #[cfg(feature = "gpu")]
 pub mod gpu;
 
+#[cfg(feature = "fpga")]
+pub mod fpga;
+
 #[cfg(feature = "zk-pok")]
 pub use ciphertext::ProvenCompactCiphertextList;
 
diff --git a/tfhe/src/integer/server_key/comparator.rs b/tfhe/src/integer/server_key/comparator.rs
index c68ce4193..17e98b476 100644
--- a/tfhe/src/integer/server_key/comparator.rs
+++ b/tfhe/src/integer/server_key/comparator.rs
@@ -16,7 +16,7 @@ pub(crate) enum ZeroComparisonType {
 
 /// Simple enum to select whether we are looking for the min or the max
 #[derive(Clone, Copy)]
-enum MinMaxSelector {
+pub(crate) enum MinMaxSelector {
     Max,
     Min,
 }
diff --git a/tfhe/src/integer/server_key/radix_parallel/count_zeros_ones.rs b/tfhe/src/integer/server_key/radix_parallel/count_zeros_ones.rs
index 828e6d709..e34f8f318 100644
--- a/tfhe/src/integer/server_key/radix_parallel/count_zeros_ones.rs
+++ b/tfhe/src/integer/server_key/radix_parallel/count_zeros_ones.rs
@@ -5,7 +5,7 @@ use crate::shortint::ciphertext::Degree;
 use rayon::prelude::*;
 
 #[derive(Copy, Clone, PartialEq, Eq)]
-enum BitCountKind {
+pub(crate) enum BitCountKind {
     Zero,
     One,
 }
@@ -44,7 +44,11 @@ impl ServerKey {
         self.unchecked_count_bits_parallelized(ct, BitCountKind::Zero)
     }
 
-    fn unchecked_count_bits_parallelized<T>(&self, ct: &T, kind: BitCountKind) -> RadixCiphertext
+    pub(crate) fn unchecked_count_bits_parallelized<T>(
+        &self,
+        ct: &T,
+        kind: BitCountKind,
+    ) -> RadixCiphertext
     where
         T: IntegerRadixCiphertext,
     {
@@ -77,7 +81,11 @@ impl ServerKey {
         self.smart_count_bits_parallelized(ct, BitCountKind::Zero)
     }
 
-    fn smart_count_bits_parallelized<T>(&self, ct: &mut T, kind: BitCountKind) -> RadixCiphertext
+    pub(crate) fn smart_count_bits_parallelized<T>(
+        &self,
+        ct: &mut T,
+        kind: BitCountKind,
+    ) -> RadixCiphertext
     where
         T: IntegerRadixCiphertext,
     {
@@ -110,7 +118,7 @@ impl ServerKey {
         self.count_bits_parallelized(ct, BitCountKind::Zero)
     }
 
-    fn count_bits_parallelized<T>(&self, ct: &T, kind: BitCountKind) -> RadixCiphertext
+    pub(crate) fn count_bits_parallelized<T>(&self, ct: &T, kind: BitCountKind) -> RadixCiphertext
     where
         T: IntegerRadixCiphertext,
     {
diff --git a/tfhe/src/integer/server_key/radix_parallel/mod.rs b/tfhe/src/integer/server_key/radix_parallel/mod.rs
index b2e6f8585..0d67f8a5c 100644
--- a/tfhe/src/integer/server_key/radix_parallel/mod.rs
+++ b/tfhe/src/integer/server_key/radix_parallel/mod.rs
@@ -4,7 +4,7 @@ mod bit_extractor;
 mod bitwise_op;
 mod block_shift;
 pub(crate) mod cmux;
-mod comparison;
+pub(crate) mod comparison;
 mod div_mod;
 mod modulus_switch_compression;
 mod mul;
@@ -22,7 +22,7 @@ mod shift;
 pub(crate) mod sub;
 mod sum;
 
-mod count_zeros_ones;
+pub(crate) mod count_zeros_ones;
 pub(crate) mod ilog2;
 mod reverse_bits;
 mod slice;
diff --git a/tfhe/src/integer/server_key/radix_parallel/modulus_switch_compression.rs b/tfhe/src/integer/server_key/radix_parallel/modulus_switch_compression.rs
index 9bd218ccc..707b29478 100644
--- a/tfhe/src/integer/server_key/radix_parallel/modulus_switch_compression.rs
+++ b/tfhe/src/integer/server_key/radix_parallel/modulus_switch_compression.rs
@@ -57,7 +57,7 @@ impl ServerKey {
     }
 
     #[allow(clippy::int_plus_one)]
-    fn switch_modulus_and_compress_generic_parallelized(
+    pub(crate) fn switch_modulus_and_compress_generic_parallelized(
         &self,
         blocks: &[Ciphertext],
     ) -> CompressedModulusSwitchedRadixCiphertextGeneric {
@@ -107,7 +107,7 @@ impl ServerKey {
         }
     }
 
-    fn decompress_generic_parallelized(
+    pub(crate) fn decompress_generic_parallelized(
         &self,
         compressed_ct: &CompressedModulusSwitchedRadixCiphertextGeneric,
     ) -> Vec<Ciphertext> {
diff --git a/tfhe/src/integer/server_key/radix_parallel/mul.rs b/tfhe/src/integer/server_key/radix_parallel/mul.rs
index 72a934e1f..e18508650 100644
--- a/tfhe/src/integer/server_key/radix_parallel/mul.rs
+++ b/tfhe/src/integer/server_key/radix_parallel/mul.rs
@@ -300,7 +300,7 @@ impl ServerKey {
         self.full_propagate_parallelized(lhs);
     }
 
-    fn unchecked_block_mul_lsb_msb_parallelized<T>(
+    pub(crate) fn unchecked_block_mul_lsb_msb_parallelized<T>(
         &self,
         result_lsb: &mut T,
         result_msb: &mut T,
diff --git a/tfhe/src/integer/server_key/radix_parallel/tests_unsigned/mod.rs b/tfhe/src/integer/server_key/radix_parallel/tests_unsigned/mod.rs
index 1cdf22d7f..816b43527 100644
--- a/tfhe/src/integer/server_key/radix_parallel/tests_unsigned/mod.rs
+++ b/tfhe/src/integer/server_key/radix_parallel/tests_unsigned/mod.rs
@@ -53,7 +53,7 @@ pub(crate) const fn nb_unchecked_tests_for_params(params: PBSParameters) -> usiz
     nb_tests_for_params(params)
 }
 
-/// Returns th number of loop iteration within randomized tests
+/// Returns the number of loop iteration within randomized tests
 ///
 /// The bigger the number of bits bootstrapped by the input parameters, the smaller the
 /// number of iteration is
@@ -208,7 +208,7 @@ pub(crate) fn unsigned_modulus_u128(block_modulus: MessageModulus, num_blocks: u
 /// Given a radix ciphertext, checks that all the block's decrypted message and carry
 /// do not exceed the block's degree.
 #[track_caller]
-fn panic_if_any_block_values_exceeds_its_degree<C>(ct: &RadixCiphertext, cks: &C)
+pub(crate) fn panic_if_any_block_values_exceeds_its_degree<C>(ct: &RadixCiphertext, cks: &C)
 where
     C: AsRef<crate::integer::ClientKey>,
 {
@@ -224,7 +224,7 @@ where
 }
 
 #[track_caller]
-fn panic_if_any_block_info_exceeds_max_degree_or_noise(
+pub(crate) fn panic_if_any_block_info_exceeds_max_degree_or_noise(
     ct: &RadixCiphertext,
     max_degree: MaxDegree,
     max_noise_level: MaxNoiseLevel,
@@ -271,7 +271,7 @@ fn panic_if_any_block_info_exceeds_max_degree_or_noise(
 /// - Its decrypted_value is <= its degree
 /// - Its noise level is nominal
 #[track_caller]
-fn panic_if_any_block_is_not_clean<C>(ct: &RadixCiphertext, cks: &C)
+pub(crate) fn panic_if_any_block_is_not_clean<C>(ct: &RadixCiphertext, cks: &C)
 where
     C: AsRef<crate::integer::ClientKey>,
 {
@@ -307,7 +307,7 @@ where
 /// Panics if a block is not either a clean block (see [panic_if_any_block_is_not_clean])
 /// or if it not trivial
 #[track_caller]
-fn panic_if_any_block_is_not_clean_or_trivial<C>(ct: &RadixCiphertext, cks: &C)
+pub(crate) fn panic_if_any_block_is_not_clean_or_trivial<C>(ct: &RadixCiphertext, cks: &C)
 where
     C: AsRef<crate::integer::ClientKey>,
 {
@@ -343,15 +343,15 @@ where
 }
 
 /// Little struct meant to reduce test boilerplate and increase readability
-struct ExpectedValues<T> {
+pub(crate) struct ExpectedValues<T> {
     values: Vec<T>,
 }
 
-type ExpectedNoiseLevels = ExpectedValues<NoiseLevel>;
-type ExpectedDegrees = ExpectedValues<Degree>;
+pub(crate) type ExpectedNoiseLevels = ExpectedValues<NoiseLevel>;
+pub(crate) type ExpectedDegrees = ExpectedValues<Degree>;
 
 impl<T> ExpectedValues<T> {
-    fn new(init: T, len: usize) -> Self
+    pub(crate) fn new(init: T, len: usize) -> Self
     where
         T: Clone,
     {
@@ -360,7 +360,7 @@ impl<T> ExpectedValues<T> {
         }
     }
 
-    fn set_with(&mut self, iter: impl Iterator<Item = T>) {
+    pub(crate) fn set_with(&mut self, iter: impl Iterator<Item = T>) {
         let mut self_iter = self.values.iter_mut();
         self_iter
             .by_ref()
@@ -377,7 +377,7 @@ impl<T> ExpectedValues<T> {
 
 impl ExpectedNoiseLevels {
     #[track_caller]
-    fn panic_if_any_is_not_equal(&self, ct: &RadixCiphertext) {
+    pub(crate) fn panic_if_any_is_not_equal(&self, ct: &RadixCiphertext) {
         assert_eq!(self.values.len(), ct.blocks.len());
         for (i, (block, expected_noise)) in ct
             .blocks
@@ -396,7 +396,7 @@ impl ExpectedNoiseLevels {
 
 impl ExpectedDegrees {
     #[track_caller]
-    fn panic_if_any_is_not_equal(&self, ct: &RadixCiphertext) {
+    pub(crate) fn panic_if_any_is_not_equal(&self, ct: &RadixCiphertext) {
         assert_eq!(self.values.len(), ct.blocks.len());
         for (i, (block, expected_degree)) in ct
             .blocks
@@ -413,7 +413,7 @@ impl ExpectedDegrees {
     }
 
     #[track_caller]
-    fn panic_if_any_is_greater(&self, ct: &RadixCiphertext) {
+    pub(crate) fn panic_if_any_is_greater(&self, ct: &RadixCiphertext) {
         assert_eq!(self.values.len(), ct.blocks.len());
         for (i, (block, expected_degree)) in ct
             .blocks
@@ -555,6 +555,8 @@ impl<T> NotTuple for &mut crate::integer::ciphertext::BaseSignedRadixCiphertext<
 
 impl<T> NotTuple for &Vec<T> {}
 
+impl<T> NotTuple for &mut Vec<T> {}
+
 impl NotTuple for &crate::integer::ciphertext::BooleanBlock {}
 
 /// For unary operations
diff --git a/tfhe/src/integer/server_key/radix_parallel/tests_unsigned/test_sum.rs b/tfhe/src/integer/server_key/radix_parallel/tests_unsigned/test_sum.rs
index efac6dc09..08b7e0364 100644
--- a/tfhe/src/integer/server_key/radix_parallel/tests_unsigned/test_sum.rs
+++ b/tfhe/src/integer/server_key/radix_parallel/tests_unsigned/test_sum.rs
@@ -4,7 +4,7 @@ use crate::integer::server_key::radix_parallel::tests_unsigned::{
     nb_tests_smaller_for_params, overflowing_sum_slice_under_modulus, CpuFunctionExecutor,
 };
 use crate::integer::tests::create_parameterized_test;
-use crate::integer::{IntegerKeyKind, RadixCiphertext, RadixClientKey, ServerKey};
+use crate::integer::{BooleanBlock, IntegerKeyKind, RadixCiphertext, RadixClientKey, ServerKey};
 #[cfg(tarpaulin)]
 use crate::shortint::parameters::coverage_parameters::*;
 use crate::shortint::parameters::*;
@@ -19,7 +19,27 @@ fn integer_default_unsigned_overflowing_sum_ciphertexts_vec<P>(param: P)
 where
     P: Into<PBSParameters>,
 {
-    integer_default_unsigned_overflowing_sum_ciphertexts_test(param);
+    let overflowing_sum_vec =
+        |sks: &ServerKey, ctxt: &Vec<RadixCiphertext>| -> Option<(RadixCiphertext, BooleanBlock)> {
+            sks.unsigned_overflowing_sum_ciphertexts_parallelized(ctxt)
+        };
+    let executor = CpuFunctionExecutor::new(overflowing_sum_vec);
+    integer_default_unsigned_overflowing_sum_ciphertexts_test(param, executor);
+}
+
+fn integer_smart_sum_ciphertexts_slice<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    // Without this the compiler seems lost, and outputs errors about
+    // 'one type is more general than the other' probably because the
+    // `sum_ciphertexts_parallelized` is generic over the input collection
+    let smart_sum_vec =
+        |sks: &ServerKey, ctxt: &mut Vec<RadixCiphertext>| -> Option<RadixCiphertext> {
+            sks.smart_sum_ciphertexts_parallelized(ctxt)
+        };
+    let executor = CpuFunctionExecutor::new(smart_sum_vec);
+    integer_smart_sum_ciphertexts_slice_test(param, executor);
 }
 
 fn integer_default_sum_ciphertexts_vec<P>(param: P)
@@ -36,17 +56,23 @@ where
     default_sum_ciphertexts_vec_test(param, executor);
 }
 
-pub(crate) fn integer_default_unsigned_overflowing_sum_ciphertexts_test<P>(param: P)
-where
+pub(crate) fn integer_default_unsigned_overflowing_sum_ciphertexts_test<P, T>(
+    param: P,
+    mut executor: T,
+) where
     P: Into<PBSParameters>,
+    T: for<'a> FunctionExecutor<&'a Vec<RadixCiphertext>, Option<(RadixCiphertext, BooleanBlock)>>,
 {
     let param = param.into();
     let nb_tests_smaller = nb_tests_smaller_for_params(param);
     let (cks, sks) = KEY_CACHE.get_from_params(param, IntegerKeyKind::Radix);
-    let cks = RadixClientKey::from((cks, NB_CTXT));
 
     let mut rng = rand::thread_rng();
 
+    let cks = RadixClientKey::from((cks, NB_CTXT));
+    let sks = Arc::new(sks);
+    executor.setup(&cks, sks.clone());
+
     // message_modulus^vec_length
     let modulus = cks.parameters().message_modulus().0.pow(NB_CTXT as u32);
 
@@ -62,9 +88,7 @@ where
                 .map(|clear| cks.encrypt(clear))
                 .collect::<Vec<_>>();
 
-            let (ct_res, overflow_res) = sks
-                .unsigned_overflowing_sum_ciphertexts_parallelized(&ctxts)
-                .unwrap();
+            let (ct_res, overflow_res) = executor.execute(&ctxts).unwrap();
 
             assert_eq!(
                 overflow_res.0.degree.get(),
@@ -182,17 +206,19 @@ where
     }
 }
 
-fn integer_smart_sum_ciphertexts_slice<P>(param: P)
+pub(crate) fn integer_smart_sum_ciphertexts_slice_test<P, T>(param: P, mut executor: T)
 where
     P: Into<PBSParameters>,
+    T: for<'a> FunctionExecutor<&'a mut Vec<RadixCiphertext>, Option<RadixCiphertext>>,
 {
     let param = param.into();
     let nb_tests_smaller = nb_tests_smaller_for_params(param);
     let (cks, sks) = KEY_CACHE.get_from_params(param, IntegerKeyKind::Radix);
     let cks = RadixClientKey::from((cks, NB_CTXT));
-
     let mut rng = rand::thread_rng();
 
+    let sks = Arc::new(sks);
+    executor.setup(&cks, sks);
     // message_modulus^vec_length
     let modulus = cks.parameters().message_modulus().0.pow(NB_CTXT as u32);
 
@@ -209,7 +235,7 @@ where
                 .map(|clear| cks.encrypt(clear))
                 .collect::<Vec<_>>();
 
-            let ct_res = sks.smart_sum_ciphertexts_parallelized(&mut ctxts).unwrap();
+            let ct_res = executor.execute(&mut ctxts).unwrap();
             let ct_res: u64 = cks.decrypt(&ct_res);
             let clear = clears.iter().sum::<u64>() % modulus;
 
diff --git a/tfhe/src/integer/wopbs/mod.rs b/tfhe/src/integer/wopbs/mod.rs
deleted file mode 100644
index 40a620bd2..000000000
--- a/tfhe/src/integer/wopbs/mod.rs
+++ /dev/null
@@ -1,1182 +0,0 @@
-//! Module with the definition of the WopbsKey (WithOut padding PBS Key).
-//!
-//! This module implements the generation of another server public key, which allows to compute
-//! an alternative version of the programmable bootstrapping. This does not require the use of a
-//! bit of padding.
-#[cfg(all(test, feature = "experimental"))]
-mod test;
-
-use serde::{Deserialize, Serialize};
-
-#[derive(Clone, Serialize, Deserialize)]
-pub struct WopbsKey {
-    wopbs_key: crate::shortint::wopbs::WopbsKey,
-}
-
-#[cfg(feature = "experimental")]
-pub use experimental::*;
-
-#[cfg(feature = "experimental")]
-mod experimental {
-    pub use crate::core_crypto::commons::parameters::{CiphertextCount, PlaintextCount};
-    use crate::core_crypto::prelude::*;
-    use crate::integer::client_key::utils::i_crt;
-    use crate::integer::{ClientKey, CrtCiphertext, IntegerCiphertext, RadixCiphertext, ServerKey};
-    use crate::shortint::ciphertext::{Degree, NoiseLevel};
-    use crate::shortint::WopbsParameters;
-
-    use crate::shortint::wopbs::WopbsLUTBase;
-
-    use super::WopbsKey;
-
-    use rayon::prelude::*;
-
-    #[must_use]
-    pub struct IntegerWopbsLUT {
-        inner: WopbsLUTBase,
-    }
-
-    impl IntegerWopbsLUT {
-        pub fn new(
-            small_lut_size: PlaintextCount,
-            output_ciphertext_count: CiphertextCount,
-        ) -> Self {
-            Self {
-                inner: WopbsLUTBase::new(small_lut_size, output_ciphertext_count),
-            }
-        }
-    }
-
-    impl TryFrom<Vec<Vec<u64>>> for IntegerWopbsLUT {
-        type Error = &'static str;
-
-        fn try_from(value: Vec<Vec<u64>>) -> Result<Self, Self::Error> {
-            let small_lut_size = value[0].len();
-            if !value.iter().all(|x| x.len() == small_lut_size) {
-                return Err("All small luts must have the same size");
-            }
-
-            let small_lut_count = value.len();
-
-            Ok(Self {
-                inner: WopbsLUTBase::from_vec(
-                    value.into_iter().flatten().collect(),
-                    CiphertextCount(small_lut_count),
-                ),
-            })
-        }
-    }
-
-    impl AsRef<WopbsLUTBase> for IntegerWopbsLUT {
-        fn as_ref(&self) -> &WopbsLUTBase {
-            &self.inner
-        }
-    }
-
-    impl AsMut<WopbsLUTBase> for IntegerWopbsLUT {
-        fn as_mut(&mut self) -> &mut WopbsLUTBase {
-            &mut self.inner
-        }
-    }
-
-    impl std::ops::Index<usize> for IntegerWopbsLUT {
-        type Output = [u64];
-
-        fn index(&self, index: usize) -> &Self::Output {
-            self.as_ref().get_small_lut(index)
-        }
-    }
-
-    impl std::ops::IndexMut<usize> for IntegerWopbsLUT {
-        fn index_mut(&mut self, index: usize) -> &mut Self::Output {
-            self.as_mut().get_small_lut_mut(index)
-        }
-    }
-
-    /// ```rust
-    /// use tfhe::integer::wopbs::{decode_radix, encode_radix};
-    ///
-    /// let val = 11;
-    /// let basis = 2;
-    /// let nb_block = 5;
-    /// let radix = encode_radix(val, basis, nb_block);
-    ///
-    /// assert_eq!(val, decode_radix(&radix, basis));
-    /// ```
-    pub fn encode_radix(val: u64, basis: u64, nb_block: u64) -> Vec<u64> {
-        let mut output = vec![];
-        //Bits of message put to 1Ã©fÃ©
-        let mask = basis - 1;
-
-        let mut power = 1_u64;
-        //Put each decomposition into a new ciphertext
-        for _ in 0..nb_block {
-            let mut decomp = val & (mask * power);
-            decomp /= power;
-
-            // fill the vector with the message moduli
-            output.push(decomp);
-
-            //modulus to the power i
-            power *= basis;
-        }
-        output
-    }
-
-    pub fn encode_crt(val: u64, basis: &[u64]) -> Vec<u64> {
-        let mut output = vec![];
-        //Put each decomposition into a new ciphertext
-        for i in basis {
-            output.push(val % i);
-        }
-        output
-    }
-
-    //Concatenate two ciphertexts in one
-    //Used to compute bivariate wopbs
-    fn ciphertext_concatenation<T>(ct1: &T, ct2: &T) -> T
-    where
-        T: IntegerCiphertext,
-    {
-        let mut new_blocks = ct1.blocks().to_vec();
-        new_blocks.extend_from_slice(ct2.blocks());
-        T::from_blocks(new_blocks)
-    }
-
-    pub fn encode_mix_radix(mut val: u64, basis: &[u64], modulus: u64) -> Vec<u64> {
-        let mut output = vec![];
-        for basis in basis.iter() {
-            output.push(val % modulus);
-            val -= val % modulus;
-            let tmp = (val % (1 << basis)) >> (f64::log2(modulus as f64) as u64);
-            val >>= basis;
-            val += tmp;
-        }
-        output
-    }
-
-    // Example: val = 5 = 0b101 , basis = [1,2] -> output = [1, 1]
-    /// ```rust
-    /// use tfhe::integer::wopbs::split_value_according_to_bit_basis;
-    /// // Generate the client key and the server key:
-    /// let val = 5;
-    /// let basis = vec![1, 2];
-    /// assert_eq!(vec![1, 2], split_value_according_to_bit_basis(val, &basis));
-    /// ```
-    pub fn split_value_according_to_bit_basis(value: u64, basis: &[u64]) -> Vec<u64> {
-        let mut output = vec![];
-        let mut tmp = value;
-        let mask = 1;
-
-        for i in basis {
-            let mut tmp_output = 0;
-            for j in 0..*i {
-                let val = tmp & mask;
-                tmp_output += val << j;
-                tmp >>= 1;
-            }
-            output.push(tmp_output);
-        }
-        output
-    }
-
-    /// ```rust
-    /// use tfhe::integer::wopbs::{decode_radix, encode_radix};
-    ///
-    /// let val = 11;
-    /// let basis = 2;
-    /// let nb_block = 5;
-    /// let radix = encode_radix(val, basis, nb_block);
-    ///
-    /// assert_eq!(val, decode_radix(&radix, basis));
-    /// ```
-    pub fn decode_radix(val: &[u64], basis: u64) -> u64 {
-        let mut result = 0_u64;
-        let mut shift = 1_u64;
-        for v_i in val.iter() {
-            //decrypt the component i of the integer and multiply it by the radix product
-            let tmp = v_i.wrapping_mul(shift);
-
-            // update the result
-            result = result.wrapping_add(tmp);
-
-            // update the shift for the next iteration
-            shift = shift.wrapping_mul(basis);
-        }
-        result
-    }
-
-    impl From<crate::shortint::wopbs::WopbsKey> for WopbsKey {
-        fn from(wopbs_key: crate::shortint::wopbs::WopbsKey) -> Self {
-            Self { wopbs_key }
-        }
-    }
-
-    impl WopbsKey {
-        /// Generates the server key required to compute a WoPBS from the client and the server
-        /// keys. # Example
-        /// ```rust
-        /// use tfhe::integer::gen_keys_radix;
-        /// use tfhe::integer::wopbs::*;
-        /// use tfhe::shortint::parameters::parameters_wopbs_message_carry::LEGACY_WOPBS_PARAM_MESSAGE_1_CARRY_1_KS_PBS;
-        /// use tfhe::shortint::parameters::V0_11_PARAM_MESSAGE_1_CARRY_1_KS_PBS_GAUSSIAN_2M64;
-        ///
-        /// // Generate the client key and the server key:
-        /// let (cks, sks) = gen_keys_radix(V0_11_PARAM_MESSAGE_1_CARRY_1_KS_PBS_GAUSSIAN_2M64, 1);
-        /// let wopbs_key = WopbsKey::new_wopbs_key(&cks, &sks, &LEGACY_WOPBS_PARAM_MESSAGE_1_CARRY_1_KS_PBS);
-        /// ```
-        pub fn new_wopbs_key<IntegerClientKey: AsRef<ClientKey>>(
-            cks: &IntegerClientKey,
-            sks: &ServerKey,
-            parameters: &WopbsParameters,
-        ) -> Self {
-            Self {
-                wopbs_key: crate::shortint::wopbs::WopbsKey::new_wopbs_key(
-                    &cks.as_ref().key,
-                    &sks.key,
-                    parameters,
-                ),
-            }
-        }
-
-        /// Deconstruct a [`WopbsKey`] into its constituents.
-        pub fn into_raw_parts(self) -> crate::shortint::wopbs::WopbsKey {
-            self.wopbs_key
-        }
-
-        /// Construct a [`WopbsKey`] from its constituents.
-        pub fn from_raw_parts(wopbs_key: crate::shortint::wopbs::WopbsKey) -> Self {
-            Self { wopbs_key }
-        }
-
-        pub fn new_wopbs_key_only_for_wopbs<IntegerClientKey: AsRef<ClientKey>>(
-            cks: &IntegerClientKey,
-            sks: &ServerKey,
-        ) -> Self {
-            Self {
-                wopbs_key: crate::shortint::wopbs::WopbsKey::new_wopbs_key_only_for_wopbs(
-                    &cks.as_ref().key,
-                    &sks.key,
-                ),
-            }
-        }
-
-        /// Computes the WoP-PBS given the luts.
-        ///
-        /// This works for both RadixCiphertext and CrtCiphertext.
-        ///
-        /// # Example
-        ///
-        /// ```rust
-        /// use tfhe::integer::gen_keys_radix;
-        /// use tfhe::integer::wopbs::*;
-        /// use tfhe::shortint::parameters::parameters_wopbs_message_carry::LEGACY_WOPBS_PARAM_MESSAGE_2_CARRY_2_KS_PBS;
-        /// use tfhe::shortint::parameters::V0_11_PARAM_MESSAGE_2_CARRY_2_KS_PBS_GAUSSIAN_2M64;
-        ///
-        /// let nb_block = 3;
-        /// //Generate the client key and the server key:
-        /// let (cks, sks) = gen_keys_radix(V0_11_PARAM_MESSAGE_2_CARRY_2_KS_PBS_GAUSSIAN_2M64, nb_block);
-        /// let wopbs_key = WopbsKey::new_wopbs_key(&cks, &sks, &LEGACY_WOPBS_PARAM_MESSAGE_2_CARRY_2_KS_PBS);
-        /// let mut moduli = 1_u64;
-        /// for _ in 0..nb_block {
-        ///     moduli *= cks.parameters().message_modulus().0;
-        /// }
-        /// let clear = 42 % moduli;
-        /// let ct = cks.encrypt(clear);
-        /// let ct = wopbs_key.keyswitch_to_wopbs_params(&sks, &ct);
-        /// let lut = wopbs_key.generate_lut_radix(&ct, |x| x);
-        /// let ct_res = wopbs_key.wopbs(&ct, &lut);
-        /// let ct_res = wopbs_key.keyswitch_to_pbs_params(&ct_res);
-        /// let res: u64 = cks.decrypt(&ct_res);
-        ///
-        /// assert_eq!(res, clear);
-        /// ```
-        pub fn wopbs<T>(&self, ct_in: &T, lut: &IntegerWopbsLUT) -> T
-        where
-            T: IntegerCiphertext,
-        {
-            let total_bits_extracted = ct_in.blocks().iter().fold(0usize, |acc, block| {
-                acc + f64::log2((block.degree.get() + 1) as f64).ceil() as usize
-            });
-
-            let extract_bits_output_lwe_size = self
-                .wopbs_key
-                .wopbs_server_key
-                .key_switching_key
-                .output_key_lwe_dimension()
-                .to_lwe_size();
-
-            let mut extracted_bits_blocks = LweCiphertextList::new(
-                0u64,
-                extract_bits_output_lwe_size,
-                LweCiphertextCount(total_bits_extracted),
-                self.wopbs_key.param.ciphertext_modulus,
-            );
-
-            let mut bits_extracted_so_far = 0;
-
-            // Extraction of each bit for each block
-            for block in ct_in.blocks().iter().rev() {
-                let message_modulus = self.wopbs_key.param.message_modulus.0;
-                let carry_modulus = self.wopbs_key.param.carry_modulus.0;
-                let delta = (1u64 << 63) / (carry_modulus * message_modulus);
-                // casting to usize is fine, ilog2 of u64 is guaranteed to be < 64
-                let delta_log = DeltaLog(delta.ilog2() as usize);
-                let nb_bit_to_extract = f64::log2((block.degree.get() + 1) as f64).ceil() as usize;
-
-                let extract_from_bit = bits_extracted_so_far;
-                let extract_to_bit = extract_from_bit + nb_bit_to_extract;
-                bits_extracted_so_far += nb_bit_to_extract;
-
-                let mut lwe_sub_list =
-                    extracted_bits_blocks.get_sub_mut(extract_from_bit..extract_to_bit);
-
-                self.wopbs_key.extract_bits_assign(
-                    delta_log,
-                    block,
-                    ExtractedBitsCount(nb_bit_to_extract),
-                    &mut lwe_sub_list,
-                );
-            }
-
-            let vec_ct_out = self
-                .wopbs_key
-                .circuit_bootstrapping_vertical_packing(lut.as_ref(), &extracted_bits_blocks);
-
-            let mut ct_vec_out = vec![];
-            for (block, block_out) in ct_in.blocks().iter().zip(vec_ct_out) {
-                ct_vec_out.push(crate::shortint::Ciphertext::new(
-                    block_out,
-                    Degree::new(block.message_modulus.0 - 1),
-                    NoiseLevel::NOMINAL,
-                    block.message_modulus,
-                    block.carry_modulus,
-                    block.pbs_order,
-                ));
-            }
-            T::from_blocks(ct_vec_out)
-        }
-
-        /// # Example
-        /// ```rust
-        /// use tfhe::integer::gen_keys_radix;
-        /// use tfhe::integer::wopbs::WopbsKey;
-        /// use tfhe::shortint::parameters::parameters_wopbs_only::LEGACY_WOPBS_ONLY_4_BLOCKS_PARAM_MESSAGE_2_CARRY_2_KS_PBS;
-        ///
-        /// let nb_block = 3;
-        /// //Generate the client key and the server key:
-        /// let (cks, sks) = gen_keys_radix(LEGACY_WOPBS_ONLY_4_BLOCKS_PARAM_MESSAGE_2_CARRY_2_KS_PBS, nb_block);
-        /// let wopbs_key = WopbsKey::new_wopbs_key_only_for_wopbs(&cks, &sks);
-        /// let mut moduli = 1_u64;
-        /// for _ in 0..nb_block {
-        ///     moduli *= cks.parameters().message_modulus().0;
-        /// }
-        /// let clear = 15 % moduli;
-        /// let ct = cks.encrypt_without_padding(clear);
-        /// let lut = wopbs_key.generate_lut_radix_without_padding(&ct, |x| 2 * x);
-        /// let ct_res = wopbs_key.wopbs_without_padding(&ct, &lut);
-        /// let res: u64 = cks.decrypt_without_padding(&ct_res);
-        ///
-        /// assert_eq!(res, (clear * 2) % moduli)
-        /// ```
-        pub fn wopbs_without_padding<T>(&self, ct_in: &T, lut: &IntegerWopbsLUT) -> T
-        where
-            T: IntegerCiphertext,
-        {
-            let total_bits_extracted = ct_in.blocks().iter().fold(0usize, |acc, block| {
-                acc + f64::log2((block.message_modulus.0 * block.carry_modulus.0) as f64) as usize
-            });
-
-            let extract_bits_output_lwe_size = self
-                .wopbs_key
-                .wopbs_server_key
-                .key_switching_key
-                .output_key_lwe_dimension()
-                .to_lwe_size();
-
-            let mut extracted_bits_blocks = LweCiphertextList::new(
-                0u64,
-                extract_bits_output_lwe_size,
-                LweCiphertextCount(total_bits_extracted),
-                self.wopbs_key.param.ciphertext_modulus,
-            );
-
-            let mut bits_extracted_so_far = 0;
-            // Extraction of each bit for each block
-            for block in ct_in.blocks().iter().rev() {
-                let block_modulus = block.message_modulus.0 * block.carry_modulus.0;
-                let delta = (1_u64 << 63) / (block_modulus / 2);
-                // casting to usize is fine, ilog2 of u64 is guaranteed to be < 64
-                let delta_log = DeltaLog(delta.ilog2() as usize);
-                let nb_bit_to_extract =
-                    f64::log2((block.message_modulus.0 * block.carry_modulus.0) as f64) as usize;
-
-                let extract_from_bit = bits_extracted_so_far;
-                let extract_to_bit = extract_from_bit + nb_bit_to_extract;
-                bits_extracted_so_far += nb_bit_to_extract;
-
-                let mut lwe_sub_list =
-                    extracted_bits_blocks.get_sub_mut(extract_from_bit..extract_to_bit);
-
-                self.wopbs_key.extract_bits_assign(
-                    delta_log,
-                    block,
-                    ExtractedBitsCount(nb_bit_to_extract),
-                    &mut lwe_sub_list,
-                );
-            }
-
-            let vec_ct_out = self
-                .wopbs_key
-                .circuit_bootstrapping_vertical_packing(lut.as_ref(), &extracted_bits_blocks);
-
-            let mut ct_vec_out = vec![];
-            for (block, block_out) in ct_in.blocks().iter().zip(vec_ct_out) {
-                ct_vec_out.push(crate::shortint::Ciphertext::new(
-                    block_out,
-                    Degree::new(block.message_modulus.0 - 1),
-                    NoiseLevel::NOMINAL,
-                    block.message_modulus,
-                    block.carry_modulus,
-                    block.pbs_order,
-                ));
-            }
-            T::from_blocks(ct_vec_out)
-        }
-
-        /// WOPBS for native CRT
-        /// # Example
-        /// ```rust
-        /// use tfhe::integer::gen_keys_crt;
-        /// use tfhe::integer::wopbs::WopbsKey;
-        /// use tfhe::shortint::parameters::parameters_wopbs_message_carry::LEGACY_WOPBS_PARAM_MESSAGE_4_CARRY_4_KS_PBS;
-        ///
-        /// let basis: Vec<u64> = vec![9, 11];
-        /// let msg_space: u64 = basis.iter().copied().product();
-        ///
-        /// let param = LEGACY_WOPBS_PARAM_MESSAGE_4_CARRY_4_KS_PBS;
-        /// //Generate the client key and the server key:
-        /// let (cks, sks) = gen_keys_crt(param, basis);
-        /// let wopbs_key = WopbsKey::new_wopbs_key_only_for_wopbs(&cks, &sks);
-        ///
-        /// let clear = 42 % msg_space; // Encrypt the integers
-        /// let ct = cks.encrypt_native_crt(clear);
-        /// let lut = wopbs_key.generate_lut_native_crt(&ct, |x| x);
-        /// let ct_res = wopbs_key.wopbs_native_crt(&ct, &lut);
-        /// let res = cks.decrypt_native_crt(&ct_res);
-        /// assert_eq!(res, clear);
-        /// ```
-        pub fn wopbs_native_crt(
-            &self,
-            ct1: &CrtCiphertext,
-            lut: &IntegerWopbsLUT,
-        ) -> CrtCiphertext {
-            self.circuit_bootstrap_vertical_packing_native_crt(&[ct1.clone()], lut)
-        }
-
-        /// # Example
-        /// ```rust
-        /// use tfhe::integer::gen_keys_radix;
-        /// use tfhe::integer::wopbs::*;
-        /// use tfhe::shortint::parameters::parameters_wopbs_message_carry::LEGACY_WOPBS_PARAM_MESSAGE_2_CARRY_2_KS_PBS;
-        /// use tfhe::shortint::parameters::V0_11_PARAM_MESSAGE_2_CARRY_2_KS_PBS_GAUSSIAN_2M64;
-        ///
-        /// let nb_block = 3;
-        /// //Generate the client key and the server key:
-        /// let (cks, sks) = gen_keys_radix(V0_11_PARAM_MESSAGE_2_CARRY_2_KS_PBS_GAUSSIAN_2M64, nb_block);
-        ///
-        /// // Generate wopbs_v0 key
-        /// let wopbs_key = WopbsKey::new_wopbs_key(&cks, &sks, &LEGACY_WOPBS_PARAM_MESSAGE_2_CARRY_2_KS_PBS);
-        /// let mut moduli = 1_u64;
-        /// for _ in 0..nb_block {
-        ///     moduli *= cks.parameters().message_modulus().0;
-        /// }
-        /// let clear1 = 42 % moduli;
-        /// let clear2 = 24 % moduli;
-        /// let ct1 = cks.encrypt(clear1);
-        /// let ct2 = cks.encrypt(clear2);
-        ///
-        /// let ct1 = wopbs_key.keyswitch_to_wopbs_params(&sks, &ct1);
-        /// let ct2 = wopbs_key.keyswitch_to_wopbs_params(&sks, &ct2);
-        /// let lut = wopbs_key.generate_lut_bivariate_radix(&ct1, &ct2, |x, y| 2 * x * y);
-        /// let ct_res = wopbs_key.bivariate_wopbs_with_degree(&ct1, &ct2, &lut);
-        /// let ct_res = wopbs_key.keyswitch_to_pbs_params(&ct_res);
-        /// let res: u64 = cks.decrypt(&ct_res);
-        ///
-        /// assert_eq!(res, (2 * clear1 * clear2) % moduli);
-        /// ```
-        pub fn bivariate_wopbs_with_degree<T>(&self, ct1: &T, ct2: &T, lut: &IntegerWopbsLUT) -> T
-        where
-            T: IntegerCiphertext,
-        {
-            let ct = ciphertext_concatenation(ct1, ct2);
-            self.wopbs(&ct, lut)
-        }
-
-        /// # Example
-        ///
-        /// ```rust
-        /// use tfhe::integer::gen_keys_radix;
-        /// use tfhe::integer::wopbs::*;
-        /// use tfhe::shortint::parameters::parameters_wopbs_message_carry::LEGACY_WOPBS_PARAM_MESSAGE_2_CARRY_2_KS_PBS;
-        /// use tfhe::shortint::parameters::V0_11_PARAM_MESSAGE_2_CARRY_2_KS_PBS_GAUSSIAN_2M64;
-        ///
-        /// let nb_block = 3;
-        /// //Generate the client key and the server key:
-        /// let (cks, sks) = gen_keys_radix(V0_11_PARAM_MESSAGE_2_CARRY_2_KS_PBS_GAUSSIAN_2M64, nb_block);
-        ///
-        /// //Generate wopbs_v0 key    ///
-        /// let wopbs_key = WopbsKey::new_wopbs_key(&cks, &sks, &LEGACY_WOPBS_PARAM_MESSAGE_2_CARRY_2_KS_PBS);
-        /// let mut moduli = 1_u64;
-        /// for _ in 0..nb_block {
-        ///     moduli *= cks.parameters().message_modulus().0;
-        /// }
-        /// let clear = 42 % moduli;
-        /// let ct = cks.encrypt(clear);
-        /// let ct = wopbs_key.keyswitch_to_wopbs_params(&sks, &ct);
-        /// let lut = wopbs_key.generate_lut_radix(&ct, |x| 2 * x);
-        /// let ct_res = wopbs_key.wopbs(&ct, &lut);
-        /// let ct_res = wopbs_key.keyswitch_to_pbs_params(&ct_res);
-        /// let res: u64 = cks.decrypt(&ct_res);
-        ///
-        /// assert_eq!(res, (2 * clear) % moduli);
-        /// ```
-        pub fn generate_lut_radix<F, T>(&self, ct: &T, f: F) -> IntegerWopbsLUT
-        where
-            F: Fn(u64) -> u64,
-            T: IntegerCiphertext,
-        {
-            let mut total_bit = 0;
-            let block_nb = ct.blocks().len();
-            let mut modulus = 1;
-
-            //This contains the basis of each block depending on the degree
-            let mut vec_deg_basis = vec![];
-
-            for (i, deg) in ct.moduli().iter().zip(ct.blocks().iter()) {
-                modulus *= i;
-                let b = f64::log2((deg.degree.get() + 1) as f64).ceil() as u64;
-                vec_deg_basis.push(b);
-                total_bit += b;
-            }
-
-            let lut_size = if 1 << total_bit < self.wopbs_key.param.polynomial_size.0 as u64 {
-                self.wopbs_key.param.polynomial_size.0
-            } else {
-                1 << total_bit
-            };
-            let mut lut =
-                IntegerWopbsLUT::new(PlaintextCount(lut_size), CiphertextCount(ct.blocks().len()));
-
-            let basis = ct.moduli()[0];
-            let delta: u64 = (1 << 63)
-                / (self.wopbs_key.param.message_modulus.0 * self.wopbs_key.param.carry_modulus.0);
-
-            for lut_index_val in 0..(1 << total_bit) {
-                let encoded_with_deg_val = encode_mix_radix(lut_index_val, &vec_deg_basis, basis);
-                let decoded_val = decode_radix(&encoded_with_deg_val, basis);
-                let f_val = f(decoded_val % modulus) % modulus;
-                let encoded_f_val = encode_radix(f_val, basis, block_nb as u64);
-                for (lut_number, radix_encoded_val) in
-                    encoded_f_val.iter().enumerate().take(block_nb)
-                {
-                    lut[lut_number][lut_index_val as usize] = radix_encoded_val * delta;
-                }
-            }
-            lut
-        }
-
-        /// # Example
-        /// ```rust
-        /// use tfhe::integer::gen_keys_radix;
-        /// use tfhe::integer::wopbs::WopbsKey;
-        /// use tfhe::shortint::parameters::parameters_wopbs_message_carry::LEGACY_WOPBS_PARAM_MESSAGE_2_CARRY_2_KS_PBS;
-        /// use tfhe::shortint::parameters::V0_11_PARAM_MESSAGE_2_CARRY_2_KS_PBS_GAUSSIAN_2M64;
-        ///
-        /// let nb_block = 3;
-        /// //Generate the client key and the server key:
-        /// let (cks, sks) = gen_keys_radix(V0_11_PARAM_MESSAGE_2_CARRY_2_KS_PBS_GAUSSIAN_2M64, nb_block);
-        /// //Generate wopbs_v0 key
-        /// let wopbs_key = WopbsKey::new_wopbs_key(&cks, &sks, &LEGACY_WOPBS_PARAM_MESSAGE_2_CARRY_2_KS_PBS);
-        /// let mut moduli = 1_u64;
-        /// for _ in 0..nb_block {
-        ///     moduli *= cks.parameters().message_modulus().0;
-        /// }
-        /// let clear = 15 % moduli;
-        /// let ct = cks.encrypt_without_padding(clear);
-        /// let ct = wopbs_key.keyswitch_to_wopbs_params(&sks, &ct);
-        /// let lut = wopbs_key.generate_lut_radix_without_padding(&ct, |x| 2 * x);
-        /// let ct_res = wopbs_key.wopbs_without_padding(&ct, &lut);
-        /// let ct_res = wopbs_key.keyswitch_to_pbs_params(&ct_res);
-        /// let res: u64 = cks.decrypt_without_padding(&ct_res);
-        ///
-        /// assert_eq!(res, (clear * 2) % moduli)
-        /// ```
-        pub fn generate_lut_radix_without_padding<F, T>(&self, ct: &T, f: F) -> IntegerWopbsLUT
-        where
-            F: Fn(u64) -> u64,
-            T: IntegerCiphertext,
-        {
-            let log_message_modulus =
-                f64::log2((self.wopbs_key.param.message_modulus.0) as f64) as u64;
-            let log_carry_modulus = f64::log2((self.wopbs_key.param.carry_modulus.0) as f64) as u64;
-            let log_basis = log_message_modulus + log_carry_modulus;
-            let delta = 64 - log_basis;
-            let nb_block = ct.blocks().len();
-            let poly_size = self.wopbs_key.param.polynomial_size.0;
-            let mut lut_size = 1 << (nb_block * log_basis as usize);
-            if lut_size < poly_size {
-                lut_size = poly_size;
-            }
-            let mut lut = IntegerWopbsLUT::new(PlaintextCount(lut_size), CiphertextCount(nb_block));
-
-            for index in 0..lut_size {
-                // find the value represented by the index
-                let mut value = 0;
-                let mut tmp_index = index;
-                for i in 0..nb_block as u64 {
-                    let tmp = tmp_index % (1 << (log_basis * (i + 1)));
-                    tmp_index -= tmp;
-                    value += tmp >> (log_carry_modulus * i);
-                }
-
-                // fill the LUTs
-                for block_index in 0..nb_block {
-                    lut[block_index][index] = ((f(value as u64)
-                        >> (log_carry_modulus * block_index as u64))
-                        % (1 << log_message_modulus))
-                        << delta;
-                }
-            }
-            lut
-        }
-
-        /// generate lut for native CRT
-        /// # Example
-        ///
-        /// ```rust
-        /// use tfhe::integer::gen_keys_crt;
-        /// use tfhe::integer::wopbs::WopbsKey;
-        /// use tfhe::shortint::parameters::parameters_wopbs_message_carry::LEGACY_WOPBS_PARAM_MESSAGE_4_CARRY_4_KS_PBS;
-        ///
-        /// let basis: Vec<u64> = vec![9, 11];
-        /// let msg_space: u64 = basis.iter().copied().product();
-        ///
-        /// let param = LEGACY_WOPBS_PARAM_MESSAGE_4_CARRY_4_KS_PBS;
-        /// //Generate the client key and the server key:
-        /// let (cks, sks) = gen_keys_crt(param, basis);
-        /// let wopbs_key = WopbsKey::new_wopbs_key_only_for_wopbs(&cks, &sks);
-        ///
-        /// let clear = 42 % msg_space; // Encrypt the integers
-        /// let ct = cks.encrypt_native_crt(clear);
-        /// let lut = wopbs_key.generate_lut_native_crt(&ct, |x| x);
-        /// let ct_res = wopbs_key.wopbs_native_crt(&ct, &lut);
-        /// let res = cks.decrypt_native_crt(&ct_res);
-        /// assert_eq!(res, clear);
-        /// ```
-        pub fn generate_lut_native_crt<F>(&self, ct: &CrtCiphertext, f: F) -> IntegerWopbsLUT
-        where
-            F: Fn(u64) -> u64,
-        {
-            let mut bit = vec![];
-            let mut total_bit = 0;
-            let mut modulus = 1;
-            let basis: Vec<_> = ct.moduli();
-
-            for i in basis.iter() {
-                modulus *= i;
-                let b = f64::log2(*i as f64).ceil() as u64;
-                total_bit += b;
-                bit.push(b);
-            }
-            let lut_size = if 1 << total_bit < self.wopbs_key.param.polynomial_size.0 as u64 {
-                self.wopbs_key.param.polynomial_size.0
-            } else {
-                1 << total_bit
-            };
-            let mut lut =
-                IntegerWopbsLUT::new(PlaintextCount(lut_size), CiphertextCount(basis.len()));
-
-            for value in 0..modulus {
-                let mut index_lut = 0;
-                let mut tmp = 1;
-                for (base, bit) in basis.iter().zip(bit.iter()) {
-                    index_lut += (((value % base) << bit) / base) * tmp;
-                    tmp <<= bit;
-                }
-                for (j, b) in basis.iter().enumerate() {
-                    lut[j][index_lut as usize] =
-                        (((f(value) % b) as u128 * (1 << 64)) / *b as u128) as u64;
-                }
-            }
-            lut
-        }
-
-        /// generate LUt for crt
-        /// # Example
-        /// ```rust
-        /// use tfhe::integer::gen_keys_crt;
-        /// use tfhe::integer::wopbs::*;
-        /// use tfhe::shortint::parameters::parameters_wopbs_message_carry::LEGACY_WOPBS_PARAM_MESSAGE_3_CARRY_3_KS_PBS;
-        /// use tfhe::shortint::parameters::V0_11_PARAM_MESSAGE_3_CARRY_3_KS_PBS_GAUSSIAN_2M64;
-        ///
-        /// let basis: Vec<u64> = vec![5, 7];
-        /// let msg_space: u64 = basis.iter().copied().product();
-        ///
-        /// //Generate the client key and the server key:
-        /// let (cks, sks) = gen_keys_crt(V0_11_PARAM_MESSAGE_3_CARRY_3_KS_PBS_GAUSSIAN_2M64, basis);
-        /// let wopbs_key = WopbsKey::new_wopbs_key(&cks, &sks, &LEGACY_WOPBS_PARAM_MESSAGE_3_CARRY_3_KS_PBS);
-        ///
-        /// let clear = 42 % msg_space;
-        /// let ct = cks.encrypt(clear);
-        /// let ct = wopbs_key.keyswitch_to_wopbs_params(&sks, &ct);
-        /// let lut = wopbs_key.generate_lut_crt(&ct, |x| x);
-        /// let ct_res = wopbs_key.wopbs(&ct, &lut);
-        /// let ct_res = wopbs_key.keyswitch_to_pbs_params(&ct_res);
-        /// let res = cks.decrypt(&ct_res);
-        /// assert_eq!(res, clear);
-        /// ```
-        pub fn generate_lut_crt<F>(&self, ct: &CrtCiphertext, f: F) -> IntegerWopbsLUT
-        where
-            F: Fn(u64) -> u64,
-        {
-            let mut total_bit = 0;
-            let mut modulus = 1;
-            let basis = ct.moduli();
-
-            for (i, deg) in basis.iter().zip(ct.blocks.iter()) {
-                modulus *= i;
-                let b = f64::log2((deg.degree.get() + 1) as f64).ceil() as u64;
-                total_bit += b;
-            }
-            let lut_size = if 1 << total_bit < self.wopbs_key.param.polynomial_size.0 as u64 {
-                self.wopbs_key.param.polynomial_size.0
-            } else {
-                1 << total_bit
-            };
-            let mut lut =
-                IntegerWopbsLUT::new(PlaintextCount(lut_size), CiphertextCount(basis.len()));
-
-            let delta: u64 = (1 << 63)
-                / (self.wopbs_key.param.message_modulus.0 * self.wopbs_key.param.carry_modulus.0);
-
-            for i in 0..(1 << total_bit) {
-                let mut decomp_terms = Vec::new();
-                let mut index_copy = i;
-                for (b, block) in basis.iter().zip(ct.blocks.iter()) {
-                    let block_bit_count = f64::log2((block.degree.get() + 1) as f64).ceil() as u64;
-                    let bits_corresponding_to_block = index_copy % (1 << block_bit_count);
-                    let decomp_term = bits_corresponding_to_block % b;
-                    index_copy >>= block_bit_count;
-                    decomp_terms.push(decomp_term);
-                }
-                let value_corresponding_to_index = i_crt(&basis, &decomp_terms);
-                let f_eval = f(value_corresponding_to_index);
-                for (j, block) in ct.blocks.iter().enumerate() {
-                    lut[j][i as usize] = (f_eval % block.message_modulus.0) * delta;
-                }
-            }
-            lut
-        }
-
-        /// # Example
-        ///
-        /// ```rust
-        /// use tfhe::integer::gen_keys_radix;
-        /// use tfhe::integer::wopbs::*;
-        /// use tfhe::shortint::parameters::parameters_wopbs_message_carry::LEGACY_WOPBS_PARAM_MESSAGE_2_CARRY_2_KS_PBS;
-        /// use tfhe::shortint::parameters::V0_11_PARAM_MESSAGE_2_CARRY_2_KS_PBS_GAUSSIAN_2M64;
-        ///
-        /// let nb_block = 3;
-        /// //Generate the client key and the server key:
-        /// let (cks, sks) = gen_keys_radix(V0_11_PARAM_MESSAGE_2_CARRY_2_KS_PBS_GAUSSIAN_2M64, nb_block);
-        ///
-        /// //Generate wopbs_v0 key    ///
-        /// let wopbs_key = WopbsKey::new_wopbs_key(&cks, &sks, &LEGACY_WOPBS_PARAM_MESSAGE_2_CARRY_2_KS_PBS);
-        /// let mut moduli = 1_u64;
-        /// for _ in 0..nb_block {
-        ///     moduli *= cks.parameters().message_modulus().0;
-        /// }
-        /// let clear1 = 42 % moduli;
-        /// let clear2 = 24 % moduli;
-        /// let ct1 = cks.encrypt(clear1);
-        /// let ct2 = cks.encrypt(clear2);
-        ///
-        /// let ct1 = wopbs_key.keyswitch_to_wopbs_params(&sks, &ct1);
-        /// let ct2 = wopbs_key.keyswitch_to_wopbs_params(&sks, &ct2);
-        /// let lut = wopbs_key.generate_lut_bivariate_radix(&ct1, &ct2, |x, y| 2 * x * y);
-        /// let ct_res = wopbs_key.bivariate_wopbs_with_degree(&ct1, &ct2, &lut);
-        /// let ct_res = wopbs_key.keyswitch_to_pbs_params(&ct_res);
-        /// let res: u64 = cks.decrypt(&ct_res);
-        ///
-        /// assert_eq!(res, (2 * clear1 * clear2) % moduli);
-        /// ```
-        pub fn generate_lut_bivariate_radix<F>(
-            &self,
-            ct1: &RadixCiphertext,
-            ct2: &RadixCiphertext,
-            f: F,
-        ) -> IntegerWopbsLUT
-        where
-            RadixCiphertext: IntegerCiphertext,
-            F: Fn(u64, u64) -> u64,
-        {
-            let mut nb_bit_to_extract = [0; 2];
-            let block_nb = ct1.blocks.len();
-            //ct2 & ct1 should have the same basis
-            let basis = ct1.moduli();
-
-            //This contains the basis of each block depending on the degree
-            let mut vec_deg_basis = vec![vec![]; 2];
-
-            let mut modulus = 1;
-            for (ct_num, ct) in [ct1, ct2].iter().enumerate() {
-                modulus = 1;
-                for deg in ct.blocks.iter() {
-                    modulus *= self.wopbs_key.param.message_modulus.0;
-                    let b = f64::log2((deg.degree.get() + 1) as f64).ceil() as u64;
-                    vec_deg_basis[ct_num].push(b);
-                    nb_bit_to_extract[ct_num] += b;
-                }
-            }
-
-            let total_bit: u64 = nb_bit_to_extract.iter().sum();
-
-            let lut_size = if 1 << total_bit < self.wopbs_key.param.polynomial_size.0 as u64 {
-                self.wopbs_key.param.polynomial_size.0
-            } else {
-                1 << total_bit
-            };
-            let mut lut =
-                IntegerWopbsLUT::new(PlaintextCount(lut_size), CiphertextCount(basis.len()));
-            let basis = ct1.moduli()[0];
-
-            let delta: u64 = (1 << 63)
-                / (self.wopbs_key.param.message_modulus.0 * self.wopbs_key.param.carry_modulus.0);
-
-            for lut_index_val in 0..(1 << total_bit) {
-                let split = [
-                    lut_index_val % (1 << nb_bit_to_extract[0]),
-                    lut_index_val >> nb_bit_to_extract[0],
-                ];
-                let mut decoded_val = [0; 2];
-                for i in 0..2 {
-                    let encoded_with_deg_val = encode_mix_radix(split[i], &vec_deg_basis[i], basis);
-                    decoded_val[i] = decode_radix(&encoded_with_deg_val, basis);
-                }
-                let f_val = f(decoded_val[0] % modulus, decoded_val[1] % modulus) % modulus;
-                let encoded_f_val = encode_radix(f_val, basis, block_nb as u64);
-                for (lut_number, radix_encoded_val) in
-                    encoded_f_val.iter().enumerate().take(block_nb)
-                {
-                    lut[lut_number][lut_index_val as usize] = radix_encoded_val * delta;
-                }
-            }
-            lut
-        }
-
-        /// generate bivariate LUT for 'fake' CRT
-        ///
-        /// # Example
-        ///
-        /// ```rust
-        /// use tfhe::integer::gen_keys_crt;
-        /// use tfhe::integer::wopbs::*;
-        /// use tfhe::shortint::parameters::parameters_wopbs_message_carry::LEGACY_WOPBS_PARAM_MESSAGE_3_CARRY_3_KS_PBS;
-        /// use tfhe::shortint::parameters::V0_11_PARAM_MESSAGE_3_CARRY_3_KS_PBS_GAUSSIAN_2M64;
-        ///
-        /// let basis: Vec<u64> = vec![5, 7];
-        /// let msg_space: u64 = basis.iter().copied().product();
-        /// //Generate the client key and the server key:
-        /// let (cks, sks) = gen_keys_crt(V0_11_PARAM_MESSAGE_3_CARRY_3_KS_PBS_GAUSSIAN_2M64, basis);
-        /// let wopbs_key = WopbsKey::new_wopbs_key(&cks, &sks, &LEGACY_WOPBS_PARAM_MESSAGE_3_CARRY_3_KS_PBS);
-        ///
-        /// let clear1 = 42 % msg_space; // Encrypt the integers
-        /// let clear2 = 24 % msg_space; // Encrypt the integers
-        /// let ct1 = cks.encrypt(clear1);
-        /// let ct2 = cks.encrypt(clear2);
-        ///
-        /// let ct1 = wopbs_key.keyswitch_to_wopbs_params(&sks, &ct1);
-        /// let ct2 = wopbs_key.keyswitch_to_wopbs_params(&sks, &ct2);
-        ///
-        /// let lut = wopbs_key.generate_lut_bivariate_crt(&ct1, &ct2, |x, y| x * y * 2);
-        /// let ct_res = wopbs_key.bivariate_wopbs_with_degree(&ct1, &ct2, &lut);
-        /// let ct_res = wopbs_key.keyswitch_to_pbs_params(&ct_res);
-        /// let res = cks.decrypt(&ct_res);
-        /// assert_eq!(res, (clear1 * clear2 * 2) % msg_space);
-        /// ```
-        pub fn generate_lut_bivariate_crt<F>(
-            &self,
-            ct1: &CrtCiphertext,
-            ct2: &CrtCiphertext,
-            f: F,
-        ) -> IntegerWopbsLUT
-        where
-            F: Fn(u64, u64) -> u64,
-        {
-            let mut nb_bit_to_extract = [0; 2];
-            let mut modulus = 1;
-
-            //ct2 & ct1 should have the same basis
-            let basis = ct1.moduli();
-
-            for (ct_num, ct) in [ct1, ct2].iter().enumerate() {
-                for (i, deg) in basis.iter().zip(ct.blocks.iter()) {
-                    modulus *= i;
-                    let b = f64::log2((deg.degree.get() + 1) as f64).ceil() as u64;
-                    nb_bit_to_extract[ct_num] += b;
-                }
-            }
-
-            let total_bit: u64 = nb_bit_to_extract.iter().sum();
-
-            let lut_size = if 1 << total_bit < self.wopbs_key.param.polynomial_size.0 as u64 {
-                self.wopbs_key.param.polynomial_size.0
-            } else {
-                1 << total_bit
-            };
-            let mut lut =
-                IntegerWopbsLUT::new(PlaintextCount(lut_size), CiphertextCount(basis.len()));
-
-            let delta: u64 = (1 << 63)
-                / (self.wopbs_key.param.message_modulus.0 * self.wopbs_key.param.carry_modulus.0);
-
-            for index in 0..(1 << total_bit) {
-                let mut split = encode_radix(index, 1 << nb_bit_to_extract[0], 2);
-                let mut crt_value = vec![vec![0; ct1.blocks.len()]; 2];
-                for (j, base) in basis.iter().enumerate().take(ct1.blocks.len()) {
-                    let deg_1 = f64::log2((ct1.blocks[j].degree.get() + 1) as f64).ceil() as u64;
-                    let deg_2 = f64::log2((ct2.blocks[j].degree.get() + 1) as f64).ceil() as u64;
-                    crt_value[0][j] = (split[0] % (1 << deg_1)) % base;
-                    crt_value[1][j] = (split[1] % (1 << deg_2)) % base;
-                    split[0] >>= deg_1;
-                    split[1] >>= deg_2;
-                }
-                let value_1 = i_crt(&ct1.moduli(), &crt_value[0]);
-                let value_2 = i_crt(&ct2.moduli(), &crt_value[1]);
-                for (j, current_mod) in basis.iter().enumerate() {
-                    let value = f(value_1, value_2) % current_mod;
-                    lut[j][index as usize] = (value % current_mod) * delta;
-                }
-            }
-
-            lut
-        }
-
-        /// generate bivariate LUT for 'true' CRT
-        /// # Example
-        ///
-        /// ```rust
-        /// use tfhe::integer::gen_keys_crt;
-        /// use tfhe::integer::wopbs::WopbsKey;
-        /// use tfhe::shortint::parameters::parameters_wopbs_message_carry::LEGACY_WOPBS_PARAM_MESSAGE_4_CARRY_4_KS_PBS;
-        ///
-        /// let basis: Vec<u64> = vec![9, 11];
-        /// let msg_space: u64 = basis.iter().copied().product();
-        ///
-        /// let param = LEGACY_WOPBS_PARAM_MESSAGE_4_CARRY_4_KS_PBS;
-        /// //Generate the client key and the server key:
-        /// let (cks, sks) = gen_keys_crt(param, basis);
-        /// let wopbs_key = WopbsKey::new_wopbs_key_only_for_wopbs(&cks, &sks);
-        ///
-        /// let clear1 = 42 % msg_space;
-        /// let clear2 = 24 % msg_space;
-        /// let ct1 = cks.encrypt_native_crt(clear1);
-        /// let ct2 = cks.encrypt_native_crt(clear2);
-        /// let lut = wopbs_key.generate_lut_bivariate_native_crt(&ct1, |x, y| x * y * 2);
-        /// let ct_res = wopbs_key.bivariate_wopbs_native_crt(&ct1, &ct2, &lut);
-        /// let res = cks.decrypt_native_crt(&ct_res);
-        /// assert_eq!(res, (clear1 * clear2 * 2) % msg_space);
-        /// ```
-        pub fn generate_lut_bivariate_native_crt<F>(
-            &self,
-            ct_1: &CrtCiphertext,
-            f: F,
-        ) -> IntegerWopbsLUT
-        where
-            F: Fn(u64, u64) -> u64,
-        {
-            let mut bit = vec![];
-            let mut total_bit = 0;
-            let mut modulus = 1;
-            let basis = ct_1.moduli();
-            for i in basis.iter() {
-                modulus *= i;
-                let b = f64::log2(*i as f64).ceil() as u64;
-                total_bit += b;
-                bit.push(b);
-            }
-            let lut_size = if 1 << (2 * total_bit) < self.wopbs_key.param.polynomial_size.0 as u64 {
-                self.wopbs_key.param.polynomial_size.0
-            } else {
-                1 << (2 * total_bit)
-            };
-            let mut lut =
-                IntegerWopbsLUT::new(PlaintextCount(lut_size), CiphertextCount(basis.len()));
-
-            for value in 0..1 << (2 * total_bit) {
-                let value_1 = value % (1 << total_bit);
-                let value_2 = value >> total_bit;
-                let mut index_lut_1 = 0;
-                let mut index_lut_2 = 0;
-                let mut tmp = 1;
-                for (base, bit) in basis.iter().zip(bit.iter()) {
-                    index_lut_1 += (((value_1 % base) << bit) / base) * tmp;
-                    index_lut_2 += (((value_2 % base) << bit) / base) * tmp;
-                    tmp <<= bit;
-                }
-                let index = (index_lut_2 << total_bit) + (index_lut_1);
-                for (j, b) in basis.iter().enumerate() {
-                    lut[j][index as usize] =
-                        (((f(value_1, value_2) % b) as u128 * (1 << 64)) / *b as u128) as u64;
-                }
-            }
-            lut
-        }
-
-        /// bivariate WOPBS for native CRT
-        /// # Example
-        ///
-        /// ```rust
-        /// use tfhe::integer::gen_keys_crt;
-        /// use tfhe::integer::wopbs::WopbsKey;
-        /// use tfhe::shortint::parameters::parameters_wopbs_message_carry::LEGACY_WOPBS_PARAM_MESSAGE_4_CARRY_4_KS_PBS;
-        ///
-        /// let basis: Vec<u64> = vec![9, 11];
-        /// let msg_space: u64 = basis.iter().copied().product();
-        ///
-        /// let param = LEGACY_WOPBS_PARAM_MESSAGE_4_CARRY_4_KS_PBS;
-        /// //Generate the client key and the server key:
-        /// let (cks, sks) = gen_keys_crt(param, basis);
-        /// let wopbs_key = WopbsKey::new_wopbs_key_only_for_wopbs(&cks, &sks);
-        ///
-        /// let clear1 = 42 % msg_space;
-        /// let clear2 = 24 % msg_space;
-        /// let ct1 = cks.encrypt_native_crt(clear1);
-        /// let ct2 = cks.encrypt_native_crt(clear2);
-        /// let lut = wopbs_key.generate_lut_bivariate_native_crt(&ct1, |x, y| x * y * 2);
-        /// let ct_res = wopbs_key.bivariate_wopbs_native_crt(&ct1, &ct2, &lut);
-        /// let res = cks.decrypt_native_crt(&ct_res);
-        /// assert_eq!(res, (clear1 * clear2 * 2) % msg_space);
-        /// ```
-        pub fn bivariate_wopbs_native_crt(
-            &self,
-            ct1: &CrtCiphertext,
-            ct2: &CrtCiphertext,
-            lut: &IntegerWopbsLUT,
-        ) -> CrtCiphertext {
-            self.circuit_bootstrap_vertical_packing_native_crt(&[ct1.clone(), ct2.clone()], lut)
-        }
-
-        fn circuit_bootstrap_vertical_packing_native_crt<T>(
-            &self,
-            vec_ct_in: &[T],
-            lut: &IntegerWopbsLUT,
-        ) -> T
-        where
-            T: IntegerCiphertext,
-        {
-            let total_bits_extracted = vec_ct_in.iter().fold(0usize, |acc, ct_in| {
-                acc + ct_in.blocks().iter().fold(0usize, |inner_acc, block| {
-                    inner_acc
-                        + f64::log2((block.message_modulus.0 * block.carry_modulus.0) as f64).ceil()
-                            as usize
-                })
-            });
-
-            let extract_bits_output_lwe_size = self
-                .wopbs_key
-                .wopbs_server_key
-                .key_switching_key
-                .output_key_lwe_dimension()
-                .to_lwe_size();
-
-            let mut extracted_bits_blocks = LweCiphertextList::new(
-                0u64,
-                extract_bits_output_lwe_size,
-                LweCiphertextCount(total_bits_extracted),
-                self.wopbs_key.param.ciphertext_modulus,
-            );
-
-            let mut bits_extracted_so_far = 0;
-            for ct_in in vec_ct_in.iter().rev() {
-                let mut ct_in = ct_in.clone();
-                // Extraction of each bit for each block
-                for block in ct_in.blocks_mut().iter_mut().rev() {
-                    let nb_bit_to_extract =
-                        f64::log2((block.message_modulus.0 * block.carry_modulus.0) as f64).ceil()
-                            as usize;
-                    let delta_log = DeltaLog(64 - nb_bit_to_extract);
-
-                    // trick ( ct - delta/2 + delta/2^4  )
-                    lwe_ciphertext_plaintext_sub_assign(
-                        &mut block.ct,
-                        Plaintext(
-                            (1 << (64 - nb_bit_to_extract - 1))
-                                - (1 << (64 - nb_bit_to_extract - 5)),
-                        ),
-                    );
-
-                    let extract_from_bit = bits_extracted_so_far;
-                    let extract_to_bit = extract_from_bit + nb_bit_to_extract;
-                    bits_extracted_so_far += nb_bit_to_extract;
-
-                    let mut lwe_sub_list =
-                        extracted_bits_blocks.get_sub_mut(extract_from_bit..extract_to_bit);
-
-                    self.wopbs_key.extract_bits_assign(
-                        delta_log,
-                        block,
-                        ExtractedBitsCount(nb_bit_to_extract),
-                        &mut lwe_sub_list,
-                    );
-                }
-            }
-
-            let vec_ct_out = self
-                .wopbs_key
-                .circuit_bootstrapping_vertical_packing(lut.as_ref(), &extracted_bits_blocks);
-
-            let mut ct_vec_out = Vec::with_capacity(vec_ct_in.len());
-            for (block, block_out) in vec_ct_in[0].blocks().iter().zip(vec_ct_out) {
-                ct_vec_out.push(crate::shortint::Ciphertext::new(
-                    block_out,
-                    Degree::new(block.message_modulus.0 - 1),
-                    NoiseLevel::NOMINAL,
-                    block.message_modulus,
-                    block.carry_modulus,
-                    block.pbs_order,
-                ));
-            }
-            T::from_blocks(ct_vec_out)
-        }
-
-        pub fn keyswitch_to_wopbs_params<'a, T>(&self, sks: &ServerKey, ct_in: &'a T) -> T
-        where
-            T: IntegerCiphertext,
-            &'a [crate::shortint::Ciphertext]:
-                IntoParallelIterator<Item = &'a crate::shortint::Ciphertext>,
-        {
-            let blocks: Vec<_> = ct_in
-                .blocks()
-                .par_iter()
-                .map(|block| self.wopbs_key.keyswitch_to_wopbs_params(&sks.key, block))
-                .collect();
-            T::from_blocks(blocks)
-        }
-
-        pub fn keyswitch_to_pbs_params<'a, T>(&self, ct_in: &'a T) -> T
-        where
-            T: IntegerCiphertext,
-            &'a [crate::shortint::Ciphertext]:
-                IntoParallelIterator<Item = &'a crate::shortint::Ciphertext>,
-        {
-            let blocks: Vec<_> = ct_in
-                .blocks()
-                .par_iter()
-                .map(|block| self.wopbs_key.keyswitch_to_pbs_params(block))
-                .collect();
-            T::from_blocks(blocks)
-        }
-    }
-}
diff --git a/tfhe/src/integer/wopbs/test.rs b/tfhe/src/integer/wopbs/test.rs
deleted file mode 100644
index 4c6d17506..000000000
--- a/tfhe/src/integer/wopbs/test.rs
+++ /dev/null
@@ -1,292 +0,0 @@
-#![allow(unused)]
-
-use crate::integer::keycache::{KEY_CACHE, KEY_CACHE_WOPBS};
-use crate::integer::parameters::*;
-use crate::integer::server_key::crt::make_basis;
-use crate::integer::wopbs::{encode_radix, WopbsKey};
-use crate::integer::{gen_keys, IntegerKeyKind};
-use crate::shortint::ciphertext::Degree;
-use crate::shortint::parameters::parameters_wopbs::*;
-use crate::shortint::parameters::*;
-use paste::paste;
-use rand::Rng;
-use std::cmp::max;
-
-#[cfg(not(tarpaulin))]
-const NB_TESTS: usize = 10;
-// Use lower numbers for coverage to ensure fast tests to counter balance slowdown due to code
-// instrumentation
-#[cfg(tarpaulin)]
-const NB_TESTS: usize = 1;
-
-macro_rules! create_parameterized_test{    (
-        $name:ident {
-            $($(#[$cfg:meta])* ($sks_param:ident, $wopbs_param:ident)),*
-            $(,)?
-        }
-    ) => {
-        ::paste::paste! {
-            $(
-                #[test]
-                $(#[$cfg])*
-                fn [<test_ $name _ $wopbs_param:lower>]() {
-                    $name(($sks_param, $wopbs_param))
-                }
-            )*
-        }
-    };
-    ($name:ident)=> {
-        create_parameterized_test!($name
-        {
-            (V0_11_PARAM_MESSAGE_2_CARRY_2_KS_PBS_GAUSSIAN_2M64, LEGACY_WOPBS_PARAM_MESSAGE_2_CARRY_2_KS_PBS),
-            #[cfg(not(tarpaulin))]
-            (V0_11_PARAM_MESSAGE_3_CARRY_3_KS_PBS_GAUSSIAN_2M64, LEGACY_WOPBS_PARAM_MESSAGE_3_CARRY_3_KS_PBS),
-            #[cfg(not(tarpaulin))]
-            (V0_11_PARAM_MESSAGE_4_CARRY_4_KS_PBS_GAUSSIAN_2M64, LEGACY_WOPBS_PARAM_MESSAGE_4_CARRY_4_KS_PBS)
-        });
-    };
-}
-
-create_parameterized_test!(wopbs_crt);
-create_parameterized_test!(wopbs_crt_non_reg);
-create_parameterized_test!(wopbs_bivariate_radix);
-create_parameterized_test!(wopbs_bivariate_crt);
-create_parameterized_test!(wopbs_radix);
-
-// test wopbs fake crt with different degree for each Ct
-pub fn wopbs_crt(params: (ClassicPBSParameters, WopbsParameters)) {
-    let mut rng = rand::thread_rng();
-
-    let basis = make_basis(params.1.message_modulus.0);
-
-    let nb_block = basis.len();
-
-    let (cks, sks) = KEY_CACHE.get_from_params(params.0, IntegerKeyKind::Radix);
-    let wopbs_key = KEY_CACHE_WOPBS.get_from_params(params);
-
-    let mut msg_space = 1;
-    for modulus in basis.iter() {
-        msg_space *= modulus;
-    }
-
-    let mut tmp = 0;
-    for _ in 0..NB_TESTS {
-        let clear1 = rng.gen::<u64>() % msg_space;
-        let mut ct1 = cks.encrypt_crt(clear1, basis.clone());
-        //artificially modify the degree
-        for ct in ct1.blocks.iter_mut() {
-            let degree = params.0.message_modulus.0
-                * ((rng.gen::<u64>() % (params.0.carry_modulus.0 - 1)) + 1);
-            ct.degree = Degree::new(degree);
-        }
-        let res = cks.decrypt_crt(&ct1);
-
-        let ct1 = wopbs_key.keyswitch_to_wopbs_params(&sks, &ct1);
-        let lut = wopbs_key.generate_lut_crt(&ct1, |x| (x * x) + x);
-        let ct_res = wopbs_key.wopbs(&ct1, &lut);
-        let ct_res = wopbs_key.keyswitch_to_pbs_params(&ct_res);
-
-        let res_wop = cks.decrypt_crt(&ct_res);
-        if ((res * res) + res) % msg_space != res_wop {
-            tmp += 1;
-        }
-    }
-    if tmp != 0 {
-        println!("failure rate {tmp:?}/{NB_TESTS:?}");
-        panic!()
-    }
-}
-
-// From https://github.com/zama-ai/tfhe-rs/issues/849
-// This checks we do not generate a LUT constant equal to 0, as used to be the case with this
-// threshold-like LUT
-pub fn wopbs_crt_non_reg(params: (ClassicPBSParameters, WopbsParameters)) {
-    let mut rng = rand::thread_rng();
-
-    let basis = make_basis(params.1.message_modulus.0);
-
-    let nb_block = basis.len();
-
-    let (cks, sks) = KEY_CACHE.get_from_params(params.0, IntegerKeyKind::Radix);
-    let wopbs_key = KEY_CACHE_WOPBS.get_from_params(params);
-
-    let mut msg_space = 1;
-    for modulus in basis.iter() {
-        msg_space *= modulus;
-    }
-
-    let threshold = msg_space / 2;
-
-    let f = |x| (x > threshold) as u64;
-
-    let mut tmp = 0;
-    for _ in 0..NB_TESTS {
-        let clear1 = rng.gen::<u64>() % msg_space;
-        let mut ct1 = cks.encrypt_crt(clear1, basis.clone());
-        //artificially modify the degree
-        for ct in ct1.blocks.iter_mut() {
-            let degree = params.0.message_modulus.0
-                * ((rng.gen::<u64>() % (params.0.carry_modulus.0 - 1)) + 1);
-            ct.degree = Degree::new(degree);
-        }
-        let sanity_dec = cks.decrypt_crt(&ct1);
-        assert_eq!(clear1, sanity_dec);
-
-        let ct1 = wopbs_key.keyswitch_to_wopbs_params(&sks, &ct1);
-        let lut = wopbs_key.generate_lut_crt(&ct1, f);
-        let ct_res = wopbs_key.wopbs(&ct1, &lut);
-        let ct_res = wopbs_key.keyswitch_to_pbs_params(&ct_res);
-
-        let res_wop = cks.decrypt_crt(&ct_res);
-        if f(clear1) % msg_space != res_wop {
-            tmp += 1;
-        }
-    }
-    if tmp != 0 {
-        println!("failure rate {tmp:?}/{NB_TESTS:?}");
-        panic!()
-    }
-}
-
-// test wopbs radix with different degree for each Ct
-pub fn wopbs_radix(params: (ClassicPBSParameters, WopbsParameters)) {
-    let mut rng = rand::thread_rng();
-
-    let nb_block = 2;
-
-    let (cks, sks) = KEY_CACHE.get_from_params(params.0, IntegerKeyKind::Radix);
-    let wopbs_key = KEY_CACHE_WOPBS.get_from_params(params);
-
-    let mut msg_space: u64 = params.0.message_modulus.0;
-    for modulus in 1..nb_block {
-        msg_space *= params.0.message_modulus.0;
-    }
-
-    let mut tmp = 0;
-    for _ in 0..NB_TESTS {
-        let clear1 = rng.gen::<u64>() % msg_space;
-        let mut ct1 = cks.encrypt_radix(clear1, nb_block);
-
-        // //artificially modify the degree
-        let res: u64 = cks.decrypt_radix(&ct1);
-        let ct1 = wopbs_key.keyswitch_to_wopbs_params(&sks, &ct1);
-        let lut = wopbs_key.generate_lut_radix(&ct1, |x| x);
-        let ct_res = wopbs_key.wopbs(&ct1, &lut);
-        let ct_res = wopbs_key.keyswitch_to_pbs_params(&ct_res);
-        let res_wop: u64 = cks.decrypt_radix(&ct_res);
-        if res % msg_space != res_wop {
-            tmp += 1;
-        }
-    }
-    if tmp != 0 {
-        println!("failure rate {tmp:?}/{NB_TESTS:?}");
-        panic!()
-    }
-}
-
-// test wopbs radix with different degree for each Ct
-pub fn wopbs_bivariate_radix(params: (ClassicPBSParameters, WopbsParameters)) {
-    let mut rng = rand::thread_rng();
-
-    let nb_block = 2;
-
-    let (cks, sks) = KEY_CACHE.get_from_params(params.0, IntegerKeyKind::Radix);
-    let wopbs_key = KEY_CACHE_WOPBS.get_from_params(params);
-
-    let mut msg_space: u64 = params.0.message_modulus.0;
-    for modulus in 1..nb_block {
-        msg_space *= params.0.message_modulus.0;
-    }
-
-    for _ in 0..NB_TESTS {
-        let mut clear1 = rng.gen::<u64>() % msg_space;
-        let mut clear2 = rng.gen::<u64>() % msg_space;
-
-        let mut ct1 = cks.encrypt_radix(clear1, nb_block);
-        let scalar = rng.gen::<u64>() % msg_space;
-        sks.smart_scalar_add_assign(&mut ct1, scalar);
-        let dec1: u64 = cks.decrypt_radix(&ct1);
-
-        let mut ct2 = cks.encrypt_radix(clear2, nb_block);
-        let scalar = rng.gen::<u64>() % msg_space;
-        sks.smart_scalar_add_assign(&mut ct2, scalar);
-        let dec2: u64 = cks.decrypt_radix(&ct2);
-
-        let ct1 = wopbs_key.keyswitch_to_wopbs_params(&sks, &ct1);
-        let ct2 = wopbs_key.keyswitch_to_wopbs_params(&sks, &ct2);
-
-        let lut = wopbs_key.generate_lut_bivariate_radix(&ct1, &ct2, |x, y| x + y * x);
-        let ct_res = wopbs_key.bivariate_wopbs_with_degree(&ct1, &ct2, &lut);
-        let ct_res = wopbs_key.keyswitch_to_pbs_params(&ct_res);
-
-        let res: u64 = cks.decrypt_radix(&ct_res);
-        assert_eq!(res, (dec1 + dec2 * dec1) % msg_space);
-    }
-}
-
-// test wopbs bivariate fake crt with different degree for each Ct
-pub fn wopbs_bivariate_crt(params: (ClassicPBSParameters, WopbsParameters)) {
-    let mut rng = rand::thread_rng();
-
-    let basis = make_basis(params.1.message_modulus.0);
-    let modulus = basis.iter().product::<u64>();
-
-    let (cks, sks) = KEY_CACHE.get_from_params(params.0, IntegerKeyKind::Radix);
-    let wopbs_key = KEY_CACHE_WOPBS.get_from_params(params);
-
-    let mut msg_space: u64 = 1;
-    for modulus in basis.iter() {
-        msg_space *= modulus;
-    }
-
-    for _ in 0..NB_TESTS {
-        let clear1 = rng.gen::<u64>() % msg_space;
-        let clear2 = rng.gen::<u64>() % msg_space;
-        let mut ct1 = cks.encrypt_crt(clear1, basis.clone());
-        let mut ct2 = cks.encrypt_crt(clear2, basis.clone());
-        //artificially modify the degree
-        for (ct_1, ct_2) in ct1.blocks.iter_mut().zip(ct2.blocks.iter_mut()) {
-            // Do not go too far otherwise we explode the RAM for larger parameters
-            ct_1.degree = Degree::new(ct_1.degree.get() * 2);
-            ct_1.degree = Degree::new(ct_2.degree.get() * 2);
-        }
-
-        let ct1 = wopbs_key.keyswitch_to_wopbs_params(&sks, &ct1);
-        let ct2 = wopbs_key.keyswitch_to_wopbs_params(&sks, &ct2);
-        let lut = wopbs_key.generate_lut_bivariate_crt(&ct1, &ct2, |x, y| (x * y) + y);
-        let ct_res = wopbs_key.bivariate_wopbs_with_degree(&ct1, &ct2, &lut);
-        let ct_res = wopbs_key.keyswitch_to_pbs_params(&ct_res);
-
-        let res = cks.decrypt_crt(&ct_res);
-        assert_eq!(res, ((clear1 * clear2) + clear2) % msg_space);
-    }
-}
-
-// Previously failing case from https://github.com/zama-ai/tfhe-rs/issues/1010
-#[test]
-pub fn test_wopbs_non_reg_trivial_0() {
-    use crate::integer::{gen_keys_radix, RadixCiphertext, RadixClientKey, ServerKey};
-
-    fn generate_keys() -> (RadixClientKey, ServerKey, WopbsKey) {
-        let (ck, sk) = gen_keys_radix(V0_11_PARAM_MESSAGE_2_CARRY_2_KS_PBS_GAUSSIAN_2M64, 16);
-        let wopbs_key =
-            WopbsKey::new_wopbs_key(&ck, &sk, &LEGACY_WOPBS_PARAM_MESSAGE_2_CARRY_2_KS_PBS);
-        (ck, sk, wopbs_key)
-    }
-
-    let (ck, sk, wopbs_key) = generate_keys();
-    let ct_max_arg: RadixCiphertext = sk.create_trivial_radix(8u64, 4);
-    let f = |x: u64| -> u64 { 5 + x };
-    let lut = wopbs_key.generate_lut_radix(&ct_max_arg, f);
-    let apply_lut = |encrypted_id: &RadixCiphertext| -> RadixCiphertext {
-        let ct = wopbs_key.keyswitch_to_wopbs_params(&sk, encrypted_id);
-        let ct_res = wopbs_key.wopbs(&ct, &lut);
-        wopbs_key.keyswitch_to_pbs_params(&ct_res)
-    };
-    let lut_at_2 = apply_lut(&sk.create_trivial_radix(2u64, 4)); // succeeds
-    assert_eq!(ck.decrypt::<u64>(&lut_at_2), 7);
-    let lut_at_1 = apply_lut(&sk.create_trivial_radix(1u64, 4)); // succeeds
-    assert_eq!(ck.decrypt::<u64>(&lut_at_1), 6);
-    let lut_at_0 = apply_lut(&sk.create_trivial_radix(0u64, 4)); // used to fail, now fixed
-    assert_eq!(ck.decrypt::<u64>(&lut_at_0), 5);
-}
diff --git a/tfhe/src/shortint/client_key/mod.rs b/tfhe/src/shortint/client_key/mod.rs
index 26d9aca04..cbcdca848 100644
--- a/tfhe/src/shortint/client_key/mod.rs
+++ b/tfhe/src/shortint/client_key/mod.rs
@@ -541,7 +541,7 @@ impl ClientKey {
         self.decrypt_message_and_carry(ct) % ct.message_modulus.0
     }
 
-    pub(crate) fn decrypt_no_decode(&self, ct: &Ciphertext) -> u64 {
+    pub fn decrypt_no_decode(&self, ct: &Ciphertext) -> u64 {
         let lwe_decryption_key = match ct.pbs_order {
             PBSOrder::KeyswitchBootstrap => self.large_lwe_secret_key(),
             PBSOrder::BootstrapKeyswitch => self.small_lwe_secret_key(),
diff --git a/tfhe/src/shortint/engine/mod.rs b/tfhe/src/shortint/engine/mod.rs
index 8986d85bc..a413de63d 100644
--- a/tfhe/src/shortint/engine/mod.rs
+++ b/tfhe/src/shortint/engine/mod.rs
@@ -158,6 +158,63 @@ where
     max_value
 }
 
+pub(crate) fn fill_accumulator_vector<C>(
+    accumulator: &mut GlweCiphertext<C>,
+    server_key: &ServerKey,
+    vector: &[u64],
+) -> u64
+where
+    C: ContainerMut<Element = u64>,
+{
+    assert_eq!(
+        accumulator.polynomial_size(),
+        server_key.bootstrapping_key.polynomial_size()
+    );
+    assert_eq!(
+        accumulator.glwe_size(),
+        server_key.bootstrapping_key.glwe_size()
+    );
+
+    let mut accumulator_view = accumulator.as_mut_view();
+
+    accumulator_view.get_mut_mask().as_mut().fill(0);
+
+    // Modulus of the msg contained in the msg bits and operations buffer
+    let modulus_sup = (server_key.message_modulus.0 * server_key.carry_modulus.0) as usize;
+
+    assert_eq!(vector.len(), modulus_sup);
+
+    // N/(p/2) = size of each block
+    let box_size = server_key.bootstrapping_key.polynomial_size().0 / modulus_sup;
+
+    // Value of the shift we multiply our messages by
+    let delta = (1_u64 << 63) / (server_key.message_modulus.0 * server_key.carry_modulus.0);
+
+    let mut body = accumulator_view.get_mut_body();
+    let accumulator_u64 = body.as_mut();
+
+    // Tracking the max value of the function to define the degree later
+    let mut max_value = 0;
+
+    for (i, &f_eval) in vector.iter().enumerate() {
+        let index = i * box_size;
+        max_value = max_value.max(f_eval);
+        accumulator_u64[index..index + box_size].fill(f_eval * delta);
+    }
+
+    let half_box_size = box_size / 2;
+
+    // Negate the first half_box_size coefficients
+    for a_i in accumulator_u64[0..half_box_size].iter_mut() {
+        *a_i = (*a_i).wrapping_neg();
+    }
+
+    // Rotate the accumulator
+    accumulator_u64.rotate_left(half_box_size);
+
+    max_value
+}
+
 pub(crate) fn fill_accumulator_no_encoding<F, C>(
     accumulator: &mut GlweCiphertext<C>,
     server_key: &ServerKey,
@@ -317,6 +374,17 @@ pub struct ShortintEngine {
 }
 
 impl ShortintEngine {
+    /// Replace the thread_local ShortIntEngine
+    ///
+    /// `new_engine` will replace the already_existing
+    /// `thread_local` engine.
+    /// ```
+    pub fn replace_thread_local(new_engine: Self) {
+        Self::with_thread_local_mut(|local_engine| {
+            let _ = std::mem::replace(local_engine, new_engine);
+        });
+    }
+
     /// Safely gives access to the `thead_local` shortint engine
     /// to call one (or many) of its method.
     #[inline]
diff --git a/tfhe/src/shortint/fpga.rs b/tfhe/src/shortint/fpga.rs
new file mode 100644
index 000000000..a50b284e3
--- /dev/null
+++ b/tfhe/src/shortint/fpga.rs
@@ -0,0 +1,166 @@
+use crate::core_crypto::fpga::lookup_vector::LookupVector;
+use crate::core_crypto::prelude::GlweCiphertext;
+use crate::shortint::ciphertext::Degree;
+use crate::shortint::engine::fill_accumulator_vector;
+use crate::shortint::server_key::LookupTableOwned;
+use crate::shortint::{Ciphertext, PBSOrder, ServerKey};
+
+impl ServerKey {
+    ////////////////////////////////////////////////////////////////////////////
+    // Generators for LookupVector
+
+    pub fn generate_lookup_vector<F>(&self, func: &F) -> LookupVector
+    where
+        F: Fn(u64) -> u64,
+    {
+        let message_modulus = self.message_modulus;
+        let carry_modulus = self.carry_modulus;
+
+        let modulus = message_modulus.0 * carry_modulus.0;
+
+        let mut max_value = 0;
+
+        let vector: Vec<u64> = (0..modulus)
+            .map(|x| {
+                let value = func(x) % modulus;
+                max_value = max_value.max(value);
+                value
+            })
+            .collect();
+
+        LookupVector::new_with_max(&vector, max_value)
+    }
+
+    pub fn generate_lookup_vector_bivariate_with_factor<F>(
+        &self,
+        func: &F,
+        factor: u64,
+    ) -> LookupVector
+    where
+        F: Fn(u64, u64) -> u64,
+    {
+        let message_modulus = self.message_modulus;
+        let carry_modulus = self.carry_modulus;
+
+        let modulus = message_modulus.0 * carry_modulus.0;
+
+        let mut max_value = 0;
+
+        let vector: Vec<u64> = (0..modulus)
+            .map(|val| {
+                let lhs = (val / factor) % message_modulus.0;
+                let rhs = (val % factor) % message_modulus.0;
+                let value = func(lhs, rhs) % modulus;
+                max_value = max_value.max(value);
+                value
+            })
+            .collect();
+
+        LookupVector::new_with_max(&vector, max_value)
+    }
+
+    pub fn generate_lookup_vector_bivariate<F>(&self, func: &F) -> LookupVector
+    where
+        F: Fn(u64, u64) -> u64,
+    {
+        let message_modulus = self.message_modulus;
+
+        self.generate_lookup_vector_bivariate_with_factor(func, message_modulus.0)
+    }
+
+    pub fn generate_lookup_table_from_vector(&self, vector: &[u64]) -> LookupTableOwned {
+        let mut acc = GlweCiphertext::new(
+            0,
+            self.bootstrapping_key.glwe_size(),
+            self.bootstrapping_key.polynomial_size(),
+            self.ciphertext_modulus,
+        );
+        let max_value = fill_accumulator_vector(&mut acc, self, vector);
+
+        LookupTableOwned {
+            acc,
+            degree: Degree::new(max_value),
+        }
+    }
+
+    ////////////////////////////////////////////////////////////////////////////
+    // Conversions between LookupTableOwned and LookupVector
+
+    pub fn convert_lookup_vector_to_lookup_table(
+        &self,
+        lookup_vector: &LookupVector,
+    ) -> LookupTableOwned {
+        let mut acc = GlweCiphertext::new(
+            0,
+            self.bootstrapping_key.glwe_size(),
+            self.bootstrapping_key.polynomial_size(),
+            self.ciphertext_modulus,
+        );
+
+        let message_modulus = self.message_modulus;
+        let carry_modulus = self.carry_modulus;
+        let modulus_sup = message_modulus.0 * carry_modulus.0;
+
+        let vector = lookup_vector.decompress(modulus_sup as usize);
+
+        let max_value = fill_accumulator_vector(&mut acc, self, &vector);
+
+        LookupTableOwned {
+            acc,
+            degree: Degree::new(max_value),
+        }
+    }
+
+    // Packs the message of the left ciphertext into the carry space of the left ciphertext
+    // while copying the message of the right ciphertext to the message space of the left ciphertext
+    // This allows to parrallellize the PBS on hardware
+    pub fn unchecked_apply_lookup_table_bivariate_assign_prep(
+        &self,
+        ct_left: &mut Ciphertext,
+        ct_right: &Ciphertext,
+    ) {
+        let max_modulus = self.message_modulus.0;
+        let modulus = ct_right.degree.get() + 1;
+        assert!(modulus <= max_modulus);
+
+        self.unchecked_scalar_mul_assign(ct_left, max_modulus as u8);
+
+        self.unchecked_add_assign(ct_left, ct_right);
+    }
+
+    ////////////////////////////////////////////////////////////////////////////
+    // Packed Lookup Table Operations,
+    //
+    // Implemented on shortint server_key, executed CPU. These versions are
+    // alternatives to the same functions available over BelfortServerKey
+    // offering hardware acceleration.
+    pub fn apply_lookup_vector_packed_assign(
+        &self,
+        cts: &mut Vec<Ciphertext>,
+        luts: &[LookupVector],
+    ) {
+        match self.pbs_order {
+            PBSOrder::KeyswitchBootstrap => {
+                self.keyswitch_programmable_bootstrap_assign_packed(cts, luts);
+            }
+            PBSOrder::BootstrapKeyswitch => {
+                panic!("Packed BootstrapKeyswitch is not supported")
+            }
+        };
+    }
+
+    pub(crate) fn keyswitch_programmable_bootstrap_assign_packed(
+        &self,
+        cts: &mut Vec<Ciphertext>,
+        luts: &[LookupVector],
+    ) {
+        use rayon::prelude::*;
+
+        cts.par_iter_mut()
+            .zip(luts.par_iter())
+            .for_each(|(ct, lut)| {
+                let l = self.convert_lookup_vector_to_lookup_table(lut);
+                self.keyswitch_programmable_bootstrap_assign(ct, &l);
+            });
+    }
+}
diff --git a/tfhe/src/shortint/mod.rs b/tfhe/src/shortint/mod.rs
index 38e066513..f870f6566 100755
--- a/tfhe/src/shortint/mod.rs
+++ b/tfhe/src/shortint/mod.rs
@@ -51,6 +51,7 @@ pub mod backward_compatibility;
 pub mod ciphertext;
 pub mod client_key;
 pub mod engine;
+pub mod fpga;
 pub mod key_switching_key;
 #[cfg(any(test, doctest, feature = "internal-keycache"))]
 pub mod keycache;
diff --git a/tfhe/src/shortint/server_key/mod.rs b/tfhe/src/shortint/server_key/mod.rs
index 0fc59daeb..b2bde9535 100644
--- a/tfhe/src/shortint/server_key/mod.rs
+++ b/tfhe/src/shortint/server_key/mod.rs
@@ -1201,7 +1201,7 @@ impl ServerKey {
             .set_deterministic_pbs_execution(new_deterministic_execution);
     }
 
-    fn trivial_pbs_assign(&self, ct: &mut Ciphertext, acc: &LookupTableOwned) {
+    pub fn trivial_pbs_assign(&self, ct: &mut Ciphertext, acc: &LookupTableOwned) {
         #[cfg(feature = "pbs-stats")]
         // We want to count trivial PBS in simulator mode
         // In the non trivial case, this increment is done in the `apply_blind_rotate` function
@@ -1334,6 +1334,73 @@ impl ServerKey {
         outputs
     }
 
+    pub(crate) fn keyswitch_programmable_bootstrap_assign(
+        &self,
+        ct: &mut Ciphertext,
+        acc: &LookupTableOwned,
+    ) {
+        if ct.is_trivial() {
+            self.trivial_pbs_assign(ct, acc);
+            return;
+        }
+
+        ShortintEngine::with_thread_local_mut(|engine| {
+            // Compute the programmable bootstrapping with fixed test polynomial
+            let (mut ciphertext_buffers, buffers) = engine.get_buffers(self);
+
+            // Compute a key switch
+            keyswitch_lwe_ciphertext(
+                &self.key_switching_key,
+                &ct.ct,
+                &mut ciphertext_buffers.buffer_lwe_after_ks,
+            );
+
+            match &self.bootstrapping_key {
+                ShortintBootstrappingKey::Classic(fourier_bsk) => {
+                    let fft = Fft::new(fourier_bsk.polynomial_size());
+                    let fft = fft.as_view();
+                    buffers.resize(
+                        programmable_bootstrap_lwe_ciphertext_mem_optimized_requirement::<u64>(
+                            fourier_bsk.glwe_size(),
+                            fourier_bsk.polynomial_size(),
+                            fft,
+                        )
+                        .unwrap()
+                        .unaligned_bytes_required(),
+                    );
+                    let stack = buffers.stack();
+
+                    // Compute a bootstrap
+                    programmable_bootstrap_lwe_ciphertext_mem_optimized(
+                        &ciphertext_buffers.buffer_lwe_after_ks,
+                        &mut ct.ct,
+                        &acc.acc,
+                        fourier_bsk,
+                        fft,
+                        stack,
+                    );
+                }
+                ShortintBootstrappingKey::MultiBit {
+                    fourier_bsk,
+                    thread_count,
+                    deterministic_execution,
+                } => {
+                    multi_bit_programmable_bootstrap_lwe_ciphertext(
+                        &ciphertext_buffers.buffer_lwe_after_ks,
+                        &mut ct.ct,
+                        &acc.acc,
+                        fourier_bsk,
+                        *thread_count,
+                        *deterministic_execution,
+                    );
+                }
+            }
+        });
+
+        ct.degree = acc.degree;
+        ct.set_noise_level(NoiseLevel::NOMINAL, self.max_noise_level);
+    }
+
     pub(crate) fn programmable_bootstrap_keyswitch_many_lut(
         &self,
         ct: &Ciphertext,
diff --git a/tfhe/web_wasm_parallel_tests/worker.js b/tfhe/web_wasm_parallel_tests/worker.js
index 4090e73b2..bc3ff3a56 100644
--- a/tfhe/web_wasm_parallel_tests/worker.js
+++ b/tfhe/web_wasm_parallel_tests/worker.js
@@ -16,6 +16,7 @@ import init, {
   FheUint8,
   ZkComputeLoad,
   CompactPkeCrs,
+  CompactPkePublicParams,
   CompactCiphertextList,
   ProvenCompactCiphertextList,
   ShortintCompactPublicKeyEncryptionParameters,
@@ -390,6 +391,13 @@ async function compactPublicKeyZeroKnowledgeTest() {
     BigInt(1000000000),
   );
 
+  let serialized = public_params.safe_serialize(BigInt(1000000000));
+  console.log("CompactPkePublicParams size:", serialized.length);
+  let deserialized = CompactPkePublicParams.safe_deserialize(
+    serialized,
+    BigInt(1000000000),
+  );
+
   // 320 bits is a use case we have, 8 bits per byte
   const metadata = new Uint8Array(320 / 8);
   crypto.getRandomValues(metadata);
